<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />
<title>dlnd_tv_script_generation-zh</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    color: #000 !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.2.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.2.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.2.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.2.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.2.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.2.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=1);
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2);
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=3);
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1);
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1);
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
@media (max-width: 991px) {
  #ipython_notebook {
    margin-left: 10px;
  }
}
[dir="rtl"] #ipython_notebook {
  float: right !important;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#login_widget {
  float: right;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  text-align: center;
  vertical-align: middle;
  display: inline;
  opacity: 0;
  z-index: 2;
  width: 12ex;
  margin-right: -12ex;
}
.alternate_upload .btn-upload {
  height: 22px;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
[dir="rtl"] #tabs li {
  float: right;
}
ul#tabs {
  margin-bottom: 4px;
}
[dir="rtl"] ul#tabs {
  margin-right: 0px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons {
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-right {
  padding-top: 1px;
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-left {
  float: right !important;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: baseline;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
#tree-selector {
  padding-right: 0px;
}
[dir="rtl"] #tree-selector a {
  float: right;
}
#button-select-all {
  min-width: 50px;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
[dir="rtl"] #new-menu {
  text-align: right;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
[dir="rtl"] #running .col-sm-8 {
  float: right !important;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI colors. */
.ansibold {
  font-weight: bold;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  border-left-width: 1px;
  padding-left: 5px;
  background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%);
}
div.cell.jupyter-soft-selected {
  border-left-color: #90CAF9;
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected {
  border-color: #ababab;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%);
}
@media print {
  div.cell.selected {
    border-color: transparent;
  }
}
div.cell.selected.jupyter-soft-selected {
  border-left-width: 0;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%);
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%);
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  padding: 0.4em;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */
  /* .CodeMirror-lines */
  padding: 0;
  border: 0;
  border-radius: 0;
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul {
  list-style: disc;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ul ul {
  list-style: square;
  margin: 0em 2em;
}
.rendered_html ul ul ul {
  list-style: circle;
  margin: 0em 2em;
}
.rendered_html ol {
  list-style: decimal;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
  margin: 0em 2em;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  background-color: #fff;
  color: #000;
  font-size: 100%;
  padding: 0px;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: 1px solid black;
  border-collapse: collapse;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  border: 1px solid black;
  border-collapse: collapse;
  margin: 1em 2em;
}
.rendered_html td,
.rendered_html th {
  text-align: left;
  vertical-align: middle;
  padding: 4px;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget {
  float: right !important;
  float: right;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  margin-top: 6px;
}
span.save_widget span.filename {
  height: 1em;
  line-height: 1em;
  padding: 3px;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  display: none;
}
.command-shortcut:before {
  content: "(command)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>
<style type="text/css">
    
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="&#29983;&#25104;&#30005;&#35270;&#21095;&#21095;&#26412;">&#29983;&#25104;&#30005;&#35270;&#21095;&#21095;&#26412;<a class="anchor-link" href="#&#29983;&#25104;&#30005;&#35270;&#21095;&#21095;&#26412;">&#182;</a></h1><p>在这个项目中，你将使用 RNN 创作你自己的<a href="https://zh.wikipedia.org/wiki/%E8%BE%9B%E6%99%AE%E6%A3%AE%E4%B8%80%E5%AE%B6">《辛普森一家》</a>电视剧剧本。你将会用到《辛普森一家》第 27 季中部分剧本的<a href="https://www.kaggle.com/wcukierski/the-simpsons-by-the-data">数据集</a>。你创建的神经网络将为一个在 <a href="https://simpsonswiki.com/wiki/Moe&#39;s_Tavern">Moe 酒馆</a>中的场景生成一集新的剧本。</p>
<h2 id="&#33719;&#21462;&#25968;&#25454;">&#33719;&#21462;&#25968;&#25454;<a class="anchor-link" href="#&#33719;&#21462;&#25968;&#25454;">&#182;</a></h2><p>我们早已为你提供了数据。你将使用原始数据集的子集，它只包括 Moe 酒馆中的场景。数据中并不包括酒馆的其他版本，比如 “Moe 的山洞”、“燃烧的 Moe 酒馆”、“Moe 叔叔的家庭大餐”等等。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">helper</span>

<span class="n">data_dir</span> <span class="o">=</span> <span class="s1">&#39;./data/simpsons/moes_tavern_lines.txt&#39;</span>
<span class="n">text</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">data_dir</span><span class="p">)</span>
<span class="c1"># Ignore notice, since we don&#39;t use it for analysing the data</span>
<span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="p">[</span><span class="mi">81</span><span class="p">:]</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="&#25506;&#32034;&#25968;&#25454;">&#25506;&#32034;&#25968;&#25454;<a class="anchor-link" href="#&#25506;&#32034;&#25968;&#25454;">&#182;</a></h2><p>使用 <code>view_sentence_range</code> 来查看数据的不同部分。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">view_sentence_range</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Dataset Stats&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Roughly the number of unique words: {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">({</span><span class="n">word</span><span class="p">:</span> <span class="bp">None</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">()})))</span>
<span class="n">scenes</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Number of scenes: {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">scenes</span><span class="p">)))</span>
<span class="n">sentence_count_scene</span> <span class="o">=</span> <span class="p">[</span><span class="n">scene</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">scene</span> <span class="ow">in</span> <span class="n">scenes</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Average number of sentences in each scene: {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">sentence_count_scene</span><span class="p">)))</span>

<span class="n">sentences</span> <span class="o">=</span> <span class="p">[</span><span class="n">sentence</span> <span class="k">for</span> <span class="n">scene</span> <span class="ow">in</span> <span class="n">scenes</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">scene</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)]</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Number of lines: {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">)))</span>
<span class="n">word_count_sentence</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Average number of words in each line: {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">word_count_sentence</span><span class="p">)))</span>

<span class="k">print</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;The sentences {} to {}:&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">view_sentence_range</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)[</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]]))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Dataset Stats
Roughly the number of unique words: 11492
Number of scenes: 262
Average number of sentences in each scene: 15.2519083969
Number of lines: 4258
Average number of words in each line: 11.5016439643
()
The sentences 0 to 10:

Moe_Szyslak: (INTO PHONE) Moe&#39;s Tavern. Where the elite meet to drink.
Bart_Simpson: Eh, yeah, hello, is Mike there? Last name, Rotch.
Moe_Szyslak: (INTO PHONE) Hold on, I&#39;ll check. (TO BARFLIES) Mike Rotch. Mike Rotch. Hey, has anybody seen Mike Rotch, lately?
Moe_Szyslak: (INTO PHONE) Listen you little puke. One of these days I&#39;m gonna catch you, and I&#39;m gonna carve my name on your back with an ice pick.
Moe_Szyslak: What&#39;s the matter Homer? You&#39;re not your normal effervescent self.
Homer_Simpson: I got my problems, Moe. Give me another one.
Moe_Szyslak: Homer, hey, you should not drink to forget your problems.
Barney_Gumble: Yeah, you should only drink to enhance your social skills.

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="&#23454;&#29616;&#39044;&#22788;&#29702;&#20989;&#25968;">&#23454;&#29616;&#39044;&#22788;&#29702;&#20989;&#25968;<a class="anchor-link" href="#&#23454;&#29616;&#39044;&#22788;&#29702;&#20989;&#25968;">&#182;</a></h2><p>对数据集进行的第一个操作是预处理。请实现下面两个预处理函数：</p>
<ul>
<li>查询表</li>
<li>标记符号的字符串</li>
</ul>
<h3 id="&#26597;&#35810;&#34920;">&#26597;&#35810;&#34920;<a class="anchor-link" href="#&#26597;&#35810;&#34920;">&#182;</a></h3><p>要创建词嵌入，你首先要将词语转换为 id。请在这个函数中创建两个字典：</p>
<ul>
<li>将词语转换为 id 的字典，我们称它为 <code>vocab_to_int</code></li>
<li>将 id 转换为词语的字典，我们称它为 <code>int_to_vocab</code></li>
</ul>
<p>请在下面的元组中返回这些字典
 <code>(vocab_to_int, int_to_vocab)</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="kn">as</span> <span class="nn">tests</span>

<span class="k">def</span> <span class="nf">create_lookup_tables</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create lookup tables for vocabulary</span>
<span class="sd">    :param text: The text of tv scripts split into words</span>
<span class="sd">    :return: A tuple of dicts (vocab_to_int, int_to_vocab)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">vocab</span><span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="n">vocab_to_int</span> <span class="o">=</span> <span class="p">{</span><span class="n">c</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">vocab</span><span class="p">)}</span>
    <span class="n">int_to_vocab</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">vocab</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">vocab_to_int</span><span class="p">,</span> <span class="n">int_to_vocab</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_create_lookup_tables</span><span class="p">(</span><span class="n">create_lookup_tables</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="&#26631;&#35760;&#31526;&#21495;&#30340;&#23383;&#31526;&#20018;">&#26631;&#35760;&#31526;&#21495;&#30340;&#23383;&#31526;&#20018;<a class="anchor-link" href="#&#26631;&#35760;&#31526;&#21495;&#30340;&#23383;&#31526;&#20018;">&#182;</a></h3><p>我们会使用空格当作分隔符，来将剧本分割为词语数组。然而，句号和感叹号等符号使得神经网络难以分辨“再见”和“再见！”之间的区别。</p>
<p>实现函数 <code>token_lookup</code> 来返回一个字典，这个字典用于将 “!” 等符号标记为 “||Exclamation_Mark||” 形式。为下列符号创建一个字典，其中符号为标志，值为标记。</p>
<ul>
<li>period ( . )</li>
<li>comma ( , )</li>
<li>quotation mark ( " )</li>
<li>semicolon ( ; )</li>
<li>exclamation mark ( ! )</li>
<li>question mark ( ? )</li>
<li>left parenthesis ( ( )</li>
<li>right parenthesis ( ) )</li>
<li>dash ( -- )</li>
<li>return ( \n )</li>
</ul>
<p>这个字典将用于标记符号并在其周围添加分隔符（空格）。这能将符号视作单独词汇分割开来，并使神经网络更轻松地预测下一个词汇。请确保你并没有使用容易与词汇混淆的标记。与其使用 “dash” 这样的标记，试试使用“||dash||”。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">def</span> <span class="nf">token_lookup</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generate a dict to turn punctuation into a token.</span>
<span class="sd">    :return: Tokenize dictionary where the key is the punctuation and the value is the token</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">punctuation</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;.&#39;</span><span class="p">:</span><span class="s1">&#39;||period||&#39;</span><span class="p">,</span><span class="s1">&#39;,&#39;</span><span class="p">:</span><span class="s1">&#39;||comma||&#39;</span><span class="p">,</span><span class="s1">&#39;&quot;&#39;</span><span class="p">:</span><span class="s1">&#39;||quotation_mark||&#39;</span><span class="p">,</span>
                  <span class="s1">&#39;;&#39;</span><span class="p">:</span><span class="s1">&#39;||semicolon||&#39;</span><span class="p">,</span><span class="s1">&#39;!&#39;</span><span class="p">:</span><span class="s1">&#39;||exclamation_mark||&#39;</span><span class="p">,</span><span class="s1">&#39;?&#39;</span><span class="p">:</span><span class="s1">&#39;||question_mark||&#39;</span><span class="p">,</span>
                  <span class="s1">&#39;(&#39;</span><span class="p">:</span><span class="s1">&#39;||left_parenthesis||&#39;</span><span class="p">,</span><span class="s1">&#39;)&#39;</span><span class="p">:</span><span class="s1">&#39;||right_parenthesis||&#39;</span><span class="p">,</span><span class="s1">&#39;--&#39;</span><span class="p">:</span><span class="s1">&#39;||dash||&#39;</span><span class="p">,</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">:</span><span class="s1">&#39;||return||&#39;</span><span class="p">}</span>
    <span class="k">return</span> <span class="n">punctuation</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_tokenize</span><span class="p">(</span><span class="n">token_lookup</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="&#39044;&#22788;&#29702;&#24182;&#20445;&#23384;&#25152;&#26377;&#25968;&#25454;">&#39044;&#22788;&#29702;&#24182;&#20445;&#23384;&#25152;&#26377;&#25968;&#25454;<a class="anchor-link" href="#&#39044;&#22788;&#29702;&#24182;&#20445;&#23384;&#25152;&#26377;&#25968;&#25454;">&#182;</a></h2><p>运行以下代码将预处理所有数据，并将它们保存至文件。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="c1"># Preprocess Training, Validation, and Testing Data</span>
<span class="n">helper</span><span class="o">.</span><span class="n">preprocess_and_save_data</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">token_lookup</span><span class="p">,</span> <span class="n">create_lookup_tables</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="&#26816;&#26597;&#28857;">&#26816;&#26597;&#28857;<a class="anchor-link" href="#&#26816;&#26597;&#28857;">&#182;</a></h1><p>这是你遇到的第一个检点。如果你想要回到这个 notebook，或需要重新打开 notebook，你都可以从这里开始。预处理的数据都已经保存完毕。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="kn">as</span> <span class="nn">tests</span>

<span class="n">int_text</span><span class="p">,</span> <span class="n">vocab_to_int</span><span class="p">,</span> <span class="n">int_to_vocab</span><span class="p">,</span> <span class="n">token_dict</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1">#单独增加的内容</span>
<span class="n">vocab</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="n">vocab_to_int1</span> <span class="o">=</span> <span class="p">{</span><span class="n">c</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">vocab</span><span class="p">)}</span>
<span class="n">int_to_vocab1</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">vocab</span><span class="p">))</span>
<span class="n">encoded</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">vocab_to_int1</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">text</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="&#21019;&#24314;&#31070;&#32463;&#32593;&#32476;">&#21019;&#24314;&#31070;&#32463;&#32593;&#32476;<a class="anchor-link" href="#&#21019;&#24314;&#31070;&#32463;&#32593;&#32476;">&#182;</a></h2><p>你将通过实现下面的函数，来创造用于构建 RNN 的必要元素：</p>
<ul>
<li>get_inputs</li>
<li>get_init_cell</li>
<li>get_embed</li>
<li>build_rnn</li>
<li>build_nn</li>
<li>get_batches</li>
</ul>
<h3 id="&#26816;&#26597;-TensorFlow-&#29256;&#26412;&#24182;&#35775;&#38382;-GPU">&#26816;&#26597; TensorFlow &#29256;&#26412;&#24182;&#35775;&#38382; GPU<a class="anchor-link" href="#&#26816;&#26597;-TensorFlow-&#29256;&#26412;&#24182;&#35775;&#38382;-GPU">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">distutils.version</span> <span class="kn">import</span> <span class="n">LooseVersion</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>

<span class="c1"># Check TensorFlow Version</span>
<span class="k">assert</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="s1">&#39;1.0&#39;</span><span class="p">),</span> <span class="s1">&#39;Please use TensorFlow version 1.0 or newer&#39;</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;TensorFlow Version: {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">))</span>

<span class="c1"># Check for a GPU</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">gpu_device_name</span><span class="p">():</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;No GPU found. Please use a GPU to train your neural network.&#39;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Default GPU Device: {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">gpu_device_name</span><span class="p">()))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>TensorFlow Version: 1.0.1
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/wangli/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:14: UserWarning: No GPU found. Please use a GPU to train your neural network.
  
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="&#36755;&#20837;">&#36755;&#20837;<a class="anchor-link" href="#&#36755;&#20837;">&#182;</a></h3><p>实现函数 <code>get_inputs()</code> 来为神经网络创建 TF 占位符。它将创建下列占位符：</p>
<ul>
<li>使用 <a href="https://www.tensorflow.org/api_docs/python/tf/placeholder">TF 占位符</a> <code>name</code> 参量输入 "input" 文本占位符。</li>
<li>Targets 占位符</li>
<li>Learning Rate 占位符</li>
</ul>
<p>返回下列元组中的占位符 <code>(Input, Targets, LearningRate)</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">def</span> <span class="nf">get_inputs</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create TF Placeholders for input, targets, and learning rate.</span>
<span class="sd">    :return: Tuple (input, targets, learning rate)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">Input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,[</span><span class="bp">None</span><span class="p">,</span><span class="bp">None</span><span class="p">],</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;input&#39;</span><span class="p">)</span><span class="c1"># pay attention shape</span>
    <span class="n">Targets</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,[</span><span class="bp">None</span><span class="p">,</span><span class="bp">None</span><span class="p">],</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;targets&#39;</span><span class="p">)</span><span class="c1">#pay attention shape</span>
    <span class="n">LearningRate</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;learningrate&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Input</span><span class="p">,</span><span class="n">Targets</span><span class="p">,</span><span class="n">LearningRate</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_get_inputs</span><span class="p">(</span><span class="n">get_inputs</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="&#21019;&#24314;-RNN-Cell-&#24182;&#21021;&#22987;&#21270;">&#21019;&#24314; RNN Cell &#24182;&#21021;&#22987;&#21270;<a class="anchor-link" href="#&#21019;&#24314;-RNN-Cell-&#24182;&#21021;&#22987;&#21270;">&#182;</a></h3><p>在 <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/MultiRNNCell"><code>MultiRNNCell</code></a> 中堆叠一个或多个 <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicLSTMCell"><code>BasicLSTMCells</code></a></p>
<ul>
<li>使用 <code>rnn_size</code> 设定 RNN 大小。</li>
<li>使用 MultiRNNCell 的 <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/MultiRNNCell#zero_state"><code>zero_state()</code></a> 函数初始化 Cell 状态</li>
<li>使用 <a href="https://www.tensorflow.org/api_docs/python/tf/identity"><code>tf.identity()</code></a> 为初始状态应用名称 "initial_state"</li>
</ul>
<p>返回 cell 和下列元组中的初始状态 <code>(Cell, InitialState)</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">def</span> <span class="nf">get_init_cell</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">rnn_size</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create an RNN Cell and initialize it.</span>
<span class="sd">    :param batch_size: Size of batches</span>
<span class="sd">    :param rnn_size: Size of RNNs</span>
<span class="sd">    :return: Tuple (cell, initialize state)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">lstm</span><span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">BasicLSTMCell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">)</span>
    <span class="n">cell</span><span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">MultiRNNCell</span><span class="p">([</span><span class="n">lstm</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">)])</span>
    <span class="n">initialize_state</span> <span class="o">=</span> <span class="n">cell</span><span class="o">.</span><span class="n">zero_state</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">initial_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">initialize_state</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;initial_state&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">initial_state</span><span class="p">)</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_get_init_cell</span><span class="p">(</span><span class="n">get_init_cell</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="&#35789;&#23884;&#20837;">&#35789;&#23884;&#20837;<a class="anchor-link" href="#&#35789;&#23884;&#20837;">&#182;</a></h3><p>使用 TensorFlow 将嵌入运用到 <code>input_data</code> 中。
返回嵌入序列。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">def</span> <span class="nf">get_embed</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create embedding for &lt;input_data&gt;.</span>
<span class="sd">    :param input_data: TF placeholder for text input.</span>
<span class="sd">    :param vocab_size: Number of words in vocabulary.</span>
<span class="sd">    :param embed_dim: Number of embedding dimensions</span>
<span class="sd">    :return: Embedded input.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">embedding</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">((</span><span class="n">vocab_size</span><span class="p">,</span><span class="n">embed_dim</span><span class="p">),</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">embed_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">embedding_lookup</span><span class="p">(</span><span class="n">embedding</span><span class="p">,</span><span class="n">input_data</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">embed_input</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_get_embed</span><span class="p">(</span><span class="n">get_embed</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="&#21019;&#24314;-RNN">&#21019;&#24314; RNN<a class="anchor-link" href="#&#21019;&#24314;-RNN">&#182;</a></h3><p>你已经在 <code>get_init_cell()</code> 函数中创建了 RNN Cell。是时候使用这个 Cell 来创建 RNN了。</p>
<ul>
<li>使用 <a href="https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn"><code>tf.nn.dynamic_rnn()</code></a> 创建 RNN</li>
<li>使用 <a href="https://www.tensorflow.org/api_docs/python/tf/identity"><code>tf.identity()</code></a> 将名称 "final_state" 应用到最终状态中</li>
</ul>
<p>返回下列元组中的输出和最终状态<code>(Outputs, FinalState)</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">def</span> <span class="nf">build_rnn</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a RNN using a RNN Cell</span>
<span class="sd">    :param cell: RNN Cell</span>
<span class="sd">    :param inputs: Input text data</span>
<span class="sd">    :return: Tuple (Outputs, Final State)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    
    <span class="n">outputs</span><span class="p">,</span><span class="n">final_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dynamic_rnn</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">final_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">final_state</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;final_state&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">final_state</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_build_rnn</span><span class="p">(</span><span class="n">build_rnn</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="&#26500;&#24314;&#31070;&#32463;&#32593;&#32476;">&#26500;&#24314;&#31070;&#32463;&#32593;&#32476;<a class="anchor-link" href="#&#26500;&#24314;&#31070;&#32463;&#32593;&#32476;">&#182;</a></h3><p>应用你在上面实现的函数，来：</p>
<ul>
<li>使用你的 <code>get_embed(input_data, vocab_size, embed_dim)</code> 函数将嵌入应用到 <code>input_data</code> 中</li>
<li>使用 <code>cell</code> 和你的 <code>build_rnn(cell, inputs)</code> 函数来创建 RNN</li>
<li>应用一个完全联通线性激活和 <code>vocab_size</code> 的分层作为输出数量。</li>
</ul>
<p>返回下列元组中的 logit 和最终状态 <code>Logits, FinalState</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">def</span> <span class="nf">build_nn</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">rnn_size</span><span class="p">,</span> <span class="n">input_data</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Build part of the neural network</span>
<span class="sd">    :param cell: RNN cell</span>
<span class="sd">    :param rnn_size: Size of rnns</span>
<span class="sd">    :param input_data: Input data</span>
<span class="sd">    :param vocab_size: Vocabulary size</span>
<span class="sd">    :param embed_dim: Number of embedding dimensions</span>
<span class="sd">    :return: Tuple (Logits, FinalState)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">embeded_input</span> <span class="o">=</span> <span class="n">get_embed</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span><span class="n">vocab_size</span><span class="p">,</span><span class="n">embed_dim</span><span class="p">)</span>
    <span class="n">outputs</span><span class="p">,</span><span class="n">final_state</span> <span class="o">=</span> <span class="n">build_rnn</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span><span class="n">embeded_input</span><span class="p">)</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">fully_connected</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span><span class="n">vocab_size</span><span class="p">,</span><span class="n">activation_fn</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">logits</span><span class="p">,</span><span class="n">final_state</span>



<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_build_nn</span><span class="p">(</span><span class="n">build_nn</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="&#25209;&#27425;">&#25209;&#27425;<a class="anchor-link" href="#&#25209;&#27425;">&#182;</a></h3><p>实现 <code>get_batches</code> 来使用 <code>int_text</code> 创建输入与目标批次。这些批次应为 Numpy 数组，并具有形状 <code>(number of batches, 2, batch size, sequence length)</code>。每个批次包含两个元素：</p>
<ul>
<li>第一个元素为<strong>输入</strong>的单独批次，并具有形状 <code>[batch size, sequence length]</code></li>
<li>第二个元素为<strong>目标</strong>的单独批次，并具有形状 <code>[batch size, sequence length]</code></li>
</ul>
<p>如果你无法在最后一个批次中填入足够数据，请放弃这个批次。</p>
<p>例如 <code>get_batches([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], 2, 3)</code> 将返回下面这个 Numpy 数组：</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[23]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">[</span>
<span class="sd">  # First Batch</span>
<span class="sd">  [</span>
<span class="sd">    # Batch of Input</span>
<span class="sd">    [[ 1  2  3], [ 7  8  9]],</span>
<span class="sd">    # Batch of targets</span>
<span class="sd">    [[ 2  3  4], [ 8  9 10]]</span>
<span class="sd">  ],</span>
<span class="sd"> </span>
<span class="sd">  # Second Batch</span>
<span class="sd">  [</span>
<span class="sd">    # Batch of Input</span>
<span class="sd">    [[ 4  5  6], [10 11 12]],</span>
<span class="sd">    # Batch of targets</span>
<span class="sd">    [[ 5  6  7], [11 12 13]]</span>
<span class="sd">  ]</span>
<span class="sd">]</span>
<span class="sd">&quot;&quot;&quot;</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[23]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;\n[\n  # First Batch\n  [\n    # Batch of Input\n    [[ 1  2  3], [ 7  8  9]],\n    # Batch of targets\n    [[ 2  3  4], [ 8  9 10]]\n  ],\n \n  # Second Batch\n  [\n    # Batch of Input\n    [[ 4  5  6], [10 11 12]],\n    # Batch of targets\n    [[ 5  6  7], [11 12 13]]\n  ]\n]\n&#39;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[21]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">def</span> <span class="nf">get_batches</span><span class="p">(</span><span class="n">int_text</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">seq_length</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return batches of input and target</span>
<span class="sd">    :param int_text: Text with the words replaced by their ids</span>
<span class="sd">    :param batch_size: The size of batch</span>
<span class="sd">    :param seq_length: The length of sequence</span>
<span class="sd">    :return: Batches as a Numpy array</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="c1">#int_text_per_batch = batch_size * seq_length</span>
    <span class="c1">#n_batches = len(int_text)//int_text_per_batch</span>
    <span class="c1">#int_text = np.array(int_text[:(n_batches * int_text_per_batch)])</span>
    <span class="c1">#targets = np.array(int_text[:(n_batches * int_text_per_batch)])</span>
    
    <span class="c1">#arr_input = int_text.reshape(batch_size,1) </span>
    <span class="c1">#arr_target = targets.reshape(batch_size,1)</span>
    
    <span class="c1">#input_batches = np.asarray(np.split(arr_input,n_batches,1))</span>
    <span class="c1">#target_batches = np.asarray(np.split(arr_target,n_batches,1))</span>
    <span class="c1">#batches = np.array(list(zip(input_batches,target_batches)))</span>
    <span class="c1">#batches = batches.reshape(n_batches,2,batch_size,seq_length)</span>
    
    <span class="n">int_text_per_batch</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">seq_length</span>
    <span class="n">n_batches</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">int_text</span><span class="p">)</span><span class="o">//</span><span class="n">int_text_per_batch</span>

    <span class="n">targets</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">int_text</span><span class="p">[</span><span class="mi">1</span><span class="p">:(</span><span class="n">n_batches</span> <span class="o">*</span> <span class="n">int_text_per_batch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)])</span>  <span class="c1"># 有改动</span>
    <span class="n">int_text</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">int_text</span><span class="p">[:(</span><span class="n">n_batches</span> <span class="o">*</span> <span class="n">int_text_per_batch</span><span class="p">)])</span>  

    <span class="n">arr_input</span> <span class="o">=</span> <span class="n">int_text</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> 
    <span class="n">arr_target</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">input_batches</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">arr_input</span><span class="p">,</span><span class="n">n_batches</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">target_batches</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">arr_target</span><span class="p">,</span><span class="n">n_batches</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">batches</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">input_batches</span><span class="p">,</span><span class="n">target_batches</span><span class="p">)))</span>
    <span class="n">batches</span> <span class="o">=</span> <span class="n">batches</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n_batches</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">batch_size</span><span class="p">,</span><span class="n">seq_length</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">batches</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_get_batches</span><span class="p">(</span><span class="n">get_batches</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;">&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;<a class="anchor-link" href="#&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;">&#182;</a></h2><h3 id="&#36229;&#21442;&#25968;">&#36229;&#21442;&#25968;<a class="anchor-link" href="#&#36229;&#21442;&#25968;">&#182;</a></h3><p>调整下列参数:</p>
<ul>
<li>将 <code>num_epochs</code> 设置为训练次数。</li>
<li>将 <code>batch_size</code> 设置为程序组大小。</li>
<li>将 <code>rnn_size</code> 设置为 RNN 大小。</li>
<li>将 <code>embed_dim</code> 设置为嵌入大小。</li>
<li>将 <code>seq_length</code> 设置为序列长度。</li>
<li>将 <code>learning_rate</code> 设置为学习率。</li>
<li>将 <code>show_every_n_batches</code> 设置为神经网络应输出的程序组数量。</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[22]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># Number of Epochs</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">300</span>
<span class="c1"># Batch Size</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="c1"># RNN Size</span>
<span class="n">rnn_size</span> <span class="o">=</span> <span class="mi">256</span>
<span class="c1"># Embedding Dimension Size</span>
<span class="n">embed_dim</span> <span class="o">=</span> <span class="mi">100</span>
<span class="c1"># Sequence Length</span>
<span class="n">seq_length</span> <span class="o">=</span> <span class="mi">12</span>
<span class="c1"># Learning Rate</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="c1"># Show stats for every n number of batches</span>
<span class="n">show_every_n_batches</span> <span class="o">=</span> <span class="mi">1</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">save_dir</span> <span class="o">=</span> <span class="s1">&#39;./save&#39;</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="&#21019;&#24314;&#22270;&#34920;">&#21019;&#24314;&#22270;&#34920;<a class="anchor-link" href="#&#21019;&#24314;&#22270;&#34920;">&#182;</a></h3><p>使用你实现的神经网络创建图表。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[24]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">tensorflow.contrib</span> <span class="kn">import</span> <span class="n">seq2seq</span>

<span class="n">train_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="k">with</span> <span class="n">train_graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
    <span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">int_to_vocab</span><span class="p">)</span>
    <span class="n">input_text</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">lr</span> <span class="o">=</span> <span class="n">get_inputs</span><span class="p">()</span>
    <span class="n">input_data_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">input_text</span><span class="p">)</span>
    <span class="n">cell</span><span class="p">,</span> <span class="n">initial_state</span> <span class="o">=</span> <span class="n">get_init_cell</span><span class="p">(</span><span class="n">input_data_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">rnn_size</span><span class="p">)</span>
    <span class="n">logits</span><span class="p">,</span> <span class="n">final_state</span> <span class="o">=</span> <span class="n">build_nn</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span> <span class="n">rnn_size</span><span class="p">,</span> <span class="n">input_text</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">)</span>

    <span class="c1"># Probabilities for generating words</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;probs&#39;</span><span class="p">)</span>

    <span class="c1"># Loss function</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="n">seq2seq</span><span class="o">.</span><span class="n">sequence_loss</span><span class="p">(</span>
        <span class="n">logits</span><span class="p">,</span>
        <span class="n">targets</span><span class="p">,</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">input_data_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">input_data_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]]))</span>

    <span class="c1"># Optimizer</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span>

    <span class="c1"># Gradient Clipping</span>
    <span class="n">gradients</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">compute_gradients</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
    <span class="n">capped_gradients</span> <span class="o">=</span> <span class="p">[(</span><span class="n">tf</span><span class="o">.</span><span class="n">clip_by_value</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">),</span> <span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">grad</span><span class="p">,</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">gradients</span> <span class="k">if</span> <span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">]</span>
    <span class="n">train_op</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="n">capped_gradients</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="&#35757;&#32451;">&#35757;&#32451;<a class="anchor-link" href="#&#35757;&#32451;">&#182;</a></h2><p>在预处理数据中训练神经网络。如果你遇到困难，请查看这个<a href="https://discussions.udacity.com/">表格</a>，看看是否有人遇到了和你一样的问题。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[25]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">batches</span> <span class="o">=</span> <span class="n">get_batches</span><span class="p">(</span><span class="n">int_text</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">seq_length</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">batches</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">train_graph</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>

    <span class="k">for</span> <span class="n">epoch_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">initial_state</span><span class="p">,</span> <span class="p">{</span><span class="n">input_text</span><span class="p">:</span> <span class="n">batches</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]})</span>
        <span class="k">for</span> <span class="n">batch_i</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">batches</span><span class="p">):</span>
            <span class="n">feed</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">input_text</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span>
                <span class="n">targets</span><span class="p">:</span> <span class="n">y</span><span class="p">,</span>
                <span class="n">initial_state</span><span class="p">:</span> <span class="n">state</span><span class="p">,</span>
                <span class="n">lr</span><span class="p">:</span> <span class="n">learning_rate</span><span class="p">}</span>
            <span class="n">train_loss</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">cost</span><span class="p">,</span> <span class="n">final_state</span><span class="p">,</span> <span class="n">train_op</span><span class="p">],</span> <span class="n">feed</span><span class="p">)</span>

            <span class="c1"># Show every &lt;show_every_n_batches&gt; batches</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">epoch_i</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">batches</span><span class="p">)</span> <span class="o">+</span> <span class="n">batch_i</span><span class="p">)</span> <span class="o">%</span> <span class="n">show_every_n_batches</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Epoch {:&gt;3} Batch {:&gt;4}/{}   train_loss = {:.3f}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">epoch_i</span><span class="p">,</span>
                    <span class="n">batch_i</span><span class="p">,</span>
                    <span class="nb">len</span><span class="p">(</span><span class="n">batches</span><span class="p">),</span>
                    <span class="n">train_loss</span><span class="p">))</span>

    <span class="c1"># Save Model</span>
    <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>
    <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">save_dir</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Model Trained and Saved&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[[1451 4644 3469 ...  687 2030 1483]
 [  55 2640 5262 ...  154 6245 2772]
 [ 894 6502 5057 ... 4077 2640 5410]
 ...
 [4292 1451  154 ... 2589 5683 3469]
 [4292 1451  722 ... 3265 6078 3989]
 [  44 4292 1451 ... 5683 3469 6044]]
Epoch   0 Batch    0/44   train_loss = 8.825
Epoch   0 Batch    1/44   train_loss = 8.767
Epoch   0 Batch    2/44   train_loss = 8.668
Epoch   0 Batch    3/44   train_loss = 8.521
Epoch   0 Batch    4/44   train_loss = 8.335
Epoch   0 Batch    5/44   train_loss = 8.091
Epoch   0 Batch    6/44   train_loss = 7.826
Epoch   0 Batch    7/44   train_loss = 7.625
Epoch   0 Batch    8/44   train_loss = 7.302
Epoch   0 Batch    9/44   train_loss = 7.033
Epoch   0 Batch   10/44   train_loss = 6.862
Epoch   0 Batch   11/44   train_loss = 6.681
Epoch   0 Batch   12/44   train_loss = 6.449
Epoch   0 Batch   13/44   train_loss = 6.410
Epoch   0 Batch   14/44   train_loss = 6.343
Epoch   0 Batch   15/44   train_loss = 6.160
Epoch   0 Batch   16/44   train_loss = 6.178
Epoch   0 Batch   17/44   train_loss = 6.174
Epoch   0 Batch   18/44   train_loss = 6.107
Epoch   0 Batch   19/44   train_loss = 6.259
Epoch   0 Batch   20/44   train_loss = 6.092
Epoch   0 Batch   21/44   train_loss = 6.214
Epoch   0 Batch   22/44   train_loss = 6.119
Epoch   0 Batch   23/44   train_loss = 6.323
Epoch   0 Batch   24/44   train_loss = 6.232
Epoch   0 Batch   25/44   train_loss = 6.310
Epoch   0 Batch   26/44   train_loss = 6.273
Epoch   0 Batch   27/44   train_loss = 6.240
Epoch   0 Batch   28/44   train_loss = 6.278
Epoch   0 Batch   29/44   train_loss = 6.428
Epoch   0 Batch   30/44   train_loss = 6.365
Epoch   0 Batch   31/44   train_loss = 6.301
Epoch   0 Batch   32/44   train_loss = 6.106
Epoch   0 Batch   33/44   train_loss = 6.322
Epoch   0 Batch   34/44   train_loss = 6.294
Epoch   0 Batch   35/44   train_loss = 6.077
Epoch   0 Batch   36/44   train_loss = 6.205
Epoch   0 Batch   37/44   train_loss = 6.247
Epoch   0 Batch   38/44   train_loss = 6.191
Epoch   0 Batch   39/44   train_loss = 6.332
Epoch   0 Batch   40/44   train_loss = 6.256
Epoch   0 Batch   41/44   train_loss = 6.172
Epoch   0 Batch   42/44   train_loss = 6.232
Epoch   0 Batch   43/44   train_loss = 6.364
Epoch   1 Batch    0/44   train_loss = 6.034
Epoch   1 Batch    1/44   train_loss = 6.112
Epoch   1 Batch    2/44   train_loss = 5.940
Epoch   1 Batch    3/44   train_loss = 5.986
Epoch   1 Batch    4/44   train_loss = 5.997
Epoch   1 Batch    5/44   train_loss = 5.999
Epoch   1 Batch    6/44   train_loss = 5.964
Epoch   1 Batch    7/44   train_loss = 6.130
Epoch   1 Batch    8/44   train_loss = 6.001
Epoch   1 Batch    9/44   train_loss = 5.973
Epoch   1 Batch   10/44   train_loss = 6.039
Epoch   1 Batch   11/44   train_loss = 6.005
Epoch   1 Batch   12/44   train_loss = 5.875
Epoch   1 Batch   13/44   train_loss = 5.993
Epoch   1 Batch   14/44   train_loss = 6.061
Epoch   1 Batch   15/44   train_loss = 5.905
Epoch   1 Batch   16/44   train_loss = 5.966
Epoch   1 Batch   17/44   train_loss = 6.013
Epoch   1 Batch   18/44   train_loss = 5.975
Epoch   1 Batch   19/44   train_loss = 6.105
Epoch   1 Batch   20/44   train_loss = 5.930
Epoch   1 Batch   21/44   train_loss = 6.030
Epoch   1 Batch   22/44   train_loss = 5.926
Epoch   1 Batch   23/44   train_loss = 6.081
Epoch   1 Batch   24/44   train_loss = 5.994
Epoch   1 Batch   25/44   train_loss = 6.085
Epoch   1 Batch   26/44   train_loss = 6.035
Epoch   1 Batch   27/44   train_loss = 6.034
Epoch   1 Batch   28/44   train_loss = 6.061
Epoch   1 Batch   29/44   train_loss = 6.190
Epoch   1 Batch   30/44   train_loss = 6.155
Epoch   1 Batch   31/44   train_loss = 6.108
Epoch   1 Batch   32/44   train_loss = 5.957
Epoch   1 Batch   33/44   train_loss = 6.148
Epoch   1 Batch   34/44   train_loss = 6.125
Epoch   1 Batch   35/44   train_loss = 5.953
Epoch   1 Batch   36/44   train_loss = 6.071
Epoch   1 Batch   37/44   train_loss = 6.075
Epoch   1 Batch   38/44   train_loss = 6.040
Epoch   1 Batch   39/44   train_loss = 6.149
Epoch   1 Batch   40/44   train_loss = 6.096
Epoch   1 Batch   41/44   train_loss = 6.033
Epoch   1 Batch   42/44   train_loss = 6.073
Epoch   1 Batch   43/44   train_loss = 6.204
Epoch   2 Batch    0/44   train_loss = 5.931
Epoch   2 Batch    1/44   train_loss = 6.013
Epoch   2 Batch    2/44   train_loss = 5.865
Epoch   2 Batch    3/44   train_loss = 5.938
Epoch   2 Batch    4/44   train_loss = 5.948
Epoch   2 Batch    5/44   train_loss = 5.976
Epoch   2 Batch    6/44   train_loss = 5.953
Epoch   2 Batch    7/44   train_loss = 6.136
Epoch   2 Batch    8/44   train_loss = 6.018
Epoch   2 Batch    9/44   train_loss = 6.001
Epoch   2 Batch   10/44   train_loss = 6.074
Epoch   2 Batch   11/44   train_loss = 6.049
Epoch   2 Batch   12/44   train_loss = 5.916
Epoch   2 Batch   13/44   train_loss = 6.032
Epoch   2 Batch   14/44   train_loss = 6.108
Epoch   2 Batch   15/44   train_loss = 5.942
Epoch   2 Batch   16/44   train_loss = 6.006
Epoch   2 Batch   17/44   train_loss = 6.045
Epoch   2 Batch   18/44   train_loss = 6.001
Epoch   2 Batch   19/44   train_loss = 6.129
Epoch   2 Batch   20/44   train_loss = 5.950
Epoch   2 Batch   21/44   train_loss = 6.043
Epoch   2 Batch   22/44   train_loss = 5.931
Epoch   2 Batch   23/44   train_loss = 6.086
Epoch   2 Batch   24/44   train_loss = 5.992
Epoch   2 Batch   25/44   train_loss = 6.079
Epoch   2 Batch   26/44   train_loss = 6.028
Epoch   2 Batch   27/44   train_loss = 6.017
Epoch   2 Batch   28/44   train_loss = 6.043
Epoch   2 Batch   29/44   train_loss = 6.166
Epoch   2 Batch   30/44   train_loss = 6.130
Epoch   2 Batch   31/44   train_loss = 6.087
Epoch   2 Batch   32/44   train_loss = 5.937
Epoch   2 Batch   33/44   train_loss = 6.118
Epoch   2 Batch   34/44   train_loss = 6.094
Epoch   2 Batch   35/44   train_loss = 5.929
Epoch   2 Batch   36/44   train_loss = 6.041
Epoch   2 Batch   37/44   train_loss = 6.048
Epoch   2 Batch   38/44   train_loss = 6.008
Epoch   2 Batch   39/44   train_loss = 6.105
Epoch   2 Batch   40/44   train_loss = 6.062
Epoch   2 Batch   41/44   train_loss = 6.002
Epoch   2 Batch   42/44   train_loss = 6.040
Epoch   2 Batch   43/44   train_loss = 6.164
Epoch   3 Batch    0/44   train_loss = 5.917
Epoch   3 Batch    1/44   train_loss = 5.999
Epoch   3 Batch    2/44   train_loss = 5.855
Epoch   3 Batch    3/44   train_loss = 5.933
Epoch   3 Batch    4/44   train_loss = 5.945
Epoch   3 Batch    5/44   train_loss = 5.972
Epoch   3 Batch    6/44   train_loss = 5.950
Epoch   3 Batch    7/44   train_loss = 6.135
Epoch   3 Batch    8/44   train_loss = 6.018
Epoch   3 Batch    9/44   train_loss = 6.002
Epoch   3 Batch   10/44   train_loss = 6.074
Epoch   3 Batch   11/44   train_loss = 6.051
Epoch   3 Batch   12/44   train_loss = 5.917
Epoch   3 Batch   13/44   train_loss = 6.034
Epoch   3 Batch   14/44   train_loss = 6.109
Epoch   3 Batch   15/44   train_loss = 5.943
Epoch   3 Batch   16/44   train_loss = 6.005
Epoch   3 Batch   17/44   train_loss = 6.045
Epoch   3 Batch   18/44   train_loss = 6.002
Epoch   3 Batch   19/44   train_loss = 6.131
Epoch   3 Batch   20/44   train_loss = 5.951
Epoch   3 Batch   21/44   train_loss = 6.044
Epoch   3 Batch   22/44   train_loss = 5.929
Epoch   3 Batch   23/44   train_loss = 6.083
Epoch   3 Batch   24/44   train_loss = 5.990
Epoch   3 Batch   25/44   train_loss = 6.076
Epoch   3 Batch   26/44   train_loss = 6.023
Epoch   3 Batch   27/44   train_loss = 6.013
Epoch   3 Batch   28/44   train_loss = 6.038
Epoch   3 Batch   29/44   train_loss = 6.161
Epoch   3 Batch   30/44   train_loss = 6.126
Epoch   3 Batch   31/44   train_loss = 6.082
Epoch   3 Batch   32/44   train_loss = 5.931
Epoch   3 Batch   33/44   train_loss = 6.112
Epoch   3 Batch   34/44   train_loss = 6.088
Epoch   3 Batch   35/44   train_loss = 5.923
Epoch   3 Batch   36/44   train_loss = 6.035
Epoch   3 Batch   37/44   train_loss = 6.041
Epoch   3 Batch   38/44   train_loss = 6.001
Epoch   3 Batch   39/44   train_loss = 6.097
Epoch   3 Batch   40/44   train_loss = 6.055
Epoch   3 Batch   41/44   train_loss = 5.995
Epoch   3 Batch   42/44   train_loss = 6.030
Epoch   3 Batch   43/44   train_loss = 6.155
Epoch   4 Batch    0/44   train_loss = 5.913
Epoch   4 Batch    1/44   train_loss = 5.994
Epoch   4 Batch    2/44   train_loss = 5.849
Epoch   4 Batch    3/44   train_loss = 5.927
Epoch   4 Batch    4/44   train_loss = 5.938
Epoch   4 Batch    5/44   train_loss = 5.967
Epoch   4 Batch    6/44   train_loss = 5.945
Epoch   4 Batch    7/44   train_loss = 6.131
Epoch   4 Batch    8/44   train_loss = 6.014
Epoch   4 Batch    9/44   train_loss = 5.997
Epoch   4 Batch   10/44   train_loss = 6.070
Epoch   4 Batch   11/44   train_loss = 6.047
Epoch   4 Batch   12/44   train_loss = 5.912
Epoch   4 Batch   13/44   train_loss = 6.028
Epoch   4 Batch   14/44   train_loss = 6.104
Epoch   4 Batch   15/44   train_loss = 5.936
Epoch   4 Batch   16/44   train_loss = 5.998
Epoch   4 Batch   17/44   train_loss = 6.041
Epoch   4 Batch   18/44   train_loss = 5.998
Epoch   4 Batch   19/44   train_loss = 6.126
Epoch   4 Batch   20/44   train_loss = 5.948
Epoch   4 Batch   21/44   train_loss = 6.040
Epoch   4 Batch   22/44   train_loss = 5.923
Epoch   4 Batch   23/44   train_loss = 6.077
Epoch   4 Batch   24/44   train_loss = 5.984
Epoch   4 Batch   25/44   train_loss = 6.071
Epoch   4 Batch   26/44   train_loss = 6.015
Epoch   4 Batch   27/44   train_loss = 6.007
Epoch   4 Batch   28/44   train_loss = 6.032
Epoch   4 Batch   29/44   train_loss = 6.156
Epoch   4 Batch   30/44   train_loss = 6.120
Epoch   4 Batch   31/44   train_loss = 6.075
Epoch   4 Batch   32/44   train_loss = 5.925
Epoch   4 Batch   33/44   train_loss = 6.106
Epoch   4 Batch   34/44   train_loss = 6.081
Epoch   4 Batch   35/44   train_loss = 5.917
Epoch   4 Batch   36/44   train_loss = 6.027
Epoch   4 Batch   37/44   train_loss = 6.034
Epoch   4 Batch   38/44   train_loss = 5.995
Epoch   4 Batch   39/44   train_loss = 6.090
Epoch   4 Batch   40/44   train_loss = 6.050
Epoch   4 Batch   41/44   train_loss = 5.989
Epoch   4 Batch   42/44   train_loss = 6.024
Epoch   4 Batch   43/44   train_loss = 6.150
Epoch   5 Batch    0/44   train_loss = 5.907
Epoch   5 Batch    1/44   train_loss = 5.989
Epoch   5 Batch    2/44   train_loss = 5.844
Epoch   5 Batch    3/44   train_loss = 5.923
Epoch   5 Batch    4/44   train_loss = 5.933
Epoch   5 Batch    5/44   train_loss = 5.962
Epoch   5 Batch    6/44   train_loss = 5.940
Epoch   5 Batch    7/44   train_loss = 6.123
Epoch   5 Batch    8/44   train_loss = 6.009
Epoch   5 Batch    9/44   train_loss = 5.991
Epoch   5 Batch   10/44   train_loss = 6.061
Epoch   5 Batch   11/44   train_loss = 6.038
Epoch   5 Batch   12/44   train_loss = 5.904
Epoch   5 Batch   13/44   train_loss = 6.019
Epoch   5 Batch   14/44   train_loss = 6.095
Epoch   5 Batch   15/44   train_loss = 5.927
Epoch   5 Batch   16/44   train_loss = 5.990
Epoch   5 Batch   17/44   train_loss = 6.034
Epoch   5 Batch   18/44   train_loss = 5.992
Epoch   5 Batch   19/44   train_loss = 6.119
Epoch   5 Batch   20/44   train_loss = 5.941
Epoch   5 Batch   21/44   train_loss = 6.032
Epoch   5 Batch   22/44   train_loss = 5.915
Epoch   5 Batch   23/44   train_loss = 6.069
Epoch   5 Batch   24/44   train_loss = 5.978
Epoch   5 Batch   25/44   train_loss = 6.064
Epoch   5 Batch   26/44   train_loss = 6.008
Epoch   5 Batch   27/44   train_loss = 6.001
Epoch   5 Batch   28/44   train_loss = 6.025
Epoch   5 Batch   29/44   train_loss = 6.150
Epoch   5 Batch   30/44   train_loss = 6.114
Epoch   5 Batch   31/44   train_loss = 6.069
Epoch   5 Batch   32/44   train_loss = 5.919
Epoch   5 Batch   33/44   train_loss = 6.101
Epoch   5 Batch   34/44   train_loss = 6.076
Epoch   5 Batch   35/44   train_loss = 5.912
Epoch   5 Batch   36/44   train_loss = 6.023
Epoch   5 Batch   37/44   train_loss = 6.029
Epoch   5 Batch   38/44   train_loss = 5.990
Epoch   5 Batch   39/44   train_loss = 6.084
Epoch   5 Batch   40/44   train_loss = 6.042
Epoch   5 Batch   41/44   train_loss = 5.982
Epoch   5 Batch   42/44   train_loss = 6.017
Epoch   5 Batch   43/44   train_loss = 6.141
Epoch   6 Batch    0/44   train_loss = 5.901
Epoch   6 Batch    1/44   train_loss = 5.982
Epoch   6 Batch    2/44   train_loss = 5.834
Epoch   6 Batch    3/44   train_loss = 5.915
Epoch   6 Batch    4/44   train_loss = 5.923
Epoch   6 Batch    5/44   train_loss = 5.951
Epoch   6 Batch    6/44   train_loss = 5.930
Epoch   6 Batch    7/44   train_loss = 6.115
Epoch   6 Batch    8/44   train_loss = 6.000
Epoch   6 Batch    9/44   train_loss = 5.982
Epoch   6 Batch   10/44   train_loss = 6.054
Epoch   6 Batch   11/44   train_loss = 6.031
Epoch   6 Batch   12/44   train_loss = 5.894
Epoch   6 Batch   13/44   train_loss = 6.012
Epoch   6 Batch   14/44   train_loss = 6.086
Epoch   6 Batch   15/44   train_loss = 5.919
Epoch   6 Batch   16/44   train_loss = 5.985
Epoch   6 Batch   17/44   train_loss = 6.027
Epoch   6 Batch   18/44   train_loss = 5.983
Epoch   6 Batch   19/44   train_loss = 6.110
Epoch   6 Batch   20/44   train_loss = 5.930
Epoch   6 Batch   21/44   train_loss = 6.022
Epoch   6 Batch   22/44   train_loss = 5.900
Epoch   6 Batch   23/44   train_loss = 6.054
Epoch   6 Batch   24/44   train_loss = 5.962
Epoch   6 Batch   25/44   train_loss = 6.050
Epoch   6 Batch   26/44   train_loss = 5.994
Epoch   6 Batch   27/44   train_loss = 5.987
Epoch   6 Batch   28/44   train_loss = 6.011
Epoch   6 Batch   29/44   train_loss = 6.134
Epoch   6 Batch   30/44   train_loss = 6.096
Epoch   6 Batch   31/44   train_loss = 6.047
Epoch   6 Batch   32/44   train_loss = 5.901
Epoch   6 Batch   33/44   train_loss = 6.075
Epoch   6 Batch   34/44   train_loss = 6.047
Epoch   6 Batch   35/44   train_loss = 5.884
Epoch   6 Batch   36/44   train_loss = 5.998
Epoch   6 Batch   37/44   train_loss = 6.001
Epoch   6 Batch   38/44   train_loss = 5.959
Epoch   6 Batch   39/44   train_loss = 6.051
Epoch   6 Batch   40/44   train_loss = 6.006
Epoch   6 Batch   41/44   train_loss = 5.944
Epoch   6 Batch   42/44   train_loss = 5.979
Epoch   6 Batch   43/44   train_loss = 6.105
Epoch   7 Batch    0/44   train_loss = 5.862
Epoch   7 Batch    1/44   train_loss = 5.938
Epoch   7 Batch    2/44   train_loss = 5.789
Epoch   7 Batch    3/44   train_loss = 5.869
Epoch   7 Batch    4/44   train_loss = 5.876
Epoch   7 Batch    5/44   train_loss = 5.906
Epoch   7 Batch    6/44   train_loss = 5.885
Epoch   7 Batch    7/44   train_loss = 6.070
Epoch   7 Batch    8/44   train_loss = 5.950
Epoch   7 Batch    9/44   train_loss = 5.934
Epoch   7 Batch   10/44   train_loss = 6.005
Epoch   7 Batch   11/44   train_loss = 5.977
Epoch   7 Batch   12/44   train_loss = 5.840
Epoch   7 Batch   13/44   train_loss = 5.954
Epoch   7 Batch   14/44   train_loss = 6.026
Epoch   7 Batch   15/44   train_loss = 5.848
Epoch   7 Batch   16/44   train_loss = 5.924
Epoch   7 Batch   17/44   train_loss = 5.960
Epoch   7 Batch   18/44   train_loss = 5.919
Epoch   7 Batch   19/44   train_loss = 6.046
Epoch   7 Batch   20/44   train_loss = 5.861
Epoch   7 Batch   21/44   train_loss = 5.954
Epoch   7 Batch   22/44   train_loss = 5.828
Epoch   7 Batch   23/44   train_loss = 5.990
Epoch   7 Batch   24/44   train_loss = 5.889
Epoch   7 Batch   25/44   train_loss = 5.978
Epoch   7 Batch   26/44   train_loss = 5.915
Epoch   7 Batch   27/44   train_loss = 5.919
Epoch   7 Batch   28/44   train_loss = 5.939
Epoch   7 Batch   29/44   train_loss = 6.065
Epoch   7 Batch   30/44   train_loss = 6.025
Epoch   7 Batch   31/44   train_loss = 5.974
Epoch   7 Batch   32/44   train_loss = 5.829
Epoch   7 Batch   33/44   train_loss = 5.999
Epoch   7 Batch   34/44   train_loss = 5.969
Epoch   7 Batch   35/44   train_loss = 5.807
Epoch   7 Batch   36/44   train_loss = 5.924
Epoch   7 Batch   37/44   train_loss = 5.930
Epoch   7 Batch   38/44   train_loss = 5.886
Epoch   7 Batch   39/44   train_loss = 5.976
Epoch   7 Batch   40/44   train_loss = 5.929
Epoch   7 Batch   41/44   train_loss = 5.865
Epoch   7 Batch   42/44   train_loss = 5.904
Epoch   7 Batch   43/44   train_loss = 6.028
Epoch   8 Batch    0/44   train_loss = 5.791
Epoch   8 Batch    1/44   train_loss = 5.856
Epoch   8 Batch    2/44   train_loss = 5.708
Epoch   8 Batch    3/44   train_loss = 5.792
Epoch   8 Batch    4/44   train_loss = 5.798
Epoch   8 Batch    5/44   train_loss = 5.829
Epoch   8 Batch    6/44   train_loss = 5.811
Epoch   8 Batch    7/44   train_loss = 5.999
Epoch   8 Batch    8/44   train_loss = 5.874
Epoch   8 Batch    9/44   train_loss = 5.867
Epoch   8 Batch   10/44   train_loss = 5.936
Epoch   8 Batch   11/44   train_loss = 5.899
Epoch   8 Batch   12/44   train_loss = 5.771
Epoch   8 Batch   13/44   train_loss = 5.883
Epoch   8 Batch   14/44   train_loss = 5.958
Epoch   8 Batch   15/44   train_loss = 5.771
Epoch   8 Batch   16/44   train_loss = 5.858
Epoch   8 Batch   17/44   train_loss = 5.890
Epoch   8 Batch   18/44   train_loss = 5.851
Epoch   8 Batch   19/44   train_loss = 5.981
Epoch   8 Batch   20/44   train_loss = 5.790
Epoch   8 Batch   21/44   train_loss = 5.887
Epoch   8 Batch   22/44   train_loss = 5.758
Epoch   8 Batch   23/44   train_loss = 5.929
Epoch   8 Batch   24/44   train_loss = 5.819
Epoch   8 Batch   25/44   train_loss = 5.912
Epoch   8 Batch   26/44   train_loss = 5.843
Epoch   8 Batch   27/44   train_loss = 5.856
Epoch   8 Batch   28/44   train_loss = 5.871
Epoch   8 Batch   29/44   train_loss = 6.002
Epoch   8 Batch   30/44   train_loss = 5.958
Epoch   8 Batch   31/44   train_loss = 5.906
Epoch   8 Batch   32/44   train_loss = 5.758
Epoch   8 Batch   33/44   train_loss = 5.924
Epoch   8 Batch   34/44   train_loss = 5.894
Epoch   8 Batch   35/44   train_loss = 5.730
Epoch   8 Batch   36/44   train_loss = 5.849
Epoch   8 Batch   37/44   train_loss = 5.858
Epoch   8 Batch   38/44   train_loss = 5.807
Epoch   8 Batch   39/44   train_loss = 5.899
Epoch   8 Batch   40/44   train_loss = 5.853
Epoch   8 Batch   41/44   train_loss = 5.787
Epoch   8 Batch   42/44   train_loss = 5.829
Epoch   8 Batch   43/44   train_loss = 5.958
Epoch   9 Batch    0/44   train_loss = 5.718
Epoch   9 Batch    1/44   train_loss = 5.773
Epoch   9 Batch    2/44   train_loss = 5.626
Epoch   9 Batch    3/44   train_loss = 5.715
Epoch   9 Batch    4/44   train_loss = 5.721
Epoch   9 Batch    5/44   train_loss = 5.751
Epoch   9 Batch    6/44   train_loss = 5.738
Epoch   9 Batch    7/44   train_loss = 5.928
Epoch   9 Batch    8/44   train_loss = 5.800
Epoch   9 Batch    9/44   train_loss = 5.798
Epoch   9 Batch   10/44   train_loss = 5.866
Epoch   9 Batch   11/44   train_loss = 5.826
Epoch   9 Batch   12/44   train_loss = 5.700
Epoch   9 Batch   13/44   train_loss = 5.812
Epoch   9 Batch   14/44   train_loss = 5.886
Epoch   9 Batch   15/44   train_loss = 5.698
Epoch   9 Batch   16/44   train_loss = 5.787
Epoch   9 Batch   17/44   train_loss = 5.824
Epoch   9 Batch   18/44   train_loss = 5.783
Epoch   9 Batch   19/44   train_loss = 5.916
Epoch   9 Batch   20/44   train_loss = 5.723
Epoch   9 Batch   21/44   train_loss = 5.819
Epoch   9 Batch   22/44   train_loss = 5.690
Epoch   9 Batch   23/44   train_loss = 5.866
Epoch   9 Batch   24/44   train_loss = 5.750
Epoch   9 Batch   25/44   train_loss = 5.843
Epoch   9 Batch   26/44   train_loss = 5.776
Epoch   9 Batch   27/44   train_loss = 5.796
Epoch   9 Batch   28/44   train_loss = 5.808
Epoch   9 Batch   29/44   train_loss = 5.939
Epoch   9 Batch   30/44   train_loss = 5.895
Epoch   9 Batch   31/44   train_loss = 5.838
Epoch   9 Batch   32/44   train_loss = 5.694
Epoch   9 Batch   33/44   train_loss = 5.858
Epoch   9 Batch   34/44   train_loss = 5.827
Epoch   9 Batch   35/44   train_loss = 5.664
Epoch   9 Batch   36/44   train_loss = 5.788
Epoch   9 Batch   37/44   train_loss = 5.797
Epoch   9 Batch   38/44   train_loss = 5.740
Epoch   9 Batch   39/44   train_loss = 5.837
Epoch   9 Batch   40/44   train_loss = 5.788
Epoch   9 Batch   41/44   train_loss = 5.723
Epoch   9 Batch   42/44   train_loss = 5.764
Epoch   9 Batch   43/44   train_loss = 5.902
Epoch  10 Batch    0/44   train_loss = 5.657
Epoch  10 Batch    1/44   train_loss = 5.710
Epoch  10 Batch    2/44   train_loss = 5.566
Epoch  10 Batch    3/44   train_loss = 5.659
Epoch  10 Batch    4/44   train_loss = 5.662
Epoch  10 Batch    5/44   train_loss = 5.694
Epoch  10 Batch    6/44   train_loss = 5.685
Epoch  10 Batch    7/44   train_loss = 5.875
Epoch  10 Batch    8/44   train_loss = 5.745
Epoch  10 Batch    9/44   train_loss = 5.746
Epoch  10 Batch   10/44   train_loss = 5.811
Epoch  10 Batch   11/44   train_loss = 5.770
Epoch  10 Batch   12/44   train_loss = 5.644
Epoch  10 Batch   13/44   train_loss = 5.753
Epoch  10 Batch   14/44   train_loss = 5.830
Epoch  10 Batch   15/44   train_loss = 5.639
Epoch  10 Batch   16/44   train_loss = 5.731
Epoch  10 Batch   17/44   train_loss = 5.767
Epoch  10 Batch   18/44   train_loss = 5.726
Epoch  10 Batch   19/44   train_loss = 5.858
Epoch  10 Batch   20/44   train_loss = 5.665
Epoch  10 Batch   21/44   train_loss = 5.762
Epoch  10 Batch   22/44   train_loss = 5.636
Epoch  10 Batch   23/44   train_loss = 5.810
Epoch  10 Batch   24/44   train_loss = 5.693
Epoch  10 Batch   25/44   train_loss = 5.785
Epoch  10 Batch   26/44   train_loss = 5.720
Epoch  10 Batch   27/44   train_loss = 5.744
Epoch  10 Batch   28/44   train_loss = 5.757
Epoch  10 Batch   29/44   train_loss = 5.888
Epoch  10 Batch   30/44   train_loss = 5.841
Epoch  10 Batch   31/44   train_loss = 5.788
Epoch  10 Batch   32/44   train_loss = 5.643
Epoch  10 Batch   33/44   train_loss = 5.809
Epoch  10 Batch   34/44   train_loss = 5.774
Epoch  10 Batch   35/44   train_loss = 5.614
Epoch  10 Batch   36/44   train_loss = 5.739
Epoch  10 Batch   37/44   train_loss = 5.751
Epoch  10 Batch   38/44   train_loss = 5.691
Epoch  10 Batch   39/44   train_loss = 5.787
Epoch  10 Batch   40/44   train_loss = 5.740
Epoch  10 Batch   41/44   train_loss = 5.675
Epoch  10 Batch   42/44   train_loss = 5.716
Epoch  10 Batch   43/44   train_loss = 5.859
Epoch  11 Batch    0/44   train_loss = 5.608
Epoch  11 Batch    1/44   train_loss = 5.660
Epoch  11 Batch    2/44   train_loss = 5.516
Epoch  11 Batch    3/44   train_loss = 5.612
Epoch  11 Batch    4/44   train_loss = 5.612
Epoch  11 Batch    5/44   train_loss = 5.644
Epoch  11 Batch    6/44   train_loss = 5.637
Epoch  11 Batch    7/44   train_loss = 5.830
Epoch  11 Batch    8/44   train_loss = 5.696
Epoch  11 Batch    9/44   train_loss = 5.700
Epoch  11 Batch   10/44   train_loss = 5.761
Epoch  11 Batch   11/44   train_loss = 5.712
Epoch  11 Batch   12/44   train_loss = 5.588
Epoch  11 Batch   13/44   train_loss = 5.691
Epoch  11 Batch   14/44   train_loss = 5.772
Epoch  11 Batch   15/44   train_loss = 5.583
Epoch  11 Batch   16/44   train_loss = 5.681
Epoch  11 Batch   17/44   train_loss = 5.721
Epoch  11 Batch   18/44   train_loss = 5.681
Epoch  11 Batch   19/44   train_loss = 5.811
Epoch  11 Batch   20/44   train_loss = 5.620
Epoch  11 Batch   21/44   train_loss = 5.721
Epoch  11 Batch   22/44   train_loss = 5.601
Epoch  11 Batch   23/44   train_loss = 5.775
Epoch  11 Batch   24/44   train_loss = 5.655
Epoch  11 Batch   25/44   train_loss = 5.745
Epoch  11 Batch   26/44   train_loss = 5.674
Epoch  11 Batch   27/44   train_loss = 5.704
Epoch  11 Batch   28/44   train_loss = 5.712
Epoch  11 Batch   29/44   train_loss = 5.846
Epoch  11 Batch   30/44   train_loss = 5.794
Epoch  11 Batch   31/44   train_loss = 5.743
Epoch  11 Batch   32/44   train_loss = 5.596
Epoch  11 Batch   33/44   train_loss = 5.762
Epoch  11 Batch   34/44   train_loss = 5.724
Epoch  11 Batch   35/44   train_loss = 5.564
Epoch  11 Batch   36/44   train_loss = 5.692
Epoch  11 Batch   37/44   train_loss = 5.704
Epoch  11 Batch   38/44   train_loss = 5.642
Epoch  11 Batch   39/44   train_loss = 5.736
Epoch  11 Batch   40/44   train_loss = 5.691
Epoch  11 Batch   41/44   train_loss = 5.628
Epoch  11 Batch   42/44   train_loss = 5.664
Epoch  11 Batch   43/44   train_loss = 5.813
Epoch  12 Batch    0/44   train_loss = 5.561
Epoch  12 Batch    1/44   train_loss = 5.611
Epoch  12 Batch    2/44   train_loss = 5.465
Epoch  12 Batch    3/44   train_loss = 5.567
Epoch  12 Batch    4/44   train_loss = 5.563
Epoch  12 Batch    5/44   train_loss = 5.593
Epoch  12 Batch    6/44   train_loss = 5.589
Epoch  12 Batch    7/44   train_loss = 5.781
Epoch  12 Batch    8/44   train_loss = 5.645
Epoch  12 Batch    9/44   train_loss = 5.653
Epoch  12 Batch   10/44   train_loss = 5.716
Epoch  12 Batch   11/44   train_loss = 5.673
Epoch  12 Batch   12/44   train_loss = 5.548
Epoch  12 Batch   13/44   train_loss = 5.652
Epoch  12 Batch   14/44   train_loss = 5.737
Epoch  12 Batch   15/44   train_loss = 5.541
Epoch  12 Batch   16/44   train_loss = 5.638
Epoch  12 Batch   17/44   train_loss = 5.676
Epoch  12 Batch   18/44   train_loss = 5.634
Epoch  12 Batch   19/44   train_loss = 5.761
Epoch  12 Batch   20/44   train_loss = 5.572
Epoch  12 Batch   21/44   train_loss = 5.672
Epoch  12 Batch   22/44   train_loss = 5.550
Epoch  12 Batch   23/44   train_loss = 5.724
Epoch  12 Batch   24/44   train_loss = 5.603
Epoch  12 Batch   25/44   train_loss = 5.695
Epoch  12 Batch   26/44   train_loss = 5.622
Epoch  12 Batch   27/44   train_loss = 5.657
Epoch  12 Batch   28/44   train_loss = 5.665
Epoch  12 Batch   29/44   train_loss = 5.801
Epoch  12 Batch   30/44   train_loss = 5.745
Epoch  12 Batch   31/44   train_loss = 5.696
Epoch  12 Batch   32/44   train_loss = 5.551
Epoch  12 Batch   33/44   train_loss = 5.716
Epoch  12 Batch   34/44   train_loss = 5.673
Epoch  12 Batch   35/44   train_loss = 5.510
Epoch  12 Batch   36/44   train_loss = 5.642
Epoch  12 Batch   37/44   train_loss = 5.650
Epoch  12 Batch   38/44   train_loss = 5.587
Epoch  12 Batch   39/44   train_loss = 5.679
Epoch  12 Batch   40/44   train_loss = 5.638
Epoch  12 Batch   41/44   train_loss = 5.578
Epoch  12 Batch   42/44   train_loss = 5.608
Epoch  12 Batch   43/44   train_loss = 5.763
Epoch  13 Batch    0/44   train_loss = 5.509
Epoch  13 Batch    1/44   train_loss = 5.552
Epoch  13 Batch    2/44   train_loss = 5.407
Epoch  13 Batch    3/44   train_loss = 5.513
Epoch  13 Batch    4/44   train_loss = 5.503
Epoch  13 Batch    5/44   train_loss = 5.530
Epoch  13 Batch    6/44   train_loss = 5.535
Epoch  13 Batch    7/44   train_loss = 5.724
Epoch  13 Batch    8/44   train_loss = 5.587
Epoch  13 Batch    9/44   train_loss = 5.597
Epoch  13 Batch   10/44   train_loss = 5.662
Epoch  13 Batch   11/44   train_loss = 5.617
Epoch  13 Batch   12/44   train_loss = 5.492
Epoch  13 Batch   13/44   train_loss = 5.593
Epoch  13 Batch   14/44   train_loss = 5.682
Epoch  13 Batch   15/44   train_loss = 5.486
Epoch  13 Batch   16/44   train_loss = 5.578
Epoch  13 Batch   17/44   train_loss = 5.619
Epoch  13 Batch   18/44   train_loss = 5.577
Epoch  13 Batch   19/44   train_loss = 5.700
Epoch  13 Batch   20/44   train_loss = 5.516
Epoch  13 Batch   21/44   train_loss = 5.610
Epoch  13 Batch   22/44   train_loss = 5.496
Epoch  13 Batch   23/44   train_loss = 5.666
Epoch  13 Batch   24/44   train_loss = 5.547
Epoch  13 Batch   25/44   train_loss = 5.637
Epoch  13 Batch   26/44   train_loss = 5.563
Epoch  13 Batch   27/44   train_loss = 5.600
Epoch  13 Batch   28/44   train_loss = 5.604
Epoch  13 Batch   29/44   train_loss = 5.750
Epoch  13 Batch   30/44   train_loss = 5.690
Epoch  13 Batch   31/44   train_loss = 5.640
Epoch  13 Batch   32/44   train_loss = 5.497
Epoch  13 Batch   33/44   train_loss = 5.667
Epoch  13 Batch   34/44   train_loss = 5.613
Epoch  13 Batch   35/44   train_loss = 5.450
Epoch  13 Batch   36/44   train_loss = 5.588
Epoch  13 Batch   37/44   train_loss = 5.595
Epoch  13 Batch   38/44   train_loss = 5.526
Epoch  13 Batch   39/44   train_loss = 5.616
Epoch  13 Batch   40/44   train_loss = 5.578
Epoch  13 Batch   41/44   train_loss = 5.523
Epoch  13 Batch   42/44   train_loss = 5.550
Epoch  13 Batch   43/44   train_loss = 5.704
Epoch  14 Batch    0/44   train_loss = 5.449
Epoch  14 Batch    1/44   train_loss = 5.489
Epoch  14 Batch    2/44   train_loss = 5.345
Epoch  14 Batch    3/44   train_loss = 5.454
Epoch  14 Batch    4/44   train_loss = 5.438
Epoch  14 Batch    5/44   train_loss = 5.465
Epoch  14 Batch    6/44   train_loss = 5.476
Epoch  14 Batch    7/44   train_loss = 5.663
Epoch  14 Batch    8/44   train_loss = 5.525
Epoch  14 Batch    9/44   train_loss = 5.541
Epoch  14 Batch   10/44   train_loss = 5.604
Epoch  14 Batch   11/44   train_loss = 5.560
Epoch  14 Batch   12/44   train_loss = 5.434
Epoch  14 Batch   13/44   train_loss = 5.531
Epoch  14 Batch   14/44   train_loss = 5.620
Epoch  14 Batch   15/44   train_loss = 5.430
Epoch  14 Batch   16/44   train_loss = 5.514
Epoch  14 Batch   17/44   train_loss = 5.561
Epoch  14 Batch   18/44   train_loss = 5.520
Epoch  14 Batch   19/44   train_loss = 5.639
Epoch  14 Batch   20/44   train_loss = 5.457
Epoch  14 Batch   21/44   train_loss = 5.548
Epoch  14 Batch   22/44   train_loss = 5.438
Epoch  14 Batch   23/44   train_loss = 5.609
Epoch  14 Batch   24/44   train_loss = 5.488
Epoch  14 Batch   25/44   train_loss = 5.574
Epoch  14 Batch   26/44   train_loss = 5.500
Epoch  14 Batch   27/44   train_loss = 5.546
Epoch  14 Batch   28/44   train_loss = 5.547
Epoch  14 Batch   29/44   train_loss = 5.692
Epoch  14 Batch   30/44   train_loss = 5.636
Epoch  14 Batch   31/44   train_loss = 5.590
Epoch  14 Batch   32/44   train_loss = 5.436
Epoch  14 Batch   33/44   train_loss = 5.613
Epoch  14 Batch   34/44   train_loss = 5.557
Epoch  14 Batch   35/44   train_loss = 5.405
Epoch  14 Batch   36/44   train_loss = 5.540
Epoch  14 Batch   37/44   train_loss = 5.544
Epoch  14 Batch   38/44   train_loss = 5.473
Epoch  14 Batch   39/44   train_loss = 5.569
Epoch  14 Batch   40/44   train_loss = 5.537
Epoch  14 Batch   41/44   train_loss = 5.472
Epoch  14 Batch   42/44   train_loss = 5.494
Epoch  14 Batch   43/44   train_loss = 5.657
Epoch  15 Batch    0/44   train_loss = 5.403
Epoch  15 Batch    1/44   train_loss = 5.435
Epoch  15 Batch    2/44   train_loss = 5.289
Epoch  15 Batch    3/44   train_loss = 5.405
Epoch  15 Batch    4/44   train_loss = 5.387
Epoch  15 Batch    5/44   train_loss = 5.416
Epoch  15 Batch    6/44   train_loss = 5.425
Epoch  15 Batch    7/44   train_loss = 5.607
Epoch  15 Batch    8/44   train_loss = 5.476
Epoch  15 Batch    9/44   train_loss = 5.492
Epoch  15 Batch   10/44   train_loss = 5.552
Epoch  15 Batch   11/44   train_loss = 5.507
Epoch  15 Batch   12/44   train_loss = 5.380
Epoch  15 Batch   13/44   train_loss = 5.474
Epoch  15 Batch   14/44   train_loss = 5.571
Epoch  15 Batch   15/44   train_loss = 5.380
Epoch  15 Batch   16/44   train_loss = 5.460
Epoch  15 Batch   17/44   train_loss = 5.508
Epoch  15 Batch   18/44   train_loss = 5.472
Epoch  15 Batch   19/44   train_loss = 5.586
Epoch  15 Batch   20/44   train_loss = 5.404
Epoch  15 Batch   21/44   train_loss = 5.493
Epoch  15 Batch   22/44   train_loss = 5.385
Epoch  15 Batch   23/44   train_loss = 5.556
Epoch  15 Batch   24/44   train_loss = 5.439
Epoch  15 Batch   25/44   train_loss = 5.524
Epoch  15 Batch   26/44   train_loss = 5.441
Epoch  15 Batch   27/44   train_loss = 5.494
Epoch  15 Batch   28/44   train_loss = 5.498
Epoch  15 Batch   29/44   train_loss = 5.643
Epoch  15 Batch   30/44   train_loss = 5.588
Epoch  15 Batch   31/44   train_loss = 5.539
Epoch  15 Batch   32/44   train_loss = 5.384
Epoch  15 Batch   33/44   train_loss = 5.571
Epoch  15 Batch   34/44   train_loss = 5.510
Epoch  15 Batch   35/44   train_loss = 5.346
Epoch  15 Batch   36/44   train_loss = 5.494
Epoch  15 Batch   37/44   train_loss = 5.503
Epoch  15 Batch   38/44   train_loss = 5.419
Epoch  15 Batch   39/44   train_loss = 5.516
Epoch  15 Batch   40/44   train_loss = 5.486
Epoch  15 Batch   41/44   train_loss = 5.431
Epoch  15 Batch   42/44   train_loss = 5.442
Epoch  15 Batch   43/44   train_loss = 5.604
Epoch  16 Batch    0/44   train_loss = 5.343
Epoch  16 Batch    1/44   train_loss = 5.385
Epoch  16 Batch    2/44   train_loss = 5.241
Epoch  16 Batch    3/44   train_loss = 5.353
Epoch  16 Batch    4/44   train_loss = 5.329
Epoch  16 Batch    5/44   train_loss = 5.363
Epoch  16 Batch    6/44   train_loss = 5.379
Epoch  16 Batch    7/44   train_loss = 5.563
Epoch  16 Batch    8/44   train_loss = 5.423
Epoch  16 Batch    9/44   train_loss = 5.443
Epoch  16 Batch   10/44   train_loss = 5.503
Epoch  16 Batch   11/44   train_loss = 5.466
Epoch  16 Batch   12/44   train_loss = 5.335
Epoch  16 Batch   13/44   train_loss = 5.423
Epoch  16 Batch   14/44   train_loss = 5.524
Epoch  16 Batch   15/44   train_loss = 5.335
Epoch  16 Batch   16/44   train_loss = 5.416
Epoch  16 Batch   17/44   train_loss = 5.465
Epoch  16 Batch   18/44   train_loss = 5.427
Epoch  16 Batch   19/44   train_loss = 5.539
Epoch  16 Batch   20/44   train_loss = 5.360
Epoch  16 Batch   21/44   train_loss = 5.449
Epoch  16 Batch   22/44   train_loss = 5.339
Epoch  16 Batch   23/44   train_loss = 5.506
Epoch  16 Batch   24/44   train_loss = 5.392
Epoch  16 Batch   25/44   train_loss = 5.480
Epoch  16 Batch   26/44   train_loss = 5.391
Epoch  16 Batch   27/44   train_loss = 5.447
Epoch  16 Batch   28/44   train_loss = 5.450
Epoch  16 Batch   29/44   train_loss = 5.599
Epoch  16 Batch   30/44   train_loss = 5.547
Epoch  16 Batch   31/44   train_loss = 5.495
Epoch  16 Batch   32/44   train_loss = 5.335
Epoch  16 Batch   33/44   train_loss = 5.528
Epoch  16 Batch   34/44   train_loss = 5.470
Epoch  16 Batch   35/44   train_loss = 5.298
Epoch  16 Batch   36/44   train_loss = 5.445
Epoch  16 Batch   37/44   train_loss = 5.458
Epoch  16 Batch   38/44   train_loss = 5.375
Epoch  16 Batch   39/44   train_loss = 5.476
Epoch  16 Batch   40/44   train_loss = 5.436
Epoch  16 Batch   41/44   train_loss = 5.382
Epoch  16 Batch   42/44   train_loss = 5.393
Epoch  16 Batch   43/44   train_loss = 5.562
Epoch  17 Batch    0/44   train_loss = 5.292
Epoch  17 Batch    1/44   train_loss = 5.330
Epoch  17 Batch    2/44   train_loss = 5.187
Epoch  17 Batch    3/44   train_loss = 5.308
Epoch  17 Batch    4/44   train_loss = 5.282
Epoch  17 Batch    5/44   train_loss = 5.314
Epoch  17 Batch    6/44   train_loss = 5.329
Epoch  17 Batch    7/44   train_loss = 5.516
Epoch  17 Batch    8/44   train_loss = 5.383
Epoch  17 Batch    9/44   train_loss = 5.404
Epoch  17 Batch   10/44   train_loss = 5.458
Epoch  17 Batch   11/44   train_loss = 5.415
Epoch  17 Batch   12/44   train_loss = 5.290
Epoch  17 Batch   13/44   train_loss = 5.383
Epoch  17 Batch   14/44   train_loss = 5.483
Epoch  17 Batch   15/44   train_loss = 5.288
Epoch  17 Batch   16/44   train_loss = 5.368
Epoch  17 Batch   17/44   train_loss = 5.423
Epoch  17 Batch   18/44   train_loss = 5.391
Epoch  17 Batch   19/44   train_loss = 5.493
Epoch  17 Batch   20/44   train_loss = 5.317
Epoch  17 Batch   21/44   train_loss = 5.408
Epoch  17 Batch   22/44   train_loss = 5.297
Epoch  17 Batch   23/44   train_loss = 5.462
Epoch  17 Batch   24/44   train_loss = 5.347
Epoch  17 Batch   25/44   train_loss = 5.436
Epoch  17 Batch   26/44   train_loss = 5.347
Epoch  17 Batch   27/44   train_loss = 5.404
Epoch  17 Batch   28/44   train_loss = 5.403
Epoch  17 Batch   29/44   train_loss = 5.553
Epoch  17 Batch   30/44   train_loss = 5.504
Epoch  17 Batch   31/44   train_loss = 5.455
Epoch  17 Batch   32/44   train_loss = 5.294
Epoch  17 Batch   33/44   train_loss = 5.487
Epoch  17 Batch   34/44   train_loss = 5.429
Epoch  17 Batch   35/44   train_loss = 5.256
Epoch  17 Batch   36/44   train_loss = 5.407
Epoch  17 Batch   37/44   train_loss = 5.418
Epoch  17 Batch   38/44   train_loss = 5.335
Epoch  17 Batch   39/44   train_loss = 5.440
Epoch  17 Batch   40/44   train_loss = 5.400
Epoch  17 Batch   41/44   train_loss = 5.343
Epoch  17 Batch   42/44   train_loss = 5.349
Epoch  17 Batch   43/44   train_loss = 5.522
Epoch  18 Batch    0/44   train_loss = 5.253
Epoch  18 Batch    1/44   train_loss = 5.286
Epoch  18 Batch    2/44   train_loss = 5.143
Epoch  18 Batch    3/44   train_loss = 5.266
Epoch  18 Batch    4/44   train_loss = 5.240
Epoch  18 Batch    5/44   train_loss = 5.270
Epoch  18 Batch    6/44   train_loss = 5.287
Epoch  18 Batch    7/44   train_loss = 5.474
Epoch  18 Batch    8/44   train_loss = 5.341
Epoch  18 Batch    9/44   train_loss = 5.367
Epoch  18 Batch   10/44   train_loss = 5.421
Epoch  18 Batch   11/44   train_loss = 5.373
Epoch  18 Batch   12/44   train_loss = 5.246
Epoch  18 Batch   13/44   train_loss = 5.342
Epoch  18 Batch   14/44   train_loss = 5.446
Epoch  18 Batch   15/44   train_loss = 5.250
Epoch  18 Batch   16/44   train_loss = 5.328
Epoch  18 Batch   17/44   train_loss = 5.379
Epoch  18 Batch   18/44   train_loss = 5.350
Epoch  18 Batch   19/44   train_loss = 5.451
Epoch  18 Batch   20/44   train_loss = 5.277
Epoch  18 Batch   21/44   train_loss = 5.368
Epoch  18 Batch   22/44   train_loss = 5.258
Epoch  18 Batch   23/44   train_loss = 5.424
Epoch  18 Batch   24/44   train_loss = 5.308
Epoch  18 Batch   25/44   train_loss = 5.397
Epoch  18 Batch   26/44   train_loss = 5.305
Epoch  18 Batch   27/44   train_loss = 5.365
Epoch  18 Batch   28/44   train_loss = 5.363
Epoch  18 Batch   29/44   train_loss = 5.510
Epoch  18 Batch   30/44   train_loss = 5.462
Epoch  18 Batch   31/44   train_loss = 5.413
Epoch  18 Batch   32/44   train_loss = 5.252
Epoch  18 Batch   33/44   train_loss = 5.447
Epoch  18 Batch   34/44   train_loss = 5.388
Epoch  18 Batch   35/44   train_loss = 5.214
Epoch  18 Batch   36/44   train_loss = 5.367
Epoch  18 Batch   37/44   train_loss = 5.381
Epoch  18 Batch   38/44   train_loss = 5.297
Epoch  18 Batch   39/44   train_loss = 5.402
Epoch  18 Batch   40/44   train_loss = 5.365
Epoch  18 Batch   41/44   train_loss = 5.306
Epoch  18 Batch   42/44   train_loss = 5.309
Epoch  18 Batch   43/44   train_loss = 5.484
Epoch  19 Batch    0/44   train_loss = 5.211
Epoch  19 Batch    1/44   train_loss = 5.245
Epoch  19 Batch    2/44   train_loss = 5.103
Epoch  19 Batch    3/44   train_loss = 5.226
Epoch  19 Batch    4/44   train_loss = 5.198
Epoch  19 Batch    5/44   train_loss = 5.224
Epoch  19 Batch    6/44   train_loss = 5.245
Epoch  19 Batch    7/44   train_loss = 5.429
Epoch  19 Batch    8/44   train_loss = 5.300
Epoch  19 Batch    9/44   train_loss = 5.325
Epoch  19 Batch   10/44   train_loss = 5.381
Epoch  19 Batch   11/44   train_loss = 5.332
Epoch  19 Batch   12/44   train_loss = 5.205
Epoch  19 Batch   13/44   train_loss = 5.302
Epoch  19 Batch   14/44   train_loss = 5.411
Epoch  19 Batch   15/44   train_loss = 5.208
Epoch  19 Batch   16/44   train_loss = 5.288
Epoch  19 Batch   17/44   train_loss = 5.335
Epoch  19 Batch   18/44   train_loss = 5.307
Epoch  19 Batch   19/44   train_loss = 5.407
Epoch  19 Batch   20/44   train_loss = 5.235
Epoch  19 Batch   21/44   train_loss = 5.327
Epoch  19 Batch   22/44   train_loss = 5.217
Epoch  19 Batch   23/44   train_loss = 5.380
Epoch  19 Batch   24/44   train_loss = 5.266
Epoch  19 Batch   25/44   train_loss = 5.356
Epoch  19 Batch   26/44   train_loss = 5.262
Epoch  19 Batch   27/44   train_loss = 5.323
Epoch  19 Batch   28/44   train_loss = 5.320
Epoch  19 Batch   29/44   train_loss = 5.464
Epoch  19 Batch   30/44   train_loss = 5.417
Epoch  19 Batch   31/44   train_loss = 5.368
Epoch  19 Batch   32/44   train_loss = 5.208
Epoch  19 Batch   33/44   train_loss = 5.404
Epoch  19 Batch   34/44   train_loss = 5.341
Epoch  19 Batch   35/44   train_loss = 5.168
Epoch  19 Batch   36/44   train_loss = 5.321
Epoch  19 Batch   37/44   train_loss = 5.341
Epoch  19 Batch   38/44   train_loss = 5.254
Epoch  19 Batch   39/44   train_loss = 5.357
Epoch  19 Batch   40/44   train_loss = 5.324
Epoch  19 Batch   41/44   train_loss = 5.264
Epoch  19 Batch   42/44   train_loss = 5.264
Epoch  19 Batch   43/44   train_loss = 5.440
Epoch  20 Batch    0/44   train_loss = 5.163
Epoch  20 Batch    1/44   train_loss = 5.200
Epoch  20 Batch    2/44   train_loss = 5.059
Epoch  20 Batch    3/44   train_loss = 5.184
Epoch  20 Batch    4/44   train_loss = 5.152
Epoch  20 Batch    5/44   train_loss = 5.179
Epoch  20 Batch    6/44   train_loss = 5.200
Epoch  20 Batch    7/44   train_loss = 5.382
Epoch  20 Batch    8/44   train_loss = 5.254
Epoch  20 Batch    9/44   train_loss = 5.282
Epoch  20 Batch   10/44   train_loss = 5.335
Epoch  20 Batch   11/44   train_loss = 5.285
Epoch  20 Batch   12/44   train_loss = 5.157
Epoch  20 Batch   13/44   train_loss = 5.256
Epoch  20 Batch   14/44   train_loss = 5.366
Epoch  20 Batch   15/44   train_loss = 5.161
Epoch  20 Batch   16/44   train_loss = 5.245
Epoch  20 Batch   17/44   train_loss = 5.290
Epoch  20 Batch   18/44   train_loss = 5.263
Epoch  20 Batch   19/44   train_loss = 5.359
Epoch  20 Batch   20/44   train_loss = 5.190
Epoch  20 Batch   21/44   train_loss = 5.284
Epoch  20 Batch   22/44   train_loss = 5.173
Epoch  20 Batch   23/44   train_loss = 5.332
Epoch  20 Batch   24/44   train_loss = 5.222
Epoch  20 Batch   25/44   train_loss = 5.311
Epoch  20 Batch   26/44   train_loss = 5.212
Epoch  20 Batch   27/44   train_loss = 5.277
Epoch  20 Batch   28/44   train_loss = 5.275
Epoch  20 Batch   29/44   train_loss = 5.415
Epoch  20 Batch   30/44   train_loss = 5.371
Epoch  20 Batch   31/44   train_loss = 5.322
Epoch  20 Batch   32/44   train_loss = 5.162
Epoch  20 Batch   33/44   train_loss = 5.362
Epoch  20 Batch   34/44   train_loss = 5.295
Epoch  20 Batch   35/44   train_loss = 5.118
Epoch  20 Batch   36/44   train_loss = 5.277
Epoch  20 Batch   37/44   train_loss = 5.297
Epoch  20 Batch   38/44   train_loss = 5.206
Epoch  20 Batch   39/44   train_loss = 5.310
Epoch  20 Batch   40/44   train_loss = 5.280
Epoch  20 Batch   41/44   train_loss = 5.219
Epoch  20 Batch   42/44   train_loss = 5.219
Epoch  20 Batch   43/44   train_loss = 5.400
Epoch  21 Batch    0/44   train_loss = 5.120
Epoch  21 Batch    1/44   train_loss = 5.158
Epoch  21 Batch    2/44   train_loss = 5.015
Epoch  21 Batch    3/44   train_loss = 5.143
Epoch  21 Batch    4/44   train_loss = 5.105
Epoch  21 Batch    5/44   train_loss = 5.131
Epoch  21 Batch    6/44   train_loss = 5.154
Epoch  21 Batch    7/44   train_loss = 5.333
Epoch  21 Batch    8/44   train_loss = 5.210
Epoch  21 Batch    9/44   train_loss = 5.237
Epoch  21 Batch   10/44   train_loss = 5.291
Epoch  21 Batch   11/44   train_loss = 5.241
Epoch  21 Batch   12/44   train_loss = 5.112
Epoch  21 Batch   13/44   train_loss = 5.212
Epoch  21 Batch   14/44   train_loss = 5.327
Epoch  21 Batch   15/44   train_loss = 5.114
Epoch  21 Batch   16/44   train_loss = 5.198
Epoch  21 Batch   17/44   train_loss = 5.242
Epoch  21 Batch   18/44   train_loss = 5.217
Epoch  21 Batch   19/44   train_loss = 5.311
Epoch  21 Batch   20/44   train_loss = 5.142
Epoch  21 Batch   21/44   train_loss = 5.237
Epoch  21 Batch   22/44   train_loss = 5.126
Epoch  21 Batch   23/44   train_loss = 5.280
Epoch  21 Batch   24/44   train_loss = 5.174
Epoch  21 Batch   25/44   train_loss = 5.260
Epoch  21 Batch   26/44   train_loss = 5.161
Epoch  21 Batch   27/44   train_loss = 5.230
Epoch  21 Batch   28/44   train_loss = 5.221
Epoch  21 Batch   29/44   train_loss = 5.358
Epoch  21 Batch   30/44   train_loss = 5.320
Epoch  21 Batch   31/44   train_loss = 5.270
Epoch  21 Batch   32/44   train_loss = 5.110
Epoch  21 Batch   33/44   train_loss = 5.314
Epoch  21 Batch   34/44   train_loss = 5.241
Epoch  21 Batch   35/44   train_loss = 5.064
Epoch  21 Batch   36/44   train_loss = 5.228
Epoch  21 Batch   37/44   train_loss = 5.247
Epoch  21 Batch   38/44   train_loss = 5.154
Epoch  21 Batch   39/44   train_loss = 5.255
Epoch  21 Batch   40/44   train_loss = 5.232
Epoch  21 Batch   41/44   train_loss = 5.170
Epoch  21 Batch   42/44   train_loss = 5.168
Epoch  21 Batch   43/44   train_loss = 5.346
Epoch  22 Batch    0/44   train_loss = 5.069
Epoch  22 Batch    1/44   train_loss = 5.104
Epoch  22 Batch    2/44   train_loss = 4.964
Epoch  22 Batch    3/44   train_loss = 5.095
Epoch  22 Batch    4/44   train_loss = 5.049
Epoch  22 Batch    5/44   train_loss = 5.074
Epoch  22 Batch    6/44   train_loss = 5.100
Epoch  22 Batch    7/44   train_loss = 5.276
Epoch  22 Batch    8/44   train_loss = 5.154
Epoch  22 Batch    9/44   train_loss = 5.181
Epoch  22 Batch   10/44   train_loss = 5.236
Epoch  22 Batch   11/44   train_loss = 5.189
Epoch  22 Batch   12/44   train_loss = 5.056
Epoch  22 Batch   13/44   train_loss = 5.157
Epoch  22 Batch   14/44   train_loss = 5.275
Epoch  22 Batch   15/44   train_loss = 5.057
Epoch  22 Batch   16/44   train_loss = 5.143
Epoch  22 Batch   17/44   train_loss = 5.187
Epoch  22 Batch   18/44   train_loss = 5.161
Epoch  22 Batch   19/44   train_loss = 5.252
Epoch  22 Batch   20/44   train_loss = 5.087
Epoch  22 Batch   21/44   train_loss = 5.181
Epoch  22 Batch   22/44   train_loss = 5.064
Epoch  22 Batch   23/44   train_loss = 5.216
Epoch  22 Batch   24/44   train_loss = 5.111
Epoch  22 Batch   25/44   train_loss = 5.202
Epoch  22 Batch   26/44   train_loss = 5.098
Epoch  22 Batch   27/44   train_loss = 5.172
Epoch  22 Batch   28/44   train_loss = 5.161
Epoch  22 Batch   29/44   train_loss = 5.295
Epoch  22 Batch   30/44   train_loss = 5.258
Epoch  22 Batch   31/44   train_loss = 5.211
Epoch  22 Batch   32/44   train_loss = 5.051
Epoch  22 Batch   33/44   train_loss = 5.258
Epoch  22 Batch   34/44   train_loss = 5.175
Epoch  22 Batch   35/44   train_loss = 5.002
Epoch  22 Batch   36/44   train_loss = 5.168
Epoch  22 Batch   37/44   train_loss = 5.189
Epoch  22 Batch   38/44   train_loss = 5.091
Epoch  22 Batch   39/44   train_loss = 5.196
Epoch  22 Batch   40/44   train_loss = 5.177
Epoch  22 Batch   41/44   train_loss = 5.108
Epoch  22 Batch   42/44   train_loss = 5.109
Epoch  22 Batch   43/44   train_loss = 5.288
Epoch  23 Batch    0/44   train_loss = 5.009
Epoch  23 Batch    1/44   train_loss = 5.044
Epoch  23 Batch    2/44   train_loss = 4.905
Epoch  23 Batch    3/44   train_loss = 5.039
Epoch  23 Batch    4/44   train_loss = 4.993
Epoch  23 Batch    5/44   train_loss = 5.013
Epoch  23 Batch    6/44   train_loss = 5.043
Epoch  23 Batch    7/44   train_loss = 5.212
Epoch  23 Batch    8/44   train_loss = 5.094
Epoch  23 Batch    9/44   train_loss = 5.115
Epoch  23 Batch   10/44   train_loss = 5.165
Epoch  23 Batch   11/44   train_loss = 5.120
Epoch  23 Batch   12/44   train_loss = 4.987
Epoch  23 Batch   13/44   train_loss = 5.087
Epoch  23 Batch   14/44   train_loss = 5.213
Epoch  23 Batch   15/44   train_loss = 4.982
Epoch  23 Batch   16/44   train_loss = 5.075
Epoch  23 Batch   17/44   train_loss = 5.118
Epoch  23 Batch   18/44   train_loss = 5.095
Epoch  23 Batch   19/44   train_loss = 5.185
Epoch  23 Batch   20/44   train_loss = 5.022
Epoch  23 Batch   21/44   train_loss = 5.111
Epoch  23 Batch   22/44   train_loss = 4.992
Epoch  23 Batch   23/44   train_loss = 5.138
Epoch  23 Batch   24/44   train_loss = 5.037
Epoch  23 Batch   25/44   train_loss = 5.134
Epoch  23 Batch   26/44   train_loss = 5.017
Epoch  23 Batch   27/44   train_loss = 5.096
Epoch  23 Batch   28/44   train_loss = 5.088
Epoch  23 Batch   29/44   train_loss = 5.217
Epoch  23 Batch   30/44   train_loss = 5.185
Epoch  23 Batch   31/44   train_loss = 5.138
Epoch  23 Batch   32/44   train_loss = 4.987
Epoch  23 Batch   33/44   train_loss = 5.186
Epoch  23 Batch   34/44   train_loss = 5.093
Epoch  23 Batch   35/44   train_loss = 4.915
Epoch  23 Batch   36/44   train_loss = 5.093
Epoch  23 Batch   37/44   train_loss = 5.108
Epoch  23 Batch   38/44   train_loss = 5.008
Epoch  23 Batch   39/44   train_loss = 5.113
Epoch  23 Batch   40/44   train_loss = 5.097
Epoch  23 Batch   41/44   train_loss = 5.028
Epoch  23 Batch   42/44   train_loss = 5.029
Epoch  23 Batch   43/44   train_loss = 5.211
Epoch  24 Batch    0/44   train_loss = 4.924
Epoch  24 Batch    1/44   train_loss = 4.959
Epoch  24 Batch    2/44   train_loss = 4.827
Epoch  24 Batch    3/44   train_loss = 4.959
Epoch  24 Batch    4/44   train_loss = 4.906
Epoch  24 Batch    5/44   train_loss = 4.925
Epoch  24 Batch    6/44   train_loss = 4.958
Epoch  24 Batch    7/44   train_loss = 5.128
Epoch  24 Batch    8/44   train_loss = 5.006
Epoch  24 Batch    9/44   train_loss = 5.030
Epoch  24 Batch   10/44   train_loss = 5.080
Epoch  24 Batch   11/44   train_loss = 5.030
Epoch  24 Batch   12/44   train_loss = 4.896
Epoch  24 Batch   13/44   train_loss = 4.992
Epoch  24 Batch   14/44   train_loss = 5.126
Epoch  24 Batch   15/44   train_loss = 4.888
Epoch  24 Batch   16/44   train_loss = 4.984
Epoch  24 Batch   17/44   train_loss = 5.023
Epoch  24 Batch   18/44   train_loss = 4.999
Epoch  24 Batch   19/44   train_loss = 5.088
Epoch  24 Batch   20/44   train_loss = 4.935
Epoch  24 Batch   21/44   train_loss = 5.016
Epoch  24 Batch   22/44   train_loss = 4.905
Epoch  24 Batch   23/44   train_loss = 5.040
Epoch  24 Batch   24/44   train_loss = 4.943
Epoch  24 Batch   25/44   train_loss = 5.048
Epoch  24 Batch   26/44   train_loss = 4.907
Epoch  24 Batch   27/44   train_loss = 4.994
Epoch  24 Batch   28/44   train_loss = 4.993
Epoch  24 Batch   29/44   train_loss = 5.121
Epoch  24 Batch   30/44   train_loss = 5.091
Epoch  24 Batch   31/44   train_loss = 5.052
Epoch  24 Batch   32/44   train_loss = 4.907
Epoch  24 Batch   33/44   train_loss = 5.096
Epoch  24 Batch   34/44   train_loss = 4.998
Epoch  24 Batch   35/44   train_loss = 4.821
Epoch  24 Batch   36/44   train_loss = 5.009
Epoch  24 Batch   37/44   train_loss = 5.023
Epoch  24 Batch   38/44   train_loss = 4.917
Epoch  24 Batch   39/44   train_loss = 5.018
Epoch  24 Batch   40/44   train_loss = 5.002
Epoch  24 Batch   41/44   train_loss = 4.939
Epoch  24 Batch   42/44   train_loss = 4.938
Epoch  24 Batch   43/44   train_loss = 5.122
Epoch  25 Batch    0/44   train_loss = 4.825
Epoch  25 Batch    1/44   train_loss = 4.871
Epoch  25 Batch    2/44   train_loss = 4.740
Epoch  25 Batch    3/44   train_loss = 4.875
Epoch  25 Batch    4/44   train_loss = 4.813
Epoch  25 Batch    5/44   train_loss = 4.834
Epoch  25 Batch    6/44   train_loss = 4.872
Epoch  25 Batch    7/44   train_loss = 5.038
Epoch  25 Batch    8/44   train_loss = 4.920
Epoch  25 Batch    9/44   train_loss = 4.942
Epoch  25 Batch   10/44   train_loss = 4.995
Epoch  25 Batch   11/44   train_loss = 4.946
Epoch  25 Batch   12/44   train_loss = 4.813
Epoch  25 Batch   13/44   train_loss = 4.899
Epoch  25 Batch   14/44   train_loss = 5.042
Epoch  25 Batch   15/44   train_loss = 4.798
Epoch  25 Batch   16/44   train_loss = 4.905
Epoch  25 Batch   17/44   train_loss = 4.940
Epoch  25 Batch   18/44   train_loss = 4.911
Epoch  25 Batch   19/44   train_loss = 5.008
Epoch  25 Batch   20/44   train_loss = 4.857
Epoch  25 Batch   21/44   train_loss = 4.931
Epoch  25 Batch   22/44   train_loss = 4.834
Epoch  25 Batch   23/44   train_loss = 4.961
Epoch  25 Batch   24/44   train_loss = 4.863
Epoch  25 Batch   25/44   train_loss = 4.973
Epoch  25 Batch   26/44   train_loss = 4.824
Epoch  25 Batch   27/44   train_loss = 4.922
Epoch  25 Batch   28/44   train_loss = 4.914
Epoch  25 Batch   29/44   train_loss = 5.050
Epoch  25 Batch   30/44   train_loss = 5.014
Epoch  25 Batch   31/44   train_loss = 4.982
Epoch  25 Batch   32/44   train_loss = 4.840
Epoch  25 Batch   33/44   train_loss = 5.027
Epoch  25 Batch   34/44   train_loss = 4.923
Epoch  25 Batch   35/44   train_loss = 4.750
Epoch  25 Batch   36/44   train_loss = 4.944
Epoch  25 Batch   37/44   train_loss = 4.951
Epoch  25 Batch   38/44   train_loss = 4.848
Epoch  25 Batch   39/44   train_loss = 4.949
Epoch  25 Batch   40/44   train_loss = 4.938
Epoch  25 Batch   41/44   train_loss = 4.872
Epoch  25 Batch   42/44   train_loss = 4.870
Epoch  25 Batch   43/44   train_loss = 5.051
Epoch  26 Batch    0/44   train_loss = 4.754
Epoch  26 Batch    1/44   train_loss = 4.800
Epoch  26 Batch    2/44   train_loss = 4.667
Epoch  26 Batch    3/44   train_loss = 4.800
Epoch  26 Batch    4/44   train_loss = 4.736
Epoch  26 Batch    5/44   train_loss = 4.763
Epoch  26 Batch    6/44   train_loss = 4.802
Epoch  26 Batch    7/44   train_loss = 4.968
Epoch  26 Batch    8/44   train_loss = 4.852
Epoch  26 Batch    9/44   train_loss = 4.875
Epoch  26 Batch   10/44   train_loss = 4.929
Epoch  26 Batch   11/44   train_loss = 4.881
Epoch  26 Batch   12/44   train_loss = 4.745
Epoch  26 Batch   13/44   train_loss = 4.829
Epoch  26 Batch   14/44   train_loss = 4.979
Epoch  26 Batch   15/44   train_loss = 4.728
Epoch  26 Batch   16/44   train_loss = 4.834
Epoch  26 Batch   17/44   train_loss = 4.871
Epoch  26 Batch   18/44   train_loss = 4.848
Epoch  26 Batch   19/44   train_loss = 4.942
Epoch  26 Batch   20/44   train_loss = 4.799
Epoch  26 Batch   21/44   train_loss = 4.870
Epoch  26 Batch   22/44   train_loss = 4.776
Epoch  26 Batch   23/44   train_loss = 4.896
Epoch  26 Batch   24/44   train_loss = 4.796
Epoch  26 Batch   25/44   train_loss = 4.901
Epoch  26 Batch   26/44   train_loss = 4.752
Epoch  26 Batch   27/44   train_loss = 4.856
Epoch  26 Batch   28/44   train_loss = 4.853
Epoch  26 Batch   29/44   train_loss = 4.983
Epoch  26 Batch   30/44   train_loss = 4.947
Epoch  26 Batch   31/44   train_loss = 4.917
Epoch  26 Batch   32/44   train_loss = 4.777
Epoch  26 Batch   33/44   train_loss = 4.959
Epoch  26 Batch   34/44   train_loss = 4.852
Epoch  26 Batch   35/44   train_loss = 4.688
Epoch  26 Batch   36/44   train_loss = 4.884
Epoch  26 Batch   37/44   train_loss = 4.887
Epoch  26 Batch   38/44   train_loss = 4.785
Epoch  26 Batch   39/44   train_loss = 4.877
Epoch  26 Batch   40/44   train_loss = 4.871
Epoch  26 Batch   41/44   train_loss = 4.802
Epoch  26 Batch   42/44   train_loss = 4.805
Epoch  26 Batch   43/44   train_loss = 4.976
Epoch  27 Batch    0/44   train_loss = 4.685
Epoch  27 Batch    1/44   train_loss = 4.733
Epoch  27 Batch    2/44   train_loss = 4.602
Epoch  27 Batch    3/44   train_loss = 4.735
Epoch  27 Batch    4/44   train_loss = 4.669
Epoch  27 Batch    5/44   train_loss = 4.694
Epoch  27 Batch    6/44   train_loss = 4.736
Epoch  27 Batch    7/44   train_loss = 4.901
Epoch  27 Batch    8/44   train_loss = 4.785
Epoch  27 Batch    9/44   train_loss = 4.812
Epoch  27 Batch   10/44   train_loss = 4.868
Epoch  27 Batch   11/44   train_loss = 4.824
Epoch  27 Batch   12/44   train_loss = 4.694
Epoch  27 Batch   13/44   train_loss = 4.770
Epoch  27 Batch   14/44   train_loss = 4.921
Epoch  27 Batch   15/44   train_loss = 4.672
Epoch  27 Batch   16/44   train_loss = 4.780
Epoch  27 Batch   17/44   train_loss = 4.812
Epoch  27 Batch   18/44   train_loss = 4.786
Epoch  27 Batch   19/44   train_loss = 4.885
Epoch  27 Batch   20/44   train_loss = 4.737
Epoch  27 Batch   21/44   train_loss = 4.810
Epoch  27 Batch   22/44   train_loss = 4.724
Epoch  27 Batch   23/44   train_loss = 4.838
Epoch  27 Batch   24/44   train_loss = 4.737
Epoch  27 Batch   25/44   train_loss = 4.843
Epoch  27 Batch   26/44   train_loss = 4.687
Epoch  27 Batch   27/44   train_loss = 4.798
Epoch  27 Batch   28/44   train_loss = 4.790
Epoch  27 Batch   29/44   train_loss = 4.914
Epoch  27 Batch   30/44   train_loss = 4.879
Epoch  27 Batch   31/44   train_loss = 4.857
Epoch  27 Batch   32/44   train_loss = 4.721
Epoch  27 Batch   33/44   train_loss = 4.895
Epoch  27 Batch   34/44   train_loss = 4.786
Epoch  27 Batch   35/44   train_loss = 4.635
Epoch  27 Batch   36/44   train_loss = 4.826
Epoch  27 Batch   37/44   train_loss = 4.829
Epoch  27 Batch   38/44   train_loss = 4.740
Epoch  27 Batch   39/44   train_loss = 4.822
Epoch  27 Batch   40/44   train_loss = 4.819
Epoch  27 Batch   41/44   train_loss = 4.746
Epoch  27 Batch   42/44   train_loss = 4.754
Epoch  27 Batch   43/44   train_loss = 4.916
Epoch  28 Batch    0/44   train_loss = 4.629
Epoch  28 Batch    1/44   train_loss = 4.678
Epoch  28 Batch    2/44   train_loss = 4.546
Epoch  28 Batch    3/44   train_loss = 4.683
Epoch  28 Batch    4/44   train_loss = 4.614
Epoch  28 Batch    5/44   train_loss = 4.628
Epoch  28 Batch    6/44   train_loss = 4.668
Epoch  28 Batch    7/44   train_loss = 4.840
Epoch  28 Batch    8/44   train_loss = 4.724
Epoch  28 Batch    9/44   train_loss = 4.748
Epoch  28 Batch   10/44   train_loss = 4.798
Epoch  28 Batch   11/44   train_loss = 4.764
Epoch  28 Batch   12/44   train_loss = 4.632
Epoch  28 Batch   13/44   train_loss = 4.708
Epoch  28 Batch   14/44   train_loss = 4.861
Epoch  28 Batch   15/44   train_loss = 4.612
Epoch  28 Batch   16/44   train_loss = 4.721
Epoch  28 Batch   17/44   train_loss = 4.750
Epoch  28 Batch   18/44   train_loss = 4.725
Epoch  28 Batch   19/44   train_loss = 4.826
Epoch  28 Batch   20/44   train_loss = 4.682
Epoch  28 Batch   21/44   train_loss = 4.756
Epoch  28 Batch   22/44   train_loss = 4.669
Epoch  28 Batch   23/44   train_loss = 4.780
Epoch  28 Batch   24/44   train_loss = 4.684
Epoch  28 Batch   25/44   train_loss = 4.784
Epoch  28 Batch   26/44   train_loss = 4.621
Epoch  28 Batch   27/44   train_loss = 4.742
Epoch  28 Batch   28/44   train_loss = 4.735
Epoch  28 Batch   29/44   train_loss = 4.844
Epoch  28 Batch   30/44   train_loss = 4.814
Epoch  28 Batch   31/44   train_loss = 4.805
Epoch  28 Batch   32/44   train_loss = 4.671
Epoch  28 Batch   33/44   train_loss = 4.833
Epoch  28 Batch   34/44   train_loss = 4.718
Epoch  28 Batch   35/44   train_loss = 4.591
Epoch  28 Batch   36/44   train_loss = 4.777
Epoch  28 Batch   37/44   train_loss = 4.771
Epoch  28 Batch   38/44   train_loss = 4.684
Epoch  28 Batch   39/44   train_loss = 4.765
Epoch  28 Batch   40/44   train_loss = 4.779
Epoch  28 Batch   41/44   train_loss = 4.691
Epoch  28 Batch   42/44   train_loss = 4.692
Epoch  28 Batch   43/44   train_loss = 4.860
Epoch  29 Batch    0/44   train_loss = 4.589
Epoch  29 Batch    1/44   train_loss = 4.646
Epoch  29 Batch    2/44   train_loss = 4.497
Epoch  29 Batch    3/44   train_loss = 4.626
Epoch  29 Batch    4/44   train_loss = 4.567
Epoch  29 Batch    5/44   train_loss = 4.588
Epoch  29 Batch    6/44   train_loss = 4.623
Epoch  29 Batch    7/44   train_loss = 4.785
Epoch  29 Batch    8/44   train_loss = 4.674
Epoch  29 Batch    9/44   train_loss = 4.705
Epoch  29 Batch   10/44   train_loss = 4.747
Epoch  29 Batch   11/44   train_loss = 4.707
Epoch  29 Batch   12/44   train_loss = 4.578
Epoch  29 Batch   13/44   train_loss = 4.649
Epoch  29 Batch   14/44   train_loss = 4.817
Epoch  29 Batch   15/44   train_loss = 4.566
Epoch  29 Batch   16/44   train_loss = 4.666
Epoch  29 Batch   17/44   train_loss = 4.695
Epoch  29 Batch   18/44   train_loss = 4.681
Epoch  29 Batch   19/44   train_loss = 4.775
Epoch  29 Batch   20/44   train_loss = 4.622
Epoch  29 Batch   21/44   train_loss = 4.699
Epoch  29 Batch   22/44   train_loss = 4.622
Epoch  29 Batch   23/44   train_loss = 4.736
Epoch  29 Batch   24/44   train_loss = 4.641
Epoch  29 Batch   25/44   train_loss = 4.732
Epoch  29 Batch   26/44   train_loss = 4.559
Epoch  29 Batch   27/44   train_loss = 4.689
Epoch  29 Batch   28/44   train_loss = 4.692
Epoch  29 Batch   29/44   train_loss = 4.796
Epoch  29 Batch   30/44   train_loss = 4.755
Epoch  29 Batch   31/44   train_loss = 4.755
Epoch  29 Batch   32/44   train_loss = 4.630
Epoch  29 Batch   33/44   train_loss = 4.792
Epoch  29 Batch   34/44   train_loss = 4.666
Epoch  29 Batch   35/44   train_loss = 4.527
Epoch  29 Batch   36/44   train_loss = 4.730
Epoch  29 Batch   37/44   train_loss = 4.737
Epoch  29 Batch   38/44   train_loss = 4.632
Epoch  29 Batch   39/44   train_loss = 4.706
Epoch  29 Batch   40/44   train_loss = 4.717
Epoch  29 Batch   41/44   train_loss = 4.653
Epoch  29 Batch   42/44   train_loss = 4.650
Epoch  29 Batch   43/44   train_loss = 4.810
Epoch  30 Batch    0/44   train_loss = 4.521
Epoch  30 Batch    1/44   train_loss = 4.591
Epoch  30 Batch    2/44   train_loss = 4.466
Epoch  30 Batch    3/44   train_loss = 4.594
Epoch  30 Batch    4/44   train_loss = 4.517
Epoch  30 Batch    5/44   train_loss = 4.524
Epoch  30 Batch    6/44   train_loss = 4.573
Epoch  30 Batch    7/44   train_loss = 4.749
Epoch  30 Batch    8/44   train_loss = 4.634
Epoch  30 Batch    9/44   train_loss = 4.656
Epoch  30 Batch   10/44   train_loss = 4.691
Epoch  30 Batch   11/44   train_loss = 4.655
Epoch  30 Batch   12/44   train_loss = 4.539
Epoch  30 Batch   13/44   train_loss = 4.607
Epoch  30 Batch   14/44   train_loss = 4.762
Epoch  30 Batch   15/44   train_loss = 4.519
Epoch  30 Batch   16/44   train_loss = 4.619
Epoch  30 Batch   17/44   train_loss = 4.658
Epoch  30 Batch   18/44   train_loss = 4.632
Epoch  30 Batch   19/44   train_loss = 4.714
Epoch  30 Batch   20/44   train_loss = 4.568
Epoch  30 Batch   21/44   train_loss = 4.646
Epoch  30 Batch   22/44   train_loss = 4.580
Epoch  30 Batch   23/44   train_loss = 4.680
Epoch  30 Batch   24/44   train_loss = 4.581
Epoch  30 Batch   25/44   train_loss = 4.678
Epoch  30 Batch   26/44   train_loss = 4.507
Epoch  30 Batch   27/44   train_loss = 4.629
Epoch  30 Batch   28/44   train_loss = 4.640
Epoch  30 Batch   29/44   train_loss = 4.739
Epoch  30 Batch   30/44   train_loss = 4.704
Epoch  30 Batch   31/44   train_loss = 4.708
Epoch  30 Batch   32/44   train_loss = 4.569
Epoch  30 Batch   33/44   train_loss = 4.729
Epoch  30 Batch   34/44   train_loss = 4.609
Epoch  30 Batch   35/44   train_loss = 4.472
Epoch  30 Batch   36/44   train_loss = 4.673
Epoch  30 Batch   37/44   train_loss = 4.666
Epoch  30 Batch   38/44   train_loss = 4.581
Epoch  30 Batch   39/44   train_loss = 4.663
Epoch  30 Batch   40/44   train_loss = 4.653
Epoch  30 Batch   41/44   train_loss = 4.584
Epoch  30 Batch   42/44   train_loss = 4.588
Epoch  30 Batch   43/44   train_loss = 4.755
Epoch  31 Batch    0/44   train_loss = 4.475
Epoch  31 Batch    1/44   train_loss = 4.536
Epoch  31 Batch    2/44   train_loss = 4.402
Epoch  31 Batch    3/44   train_loss = 4.534
Epoch  31 Batch    4/44   train_loss = 4.463
Epoch  31 Batch    5/44   train_loss = 4.477
Epoch  31 Batch    6/44   train_loss = 4.524
Epoch  31 Batch    7/44   train_loss = 4.681
Epoch  31 Batch    8/44   train_loss = 4.565
Epoch  31 Batch    9/44   train_loss = 4.606
Epoch  31 Batch   10/44   train_loss = 4.646
Epoch  31 Batch   11/44   train_loss = 4.606
Epoch  31 Batch   12/44   train_loss = 4.481
Epoch  31 Batch   13/44   train_loss = 4.544
Epoch  31 Batch   14/44   train_loss = 4.704
Epoch  31 Batch   15/44   train_loss = 4.478
Epoch  31 Batch   16/44   train_loss = 4.568
Epoch  31 Batch   17/44   train_loss = 4.597
Epoch  31 Batch   18/44   train_loss = 4.581
Epoch  31 Batch   19/44   train_loss = 4.663
Epoch  31 Batch   20/44   train_loss = 4.520
Epoch  31 Batch   21/44   train_loss = 4.587
Epoch  31 Batch   22/44   train_loss = 4.528
Epoch  31 Batch   23/44   train_loss = 4.629
Epoch  31 Batch   24/44   train_loss = 4.530
Epoch  31 Batch   25/44   train_loss = 4.628
Epoch  31 Batch   26/44   train_loss = 4.454
Epoch  31 Batch   27/44   train_loss = 4.573
Epoch  31 Batch   28/44   train_loss = 4.589
Epoch  31 Batch   29/44   train_loss = 4.681
Epoch  31 Batch   30/44   train_loss = 4.641
Epoch  31 Batch   31/44   train_loss = 4.650
Epoch  31 Batch   32/44   train_loss = 4.521
Epoch  31 Batch   33/44   train_loss = 4.673
Epoch  31 Batch   34/44   train_loss = 4.551
Epoch  31 Batch   35/44   train_loss = 4.426
Epoch  31 Batch   36/44   train_loss = 4.627
Epoch  31 Batch   37/44   train_loss = 4.616
Epoch  31 Batch   38/44   train_loss = 4.534
Epoch  31 Batch   39/44   train_loss = 4.598
Epoch  31 Batch   40/44   train_loss = 4.603
Epoch  31 Batch   41/44   train_loss = 4.537
Epoch  31 Batch   42/44   train_loss = 4.531
Epoch  31 Batch   43/44   train_loss = 4.689
Epoch  32 Batch    0/44   train_loss = 4.424
Epoch  32 Batch    1/44   train_loss = 4.487
Epoch  32 Batch    2/44   train_loss = 4.357
Epoch  32 Batch    3/44   train_loss = 4.486
Epoch  32 Batch    4/44   train_loss = 4.412
Epoch  32 Batch    5/44   train_loss = 4.424
Epoch  32 Batch    6/44   train_loss = 4.469
Epoch  32 Batch    7/44   train_loss = 4.630
Epoch  32 Batch    8/44   train_loss = 4.511
Epoch  32 Batch    9/44   train_loss = 4.548
Epoch  32 Batch   10/44   train_loss = 4.586
Epoch  32 Batch   11/44   train_loss = 4.548
Epoch  32 Batch   12/44   train_loss = 4.429
Epoch  32 Batch   13/44   train_loss = 4.490
Epoch  32 Batch   14/44   train_loss = 4.652
Epoch  32 Batch   15/44   train_loss = 4.428
Epoch  32 Batch   16/44   train_loss = 4.518
Epoch  32 Batch   17/44   train_loss = 4.547
Epoch  32 Batch   18/44   train_loss = 4.531
Epoch  32 Batch   19/44   train_loss = 4.608
Epoch  32 Batch   20/44   train_loss = 4.476
Epoch  32 Batch   21/44   train_loss = 4.538
Epoch  32 Batch   22/44   train_loss = 4.484
Epoch  32 Batch   23/44   train_loss = 4.580
Epoch  32 Batch   24/44   train_loss = 4.485
Epoch  32 Batch   25/44   train_loss = 4.578
Epoch  32 Batch   26/44   train_loss = 4.404
Epoch  32 Batch   27/44   train_loss = 4.526
Epoch  32 Batch   28/44   train_loss = 4.537
Epoch  32 Batch   29/44   train_loss = 4.625
Epoch  32 Batch   30/44   train_loss = 4.581
Epoch  32 Batch   31/44   train_loss = 4.601
Epoch  32 Batch   32/44   train_loss = 4.475
Epoch  32 Batch   33/44   train_loss = 4.622
Epoch  32 Batch   34/44   train_loss = 4.496
Epoch  32 Batch   35/44   train_loss = 4.377
Epoch  32 Batch   36/44   train_loss = 4.583
Epoch  32 Batch   37/44   train_loss = 4.568
Epoch  32 Batch   38/44   train_loss = 4.486
Epoch  32 Batch   39/44   train_loss = 4.546
Epoch  32 Batch   40/44   train_loss = 4.553
Epoch  32 Batch   41/44   train_loss = 4.495
Epoch  32 Batch   42/44   train_loss = 4.485
Epoch  32 Batch   43/44   train_loss = 4.638
Epoch  33 Batch    0/44   train_loss = 4.376
Epoch  33 Batch    1/44   train_loss = 4.445
Epoch  33 Batch    2/44   train_loss = 4.316
Epoch  33 Batch    3/44   train_loss = 4.441
Epoch  33 Batch    4/44   train_loss = 4.366
Epoch  33 Batch    5/44   train_loss = 4.376
Epoch  33 Batch    6/44   train_loss = 4.421
Epoch  33 Batch    7/44   train_loss = 4.580
Epoch  33 Batch    8/44   train_loss = 4.458
Epoch  33 Batch    9/44   train_loss = 4.497
Epoch  33 Batch   10/44   train_loss = 4.534
Epoch  33 Batch   11/44   train_loss = 4.497
Epoch  33 Batch   12/44   train_loss = 4.379
Epoch  33 Batch   13/44   train_loss = 4.440
Epoch  33 Batch   14/44   train_loss = 4.599
Epoch  33 Batch   15/44   train_loss = 4.377
Epoch  33 Batch   16/44   train_loss = 4.466
Epoch  33 Batch   17/44   train_loss = 4.501
Epoch  33 Batch   18/44   train_loss = 4.486
Epoch  33 Batch   19/44   train_loss = 4.552
Epoch  33 Batch   20/44   train_loss = 4.427
Epoch  33 Batch   21/44   train_loss = 4.487
Epoch  33 Batch   22/44   train_loss = 4.441
Epoch  33 Batch   23/44   train_loss = 4.533
Epoch  33 Batch   24/44   train_loss = 4.439
Epoch  33 Batch   25/44   train_loss = 4.533
Epoch  33 Batch   26/44   train_loss = 4.358
Epoch  33 Batch   27/44   train_loss = 4.481
Epoch  33 Batch   28/44   train_loss = 4.493
Epoch  33 Batch   29/44   train_loss = 4.579
Epoch  33 Batch   30/44   train_loss = 4.531
Epoch  33 Batch   31/44   train_loss = 4.556
Epoch  33 Batch   32/44   train_loss = 4.431
Epoch  33 Batch   33/44   train_loss = 4.575
Epoch  33 Batch   34/44   train_loss = 4.447
Epoch  33 Batch   35/44   train_loss = 4.332
Epoch  33 Batch   36/44   train_loss = 4.537
Epoch  33 Batch   37/44   train_loss = 4.519
Epoch  33 Batch   38/44   train_loss = 4.439
Epoch  33 Batch   39/44   train_loss = 4.496
Epoch  33 Batch   40/44   train_loss = 4.500
Epoch  33 Batch   41/44   train_loss = 4.447
Epoch  33 Batch   42/44   train_loss = 4.437
Epoch  33 Batch   43/44   train_loss = 4.587
Epoch  34 Batch    0/44   train_loss = 4.328
Epoch  34 Batch    1/44   train_loss = 4.395
Epoch  34 Batch    2/44   train_loss = 4.270
Epoch  34 Batch    3/44   train_loss = 4.395
Epoch  34 Batch    4/44   train_loss = 4.324
Epoch  34 Batch    5/44   train_loss = 4.332
Epoch  34 Batch    6/44   train_loss = 4.374
Epoch  34 Batch    7/44   train_loss = 4.533
Epoch  34 Batch    8/44   train_loss = 4.412
Epoch  34 Batch    9/44   train_loss = 4.447
Epoch  34 Batch   10/44   train_loss = 4.482
Epoch  34 Batch   11/44   train_loss = 4.448
Epoch  34 Batch   12/44   train_loss = 4.331
Epoch  34 Batch   13/44   train_loss = 4.390
Epoch  34 Batch   14/44   train_loss = 4.548
Epoch  34 Batch   15/44   train_loss = 4.332
Epoch  34 Batch   16/44   train_loss = 4.422
Epoch  34 Batch   17/44   train_loss = 4.453
Epoch  34 Batch   18/44   train_loss = 4.440
Epoch  34 Batch   19/44   train_loss = 4.501
Epoch  34 Batch   20/44   train_loss = 4.377
Epoch  34 Batch   21/44   train_loss = 4.437
Epoch  34 Batch   22/44   train_loss = 4.398
Epoch  34 Batch   23/44   train_loss = 4.476
Epoch  34 Batch   24/44   train_loss = 4.387
Epoch  34 Batch   25/44   train_loss = 4.481
Epoch  34 Batch   26/44   train_loss = 4.307
Epoch  34 Batch   27/44   train_loss = 4.432
Epoch  34 Batch   28/44   train_loss = 4.446
Epoch  34 Batch   29/44   train_loss = 4.531
Epoch  34 Batch   30/44   train_loss = 4.478
Epoch  34 Batch   31/44   train_loss = 4.508
Epoch  34 Batch   32/44   train_loss = 4.383
Epoch  34 Batch   33/44   train_loss = 4.525
Epoch  34 Batch   34/44   train_loss = 4.396
Epoch  34 Batch   35/44   train_loss = 4.289
Epoch  34 Batch   36/44   train_loss = 4.493
Epoch  34 Batch   37/44   train_loss = 4.470
Epoch  34 Batch   38/44   train_loss = 4.391
Epoch  34 Batch   39/44   train_loss = 4.452
Epoch  34 Batch   40/44   train_loss = 4.448
Epoch  34 Batch   41/44   train_loss = 4.395
Epoch  34 Batch   42/44   train_loss = 4.390
Epoch  34 Batch   43/44   train_loss = 4.537
Epoch  35 Batch    0/44   train_loss = 4.283
Epoch  35 Batch    1/44   train_loss = 4.346
Epoch  35 Batch    2/44   train_loss = 4.226
Epoch  35 Batch    3/44   train_loss = 4.351
Epoch  35 Batch    4/44   train_loss = 4.280
Epoch  35 Batch    5/44   train_loss = 4.286
Epoch  35 Batch    6/44   train_loss = 4.326
Epoch  35 Batch    7/44   train_loss = 4.482
Epoch  35 Batch    8/44   train_loss = 4.366
Epoch  35 Batch    9/44   train_loss = 4.403
Epoch  35 Batch   10/44   train_loss = 4.437
Epoch  35 Batch   11/44   train_loss = 4.397
Epoch  35 Batch   12/44   train_loss = 4.285
Epoch  35 Batch   13/44   train_loss = 4.339
Epoch  35 Batch   14/44   train_loss = 4.501
Epoch  35 Batch   15/44   train_loss = 4.288
Epoch  35 Batch   16/44   train_loss = 4.376
Epoch  35 Batch   17/44   train_loss = 4.407
Epoch  35 Batch   18/44   train_loss = 4.398
Epoch  35 Batch   19/44   train_loss = 4.453
Epoch  35 Batch   20/44   train_loss = 4.336
Epoch  35 Batch   21/44   train_loss = 4.393
Epoch  35 Batch   22/44   train_loss = 4.359
Epoch  35 Batch   23/44   train_loss = 4.431
Epoch  35 Batch   24/44   train_loss = 4.339
Epoch  35 Batch   25/44   train_loss = 4.433
Epoch  35 Batch   26/44   train_loss = 4.264
Epoch  35 Batch   27/44   train_loss = 4.388
Epoch  35 Batch   28/44   train_loss = 4.400
Epoch  35 Batch   29/44   train_loss = 4.482
Epoch  35 Batch   30/44   train_loss = 4.431
Epoch  35 Batch   31/44   train_loss = 4.466
Epoch  35 Batch   32/44   train_loss = 4.342
Epoch  35 Batch   33/44   train_loss = 4.482
Epoch  35 Batch   34/44   train_loss = 4.354
Epoch  35 Batch   35/44   train_loss = 4.250
Epoch  35 Batch   36/44   train_loss = 4.452
Epoch  35 Batch   37/44   train_loss = 4.427
Epoch  35 Batch   38/44   train_loss = 4.350
Epoch  35 Batch   39/44   train_loss = 4.409
Epoch  35 Batch   40/44   train_loss = 4.402
Epoch  35 Batch   41/44   train_loss = 4.349
Epoch  35 Batch   42/44   train_loss = 4.344
Epoch  35 Batch   43/44   train_loss = 4.492
Epoch  36 Batch    0/44   train_loss = 4.245
Epoch  36 Batch    1/44   train_loss = 4.302
Epoch  36 Batch    2/44   train_loss = 4.183
Epoch  36 Batch    3/44   train_loss = 4.311
Epoch  36 Batch    4/44   train_loss = 4.243
Epoch  36 Batch    5/44   train_loss = 4.245
Epoch  36 Batch    6/44   train_loss = 4.284
Epoch  36 Batch    7/44   train_loss = 4.433
Epoch  36 Batch    8/44   train_loss = 4.321
Epoch  36 Batch    9/44   train_loss = 4.365
Epoch  36 Batch   10/44   train_loss = 4.397
Epoch  36 Batch   11/44   train_loss = 4.349
Epoch  36 Batch   12/44   train_loss = 4.244
Epoch  36 Batch   13/44   train_loss = 4.300
Epoch  36 Batch   14/44   train_loss = 4.462
Epoch  36 Batch   15/44   train_loss = 4.249
Epoch  36 Batch   16/44   train_loss = 4.331
Epoch  36 Batch   17/44   train_loss = 4.368
Epoch  36 Batch   18/44   train_loss = 4.364
Epoch  36 Batch   19/44   train_loss = 4.415
Epoch  36 Batch   20/44   train_loss = 4.294
Epoch  36 Batch   21/44   train_loss = 4.351
Epoch  36 Batch   22/44   train_loss = 4.330
Epoch  36 Batch   23/44   train_loss = 4.405
Epoch  36 Batch   24/44   train_loss = 4.298
Epoch  36 Batch   25/44   train_loss = 4.391
Epoch  36 Batch   26/44   train_loss = 4.229
Epoch  36 Batch   27/44   train_loss = 4.368
Epoch  36 Batch   28/44   train_loss = 4.358
Epoch  36 Batch   29/44   train_loss = 4.436
Epoch  36 Batch   30/44   train_loss = 4.381
Epoch  36 Batch   31/44   train_loss = 4.430
Epoch  36 Batch   32/44   train_loss = 4.308
Epoch  36 Batch   33/44   train_loss = 4.442
Epoch  36 Batch   34/44   train_loss = 4.303
Epoch  36 Batch   35/44   train_loss = 4.210
Epoch  36 Batch   36/44   train_loss = 4.421
Epoch  36 Batch   37/44   train_loss = 4.391
Epoch  36 Batch   38/44   train_loss = 4.311
Epoch  36 Batch   39/44   train_loss = 4.367
Epoch  36 Batch   40/44   train_loss = 4.359
Epoch  36 Batch   41/44   train_loss = 4.309
Epoch  36 Batch   42/44   train_loss = 4.294
Epoch  36 Batch   43/44   train_loss = 4.443
Epoch  37 Batch    0/44   train_loss = 4.209
Epoch  37 Batch    1/44   train_loss = 4.265
Epoch  37 Batch    2/44   train_loss = 4.145
Epoch  37 Batch    3/44   train_loss = 4.270
Epoch  37 Batch    4/44   train_loss = 4.197
Epoch  37 Batch    5/44   train_loss = 4.209
Epoch  37 Batch    6/44   train_loss = 4.253
Epoch  37 Batch    7/44   train_loss = 4.392
Epoch  37 Batch    8/44   train_loss = 4.268
Epoch  37 Batch    9/44   train_loss = 4.317
Epoch  37 Batch   10/44   train_loss = 4.366
Epoch  37 Batch   11/44   train_loss = 4.317
Epoch  37 Batch   12/44   train_loss = 4.200
Epoch  37 Batch   13/44   train_loss = 4.241
Epoch  37 Batch   14/44   train_loss = 4.419
Epoch  37 Batch   15/44   train_loss = 4.221
Epoch  37 Batch   16/44   train_loss = 4.301
Epoch  37 Batch   17/44   train_loss = 4.331
Epoch  37 Batch   18/44   train_loss = 4.318
Epoch  37 Batch   19/44   train_loss = 4.375
Epoch  37 Batch   20/44   train_loss = 4.274
Epoch  37 Batch   21/44   train_loss = 4.311
Epoch  37 Batch   22/44   train_loss = 4.290
Epoch  37 Batch   23/44   train_loss = 4.369
Epoch  37 Batch   24/44   train_loss = 4.272
Epoch  37 Batch   25/44   train_loss = 4.364
Epoch  37 Batch   26/44   train_loss = 4.192
Epoch  37 Batch   27/44   train_loss = 4.323
Epoch  37 Batch   28/44   train_loss = 4.333
Epoch  37 Batch   29/44   train_loss = 4.427
Epoch  37 Batch   30/44   train_loss = 4.348
Epoch  37 Batch   31/44   train_loss = 4.387
Epoch  37 Batch   32/44   train_loss = 4.266
Epoch  37 Batch   33/44   train_loss = 4.418
Epoch  37 Batch   34/44   train_loss = 4.285
Epoch  37 Batch   35/44   train_loss = 4.173
Epoch  37 Batch   36/44   train_loss = 4.373
Epoch  37 Batch   37/44   train_loss = 4.338
Epoch  37 Batch   38/44   train_loss = 4.275
Epoch  37 Batch   39/44   train_loss = 4.336
Epoch  37 Batch   40/44   train_loss = 4.330
Epoch  37 Batch   41/44   train_loss = 4.268
Epoch  37 Batch   42/44   train_loss = 4.243
Epoch  37 Batch   43/44   train_loss = 4.386
Epoch  38 Batch    0/44   train_loss = 4.163
Epoch  38 Batch    1/44   train_loss = 4.240
Epoch  38 Batch    2/44   train_loss = 4.121
Epoch  38 Batch    3/44   train_loss = 4.231
Epoch  38 Batch    4/44   train_loss = 4.151
Epoch  38 Batch    5/44   train_loss = 4.163
Epoch  38 Batch    6/44   train_loss = 4.212
Epoch  38 Batch    7/44   train_loss = 4.357
Epoch  38 Batch    8/44   train_loss = 4.239
Epoch  38 Batch    9/44   train_loss = 4.269
Epoch  38 Batch   10/44   train_loss = 4.307
Epoch  38 Batch   11/44   train_loss = 4.262
Epoch  38 Batch   12/44   train_loss = 4.169
Epoch  38 Batch   13/44   train_loss = 4.213
Epoch  38 Batch   14/44   train_loss = 4.381
Epoch  38 Batch   15/44   train_loss = 4.169
Epoch  38 Batch   16/44   train_loss = 4.254
Epoch  38 Batch   17/44   train_loss = 4.295
Epoch  38 Batch   18/44   train_loss = 4.295
Epoch  38 Batch   19/44   train_loss = 4.346
Epoch  38 Batch   20/44   train_loss = 4.244
Epoch  38 Batch   21/44   train_loss = 4.271
Epoch  38 Batch   22/44   train_loss = 4.249
Epoch  38 Batch   23/44   train_loss = 4.324
Epoch  38 Batch   24/44   train_loss = 4.244
Epoch  38 Batch   25/44   train_loss = 4.351
Epoch  38 Batch   26/44   train_loss = 4.174
Epoch  38 Batch   27/44   train_loss = 4.279
Epoch  38 Batch   28/44   train_loss = 4.280
Epoch  38 Batch   29/44   train_loss = 4.368
Epoch  38 Batch   30/44   train_loss = 4.321
Epoch  38 Batch   31/44   train_loss = 4.398
Epoch  38 Batch   32/44   train_loss = 4.252
Epoch  38 Batch   33/44   train_loss = 4.358
Epoch  38 Batch   34/44   train_loss = 4.221
Epoch  38 Batch   35/44   train_loss = 4.131
Epoch  38 Batch   36/44   train_loss = 4.356
Epoch  38 Batch   37/44   train_loss = 4.325
Epoch  38 Batch   38/44   train_loss = 4.250
Epoch  38 Batch   39/44   train_loss = 4.290
Epoch  38 Batch   40/44   train_loss = 4.278
Epoch  38 Batch   41/44   train_loss = 4.227
Epoch  38 Batch   42/44   train_loss = 4.218
Epoch  38 Batch   43/44   train_loss = 4.353
Epoch  39 Batch    0/44   train_loss = 4.129
Epoch  39 Batch    1/44   train_loss = 4.195
Epoch  39 Batch    2/44   train_loss = 4.077
Epoch  39 Batch    3/44   train_loss = 4.190
Epoch  39 Batch    4/44   train_loss = 4.115
Epoch  39 Batch    5/44   train_loss = 4.129
Epoch  39 Batch    6/44   train_loss = 4.187
Epoch  39 Batch    7/44   train_loss = 4.324
Epoch  39 Batch    8/44   train_loss = 4.192
Epoch  39 Batch    9/44   train_loss = 4.219
Epoch  39 Batch   10/44   train_loss = 4.266
Epoch  39 Batch   11/44   train_loss = 4.231
Epoch  39 Batch   12/44   train_loss = 4.141
Epoch  39 Batch   13/44   train_loss = 4.166
Epoch  39 Batch   14/44   train_loss = 4.325
Epoch  39 Batch   15/44   train_loss = 4.117
Epoch  39 Batch   16/44   train_loss = 4.215
Epoch  39 Batch   17/44   train_loss = 4.267
Epoch  39 Batch   18/44   train_loss = 4.262
Epoch  39 Batch   19/44   train_loss = 4.296
Epoch  39 Batch   20/44   train_loss = 4.183
Epoch  39 Batch   21/44   train_loss = 4.207
Epoch  39 Batch   22/44   train_loss = 4.205
Epoch  39 Batch   23/44   train_loss = 4.292
Epoch  39 Batch   24/44   train_loss = 4.205
Epoch  39 Batch   25/44   train_loss = 4.288
Epoch  39 Batch   26/44   train_loss = 4.101
Epoch  39 Batch   27/44   train_loss = 4.222
Epoch  39 Batch   28/44   train_loss = 4.246
Epoch  39 Batch   29/44   train_loss = 4.327
Epoch  39 Batch   30/44   train_loss = 4.266
Epoch  39 Batch   31/44   train_loss = 4.314
Epoch  39 Batch   32/44   train_loss = 4.178
Epoch  39 Batch   33/44   train_loss = 4.311
Epoch  39 Batch   34/44   train_loss = 4.187
Epoch  39 Batch   35/44   train_loss = 4.104
Epoch  39 Batch   36/44   train_loss = 4.315
Epoch  39 Batch   37/44   train_loss = 4.254
Epoch  39 Batch   38/44   train_loss = 4.188
Epoch  39 Batch   39/44   train_loss = 4.225
Epoch  39 Batch   40/44   train_loss = 4.239
Epoch  39 Batch   41/44   train_loss = 4.188
Epoch  39 Batch   42/44   train_loss = 4.171
Epoch  39 Batch   43/44   train_loss = 4.289
Epoch  40 Batch    0/44   train_loss = 4.062
Epoch  40 Batch    1/44   train_loss = 4.144
Epoch  40 Batch    2/44   train_loss = 4.044
Epoch  40 Batch    3/44   train_loss = 4.168
Epoch  40 Batch    4/44   train_loss = 4.074
Epoch  40 Batch    5/44   train_loss = 4.079
Epoch  40 Batch    6/44   train_loss = 4.129
Epoch  40 Batch    7/44   train_loss = 4.267
Epoch  40 Batch    8/44   train_loss = 4.157
Epoch  40 Batch    9/44   train_loss = 4.191
Epoch  40 Batch   10/44   train_loss = 4.213
Epoch  40 Batch   11/44   train_loss = 4.183
Epoch  40 Batch   12/44   train_loss = 4.082
Epoch  40 Batch   13/44   train_loss = 4.114
Epoch  40 Batch   14/44   train_loss = 4.288
Epoch  40 Batch   15/44   train_loss = 4.077
Epoch  40 Batch   16/44   train_loss = 4.159
Epoch  40 Batch   17/44   train_loss = 4.195
Epoch  40 Batch   18/44   train_loss = 4.197
Epoch  40 Batch   19/44   train_loss = 4.234
Epoch  40 Batch   20/44   train_loss = 4.138
Epoch  40 Batch   21/44   train_loss = 4.163
Epoch  40 Batch   22/44   train_loss = 4.146
Epoch  40 Batch   23/44   train_loss = 4.220
Epoch  40 Batch   24/44   train_loss = 4.137
Epoch  40 Batch   25/44   train_loss = 4.236
Epoch  40 Batch   26/44   train_loss = 4.060
Epoch  40 Batch   27/44   train_loss = 4.181
Epoch  40 Batch   28/44   train_loss = 4.183
Epoch  40 Batch   29/44   train_loss = 4.253
Epoch  40 Batch   30/44   train_loss = 4.207
Epoch  40 Batch   31/44   train_loss = 4.274
Epoch  40 Batch   32/44   train_loss = 4.146
Epoch  40 Batch   33/44   train_loss = 4.269
Epoch  40 Batch   34/44   train_loss = 4.126
Epoch  40 Batch   35/44   train_loss = 4.049
Epoch  40 Batch   36/44   train_loss = 4.269
Epoch  40 Batch   37/44   train_loss = 4.222
Epoch  40 Batch   38/44   train_loss = 4.164
Epoch  40 Batch   39/44   train_loss = 4.173
Epoch  40 Batch   40/44   train_loss = 4.182
Epoch  40 Batch   41/44   train_loss = 4.137
Epoch  40 Batch   42/44   train_loss = 4.122
Epoch  40 Batch   43/44   train_loss = 4.246
Epoch  41 Batch    0/44   train_loss = 4.025
Epoch  41 Batch    1/44   train_loss = 4.100
Epoch  41 Batch    2/44   train_loss = 3.993
Epoch  41 Batch    3/44   train_loss = 4.108
Epoch  41 Batch    4/44   train_loss = 4.026
Epoch  41 Batch    5/44   train_loss = 4.045
Epoch  41 Batch    6/44   train_loss = 4.098
Epoch  41 Batch    7/44   train_loss = 4.216
Epoch  41 Batch    8/44   train_loss = 4.092
Epoch  41 Batch    9/44   train_loss = 4.133
Epoch  41 Batch   10/44   train_loss = 4.162
Epoch  41 Batch   11/44   train_loss = 4.143
Epoch  41 Batch   12/44   train_loss = 4.038
Epoch  41 Batch   13/44   train_loss = 4.061
Epoch  41 Batch   14/44   train_loss = 4.230
Epoch  41 Batch   15/44   train_loss = 4.033
Epoch  41 Batch   16/44   train_loss = 4.122
Epoch  41 Batch   17/44   train_loss = 4.159
Epoch  41 Batch   18/44   train_loss = 4.154
Epoch  41 Batch   19/44   train_loss = 4.178
Epoch  41 Batch   20/44   train_loss = 4.083
Epoch  41 Batch   21/44   train_loss = 4.113
Epoch  41 Batch   22/44   train_loss = 4.105
Epoch  41 Batch   23/44   train_loss = 4.170
Epoch  41 Batch   24/44   train_loss = 4.088
Epoch  41 Batch   25/44   train_loss = 4.180
Epoch  41 Batch   26/44   train_loss = 4.010
Epoch  41 Batch   27/44   train_loss = 4.140
Epoch  41 Batch   28/44   train_loss = 4.142
Epoch  41 Batch   29/44   train_loss = 4.205
Epoch  41 Batch   30/44   train_loss = 4.144
Epoch  41 Batch   31/44   train_loss = 4.212
Epoch  41 Batch   32/44   train_loss = 4.098
Epoch  41 Batch   33/44   train_loss = 4.230
Epoch  41 Batch   34/44   train_loss = 4.088
Epoch  41 Batch   35/44   train_loss = 4.006
Epoch  41 Batch   36/44   train_loss = 4.213
Epoch  41 Batch   37/44   train_loss = 4.170
Epoch  41 Batch   38/44   train_loss = 4.121
Epoch  41 Batch   39/44   train_loss = 4.130
Epoch  41 Batch   40/44   train_loss = 4.145
Epoch  41 Batch   41/44   train_loss = 4.094
Epoch  41 Batch   42/44   train_loss = 4.069
Epoch  41 Batch   43/44   train_loss = 4.195
Epoch  42 Batch    0/44   train_loss = 3.982
Epoch  42 Batch    1/44   train_loss = 4.066
Epoch  42 Batch    2/44   train_loss = 3.959
Epoch  42 Batch    3/44   train_loss = 4.060
Epoch  42 Batch    4/44   train_loss = 3.973
Epoch  42 Batch    5/44   train_loss = 3.996
Epoch  42 Batch    6/44   train_loss = 4.056
Epoch  42 Batch    7/44   train_loss = 4.178
Epoch  42 Batch    8/44   train_loss = 4.053
Epoch  42 Batch    9/44   train_loss = 4.085
Epoch  42 Batch   10/44   train_loss = 4.104
Epoch  42 Batch   11/44   train_loss = 4.085
Epoch  42 Batch   12/44   train_loss = 3.992
Epoch  42 Batch   13/44   train_loss = 4.021
Epoch  42 Batch   14/44   train_loss = 4.180
Epoch  42 Batch   15/44   train_loss = 3.985
Epoch  42 Batch   16/44   train_loss = 4.066
Epoch  42 Batch   17/44   train_loss = 4.108
Epoch  42 Batch   18/44   train_loss = 4.114
Epoch  42 Batch   19/44   train_loss = 4.134
Epoch  42 Batch   20/44   train_loss = 4.039
Epoch  42 Batch   21/44   train_loss = 4.061
Epoch  42 Batch   22/44   train_loss = 4.053
Epoch  42 Batch   23/44   train_loss = 4.123
Epoch  42 Batch   24/44   train_loss = 4.045
Epoch  42 Batch   25/44   train_loss = 4.140
Epoch  42 Batch   26/44   train_loss = 3.966
Epoch  42 Batch   27/44   train_loss = 4.091
Epoch  42 Batch   28/44   train_loss = 4.089
Epoch  42 Batch   29/44   train_loss = 4.158
Epoch  42 Batch   30/44   train_loss = 4.100
Epoch  42 Batch   31/44   train_loss = 4.169
Epoch  42 Batch   32/44   train_loss = 4.048
Epoch  42 Batch   33/44   train_loss = 4.169
Epoch  42 Batch   34/44   train_loss = 4.036
Epoch  42 Batch   35/44   train_loss = 3.967
Epoch  42 Batch   36/44   train_loss = 4.173
Epoch  42 Batch   37/44   train_loss = 4.124
Epoch  42 Batch   38/44   train_loss = 4.066
Epoch  42 Batch   39/44   train_loss = 4.074
Epoch  42 Batch   40/44   train_loss = 4.098
Epoch  42 Batch   41/44   train_loss = 4.053
Epoch  42 Batch   42/44   train_loss = 4.023
Epoch  42 Batch   43/44   train_loss = 4.149
Epoch  43 Batch    0/44   train_loss = 3.934
Epoch  43 Batch    1/44   train_loss = 4.015
Epoch  43 Batch    2/44   train_loss = 3.922
Epoch  43 Batch    3/44   train_loss = 4.023
Epoch  43 Batch    4/44   train_loss = 3.935
Epoch  43 Batch    5/44   train_loss = 3.953
Epoch  43 Batch    6/44   train_loss = 4.005
Epoch  43 Batch    7/44   train_loss = 4.125
Epoch  43 Batch    8/44   train_loss = 4.012
Epoch  43 Batch    9/44   train_loss = 4.050
Epoch  43 Batch   10/44   train_loss = 4.065
Epoch  43 Batch   11/44   train_loss = 4.034
Epoch  43 Batch   12/44   train_loss = 3.946
Epoch  43 Batch   13/44   train_loss = 3.973
Epoch  43 Batch   14/44   train_loss = 4.132
Epoch  43 Batch   15/44   train_loss = 3.944
Epoch  43 Batch   16/44   train_loss = 4.021
Epoch  43 Batch   17/44   train_loss = 4.065
Epoch  43 Batch   18/44   train_loss = 4.069
Epoch  43 Batch   19/44   train_loss = 4.085
Epoch  43 Batch   20/44   train_loss = 3.997
Epoch  43 Batch   21/44   train_loss = 4.016
Epoch  43 Batch   22/44   train_loss = 4.010
Epoch  43 Batch   23/44   train_loss = 4.075
Epoch  43 Batch   24/44   train_loss = 3.991
Epoch  43 Batch   25/44   train_loss = 4.091
Epoch  43 Batch   26/44   train_loss = 3.927
Epoch  43 Batch   27/44   train_loss = 4.048
Epoch  43 Batch   28/44   train_loss = 4.035
Epoch  43 Batch   29/44   train_loss = 4.106
Epoch  43 Batch   30/44   train_loss = 4.049
Epoch  43 Batch   31/44   train_loss = 4.129
Epoch  43 Batch   32/44   train_loss = 4.009
Epoch  43 Batch   33/44   train_loss = 4.122
Epoch  43 Batch   34/44   train_loss = 3.982
Epoch  43 Batch   35/44   train_loss = 3.917
Epoch  43 Batch   36/44   train_loss = 4.132
Epoch  43 Batch   37/44   train_loss = 4.086
Epoch  43 Batch   38/44   train_loss = 4.027
Epoch  43 Batch   39/44   train_loss = 4.031
Epoch  43 Batch   40/44   train_loss = 4.047
Epoch  43 Batch   41/44   train_loss = 4.006
Epoch  43 Batch   42/44   train_loss = 3.977
Epoch  43 Batch   43/44   train_loss = 4.107
Epoch  44 Batch    0/44   train_loss = 3.893
Epoch  44 Batch    1/44   train_loss = 3.962
Epoch  44 Batch    2/44   train_loss = 3.878
Epoch  44 Batch    3/44   train_loss = 3.976
Epoch  44 Batch    4/44   train_loss = 3.897
Epoch  44 Batch    5/44   train_loss = 3.916
Epoch  44 Batch    6/44   train_loss = 3.967
Epoch  44 Batch    7/44   train_loss = 4.077
Epoch  44 Batch    8/44   train_loss = 3.964
Epoch  44 Batch    9/44   train_loss = 4.003
Epoch  44 Batch   10/44   train_loss = 4.023
Epoch  44 Batch   11/44   train_loss = 3.992
Epoch  44 Batch   12/44   train_loss = 3.910
Epoch  44 Batch   13/44   train_loss = 3.931
Epoch  44 Batch   14/44   train_loss = 4.082
Epoch  44 Batch   15/44   train_loss = 3.899
Epoch  44 Batch   16/44   train_loss = 3.985
Epoch  44 Batch   17/44   train_loss = 4.024
Epoch  44 Batch   18/44   train_loss = 4.033
Epoch  44 Batch   19/44   train_loss = 4.037
Epoch  44 Batch   20/44   train_loss = 3.953
Epoch  44 Batch   21/44   train_loss = 3.972
Epoch  44 Batch   22/44   train_loss = 3.976
Epoch  44 Batch   23/44   train_loss = 4.045
Epoch  44 Batch   24/44   train_loss = 3.951
Epoch  44 Batch   25/44   train_loss = 4.048
Epoch  44 Batch   26/44   train_loss = 3.882
Epoch  44 Batch   27/44   train_loss = 4.009
Epoch  44 Batch   28/44   train_loss = 3.995
Epoch  44 Batch   29/44   train_loss = 4.061
Epoch  44 Batch   30/44   train_loss = 3.998
Epoch  44 Batch   31/44   train_loss = 4.078
Epoch  44 Batch   32/44   train_loss = 3.965
Epoch  44 Batch   33/44   train_loss = 4.080
Epoch  44 Batch   34/44   train_loss = 3.941
Epoch  44 Batch   35/44   train_loss = 3.874
Epoch  44 Batch   36/44   train_loss = 4.090
Epoch  44 Batch   37/44   train_loss = 4.041
Epoch  44 Batch   38/44   train_loss = 3.991
Epoch  44 Batch   39/44   train_loss = 4.000
Epoch  44 Batch   40/44   train_loss = 4.012
Epoch  44 Batch   41/44   train_loss = 3.969
Epoch  44 Batch   42/44   train_loss = 3.931
Epoch  44 Batch   43/44   train_loss = 4.059
Epoch  45 Batch    0/44   train_loss = 3.854
Epoch  45 Batch    1/44   train_loss = 3.922
Epoch  45 Batch    2/44   train_loss = 3.840
Epoch  45 Batch    3/44   train_loss = 3.931
Epoch  45 Batch    4/44   train_loss = 3.853
Epoch  45 Batch    5/44   train_loss = 3.872
Epoch  45 Batch    6/44   train_loss = 3.932
Epoch  45 Batch    7/44   train_loss = 4.042
Epoch  45 Batch    8/44   train_loss = 3.924
Epoch  45 Batch    9/44   train_loss = 3.952
Epoch  45 Batch   10/44   train_loss = 3.969
Epoch  45 Batch   11/44   train_loss = 3.948
Epoch  45 Batch   12/44   train_loss = 3.881
Epoch  45 Batch   13/44   train_loss = 3.898
Epoch  45 Batch   14/44   train_loss = 4.042
Epoch  45 Batch   15/44   train_loss = 3.849
Epoch  45 Batch   16/44   train_loss = 3.940
Epoch  45 Batch   17/44   train_loss = 3.979
Epoch  45 Batch   18/44   train_loss = 4.001
Epoch  45 Batch   19/44   train_loss = 3.994
Epoch  45 Batch   20/44   train_loss = 3.909
Epoch  45 Batch   21/44   train_loss = 3.923
Epoch  45 Batch   22/44   train_loss = 3.928
Epoch  45 Batch   23/44   train_loss = 4.009
Epoch  45 Batch   24/44   train_loss = 3.917
Epoch  45 Batch   25/44   train_loss = 4.016
Epoch  45 Batch   26/44   train_loss = 3.841
Epoch  45 Batch   27/44   train_loss = 3.963
Epoch  45 Batch   28/44   train_loss = 3.949
Epoch  45 Batch   29/44   train_loss = 4.025
Epoch  45 Batch   30/44   train_loss = 3.965
Epoch  45 Batch   31/44   train_loss = 4.035
Epoch  45 Batch   32/44   train_loss = 3.915
Epoch  45 Batch   33/44   train_loss = 4.034
Epoch  45 Batch   34/44   train_loss = 3.898
Epoch  45 Batch   35/44   train_loss = 3.838
Epoch  45 Batch   36/44   train_loss = 4.052
Epoch  45 Batch   37/44   train_loss = 3.991
Epoch  45 Batch   38/44   train_loss = 3.943
Epoch  45 Batch   39/44   train_loss = 3.949
Epoch  45 Batch   40/44   train_loss = 3.977
Epoch  45 Batch   41/44   train_loss = 3.938
Epoch  45 Batch   42/44   train_loss = 3.894
Epoch  45 Batch   43/44   train_loss = 4.008
Epoch  46 Batch    0/44   train_loss = 3.804
Epoch  46 Batch    1/44   train_loss = 3.879
Epoch  46 Batch    2/44   train_loss = 3.808
Epoch  46 Batch    3/44   train_loss = 3.898
Epoch  46 Batch    4/44   train_loss = 3.818
Epoch  46 Batch    5/44   train_loss = 3.828
Epoch  46 Batch    6/44   train_loss = 3.887
Epoch  46 Batch    7/44   train_loss = 4.001
Epoch  46 Batch    8/44   train_loss = 3.887
Epoch  46 Batch    9/44   train_loss = 3.909
Epoch  46 Batch   10/44   train_loss = 3.916
Epoch  46 Batch   11/44   train_loss = 3.899
Epoch  46 Batch   12/44   train_loss = 3.840
Epoch  46 Batch   13/44   train_loss = 3.856
Epoch  46 Batch   14/44   train_loss = 4.013
Epoch  46 Batch   15/44   train_loss = 3.818
Epoch  46 Batch   16/44   train_loss = 3.904
Epoch  46 Batch   17/44   train_loss = 3.936
Epoch  46 Batch   18/44   train_loss = 3.964
Epoch  46 Batch   19/44   train_loss = 3.961
Epoch  46 Batch   20/44   train_loss = 3.878
Epoch  46 Batch   21/44   train_loss = 3.883
Epoch  46 Batch   22/44   train_loss = 3.883
Epoch  46 Batch   23/44   train_loss = 3.958
Epoch  46 Batch   24/44   train_loss = 3.874
Epoch  46 Batch   25/44   train_loss = 3.987
Epoch  46 Batch   26/44   train_loss = 3.815
Epoch  46 Batch   27/44   train_loss = 3.928
Epoch  46 Batch   28/44   train_loss = 3.904
Epoch  46 Batch   29/44   train_loss = 3.978
Epoch  46 Batch   30/44   train_loss = 3.934
Epoch  46 Batch   31/44   train_loss = 4.010
Epoch  46 Batch   32/44   train_loss = 3.881
Epoch  46 Batch   33/44   train_loss = 3.999
Epoch  46 Batch   34/44   train_loss = 3.856
Epoch  46 Batch   35/44   train_loss = 3.802
Epoch  46 Batch   36/44   train_loss = 4.019
Epoch  46 Batch   37/44   train_loss = 3.957
Epoch  46 Batch   38/44   train_loss = 3.910
Epoch  46 Batch   39/44   train_loss = 3.894
Epoch  46 Batch   40/44   train_loss = 3.926
Epoch  46 Batch   41/44   train_loss = 3.903
Epoch  46 Batch   42/44   train_loss = 3.865
Epoch  46 Batch   43/44   train_loss = 3.970
Epoch  47 Batch    0/44   train_loss = 3.765
Epoch  47 Batch    1/44   train_loss = 3.833
Epoch  47 Batch    2/44   train_loss = 3.762
Epoch  47 Batch    3/44   train_loss = 3.858
Epoch  47 Batch    4/44   train_loss = 3.782
Epoch  47 Batch    5/44   train_loss = 3.801
Epoch  47 Batch    6/44   train_loss = 3.855
Epoch  47 Batch    7/44   train_loss = 3.959
Epoch  47 Batch    8/44   train_loss = 3.848
Epoch  47 Batch    9/44   train_loss = 3.873
Epoch  47 Batch   10/44   train_loss = 3.880
Epoch  47 Batch   11/44   train_loss = 3.876
Epoch  47 Batch   12/44   train_loss = 3.803
Epoch  47 Batch   13/44   train_loss = 3.811
Epoch  47 Batch   14/44   train_loss = 3.971
Epoch  47 Batch   15/44   train_loss = 3.794
Epoch  47 Batch   16/44   train_loss = 3.883
Epoch  47 Batch   17/44   train_loss = 3.910
Epoch  47 Batch   18/44   train_loss = 3.927
Epoch  47 Batch   19/44   train_loss = 3.922
Epoch  47 Batch   20/44   train_loss = 3.838
Epoch  47 Batch   21/44   train_loss = 3.852
Epoch  47 Batch   22/44   train_loss = 3.862
Epoch  47 Batch   23/44   train_loss = 3.919
Epoch  47 Batch   24/44   train_loss = 3.825
Epoch  47 Batch   25/44   train_loss = 3.937
Epoch  47 Batch   26/44   train_loss = 3.779
Epoch  47 Batch   27/44   train_loss = 3.908
Epoch  47 Batch   28/44   train_loss = 3.886
Epoch  47 Batch   29/44   train_loss = 3.932
Epoch  47 Batch   30/44   train_loss = 3.882
Epoch  47 Batch   31/44   train_loss = 3.966
Epoch  47 Batch   32/44   train_loss = 3.852
Epoch  47 Batch   33/44   train_loss = 3.979
Epoch  47 Batch   34/44   train_loss = 3.830
Epoch  47 Batch   35/44   train_loss = 3.769
Epoch  47 Batch   36/44   train_loss = 3.968
Epoch  47 Batch   37/44   train_loss = 3.913
Epoch  47 Batch   38/44   train_loss = 3.876
Epoch  47 Batch   39/44   train_loss = 3.854
Epoch  47 Batch   40/44   train_loss = 3.895
Epoch  47 Batch   41/44   train_loss = 3.858
Epoch  47 Batch   42/44   train_loss = 3.811
Epoch  47 Batch   43/44   train_loss = 3.918
Epoch  48 Batch    0/44   train_loss = 3.739
Epoch  48 Batch    1/44   train_loss = 3.820
Epoch  48 Batch    2/44   train_loss = 3.732
Epoch  48 Batch    3/44   train_loss = 3.808
Epoch  48 Batch    4/44   train_loss = 3.731
Epoch  48 Batch    5/44   train_loss = 3.766
Epoch  48 Batch    6/44   train_loss = 3.837
Epoch  48 Batch    7/44   train_loss = 3.936
Epoch  48 Batch    8/44   train_loss = 3.807
Epoch  48 Batch    9/44   train_loss = 3.824
Epoch  48 Batch   10/44   train_loss = 3.829
Epoch  48 Batch   11/44   train_loss = 3.847
Epoch  48 Batch   12/44   train_loss = 3.777
Epoch  48 Batch   13/44   train_loss = 3.779
Epoch  48 Batch   14/44   train_loss = 3.922
Epoch  48 Batch   15/44   train_loss = 3.755
Epoch  48 Batch   16/44   train_loss = 3.840
Epoch  48 Batch   17/44   train_loss = 3.879
Epoch  48 Batch   18/44   train_loss = 3.902
Epoch  48 Batch   19/44   train_loss = 3.895
Epoch  48 Batch   20/44   train_loss = 3.794
Epoch  48 Batch   21/44   train_loss = 3.806
Epoch  48 Batch   22/44   train_loss = 3.829
Epoch  48 Batch   23/44   train_loss = 3.882
Epoch  48 Batch   24/44   train_loss = 3.795
Epoch  48 Batch   25/44   train_loss = 3.893
Epoch  48 Batch   26/44   train_loss = 3.732
Epoch  48 Batch   27/44   train_loss = 3.854
Epoch  48 Batch   28/44   train_loss = 3.850
Epoch  48 Batch   29/44   train_loss = 3.904
Epoch  48 Batch   30/44   train_loss = 3.851
Epoch  48 Batch   31/44   train_loss = 3.919
Epoch  48 Batch   32/44   train_loss = 3.802
Epoch  48 Batch   33/44   train_loss = 3.932
Epoch  48 Batch   34/44   train_loss = 3.797
Epoch  48 Batch   35/44   train_loss = 3.741
Epoch  48 Batch   36/44   train_loss = 3.928
Epoch  48 Batch   37/44   train_loss = 3.864
Epoch  48 Batch   38/44   train_loss = 3.821
Epoch  48 Batch   39/44   train_loss = 3.801
Epoch  48 Batch   40/44   train_loss = 3.862
Epoch  48 Batch   41/44   train_loss = 3.839
Epoch  48 Batch   42/44   train_loss = 3.785
Epoch  48 Batch   43/44   train_loss = 3.875
Epoch  49 Batch    0/44   train_loss = 3.686
Epoch  49 Batch    1/44   train_loss = 3.770
Epoch  49 Batch    2/44   train_loss = 3.712
Epoch  49 Batch    3/44   train_loss = 3.790
Epoch  49 Batch    4/44   train_loss = 3.706
Epoch  49 Batch    5/44   train_loss = 3.724
Epoch  49 Batch    6/44   train_loss = 3.785
Epoch  49 Batch    7/44   train_loss = 3.905
Epoch  49 Batch    8/44   train_loss = 3.790
Epoch  49 Batch    9/44   train_loss = 3.820
Epoch  49 Batch   10/44   train_loss = 3.801
Epoch  49 Batch   11/44   train_loss = 3.798
Epoch  49 Batch   12/44   train_loss = 3.734
Epoch  49 Batch   13/44   train_loss = 3.742
Epoch  49 Batch   14/44   train_loss = 3.878
Epoch  49 Batch   15/44   train_loss = 3.722
Epoch  49 Batch   16/44   train_loss = 3.804
Epoch  49 Batch   17/44   train_loss = 3.835
Epoch  49 Batch   18/44   train_loss = 3.856
Epoch  49 Batch   19/44   train_loss = 3.844
Epoch  49 Batch   20/44   train_loss = 3.762
Epoch  49 Batch   21/44   train_loss = 3.773
Epoch  49 Batch   22/44   train_loss = 3.799
Epoch  49 Batch   23/44   train_loss = 3.843
Epoch  49 Batch   24/44   train_loss = 3.742
Epoch  49 Batch   25/44   train_loss = 3.851
Epoch  49 Batch   26/44   train_loss = 3.692
Epoch  49 Batch   27/44   train_loss = 3.814
Epoch  49 Batch   28/44   train_loss = 3.807
Epoch  49 Batch   29/44   train_loss = 3.861
Epoch  49 Batch   30/44   train_loss = 3.810
Epoch  49 Batch   31/44   train_loss = 3.885
Epoch  49 Batch   32/44   train_loss = 3.769
Epoch  49 Batch   33/44   train_loss = 3.888
Epoch  49 Batch   34/44   train_loss = 3.753
Epoch  49 Batch   35/44   train_loss = 3.699
Epoch  49 Batch   36/44   train_loss = 3.893
Epoch  49 Batch   37/44   train_loss = 3.814
Epoch  49 Batch   38/44   train_loss = 3.766
Epoch  49 Batch   39/44   train_loss = 3.752
Epoch  49 Batch   40/44   train_loss = 3.808
Epoch  49 Batch   41/44   train_loss = 3.784
Epoch  49 Batch   42/44   train_loss = 3.749
Epoch  49 Batch   43/44   train_loss = 3.852
Epoch  50 Batch    0/44   train_loss = 3.668
Epoch  50 Batch    1/44   train_loss = 3.716
Epoch  50 Batch    2/44   train_loss = 3.655
Epoch  50 Batch    3/44   train_loss = 3.739
Epoch  50 Batch    4/44   train_loss = 3.663
Epoch  50 Batch    5/44   train_loss = 3.685
Epoch  50 Batch    6/44   train_loss = 3.742
Epoch  50 Batch    7/44   train_loss = 3.846
Epoch  50 Batch    8/44   train_loss = 3.736
Epoch  50 Batch    9/44   train_loss = 3.786
Epoch  50 Batch   10/44   train_loss = 3.784
Epoch  50 Batch   11/44   train_loss = 3.776
Epoch  50 Batch   12/44   train_loss = 3.715
Epoch  50 Batch   13/44   train_loss = 3.706
Epoch  50 Batch   14/44   train_loss = 3.833
Epoch  50 Batch   15/44   train_loss = 3.670
Epoch  50 Batch   16/44   train_loss = 3.756
Epoch  50 Batch   17/44   train_loss = 3.793
Epoch  50 Batch   18/44   train_loss = 3.823
Epoch  50 Batch   19/44   train_loss = 3.803
Epoch  50 Batch   20/44   train_loss = 3.728
Epoch  50 Batch   21/44   train_loss = 3.729
Epoch  50 Batch   22/44   train_loss = 3.773
Epoch  50 Batch   23/44   train_loss = 3.826
Epoch  50 Batch   24/44   train_loss = 3.727
Epoch  50 Batch   25/44   train_loss = 3.824
Epoch  50 Batch   26/44   train_loss = 3.643
Epoch  50 Batch   27/44   train_loss = 3.756
Epoch  50 Batch   28/44   train_loss = 3.752
Epoch  50 Batch   29/44   train_loss = 3.818
Epoch  50 Batch   30/44   train_loss = 3.771
Epoch  50 Batch   31/44   train_loss = 3.848
Epoch  50 Batch   32/44   train_loss = 3.732
Epoch  50 Batch   33/44   train_loss = 3.856
Epoch  50 Batch   34/44   train_loss = 3.730
Epoch  50 Batch   35/44   train_loss = 3.676
Epoch  50 Batch   36/44   train_loss = 3.868
Epoch  50 Batch   37/44   train_loss = 3.790
Epoch  50 Batch   38/44   train_loss = 3.730
Epoch  50 Batch   39/44   train_loss = 3.699
Epoch  50 Batch   40/44   train_loss = 3.752
Epoch  50 Batch   41/44   train_loss = 3.726
Epoch  50 Batch   42/44   train_loss = 3.709
Epoch  50 Batch   43/44   train_loss = 3.815
Epoch  51 Batch    0/44   train_loss = 3.636
Epoch  51 Batch    1/44   train_loss = 3.687
Epoch  51 Batch    2/44   train_loss = 3.631
Epoch  51 Batch    3/44   train_loss = 3.708
Epoch  51 Batch    4/44   train_loss = 3.624
Epoch  51 Batch    5/44   train_loss = 3.635
Epoch  51 Batch    6/44   train_loss = 3.702
Epoch  51 Batch    7/44   train_loss = 3.799
Epoch  51 Batch    8/44   train_loss = 3.692
Epoch  51 Batch    9/44   train_loss = 3.722
Epoch  51 Batch   10/44   train_loss = 3.722
Epoch  51 Batch   11/44   train_loss = 3.725
Epoch  51 Batch   12/44   train_loss = 3.690
Epoch  51 Batch   13/44   train_loss = 3.682
Epoch  51 Batch   14/44   train_loss = 3.812
Epoch  51 Batch   15/44   train_loss = 3.631
Epoch  51 Batch   16/44   train_loss = 3.708
Epoch  51 Batch   17/44   train_loss = 3.742
Epoch  51 Batch   18/44   train_loss = 3.768
Epoch  51 Batch   19/44   train_loss = 3.753
Epoch  51 Batch   20/44   train_loss = 3.700
Epoch  51 Batch   21/44   train_loss = 3.692
Epoch  51 Batch   22/44   train_loss = 3.735
Epoch  51 Batch   23/44   train_loss = 3.777
Epoch  51 Batch   24/44   train_loss = 3.699
Epoch  51 Batch   25/44   train_loss = 3.816
Epoch  51 Batch   26/44   train_loss = 3.639
Epoch  51 Batch   27/44   train_loss = 3.730
Epoch  51 Batch   28/44   train_loss = 3.717
Epoch  51 Batch   29/44   train_loss = 3.760
Epoch  51 Batch   30/44   train_loss = 3.729
Epoch  51 Batch   31/44   train_loss = 3.818
Epoch  51 Batch   32/44   train_loss = 3.702
Epoch  51 Batch   33/44   train_loss = 3.810
Epoch  51 Batch   34/44   train_loss = 3.692
Epoch  51 Batch   35/44   train_loss = 3.650
Epoch  51 Batch   36/44   train_loss = 3.845
Epoch  51 Batch   37/44   train_loss = 3.772
Epoch  51 Batch   38/44   train_loss = 3.713
Epoch  51 Batch   39/44   train_loss = 3.669
Epoch  51 Batch   40/44   train_loss = 3.719
Epoch  51 Batch   41/44   train_loss = 3.677
Epoch  51 Batch   42/44   train_loss = 3.650
Epoch  51 Batch   43/44   train_loss = 3.763
Epoch  52 Batch    0/44   train_loss = 3.598
Epoch  52 Batch    1/44   train_loss = 3.661
Epoch  52 Batch    2/44   train_loss = 3.607
Epoch  52 Batch    3/44   train_loss = 3.681
Epoch  52 Batch    4/44   train_loss = 3.597
Epoch  52 Batch    5/44   train_loss = 3.601
Epoch  52 Batch    6/44   train_loss = 3.677
Epoch  52 Batch    7/44   train_loss = 3.770
Epoch  52 Batch    8/44   train_loss = 3.663
Epoch  52 Batch    9/44   train_loss = 3.683
Epoch  52 Batch   10/44   train_loss = 3.675
Epoch  52 Batch   11/44   train_loss = 3.673
Epoch  52 Batch   12/44   train_loss = 3.637
Epoch  52 Batch   13/44   train_loss = 3.636
Epoch  52 Batch   14/44   train_loss = 3.780
Epoch  52 Batch   15/44   train_loss = 3.608
Epoch  52 Batch   16/44   train_loss = 3.693
Epoch  52 Batch   17/44   train_loss = 3.720
Epoch  52 Batch   18/44   train_loss = 3.724
Epoch  52 Batch   19/44   train_loss = 3.692
Epoch  52 Batch   20/44   train_loss = 3.639
Epoch  52 Batch   21/44   train_loss = 3.638
Epoch  52 Batch   22/44   train_loss = 3.706
Epoch  52 Batch   23/44   train_loss = 3.732
Epoch  52 Batch   24/44   train_loss = 3.656
Epoch  52 Batch   25/44   train_loss = 3.771
Epoch  52 Batch   26/44   train_loss = 3.602
Epoch  52 Batch   27/44   train_loss = 3.717
Epoch  52 Batch   28/44   train_loss = 3.716
Epoch  52 Batch   29/44   train_loss = 3.729
Epoch  52 Batch   30/44   train_loss = 3.691
Epoch  52 Batch   31/44   train_loss = 3.766
Epoch  52 Batch   32/44   train_loss = 3.667
Epoch  52 Batch   33/44   train_loss = 3.761
Epoch  52 Batch   34/44   train_loss = 3.649
Epoch  52 Batch   35/44   train_loss = 3.597
Epoch  52 Batch   36/44   train_loss = 3.795
Epoch  52 Batch   37/44   train_loss = 3.734
Epoch  52 Batch   38/44   train_loss = 3.693
Epoch  52 Batch   39/44   train_loss = 3.656
Epoch  52 Batch   40/44   train_loss = 3.701
Epoch  52 Batch   41/44   train_loss = 3.653
Epoch  52 Batch   42/44   train_loss = 3.603
Epoch  52 Batch   43/44   train_loss = 3.708
Epoch  53 Batch    0/44   train_loss = 3.547
Epoch  53 Batch    1/44   train_loss = 3.637
Epoch  53 Batch    2/44   train_loss = 3.597
Epoch  53 Batch    3/44   train_loss = 3.663
Epoch  53 Batch    4/44   train_loss = 3.584
Epoch  53 Batch    5/44   train_loss = 3.560
Epoch  53 Batch    6/44   train_loss = 3.632
Epoch  53 Batch    7/44   train_loss = 3.729
Epoch  53 Batch    8/44   train_loss = 3.653
Epoch  53 Batch    9/44   train_loss = 3.681
Epoch  53 Batch   10/44   train_loss = 3.662
Epoch  53 Batch   11/44   train_loss = 3.640
Epoch  53 Batch   12/44   train_loss = 3.587
Epoch  53 Batch   13/44   train_loss = 3.583
Epoch  53 Batch   14/44   train_loss = 3.714
Epoch  53 Batch   15/44   train_loss = 3.560
Epoch  53 Batch   16/44   train_loss = 3.656
Epoch  53 Batch   17/44   train_loss = 3.704
Epoch  53 Batch   18/44   train_loss = 3.711
Epoch  53 Batch   19/44   train_loss = 3.677
Epoch  53 Batch   20/44   train_loss = 3.609
Epoch  53 Batch   21/44   train_loss = 3.586
Epoch  53 Batch   22/44   train_loss = 3.645
Epoch  53 Batch   23/44   train_loss = 3.672
Epoch  53 Batch   24/44   train_loss = 3.607
Epoch  53 Batch   25/44   train_loss = 3.727
Epoch  53 Batch   26/44   train_loss = 3.570
Epoch  53 Batch   27/44   train_loss = 3.688
Epoch  53 Batch   28/44   train_loss = 3.680
Epoch  53 Batch   29/44   train_loss = 3.679
Epoch  53 Batch   30/44   train_loss = 3.650
Epoch  53 Batch   31/44   train_loss = 3.724
Epoch  53 Batch   32/44   train_loss = 3.627
Epoch  53 Batch   33/44   train_loss = 3.710
Epoch  53 Batch   34/44   train_loss = 3.600
Epoch  53 Batch   35/44   train_loss = 3.552
Epoch  53 Batch   36/44   train_loss = 3.738
Epoch  53 Batch   37/44   train_loss = 3.671
Epoch  53 Batch   38/44   train_loss = 3.643
Epoch  53 Batch   39/44   train_loss = 3.605
Epoch  53 Batch   40/44   train_loss = 3.658
Epoch  53 Batch   41/44   train_loss = 3.616
Epoch  53 Batch   42/44   train_loss = 3.567
Epoch  53 Batch   43/44   train_loss = 3.664
Epoch  54 Batch    0/44   train_loss = 3.497
Epoch  54 Batch    1/44   train_loss = 3.573
Epoch  54 Batch    2/44   train_loss = 3.532
Epoch  54 Batch    3/44   train_loss = 3.619
Epoch  54 Batch    4/44   train_loss = 3.561
Epoch  54 Batch    5/44   train_loss = 3.541
Epoch  54 Batch    6/44   train_loss = 3.596
Epoch  54 Batch    7/44   train_loss = 3.678
Epoch  54 Batch    8/44   train_loss = 3.588
Epoch  54 Batch    9/44   train_loss = 3.627
Epoch  54 Batch   10/44   train_loss = 3.633
Epoch  54 Batch   11/44   train_loss = 3.614
Epoch  54 Batch   12/44   train_loss = 3.569
Epoch  54 Batch   13/44   train_loss = 3.553
Epoch  54 Batch   14/44   train_loss = 3.652
Epoch  54 Batch   15/44   train_loss = 3.499
Epoch  54 Batch   16/44   train_loss = 3.587
Epoch  54 Batch   17/44   train_loss = 3.654
Epoch  54 Batch   18/44   train_loss = 3.666
Epoch  54 Batch   19/44   train_loss = 3.632
Epoch  54 Batch   20/44   train_loss = 3.591
Epoch  54 Batch   21/44   train_loss = 3.574
Epoch  54 Batch   22/44   train_loss = 3.619
Epoch  54 Batch   23/44   train_loss = 3.616
Epoch  54 Batch   24/44   train_loss = 3.538
Epoch  54 Batch   25/44   train_loss = 3.654
Epoch  54 Batch   26/44   train_loss = 3.516
Epoch  54 Batch   27/44   train_loss = 3.650
Epoch  54 Batch   28/44   train_loss = 3.650
Epoch  54 Batch   29/44   train_loss = 3.640
Epoch  54 Batch   30/44   train_loss = 3.611
Epoch  54 Batch   31/44   train_loss = 3.690
Epoch  54 Batch   32/44   train_loss = 3.583
Epoch  54 Batch   33/44   train_loss = 3.666
Epoch  54 Batch   34/44   train_loss = 3.547
Epoch  54 Batch   35/44   train_loss = 3.505
Epoch  54 Batch   36/44   train_loss = 3.688
Epoch  54 Batch   37/44   train_loss = 3.616
Epoch  54 Batch   38/44   train_loss = 3.591
Epoch  54 Batch   39/44   train_loss = 3.546
Epoch  54 Batch   40/44   train_loss = 3.604
Epoch  54 Batch   41/44   train_loss = 3.564
Epoch  54 Batch   42/44   train_loss = 3.519
Epoch  54 Batch   43/44   train_loss = 3.605
Epoch  55 Batch    0/44   train_loss = 3.455
Epoch  55 Batch    1/44   train_loss = 3.529
Epoch  55 Batch    2/44   train_loss = 3.470
Epoch  55 Batch    3/44   train_loss = 3.546
Epoch  55 Batch    4/44   train_loss = 3.483
Epoch  55 Batch    5/44   train_loss = 3.479
Epoch  55 Batch    6/44   train_loss = 3.555
Epoch  55 Batch    7/44   train_loss = 3.642
Epoch  55 Batch    8/44   train_loss = 3.544
Epoch  55 Batch    9/44   train_loss = 3.564
Epoch  55 Batch   10/44   train_loss = 3.554
Epoch  55 Batch   11/44   train_loss = 3.548
Epoch  55 Batch   12/44   train_loss = 3.533
Epoch  55 Batch   13/44   train_loss = 3.519
Epoch  55 Batch   14/44   train_loss = 3.619
Epoch  55 Batch   15/44   train_loss = 3.457
Epoch  55 Batch   16/44   train_loss = 3.530
Epoch  55 Batch   17/44   train_loss = 3.592
Epoch  55 Batch   18/44   train_loss = 3.610
Epoch  55 Batch   19/44   train_loss = 3.573
Epoch  55 Batch   20/44   train_loss = 3.536
Epoch  55 Batch   21/44   train_loss = 3.530
Epoch  55 Batch   22/44   train_loss = 3.596
Epoch  55 Batch   23/44   train_loss = 3.604
Epoch  55 Batch   24/44   train_loss = 3.508
Epoch  55 Batch   25/44   train_loss = 3.591
Epoch  55 Batch   26/44   train_loss = 3.437
Epoch  55 Batch   27/44   train_loss = 3.588
Epoch  55 Batch   28/44   train_loss = 3.604
Epoch  55 Batch   29/44   train_loss = 3.608
Epoch  55 Batch   30/44   train_loss = 3.583
Epoch  55 Batch   31/44   train_loss = 3.652
Epoch  55 Batch   32/44   train_loss = 3.537
Epoch  55 Batch   33/44   train_loss = 3.626
Epoch  55 Batch   34/44   train_loss = 3.508
Epoch  55 Batch   35/44   train_loss = 3.476
Epoch  55 Batch   36/44   train_loss = 3.659
Epoch  55 Batch   37/44   train_loss = 3.569
Epoch  55 Batch   38/44   train_loss = 3.540
Epoch  55 Batch   39/44   train_loss = 3.495
Epoch  55 Batch   40/44   train_loss = 3.563
Epoch  55 Batch   41/44   train_loss = 3.531
Epoch  55 Batch   42/44   train_loss = 3.480
Epoch  55 Batch   43/44   train_loss = 3.547
Epoch  56 Batch    0/44   train_loss = 3.408
Epoch  56 Batch    1/44   train_loss = 3.490
Epoch  56 Batch    2/44   train_loss = 3.429
Epoch  56 Batch    3/44   train_loss = 3.498
Epoch  56 Batch    4/44   train_loss = 3.416
Epoch  56 Batch    5/44   train_loss = 3.419
Epoch  56 Batch    6/44   train_loss = 3.498
Epoch  56 Batch    7/44   train_loss = 3.590
Epoch  56 Batch    8/44   train_loss = 3.498
Epoch  56 Batch    9/44   train_loss = 3.518
Epoch  56 Batch   10/44   train_loss = 3.491
Epoch  56 Batch   11/44   train_loss = 3.484
Epoch  56 Batch   12/44   train_loss = 3.476
Epoch  56 Batch   13/44   train_loss = 3.466
Epoch  56 Batch   14/44   train_loss = 3.572
Epoch  56 Batch   15/44   train_loss = 3.416
Epoch  56 Batch   16/44   train_loss = 3.488
Epoch  56 Batch   17/44   train_loss = 3.547
Epoch  56 Batch   18/44   train_loss = 3.561
Epoch  56 Batch   19/44   train_loss = 3.520
Epoch  56 Batch   20/44   train_loss = 3.481
Epoch  56 Batch   21/44   train_loss = 3.471
Epoch  56 Batch   22/44   train_loss = 3.544
Epoch  56 Batch   23/44   train_loss = 3.572
Epoch  56 Batch   24/44   train_loss = 3.501
Epoch  56 Batch   25/44   train_loss = 3.577
Epoch  56 Batch   26/44   train_loss = 3.385
Epoch  56 Batch   27/44   train_loss = 3.517
Epoch  56 Batch   28/44   train_loss = 3.528
Epoch  56 Batch   29/44   train_loss = 3.560
Epoch  56 Batch   30/44   train_loss = 3.569
Epoch  56 Batch   31/44   train_loss = 3.640
Epoch  56 Batch   32/44   train_loss = 3.508
Epoch  56 Batch   33/44   train_loss = 3.579
Epoch  56 Batch   34/44   train_loss = 3.449
Epoch  56 Batch   35/44   train_loss = 3.439
Epoch  56 Batch   36/44   train_loss = 3.657
Epoch  56 Batch   37/44   train_loss = 3.567
Epoch  56 Batch   38/44   train_loss = 3.513
Epoch  56 Batch   39/44   train_loss = 3.440
Epoch  56 Batch   40/44   train_loss = 3.512
Epoch  56 Batch   41/44   train_loss = 3.503
Epoch  56 Batch   42/44   train_loss = 3.463
Epoch  56 Batch   43/44   train_loss = 3.535
Epoch  57 Batch    0/44   train_loss = 3.387
Epoch  57 Batch    1/44   train_loss = 3.446
Epoch  57 Batch    2/44   train_loss = 3.390
Epoch  57 Batch    3/44   train_loss = 3.464
Epoch  57 Batch    4/44   train_loss = 3.383
Epoch  57 Batch    5/44   train_loss = 3.388
Epoch  57 Batch    6/44   train_loss = 3.453
Epoch  57 Batch    7/44   train_loss = 3.534
Epoch  57 Batch    8/44   train_loss = 3.458
Epoch  57 Batch    9/44   train_loss = 3.480
Epoch  57 Batch   10/44   train_loss = 3.455
Epoch  57 Batch   11/44   train_loss = 3.454
Epoch  57 Batch   12/44   train_loss = 3.420
Epoch  57 Batch   13/44   train_loss = 3.406
Epoch  57 Batch   14/44   train_loss = 3.515
Epoch  57 Batch   15/44   train_loss = 3.384
Epoch  57 Batch   16/44   train_loss = 3.466
Epoch  57 Batch   17/44   train_loss = 3.512
Epoch  57 Batch   18/44   train_loss = 3.508
Epoch  57 Batch   19/44   train_loss = 3.453
Epoch  57 Batch   20/44   train_loss = 3.428
Epoch  57 Batch   21/44   train_loss = 3.425
Epoch  57 Batch   22/44   train_loss = 3.501
Epoch  57 Batch   23/44   train_loss = 3.512
Epoch  57 Batch   24/44   train_loss = 3.441
Epoch  57 Batch   25/44   train_loss = 3.538
Epoch  57 Batch   26/44   train_loss = 3.366
Epoch  57 Batch   27/44   train_loss = 3.490
Epoch  57 Batch   28/44   train_loss = 3.464
Epoch  57 Batch   29/44   train_loss = 3.485
Epoch  57 Batch   30/44   train_loss = 3.503
Epoch  57 Batch   31/44   train_loss = 3.601
Epoch  57 Batch   32/44   train_loss = 3.497
Epoch  57 Batch   33/44   train_loss = 3.568
Epoch  57 Batch   34/44   train_loss = 3.410
Epoch  57 Batch   35/44   train_loss = 3.373
Epoch  57 Batch   36/44   train_loss = 3.588
Epoch  57 Batch   37/44   train_loss = 3.529
Epoch  57 Batch   38/44   train_loss = 3.502
Epoch  57 Batch   39/44   train_loss = 3.442
Epoch  57 Batch   40/44   train_loss = 3.492
Epoch  57 Batch   41/44   train_loss = 3.446
Epoch  57 Batch   42/44   train_loss = 3.391
Epoch  57 Batch   43/44   train_loss = 3.486
Epoch  58 Batch    0/44   train_loss = 3.370
Epoch  58 Batch    1/44   train_loss = 3.444
Epoch  58 Batch    2/44   train_loss = 3.386
Epoch  58 Batch    3/44   train_loss = 3.435
Epoch  58 Batch    4/44   train_loss = 3.347
Epoch  58 Batch    5/44   train_loss = 3.346
Epoch  58 Batch    6/44   train_loss = 3.416
Epoch  58 Batch    7/44   train_loss = 3.492
Epoch  58 Batch    8/44   train_loss = 3.427
Epoch  58 Batch    9/44   train_loss = 3.450
Epoch  58 Batch   10/44   train_loss = 3.432
Epoch  58 Batch   11/44   train_loss = 3.451
Epoch  58 Batch   12/44   train_loss = 3.395
Epoch  58 Batch   13/44   train_loss = 3.366
Epoch  58 Batch   14/44   train_loss = 3.457
Epoch  58 Batch   15/44   train_loss = 3.329
Epoch  58 Batch   16/44   train_loss = 3.436
Epoch  58 Batch   17/44   train_loss = 3.505
Epoch  58 Batch   18/44   train_loss = 3.508
Epoch  58 Batch   19/44   train_loss = 3.431
Epoch  58 Batch   20/44   train_loss = 3.385
Epoch  58 Batch   21/44   train_loss = 3.355
Epoch  58 Batch   22/44   train_loss = 3.439
Epoch  58 Batch   23/44   train_loss = 3.459
Epoch  58 Batch   24/44   train_loss = 3.406
Epoch  58 Batch   25/44   train_loss = 3.512
Epoch  58 Batch   26/44   train_loss = 3.335
Epoch  58 Batch   27/44   train_loss = 3.463
Epoch  58 Batch   28/44   train_loss = 3.427
Epoch  58 Batch   29/44   train_loss = 3.425
Epoch  58 Batch   30/44   train_loss = 3.429
Epoch  58 Batch   31/44   train_loss = 3.529
Epoch  58 Batch   32/44   train_loss = 3.460
Epoch  58 Batch   33/44   train_loss = 3.559
Epoch  58 Batch   34/44   train_loss = 3.407
Epoch  58 Batch   35/44   train_loss = 3.349
Epoch  58 Batch   36/44   train_loss = 3.525
Epoch  58 Batch   37/44   train_loss = 3.440
Epoch  58 Batch   38/44   train_loss = 3.425
Epoch  58 Batch   39/44   train_loss = 3.408
Epoch  58 Batch   40/44   train_loss = 3.499
Epoch  58 Batch   41/44   train_loss = 3.456
Epoch  58 Batch   42/44   train_loss = 3.372
Epoch  58 Batch   43/44   train_loss = 3.417
Epoch  59 Batch    0/44   train_loss = 3.282
Epoch  59 Batch    1/44   train_loss = 3.375
Epoch  59 Batch    2/44   train_loss = 3.353
Epoch  59 Batch    3/44   train_loss = 3.431
Epoch  59 Batch    4/44   train_loss = 3.366
Epoch  59 Batch    5/44   train_loss = 3.354
Epoch  59 Batch    6/44   train_loss = 3.408
Epoch  59 Batch    7/44   train_loss = 3.466
Epoch  59 Batch    8/44   train_loss = 3.372
Epoch  59 Batch    9/44   train_loss = 3.403
Epoch  59 Batch   10/44   train_loss = 3.388
Epoch  59 Batch   11/44   train_loss = 3.432
Epoch  59 Batch   12/44   train_loss = 3.399
Epoch  59 Batch   13/44   train_loss = 3.375
Epoch  59 Batch   14/44   train_loss = 3.435
Epoch  59 Batch   15/44   train_loss = 3.302
Epoch  59 Batch   16/44   train_loss = 3.379
Epoch  59 Batch   17/44   train_loss = 3.449
Epoch  59 Batch   18/44   train_loss = 3.465
Epoch  59 Batch   19/44   train_loss = 3.415
Epoch  59 Batch   20/44   train_loss = 3.391
Epoch  59 Batch   21/44   train_loss = 3.346
Epoch  59 Batch   22/44   train_loss = 3.404
Epoch  59 Batch   23/44   train_loss = 3.386
Epoch  59 Batch   24/44   train_loss = 3.339
Epoch  59 Batch   25/44   train_loss = 3.438
Epoch  59 Batch   26/44   train_loss = 3.291
Epoch  59 Batch   27/44   train_loss = 3.444
Epoch  59 Batch   28/44   train_loss = 3.418
Epoch  59 Batch   29/44   train_loss = 3.404
Epoch  59 Batch   30/44   train_loss = 3.386
Epoch  59 Batch   31/44   train_loss = 3.463
Epoch  59 Batch   32/44   train_loss = 3.376
Epoch  59 Batch   33/44   train_loss = 3.468
Epoch  59 Batch   34/44   train_loss = 3.350
Epoch  59 Batch   35/44   train_loss = 3.324
Epoch  59 Batch   36/44   train_loss = 3.511
Epoch  59 Batch   37/44   train_loss = 3.416
Epoch  59 Batch   38/44   train_loss = 3.377
Epoch  59 Batch   39/44   train_loss = 3.312
Epoch  59 Batch   40/44   train_loss = 3.406
Epoch  59 Batch   41/44   train_loss = 3.384
Epoch  59 Batch   42/44   train_loss = 3.336
Epoch  59 Batch   43/44   train_loss = 3.395
Epoch  60 Batch    0/44   train_loss = 3.260
Epoch  60 Batch    1/44   train_loss = 3.330
Epoch  60 Batch    2/44   train_loss = 3.290
Epoch  60 Batch    3/44   train_loss = 3.349
Epoch  60 Batch    4/44   train_loss = 3.296
Epoch  60 Batch    5/44   train_loss = 3.296
Epoch  60 Batch    6/44   train_loss = 3.378
Epoch  60 Batch    7/44   train_loss = 3.445
Epoch  60 Batch    8/44   train_loss = 3.338
Epoch  60 Batch    9/44   train_loss = 3.373
Epoch  60 Batch   10/44   train_loss = 3.334
Epoch  60 Batch   11/44   train_loss = 3.350
Epoch  60 Batch   12/44   train_loss = 3.345
Epoch  60 Batch   13/44   train_loss = 3.332
Epoch  60 Batch   14/44   train_loss = 3.396
Epoch  60 Batch   15/44   train_loss = 3.287
Epoch  60 Batch   16/44   train_loss = 3.353
Epoch  60 Batch   17/44   train_loss = 3.412
Epoch  60 Batch   18/44   train_loss = 3.423
Epoch  60 Batch   19/44   train_loss = 3.367
Epoch  60 Batch   20/44   train_loss = 3.342
Epoch  60 Batch   21/44   train_loss = 3.300
Epoch  60 Batch   22/44   train_loss = 3.363
Epoch  60 Batch   23/44   train_loss = 3.356
Epoch  60 Batch   24/44   train_loss = 3.306
Epoch  60 Batch   25/44   train_loss = 3.385
Epoch  60 Batch   26/44   train_loss = 3.233
Epoch  60 Batch   27/44   train_loss = 3.379
Epoch  60 Batch   28/44   train_loss = 3.352
Epoch  60 Batch   29/44   train_loss = 3.340
Epoch  60 Batch   30/44   train_loss = 3.328
Epoch  60 Batch   31/44   train_loss = 3.411
Epoch  60 Batch   32/44   train_loss = 3.326
Epoch  60 Batch   33/44   train_loss = 3.411
Epoch  60 Batch   34/44   train_loss = 3.292
Epoch  60 Batch   35/44   train_loss = 3.266
Epoch  60 Batch   36/44   train_loss = 3.448
Epoch  60 Batch   37/44   train_loss = 3.356
Epoch  60 Batch   38/44   train_loss = 3.322
Epoch  60 Batch   39/44   train_loss = 3.248
Epoch  60 Batch   40/44   train_loss = 3.350
Epoch  60 Batch   41/44   train_loss = 3.327
Epoch  60 Batch   42/44   train_loss = 3.284
Epoch  60 Batch   43/44   train_loss = 3.335
Epoch  61 Batch    0/44   train_loss = 3.212
Epoch  61 Batch    1/44   train_loss = 3.267
Epoch  61 Batch    2/44   train_loss = 3.231
Epoch  61 Batch    3/44   train_loss = 3.297
Epoch  61 Batch    4/44   train_loss = 3.247
Epoch  61 Batch    5/44   train_loss = 3.247
Epoch  61 Batch    6/44   train_loss = 3.331
Epoch  61 Batch    7/44   train_loss = 3.395
Epoch  61 Batch    8/44   train_loss = 3.279
Epoch  61 Batch    9/44   train_loss = 3.314
Epoch  61 Batch   10/44   train_loss = 3.269
Epoch  61 Batch   11/44   train_loss = 3.284
Epoch  61 Batch   12/44   train_loss = 3.307
Epoch  61 Batch   13/44   train_loss = 3.299
Epoch  61 Batch   14/44   train_loss = 3.358
Epoch  61 Batch   15/44   train_loss = 3.263
Epoch  61 Batch   16/44   train_loss = 3.302
Epoch  61 Batch   17/44   train_loss = 3.353
Epoch  61 Batch   18/44   train_loss = 3.358
Epoch  61 Batch   19/44   train_loss = 3.310
Epoch  61 Batch   20/44   train_loss = 3.309
Epoch  61 Batch   21/44   train_loss = 3.277
Epoch  61 Batch   22/44   train_loss = 3.349
Epoch  61 Batch   23/44   train_loss = 3.350
Epoch  61 Batch   24/44   train_loss = 3.265
Epoch  61 Batch   25/44   train_loss = 3.336
Epoch  61 Batch   26/44   train_loss = 3.171
Epoch  61 Batch   27/44   train_loss = 3.320
Epoch  61 Batch   28/44   train_loss = 3.307
Epoch  61 Batch   29/44   train_loss = 3.315
Epoch  61 Batch   30/44   train_loss = 3.311
Epoch  61 Batch   31/44   train_loss = 3.387
Epoch  61 Batch   32/44   train_loss = 3.281
Epoch  61 Batch   33/44   train_loss = 3.354
Epoch  61 Batch   34/44   train_loss = 3.228
Epoch  61 Batch   35/44   train_loss = 3.210
Epoch  61 Batch   36/44   train_loss = 3.411
Epoch  61 Batch   37/44   train_loss = 3.321
Epoch  61 Batch   38/44   train_loss = 3.290
Epoch  61 Batch   39/44   train_loss = 3.194
Epoch  61 Batch   40/44   train_loss = 3.286
Epoch  61 Batch   41/44   train_loss = 3.255
Epoch  61 Batch   42/44   train_loss = 3.211
Epoch  61 Batch   43/44   train_loss = 3.274
Epoch  62 Batch    0/44   train_loss = 3.175
Epoch  62 Batch    1/44   train_loss = 3.232
Epoch  62 Batch    2/44   train_loss = 3.192
Epoch  62 Batch    3/44   train_loss = 3.245
Epoch  62 Batch    4/44   train_loss = 3.180
Epoch  62 Batch    5/44   train_loss = 3.168
Epoch  62 Batch    6/44   train_loss = 3.258
Epoch  62 Batch    7/44   train_loss = 3.339
Epoch  62 Batch    8/44   train_loss = 3.245
Epoch  62 Batch    9/44   train_loss = 3.287
Epoch  62 Batch   10/44   train_loss = 3.227
Epoch  62 Batch   11/44   train_loss = 3.224
Epoch  62 Batch   12/44   train_loss = 3.228
Epoch  62 Batch   13/44   train_loss = 3.213
Epoch  62 Batch   14/44   train_loss = 3.280
Epoch  62 Batch   15/44   train_loss = 3.209
Epoch  62 Batch   16/44   train_loss = 3.271
Epoch  62 Batch   17/44   train_loss = 3.325
Epoch  62 Batch   18/44   train_loss = 3.321
Epoch  62 Batch   19/44   train_loss = 3.243
Epoch  62 Batch   20/44   train_loss = 3.237
Epoch  62 Batch   21/44   train_loss = 3.193
Epoch  62 Batch   22/44   train_loss = 3.289
Epoch  62 Batch   23/44   train_loss = 3.312
Epoch  62 Batch   24/44   train_loss = 3.243
Epoch  62 Batch   25/44   train_loss = 3.323
Epoch  62 Batch   26/44   train_loss = 3.139
Epoch  62 Batch   27/44   train_loss = 3.265
Epoch  62 Batch   28/44   train_loss = 3.237
Epoch  62 Batch   29/44   train_loss = 3.240
Epoch  62 Batch   30/44   train_loss = 3.257
Epoch  62 Batch   31/44   train_loss = 3.358
Epoch  62 Batch   32/44   train_loss = 3.256
Epoch  62 Batch   33/44   train_loss = 3.334
Epoch  62 Batch   34/44   train_loss = 3.193
Epoch  62 Batch   35/44   train_loss = 3.156
Epoch  62 Batch   36/44   train_loss = 3.343
Epoch  62 Batch   37/44   train_loss = 3.253
Epoch  62 Batch   38/44   train_loss = 3.232
Epoch  62 Batch   39/44   train_loss = 3.144
Epoch  62 Batch   40/44   train_loss = 3.247
Epoch  62 Batch   41/44   train_loss = 3.214
Epoch  62 Batch   42/44   train_loss = 3.146
Epoch  62 Batch   43/44   train_loss = 3.204
Epoch  63 Batch    0/44   train_loss = 3.106
Epoch  63 Batch    1/44   train_loss = 3.164
Epoch  63 Batch    2/44   train_loss = 3.145
Epoch  63 Batch    3/44   train_loss = 3.209
Epoch  63 Batch    4/44   train_loss = 3.147
Epoch  63 Batch    5/44   train_loss = 3.126
Epoch  63 Batch    6/44   train_loss = 3.197
Epoch  63 Batch    7/44   train_loss = 3.263
Epoch  63 Batch    8/44   train_loss = 3.174
Epoch  63 Batch    9/44   train_loss = 3.229
Epoch  63 Batch   10/44   train_loss = 3.183
Epoch  63 Batch   11/44   train_loss = 3.193
Epoch  63 Batch   12/44   train_loss = 3.189
Epoch  63 Batch   13/44   train_loss = 3.151
Epoch  63 Batch   14/44   train_loss = 3.206
Epoch  63 Batch   15/44   train_loss = 3.122
Epoch  63 Batch   16/44   train_loss = 3.195
Epoch  63 Batch   17/44   train_loss = 3.267
Epoch  63 Batch   18/44   train_loss = 3.277
Epoch  63 Batch   19/44   train_loss = 3.194
Epoch  63 Batch   20/44   train_loss = 3.192
Epoch  63 Batch   21/44   train_loss = 3.134
Epoch  63 Batch   22/44   train_loss = 3.221
Epoch  63 Batch   23/44   train_loss = 3.228
Epoch  63 Batch   24/44   train_loss = 3.178
Epoch  63 Batch   25/44   train_loss = 3.266
Epoch  63 Batch   26/44   train_loss = 3.103
Epoch  63 Batch   27/44   train_loss = 3.232
Epoch  63 Batch   28/44   train_loss = 3.199
Epoch  63 Batch   29/44   train_loss = 3.181
Epoch  63 Batch   30/44   train_loss = 3.195
Epoch  63 Batch   31/44   train_loss = 3.293
Epoch  63 Batch   32/44   train_loss = 3.199
Epoch  63 Batch   33/44   train_loss = 3.290
Epoch  63 Batch   34/44   train_loss = 3.160
Epoch  63 Batch   35/44   train_loss = 3.125
Epoch  63 Batch   36/44   train_loss = 3.309
Epoch  63 Batch   37/44   train_loss = 3.204
Epoch  63 Batch   38/44   train_loss = 3.176
Epoch  63 Batch   39/44   train_loss = 3.087
Epoch  63 Batch   40/44   train_loss = 3.195
Epoch  63 Batch   41/44   train_loss = 3.169
Epoch  63 Batch   42/44   train_loss = 3.096
Epoch  63 Batch   43/44   train_loss = 3.152
Epoch  64 Batch    0/44   train_loss = 3.055
Epoch  64 Batch    1/44   train_loss = 3.104
Epoch  64 Batch    2/44   train_loss = 3.092
Epoch  64 Batch    3/44   train_loss = 3.154
Epoch  64 Batch    4/44   train_loss = 3.098
Epoch  64 Batch    5/44   train_loss = 3.084
Epoch  64 Batch    6/44   train_loss = 3.150
Epoch  64 Batch    7/44   train_loss = 3.212
Epoch  64 Batch    8/44   train_loss = 3.124
Epoch  64 Batch    9/44   train_loss = 3.168
Epoch  64 Batch   10/44   train_loss = 3.125
Epoch  64 Batch   11/44   train_loss = 3.151
Epoch  64 Batch   12/44   train_loss = 3.159
Epoch  64 Batch   13/44   train_loss = 3.114
Epoch  64 Batch   14/44   train_loss = 3.165
Epoch  64 Batch   15/44   train_loss = 3.067
Epoch  64 Batch   16/44   train_loss = 3.139
Epoch  64 Batch   17/44   train_loss = 3.211
Epoch  64 Batch   18/44   train_loss = 3.224
Epoch  64 Batch   19/44   train_loss = 3.141
Epoch  64 Batch   20/44   train_loss = 3.148
Epoch  64 Batch   21/44   train_loss = 3.088
Epoch  64 Batch   22/44   train_loss = 3.178
Epoch  64 Batch   23/44   train_loss = 3.170
Epoch  64 Batch   24/44   train_loss = 3.124
Epoch  64 Batch   25/44   train_loss = 3.198
Epoch  64 Batch   26/44   train_loss = 3.048
Epoch  64 Batch   27/44   train_loss = 3.180
Epoch  64 Batch   28/44   train_loss = 3.158
Epoch  64 Batch   29/44   train_loss = 3.136
Epoch  64 Batch   30/44   train_loss = 3.153
Epoch  64 Batch   31/44   train_loss = 3.241
Epoch  64 Batch   32/44   train_loss = 3.150
Epoch  64 Batch   33/44   train_loss = 3.238
Epoch  64 Batch   34/44   train_loss = 3.112
Epoch  64 Batch   35/44   train_loss = 3.089
Epoch  64 Batch   36/44   train_loss = 3.280
Epoch  64 Batch   37/44   train_loss = 3.169
Epoch  64 Batch   38/44   train_loss = 3.136
Epoch  64 Batch   39/44   train_loss = 3.047
Epoch  64 Batch   40/44   train_loss = 3.149
Epoch  64 Batch   41/44   train_loss = 3.120
Epoch  64 Batch   42/44   train_loss = 3.048
Epoch  64 Batch   43/44   train_loss = 3.104
Epoch  65 Batch    0/44   train_loss = 3.014
Epoch  65 Batch    1/44   train_loss = 3.060
Epoch  65 Batch    2/44   train_loss = 3.052
Epoch  65 Batch    3/44   train_loss = 3.106
Epoch  65 Batch    4/44   train_loss = 3.049
Epoch  65 Batch    5/44   train_loss = 3.037
Epoch  65 Batch    6/44   train_loss = 3.101
Epoch  65 Batch    7/44   train_loss = 3.167
Epoch  65 Batch    8/44   train_loss = 3.086
Epoch  65 Batch    9/44   train_loss = 3.118
Epoch  65 Batch   10/44   train_loss = 3.074
Epoch  65 Batch   11/44   train_loss = 3.107
Epoch  65 Batch   12/44   train_loss = 3.128
Epoch  65 Batch   13/44   train_loss = 3.084
Epoch  65 Batch   14/44   train_loss = 3.135
Epoch  65 Batch   15/44   train_loss = 3.029
Epoch  65 Batch   16/44   train_loss = 3.097
Epoch  65 Batch   17/44   train_loss = 3.168
Epoch  65 Batch   18/44   train_loss = 3.181
Epoch  65 Batch   19/44   train_loss = 3.095
Epoch  65 Batch   20/44   train_loss = 3.102
Epoch  65 Batch   21/44   train_loss = 3.042
Epoch  65 Batch   22/44   train_loss = 3.143
Epoch  65 Batch   23/44   train_loss = 3.130
Epoch  65 Batch   24/44   train_loss = 3.086
Epoch  65 Batch   25/44   train_loss = 3.150
Epoch  65 Batch   26/44   train_loss = 3.002
Epoch  65 Batch   27/44   train_loss = 3.132
Epoch  65 Batch   28/44   train_loss = 3.112
Epoch  65 Batch   29/44   train_loss = 3.095
Epoch  65 Batch   30/44   train_loss = 3.119
Epoch  65 Batch   31/44   train_loss = 3.202
Epoch  65 Batch   32/44   train_loss = 3.114
Epoch  65 Batch   33/44   train_loss = 3.193
Epoch  65 Batch   34/44   train_loss = 3.069
Epoch  65 Batch   35/44   train_loss = 3.051
Epoch  65 Batch   36/44   train_loss = 3.251
Epoch  65 Batch   37/44   train_loss = 3.140
Epoch  65 Batch   38/44   train_loss = 3.103
Epoch  65 Batch   39/44   train_loss = 3.018
Epoch  65 Batch   40/44   train_loss = 3.115
Epoch  65 Batch   41/44   train_loss = 3.082
Epoch  65 Batch   42/44   train_loss = 3.005
Epoch  65 Batch   43/44   train_loss = 3.058
Epoch  66 Batch    0/44   train_loss = 2.975
Epoch  66 Batch    1/44   train_loss = 3.017
Epoch  66 Batch    2/44   train_loss = 3.018
Epoch  66 Batch    3/44   train_loss = 3.069
Epoch  66 Batch    4/44   train_loss = 3.006
Epoch  66 Batch    5/44   train_loss = 2.995
Epoch  66 Batch    6/44   train_loss = 3.059
Epoch  66 Batch    7/44   train_loss = 3.123
Epoch  66 Batch    8/44   train_loss = 3.050
Epoch  66 Batch    9/44   train_loss = 3.073
Epoch  66 Batch   10/44   train_loss = 3.026
Epoch  66 Batch   11/44   train_loss = 3.061
Epoch  66 Batch   12/44   train_loss = 3.092
Epoch  66 Batch   13/44   train_loss = 3.061
Epoch  66 Batch   14/44   train_loss = 3.110
Epoch  66 Batch   15/44   train_loss = 3.002
Epoch  66 Batch   16/44   train_loss = 3.064
Epoch  66 Batch   17/44   train_loss = 3.134
Epoch  66 Batch   18/44   train_loss = 3.153
Epoch  66 Batch   19/44   train_loss = 3.058
Epoch  66 Batch   20/44   train_loss = 3.062
Epoch  66 Batch   21/44   train_loss = 2.996
Epoch  66 Batch   22/44   train_loss = 3.106
Epoch  66 Batch   23/44   train_loss = 3.096
Epoch  66 Batch   24/44   train_loss = 3.060
Epoch  66 Batch   25/44   train_loss = 3.120
Epoch  66 Batch   26/44   train_loss = 2.968
Epoch  66 Batch   27/44   train_loss = 3.086
Epoch  66 Batch   28/44   train_loss = 3.063
Epoch  66 Batch   29/44   train_loss = 3.052
Epoch  66 Batch   30/44   train_loss = 3.089
Epoch  66 Batch   31/44   train_loss = 3.175
Epoch  66 Batch   32/44   train_loss = 3.087
Epoch  66 Batch   33/44   train_loss = 3.161
Epoch  66 Batch   34/44   train_loss = 3.032
Epoch  66 Batch   35/44   train_loss = 3.017
Epoch  66 Batch   36/44   train_loss = 3.222
Epoch  66 Batch   37/44   train_loss = 3.114
Epoch  66 Batch   38/44   train_loss = 3.075
Epoch  66 Batch   39/44   train_loss = 2.994
Epoch  66 Batch   40/44   train_loss = 3.093
Epoch  66 Batch   41/44   train_loss = 3.059
Epoch  66 Batch   42/44   train_loss = 2.976
Epoch  66 Batch   43/44   train_loss = 3.014
Epoch  67 Batch    0/44   train_loss = 2.929
Epoch  67 Batch    1/44   train_loss = 2.969
Epoch  67 Batch    2/44   train_loss = 2.986
Epoch  67 Batch    3/44   train_loss = 3.044
Epoch  67 Batch    4/44   train_loss = 2.970
Epoch  67 Batch    5/44   train_loss = 2.957
Epoch  67 Batch    6/44   train_loss = 3.014
Epoch  67 Batch    7/44   train_loss = 3.074
Epoch  67 Batch    8/44   train_loss = 3.021
Epoch  67 Batch    9/44   train_loss = 3.041
Epoch  67 Batch   10/44   train_loss = 2.988
Epoch  67 Batch   11/44   train_loss = 3.015
Epoch  67 Batch   12/44   train_loss = 3.042
Epoch  67 Batch   13/44   train_loss = 3.025
Epoch  67 Batch   14/44   train_loss = 3.089
Epoch  67 Batch   15/44   train_loss = 2.984
Epoch  67 Batch   16/44   train_loss = 3.038
Epoch  67 Batch   17/44   train_loss = 3.109
Epoch  67 Batch   18/44   train_loss = 3.137
Epoch  67 Batch   19/44   train_loss = 3.045
Epoch  67 Batch   20/44   train_loss = 3.036
Epoch  67 Batch   21/44   train_loss = 2.966
Epoch  67 Batch   22/44   train_loss = 3.067
Epoch  67 Batch   23/44   train_loss = 3.054
Epoch  67 Batch   24/44   train_loss = 3.042
Epoch  67 Batch   25/44   train_loss = 3.118
Epoch  67 Batch   26/44   train_loss = 2.967
Epoch  67 Batch   27/44   train_loss = 3.066
Epoch  67 Batch   28/44   train_loss = 3.021
Epoch  67 Batch   29/44   train_loss = 2.998
Epoch  67 Batch   30/44   train_loss = 3.046
Epoch  67 Batch   31/44   train_loss = 3.156
Epoch  67 Batch   32/44   train_loss = 3.083
Epoch  67 Batch   33/44   train_loss = 3.155
Epoch  67 Batch   34/44   train_loss = 3.010
Epoch  67 Batch   35/44   train_loss = 2.984
Epoch  67 Batch   36/44   train_loss = 3.193
Epoch  67 Batch   37/44   train_loss = 3.094
Epoch  67 Batch   38/44   train_loss = 3.065
Epoch  67 Batch   39/44   train_loss = 2.986
Epoch  67 Batch   40/44   train_loss = 3.083
Epoch  67 Batch   41/44   train_loss = 3.053
Epoch  67 Batch   42/44   train_loss = 2.974
Epoch  67 Batch   43/44   train_loss = 3.005
Epoch  68 Batch    0/44   train_loss = 2.910
Epoch  68 Batch    1/44   train_loss = 2.929
Epoch  68 Batch    2/44   train_loss = 2.954
Epoch  68 Batch    3/44   train_loss = 3.020
Epoch  68 Batch    4/44   train_loss = 2.958
Epoch  68 Batch    5/44   train_loss = 2.950
Epoch  68 Batch    6/44   train_loss = 2.996
Epoch  68 Batch    7/44   train_loss = 3.023
Epoch  68 Batch    8/44   train_loss = 2.972
Epoch  68 Batch    9/44   train_loss = 3.014
Epoch  68 Batch   10/44   train_loss = 2.974
Epoch  68 Batch   11/44   train_loss = 3.002
Epoch  68 Batch   12/44   train_loss = 2.993
Epoch  68 Batch   13/44   train_loss = 2.966
Epoch  68 Batch   14/44   train_loss = 3.033
Epoch  68 Batch   15/44   train_loss = 2.968
Epoch  68 Batch   16/44   train_loss = 3.031
Epoch  68 Batch   17/44   train_loss = 3.097
Epoch  68 Batch   18/44   train_loss = 3.104
Epoch  68 Batch   19/44   train_loss = 3.001
Epoch  68 Batch   20/44   train_loss = 3.019
Epoch  68 Batch   21/44   train_loss = 2.985
Epoch  68 Batch   22/44   train_loss = 3.077
Epoch  68 Batch   23/44   train_loss = 3.035
Epoch  68 Batch   24/44   train_loss = 2.986
Epoch  68 Batch   25/44   train_loss = 3.062
Epoch  68 Batch   26/44   train_loss = 2.963
Epoch  68 Batch   27/44   train_loss = 3.125
Epoch  68 Batch   28/44   train_loss = 3.087
Epoch  68 Batch   29/44   train_loss = 3.021
Epoch  68 Batch   30/44   train_loss = 2.984
Epoch  68 Batch   31/44   train_loss = 3.080
Epoch  68 Batch   32/44   train_loss = 3.048
Epoch  68 Batch   33/44   train_loss = 3.171
Epoch  68 Batch   34/44   train_loss = 3.060
Epoch  68 Batch   35/44   train_loss = 3.024
Epoch  68 Batch   36/44   train_loss = 3.190
Epoch  68 Batch   37/44   train_loss = 3.050
Epoch  68 Batch   38/44   train_loss = 3.027
Epoch  68 Batch   39/44   train_loss = 2.959
Epoch  68 Batch   40/44   train_loss = 3.089
Epoch  68 Batch   41/44   train_loss = 3.080
Epoch  68 Batch   42/44   train_loss = 2.991
Epoch  68 Batch   43/44   train_loss = 3.019
Epoch  69 Batch    0/44   train_loss = 2.926
Epoch  69 Batch    1/44   train_loss = 2.955
Epoch  69 Batch    2/44   train_loss = 2.972
Epoch  69 Batch    3/44   train_loss = 3.002
Epoch  69 Batch    4/44   train_loss = 2.933
Epoch  69 Batch    5/44   train_loss = 2.919
Epoch  69 Batch    6/44   train_loss = 2.990
Epoch  69 Batch    7/44   train_loss = 3.036
Epoch  69 Batch    8/44   train_loss = 2.966
Epoch  69 Batch    9/44   train_loss = 2.986
Epoch  69 Batch   10/44   train_loss = 2.921
Epoch  69 Batch   11/44   train_loss = 2.953
Epoch  69 Batch   12/44   train_loss = 2.970
Epoch  69 Batch   13/44   train_loss = 2.952
Epoch  69 Batch   14/44   train_loss = 2.988
Epoch  69 Batch   15/44   train_loss = 2.905
Epoch  69 Batch   16/44   train_loss = 2.952
Epoch  69 Batch   17/44   train_loss = 3.039
Epoch  69 Batch   18/44   train_loss = 3.074
Epoch  69 Batch   19/44   train_loss = 2.970
Epoch  69 Batch   20/44   train_loss = 2.968
Epoch  69 Batch   21/44   train_loss = 2.905
Epoch  69 Batch   22/44   train_loss = 3.022
Epoch  69 Batch   23/44   train_loss = 3.008
Epoch  69 Batch   24/44   train_loss = 2.975
Epoch  69 Batch   25/44   train_loss = 3.018
Epoch  69 Batch   26/44   train_loss = 2.865
Epoch  69 Batch   27/44   train_loss = 3.000
Epoch  69 Batch   28/44   train_loss = 3.013
Epoch  69 Batch   29/44   train_loss = 3.016
Epoch  69 Batch   30/44   train_loss = 3.006
Epoch  69 Batch   31/44   train_loss = 3.078
Epoch  69 Batch   32/44   train_loss = 2.965
Epoch  69 Batch   33/44   train_loss = 3.037
Epoch  69 Batch   34/44   train_loss = 2.949
Epoch  69 Batch   35/44   train_loss = 2.975
Epoch  69 Batch   36/44   train_loss = 3.182
Epoch  69 Batch   37/44   train_loss = 3.056
Epoch  69 Batch   38/44   train_loss = 3.009
Epoch  69 Batch   39/44   train_loss = 2.901
Epoch  69 Batch   40/44   train_loss = 3.000
Epoch  69 Batch   41/44   train_loss = 2.997
Epoch  69 Batch   42/44   train_loss = 2.940
Epoch  69 Batch   43/44   train_loss = 3.005
Epoch  70 Batch    0/44   train_loss = 2.913
Epoch  70 Batch    1/44   train_loss = 2.943
Epoch  70 Batch    2/44   train_loss = 2.961
Epoch  70 Batch    3/44   train_loss = 2.999
Epoch  70 Batch    4/44   train_loss = 2.929
Epoch  70 Batch    5/44   train_loss = 2.900
Epoch  70 Batch    6/44   train_loss = 2.947
Epoch  70 Batch    7/44   train_loss = 2.976
Epoch  70 Batch    8/44   train_loss = 2.919
Epoch  70 Batch    9/44   train_loss = 2.966
Epoch  70 Batch   10/44   train_loss = 2.920
Epoch  70 Batch   11/44   train_loss = 2.934
Epoch  70 Batch   12/44   train_loss = 2.946
Epoch  70 Batch   13/44   train_loss = 2.907
Epoch  70 Batch   14/44   train_loss = 2.947
Epoch  70 Batch   15/44   train_loss = 2.878
Epoch  70 Batch   16/44   train_loss = 2.933
Epoch  70 Batch   17/44   train_loss = 2.990
Epoch  70 Batch   18/44   train_loss = 3.021
Epoch  70 Batch   19/44   train_loss = 2.917
Epoch  70 Batch   20/44   train_loss = 2.925
Epoch  70 Batch   21/44   train_loss = 2.863
Epoch  70 Batch   22/44   train_loss = 2.978
Epoch  70 Batch   23/44   train_loss = 2.950
Epoch  70 Batch   24/44   train_loss = 2.923
Epoch  70 Batch   25/44   train_loss = 2.972
Epoch  70 Batch   26/44   train_loss = 2.820
Epoch  70 Batch   27/44   train_loss = 2.949
Epoch  70 Batch   28/44   train_loss = 2.930
Epoch  70 Batch   29/44   train_loss = 2.911
Epoch  70 Batch   30/44   train_loss = 2.920
Epoch  70 Batch   31/44   train_loss = 3.014
Epoch  70 Batch   32/44   train_loss = 2.929
Epoch  70 Batch   33/44   train_loss = 2.989
Epoch  70 Batch   34/44   train_loss = 2.876
Epoch  70 Batch   35/44   train_loss = 2.886
Epoch  70 Batch   36/44   train_loss = 3.090
Epoch  70 Batch   37/44   train_loss = 2.979
Epoch  70 Batch   38/44   train_loss = 2.963
Epoch  70 Batch   39/44   train_loss = 2.854
Epoch  70 Batch   40/44   train_loss = 2.938
Epoch  70 Batch   41/44   train_loss = 2.915
Epoch  70 Batch   42/44   train_loss = 2.844
Epoch  70 Batch   43/44   train_loss = 2.906
Epoch  71 Batch    0/44   train_loss = 2.841
Epoch  71 Batch    1/44   train_loss = 2.874
Epoch  71 Batch    2/44   train_loss = 2.909
Epoch  71 Batch    3/44   train_loss = 2.951
Epoch  71 Batch    4/44   train_loss = 2.895
Epoch  71 Batch    5/44   train_loss = 2.876
Epoch  71 Batch    6/44   train_loss = 2.926
Epoch  71 Batch    7/44   train_loss = 2.936
Epoch  71 Batch    8/44   train_loss = 2.867
Epoch  71 Batch    9/44   train_loss = 2.901
Epoch  71 Batch   10/44   train_loss = 2.859
Epoch  71 Batch   11/44   train_loss = 2.880
Epoch  71 Batch   12/44   train_loss = 2.931
Epoch  71 Batch   13/44   train_loss = 2.891
Epoch  71 Batch   14/44   train_loss = 2.934
Epoch  71 Batch   15/44   train_loss = 2.858
Epoch  71 Batch   16/44   train_loss = 2.909
Epoch  71 Batch   17/44   train_loss = 2.959
Epoch  71 Batch   18/44   train_loss = 2.990
Epoch  71 Batch   19/44   train_loss = 2.880
Epoch  71 Batch   20/44   train_loss = 2.892
Epoch  71 Batch   21/44   train_loss = 2.835
Epoch  71 Batch   22/44   train_loss = 2.955
Epoch  71 Batch   23/44   train_loss = 2.931
Epoch  71 Batch   24/44   train_loss = 2.904
Epoch  71 Batch   25/44   train_loss = 2.946
Epoch  71 Batch   26/44   train_loss = 2.791
Epoch  71 Batch   27/44   train_loss = 2.920
Epoch  71 Batch   28/44   train_loss = 2.888
Epoch  71 Batch   29/44   train_loss = 2.867
Epoch  71 Batch   30/44   train_loss = 2.873
Epoch  71 Batch   31/44   train_loss = 2.962
Epoch  71 Batch   32/44   train_loss = 2.886
Epoch  71 Batch   33/44   train_loss = 2.952
Epoch  71 Batch   34/44   train_loss = 2.839
Epoch  71 Batch   35/44   train_loss = 2.850
Epoch  71 Batch   36/44   train_loss = 3.043
Epoch  71 Batch   37/44   train_loss = 2.922
Epoch  71 Batch   38/44   train_loss = 2.910
Epoch  71 Batch   39/44   train_loss = 2.807
Epoch  71 Batch   40/44   train_loss = 2.891
Epoch  71 Batch   41/44   train_loss = 2.864
Epoch  71 Batch   42/44   train_loss = 2.786
Epoch  71 Batch   43/44   train_loss = 2.830
Epoch  72 Batch    0/44   train_loss = 2.773
Epoch  72 Batch    1/44   train_loss = 2.804
Epoch  72 Batch    2/44   train_loss = 2.852
Epoch  72 Batch    3/44   train_loss = 2.894
Epoch  72 Batch    4/44   train_loss = 2.835
Epoch  72 Batch    5/44   train_loss = 2.822
Epoch  72 Batch    6/44   train_loss = 2.882
Epoch  72 Batch    7/44   train_loss = 2.906
Epoch  72 Batch    8/44   train_loss = 2.847
Epoch  72 Batch    9/44   train_loss = 2.865
Epoch  72 Batch   10/44   train_loss = 2.808
Epoch  72 Batch   11/44   train_loss = 2.814
Epoch  72 Batch   12/44   train_loss = 2.875
Epoch  72 Batch   13/44   train_loss = 2.838
Epoch  72 Batch   14/44   train_loss = 2.899
Epoch  72 Batch   15/44   train_loss = 2.833
Epoch  72 Batch   16/44   train_loss = 2.901
Epoch  72 Batch   17/44   train_loss = 2.947
Epoch  72 Batch   18/44   train_loss = 2.979
Epoch  72 Batch   19/44   train_loss = 2.843
Epoch  72 Batch   20/44   train_loss = 2.850
Epoch  72 Batch   21/44   train_loss = 2.785
Epoch  72 Batch   22/44   train_loss = 2.926
Epoch  72 Batch   23/44   train_loss = 2.909
Epoch  72 Batch   24/44   train_loss = 2.888
Epoch  72 Batch   25/44   train_loss = 2.938
Epoch  72 Batch   26/44   train_loss = 2.786
Epoch  72 Batch   27/44   train_loss = 2.919
Epoch  72 Batch   28/44   train_loss = 2.881
Epoch  72 Batch   29/44   train_loss = 2.859
Epoch  72 Batch   30/44   train_loss = 2.851
Epoch  72 Batch   31/44   train_loss = 2.937
Epoch  72 Batch   32/44   train_loss = 2.860
Epoch  72 Batch   33/44   train_loss = 2.923
Epoch  72 Batch   34/44   train_loss = 2.810
Epoch  72 Batch   35/44   train_loss = 2.828
Epoch  72 Batch   36/44   train_loss = 3.013
Epoch  72 Batch   37/44   train_loss = 2.886
Epoch  72 Batch   38/44   train_loss = 2.879
Epoch  72 Batch   39/44   train_loss = 2.780
Epoch  72 Batch   40/44   train_loss = 2.866
Epoch  72 Batch   41/44   train_loss = 2.843
Epoch  72 Batch   42/44   train_loss = 2.762
Epoch  72 Batch   43/44   train_loss = 2.789
Epoch  73 Batch    0/44   train_loss = 2.733
Epoch  73 Batch    1/44   train_loss = 2.754
Epoch  73 Batch    2/44   train_loss = 2.811
Epoch  73 Batch    3/44   train_loss = 2.855
Epoch  73 Batch    4/44   train_loss = 2.793
Epoch  73 Batch    5/44   train_loss = 2.774
Epoch  73 Batch    6/44   train_loss = 2.834
Epoch  73 Batch    7/44   train_loss = 2.858
Epoch  73 Batch    8/44   train_loss = 2.811
Epoch  73 Batch    9/44   train_loss = 2.835
Epoch  73 Batch   10/44   train_loss = 2.782
Epoch  73 Batch   11/44   train_loss = 2.775
Epoch  73 Batch   12/44   train_loss = 2.827
Epoch  73 Batch   13/44   train_loss = 2.774
Epoch  73 Batch   14/44   train_loss = 2.831
Epoch  73 Batch   15/44   train_loss = 2.784
Epoch  73 Batch   16/44   train_loss = 2.872
Epoch  73 Batch   17/44   train_loss = 2.925
Epoch  73 Batch   18/44   train_loss = 2.973
Epoch  73 Batch   19/44   train_loss = 2.826
Epoch  73 Batch   20/44   train_loss = 2.825
Epoch  73 Batch   21/44   train_loss = 2.738
Epoch  73 Batch   22/44   train_loss = 2.874
Epoch  73 Batch   23/44   train_loss = 2.851
Epoch  73 Batch   24/44   train_loss = 2.844
Epoch  73 Batch   25/44   train_loss = 2.913
Epoch  73 Batch   26/44   train_loss = 2.773
Epoch  73 Batch   27/44   train_loss = 2.910
Epoch  73 Batch   28/44   train_loss = 2.869
Epoch  73 Batch   29/44   train_loss = 2.852
Epoch  73 Batch   30/44   train_loss = 2.843
Epoch  73 Batch   31/44   train_loss = 2.924
Epoch  73 Batch   32/44   train_loss = 2.845
Epoch  73 Batch   33/44   train_loss = 2.902
Epoch  73 Batch   34/44   train_loss = 2.785
Epoch  73 Batch   35/44   train_loss = 2.819
Epoch  73 Batch   36/44   train_loss = 2.997
Epoch  73 Batch   37/44   train_loss = 2.871
Epoch  73 Batch   38/44   train_loss = 2.854
Epoch  73 Batch   39/44   train_loss = 2.762
Epoch  73 Batch   40/44   train_loss = 2.849
Epoch  73 Batch   41/44   train_loss = 2.832
Epoch  73 Batch   42/44   train_loss = 2.752
Epoch  73 Batch   43/44   train_loss = 2.771
Epoch  74 Batch    0/44   train_loss = 2.715
Epoch  74 Batch    1/44   train_loss = 2.732
Epoch  74 Batch    2/44   train_loss = 2.788
Epoch  74 Batch    3/44   train_loss = 2.834
Epoch  74 Batch    4/44   train_loss = 2.764
Epoch  74 Batch    5/44   train_loss = 2.752
Epoch  74 Batch    6/44   train_loss = 2.797
Epoch  74 Batch    7/44   train_loss = 2.813
Epoch  74 Batch    8/44   train_loss = 2.773
Epoch  74 Batch    9/44   train_loss = 2.803
Epoch  74 Batch   10/44   train_loss = 2.755
Epoch  74 Batch   11/44   train_loss = 2.745
Epoch  74 Batch   12/44   train_loss = 2.804
Epoch  74 Batch   13/44   train_loss = 2.731
Epoch  74 Batch   14/44   train_loss = 2.780
Epoch  74 Batch   15/44   train_loss = 2.731
Epoch  74 Batch   16/44   train_loss = 2.814
Epoch  74 Batch   17/44   train_loss = 2.880
Epoch  74 Batch   18/44   train_loss = 2.935
Epoch  74 Batch   19/44   train_loss = 2.798
Epoch  74 Batch   20/44   train_loss = 2.806
Epoch  74 Batch   21/44   train_loss = 2.711
Epoch  74 Batch   22/44   train_loss = 2.844
Epoch  74 Batch   23/44   train_loss = 2.797
Epoch  74 Batch   24/44   train_loss = 2.794
Epoch  74 Batch   25/44   train_loss = 2.865
Epoch  74 Batch   26/44   train_loss = 2.738
Epoch  74 Batch   27/44   train_loss = 2.881
Epoch  74 Batch   28/44   train_loss = 2.846
Epoch  74 Batch   29/44   train_loss = 2.826
Epoch  74 Batch   30/44   train_loss = 2.821
Epoch  74 Batch   31/44   train_loss = 2.894
Epoch  74 Batch   32/44   train_loss = 2.834
Epoch  74 Batch   33/44   train_loss = 2.869
Epoch  74 Batch   34/44   train_loss = 2.755
Epoch  74 Batch   35/44   train_loss = 2.797
Epoch  74 Batch   36/44   train_loss = 2.975
Epoch  74 Batch   37/44   train_loss = 2.864
Epoch  74 Batch   38/44   train_loss = 2.832
Epoch  74 Batch   39/44   train_loss = 2.745
Epoch  74 Batch   40/44   train_loss = 2.826
Epoch  74 Batch   41/44   train_loss = 2.803
Epoch  74 Batch   42/44   train_loss = 2.728
Epoch  74 Batch   43/44   train_loss = 2.748
Epoch  75 Batch    0/44   train_loss = 2.691
Epoch  75 Batch    1/44   train_loss = 2.712
Epoch  75 Batch    2/44   train_loss = 2.762
Epoch  75 Batch    3/44   train_loss = 2.819
Epoch  75 Batch    4/44   train_loss = 2.754
Epoch  75 Batch    5/44   train_loss = 2.754
Epoch  75 Batch    6/44   train_loss = 2.796
Epoch  75 Batch    7/44   train_loss = 2.790
Epoch  75 Batch    8/44   train_loss = 2.747
Epoch  75 Batch    9/44   train_loss = 2.769
Epoch  75 Batch   10/44   train_loss = 2.717
Epoch  75 Batch   11/44   train_loss = 2.708
Epoch  75 Batch   12/44   train_loss = 2.780
Epoch  75 Batch   13/44   train_loss = 2.708
Epoch  75 Batch   14/44   train_loss = 2.765
Epoch  75 Batch   15/44   train_loss = 2.720
Epoch  75 Batch   16/44   train_loss = 2.790
Epoch  75 Batch   17/44   train_loss = 2.846
Epoch  75 Batch   18/44   train_loss = 2.892
Epoch  75 Batch   19/44   train_loss = 2.754
Epoch  75 Batch   20/44   train_loss = 2.772
Epoch  75 Batch   21/44   train_loss = 2.678
Epoch  75 Batch   22/44   train_loss = 2.821
Epoch  75 Batch   23/44   train_loss = 2.759
Epoch  75 Batch   24/44   train_loss = 2.755
Epoch  75 Batch   25/44   train_loss = 2.822
Epoch  75 Batch   26/44   train_loss = 2.701
Epoch  75 Batch   27/44   train_loss = 2.852
Epoch  75 Batch   28/44   train_loss = 2.831
Epoch  75 Batch   29/44   train_loss = 2.802
Epoch  75 Batch   30/44   train_loss = 2.796
Epoch  75 Batch   31/44   train_loss = 2.860
Epoch  75 Batch   32/44   train_loss = 2.806
Epoch  75 Batch   33/44   train_loss = 2.829
Epoch  75 Batch   34/44   train_loss = 2.706
Epoch  75 Batch   35/44   train_loss = 2.749
Epoch  75 Batch   36/44   train_loss = 2.940
Epoch  75 Batch   37/44   train_loss = 2.850
Epoch  75 Batch   38/44   train_loss = 2.830
Epoch  75 Batch   39/44   train_loss = 2.741
Epoch  75 Batch   40/44   train_loss = 2.815
Epoch  75 Batch   41/44   train_loss = 2.776
Epoch  75 Batch   42/44   train_loss = 2.693
Epoch  75 Batch   43/44   train_loss = 2.711
Epoch  76 Batch    0/44   train_loss = 2.665
Epoch  76 Batch    1/44   train_loss = 2.682
Epoch  76 Batch    2/44   train_loss = 2.726
Epoch  76 Batch    3/44   train_loss = 2.784
Epoch  76 Batch    4/44   train_loss = 2.722
Epoch  76 Batch    5/44   train_loss = 2.745
Epoch  76 Batch    6/44   train_loss = 2.809
Epoch  76 Batch    7/44   train_loss = 2.812
Epoch  76 Batch    8/44   train_loss = 2.762
Epoch  76 Batch    9/44   train_loss = 2.772
Epoch  76 Batch   10/44   train_loss = 2.698
Epoch  76 Batch   11/44   train_loss = 2.681
Epoch  76 Batch   12/44   train_loss = 2.743
Epoch  76 Batch   13/44   train_loss = 2.664
Epoch  76 Batch   14/44   train_loss = 2.734
Epoch  76 Batch   15/44   train_loss = 2.712
Epoch  76 Batch   16/44   train_loss = 2.794
Epoch  76 Batch   17/44   train_loss = 2.856
Epoch  76 Batch   18/44   train_loss = 2.908
Epoch  76 Batch   19/44   train_loss = 2.754
Epoch  76 Batch   20/44   train_loss = 2.768
Epoch  76 Batch   21/44   train_loss = 2.666
Epoch  76 Batch   22/44   train_loss = 2.819
Epoch  76 Batch   23/44   train_loss = 2.743
Epoch  76 Batch   24/44   train_loss = 2.728
Epoch  76 Batch   25/44   train_loss = 2.792
Epoch  76 Batch   26/44   train_loss = 2.658
Epoch  76 Batch   27/44   train_loss = 2.816
Epoch  76 Batch   28/44   train_loss = 2.820
Epoch  76 Batch   29/44   train_loss = 2.808
Epoch  76 Batch   30/44   train_loss = 2.819
Epoch  76 Batch   31/44   train_loss = 2.894
Epoch  76 Batch   32/44   train_loss = 2.819
Epoch  76 Batch   33/44   train_loss = 2.816
Epoch  76 Batch   34/44   train_loss = 2.671
Epoch  76 Batch   35/44   train_loss = 2.698
Epoch  76 Batch   36/44   train_loss = 2.885
Epoch  76 Batch   37/44   train_loss = 2.807
Epoch  76 Batch   38/44   train_loss = 2.821
Epoch  76 Batch   39/44   train_loss = 2.755
Epoch  76 Batch   40/44   train_loss = 2.848
Epoch  76 Batch   41/44   train_loss = 2.801
Epoch  76 Batch   42/44   train_loss = 2.708
Epoch  76 Batch   43/44   train_loss = 2.717
Epoch  77 Batch    0/44   train_loss = 2.667
Epoch  77 Batch    1/44   train_loss = 2.671
Epoch  77 Batch    2/44   train_loss = 2.708
Epoch  77 Batch    3/44   train_loss = 2.752
Epoch  77 Batch    4/44   train_loss = 2.680
Epoch  77 Batch    5/44   train_loss = 2.693
Epoch  77 Batch    6/44   train_loss = 2.777
Epoch  77 Batch    7/44   train_loss = 2.811
Epoch  77 Batch    8/44   train_loss = 2.797
Epoch  77 Batch    9/44   train_loss = 2.837
Epoch  77 Batch   10/44   train_loss = 2.748
Epoch  77 Batch   11/44   train_loss = 2.727
Epoch  77 Batch   12/44   train_loss = 2.742
Epoch  77 Batch   13/44   train_loss = 2.636
Epoch  77 Batch   14/44   train_loss = 2.678
Epoch  77 Batch   15/44   train_loss = 2.656
Epoch  77 Batch   16/44   train_loss = 2.762
Epoch  77 Batch   17/44   train_loss = 2.834
Epoch  77 Batch   18/44   train_loss = 2.918
Epoch  77 Batch   19/44   train_loss = 2.768
Epoch  77 Batch   20/44   train_loss = 2.788
Epoch  77 Batch   21/44   train_loss = 2.693
Epoch  77 Batch   22/44   train_loss = 2.837
Epoch  77 Batch   23/44   train_loss = 2.756
Epoch  77 Batch   24/44   train_loss = 2.733
Epoch  77 Batch   25/44   train_loss = 2.795
Epoch  77 Batch   26/44   train_loss = 2.642
Epoch  77 Batch   27/44   train_loss = 2.775
Epoch  77 Batch   28/44   train_loss = 2.747
Epoch  77 Batch   29/44   train_loss = 2.740
Epoch  77 Batch   30/44   train_loss = 2.785
Epoch  77 Batch   31/44   train_loss = 2.909
Epoch  77 Batch   32/44   train_loss = 2.888
Epoch  77 Batch   33/44   train_loss = 2.890
Epoch  77 Batch   34/44   train_loss = 2.736
Epoch  77 Batch   35/44   train_loss = 2.724
Epoch  77 Batch   36/44   train_loss = 2.849
Epoch  77 Batch   37/44   train_loss = 2.742
Epoch  77 Batch   38/44   train_loss = 2.763
Epoch  77 Batch   39/44   train_loss = 2.706
Epoch  77 Batch   40/44   train_loss = 2.811
Epoch  77 Batch   41/44   train_loss = 2.799
Epoch  77 Batch   42/44   train_loss = 2.713
Epoch  77 Batch   43/44   train_loss = 2.734
Epoch  78 Batch    0/44   train_loss = 2.682
Epoch  78 Batch    1/44   train_loss = 2.689
Epoch  78 Batch    2/44   train_loss = 2.713
Epoch  78 Batch    3/44   train_loss = 2.775
Epoch  78 Batch    4/44   train_loss = 2.687
Epoch  78 Batch    5/44   train_loss = 2.662
Epoch  78 Batch    6/44   train_loss = 2.717
Epoch  78 Batch    7/44   train_loss = 2.710
Epoch  78 Batch    8/44   train_loss = 2.715
Epoch  78 Batch    9/44   train_loss = 2.804
Epoch  78 Batch   10/44   train_loss = 2.760
Epoch  78 Batch   11/44   train_loss = 2.794
Epoch  78 Batch   12/44   train_loss = 2.817
Epoch  78 Batch   13/44   train_loss = 2.696
Epoch  78 Batch   14/44   train_loss = 2.711
Epoch  78 Batch   15/44   train_loss = 2.635
Epoch  78 Batch   16/44   train_loss = 2.717
Epoch  78 Batch   17/44   train_loss = 2.773
Epoch  78 Batch   18/44   train_loss = 2.869
Epoch  78 Batch   19/44   train_loss = 2.733
Epoch  78 Batch   20/44   train_loss = 2.755
Epoch  78 Batch   21/44   train_loss = 2.666
Epoch  78 Batch   22/44   train_loss = 2.809
Epoch  78 Batch   23/44   train_loss = 2.726
Epoch  78 Batch   24/44   train_loss = 2.723
Epoch  78 Batch   25/44   train_loss = 2.808
Epoch  78 Batch   26/44   train_loss = 2.662
Epoch  78 Batch   27/44   train_loss = 2.792
Epoch  78 Batch   28/44   train_loss = 2.722
Epoch  78 Batch   29/44   train_loss = 2.689
Epoch  78 Batch   30/44   train_loss = 2.707
Epoch  78 Batch   31/44   train_loss = 2.804
Epoch  78 Batch   32/44   train_loss = 2.818
Epoch  78 Batch   33/44   train_loss = 2.894
Epoch  78 Batch   34/44   train_loss = 2.776
Epoch  78 Batch   35/44   train_loss = 2.778
Epoch  78 Batch   36/44   train_loss = 2.885
Epoch  78 Batch   37/44   train_loss = 2.751
Epoch  78 Batch   38/44   train_loss = 2.745
Epoch  78 Batch   39/44   train_loss = 2.659
Epoch  78 Batch   40/44   train_loss = 2.763
Epoch  78 Batch   41/44   train_loss = 2.776
Epoch  78 Batch   42/44   train_loss = 2.694
Epoch  78 Batch   43/44   train_loss = 2.713
Epoch  79 Batch    0/44   train_loss = 2.645
Epoch  79 Batch    1/44   train_loss = 2.643
Epoch  79 Batch    2/44   train_loss = 2.654
Epoch  79 Batch    3/44   train_loss = 2.743
Epoch  79 Batch    4/44   train_loss = 2.675
Epoch  79 Batch    5/44   train_loss = 2.666
Epoch  79 Batch    6/44   train_loss = 2.727
Epoch  79 Batch    7/44   train_loss = 2.708
Epoch  79 Batch    8/44   train_loss = 2.663
Epoch  79 Batch    9/44   train_loss = 2.704
Epoch  79 Batch   10/44   train_loss = 2.661
Epoch  79 Batch   11/44   train_loss = 2.713
Epoch  79 Batch   12/44   train_loss = 2.779
Epoch  79 Batch   13/44   train_loss = 2.683
Epoch  79 Batch   14/44   train_loss = 2.715
Epoch  79 Batch   15/44   train_loss = 2.639
Epoch  79 Batch   16/44   train_loss = 2.674
Epoch  79 Batch   17/44   train_loss = 2.721
Epoch  79 Batch   18/44   train_loss = 2.809
Epoch  79 Batch   19/44   train_loss = 2.683
Epoch  79 Batch   20/44   train_loss = 2.719
Epoch  79 Batch   21/44   train_loss = 2.634
Epoch  79 Batch   22/44   train_loss = 2.771
Epoch  79 Batch   23/44   train_loss = 2.671
Epoch  79 Batch   24/44   train_loss = 2.663
Epoch  79 Batch   25/44   train_loss = 2.732
Epoch  79 Batch   26/44   train_loss = 2.611
Epoch  79 Batch   27/44   train_loss = 2.767
Epoch  79 Batch   28/44   train_loss = 2.713
Epoch  79 Batch   29/44   train_loss = 2.694
Epoch  79 Batch   30/44   train_loss = 2.710
Epoch  79 Batch   31/44   train_loss = 2.769
Epoch  79 Batch   32/44   train_loss = 2.734
Epoch  79 Batch   33/44   train_loss = 2.796
Epoch  79 Batch   34/44   train_loss = 2.706
Epoch  79 Batch   35/44   train_loss = 2.747
Epoch  79 Batch   36/44   train_loss = 2.898
Epoch  79 Batch   37/44   train_loss = 2.767
Epoch  79 Batch   38/44   train_loss = 2.730
Epoch  79 Batch   39/44   train_loss = 2.588
Epoch  79 Batch   40/44   train_loss = 2.695
Epoch  79 Batch   41/44   train_loss = 2.706
Epoch  79 Batch   42/44   train_loss = 2.655
Epoch  79 Batch   43/44   train_loss = 2.700
Epoch  80 Batch    0/44   train_loss = 2.662
Epoch  80 Batch    1/44   train_loss = 2.648
Epoch  80 Batch    2/44   train_loss = 2.628
Epoch  80 Batch    3/44   train_loss = 2.662
Epoch  80 Batch    4/44   train_loss = 2.586
Epoch  80 Batch    5/44   train_loss = 2.588
Epoch  80 Batch    6/44   train_loss = 2.664
Epoch  80 Batch    7/44   train_loss = 2.687
Epoch  80 Batch    8/44   train_loss = 2.652
Epoch  80 Batch    9/44   train_loss = 2.682
Epoch  80 Batch   10/44   train_loss = 2.610
Epoch  80 Batch   11/44   train_loss = 2.635
Epoch  80 Batch   12/44   train_loss = 2.715
Epoch  80 Batch   13/44   train_loss = 2.614
Epoch  80 Batch   14/44   train_loss = 2.678
Epoch  80 Batch   15/44   train_loss = 2.629
Epoch  80 Batch   16/44   train_loss = 2.661
Epoch  80 Batch   17/44   train_loss = 2.677
Epoch  80 Batch   18/44   train_loss = 2.728
Epoch  80 Batch   19/44   train_loss = 2.589
Epoch  80 Batch   20/44   train_loss = 2.653
Epoch  80 Batch   21/44   train_loss = 2.590
Epoch  80 Batch   22/44   train_loss = 2.765
Epoch  80 Batch   23/44   train_loss = 2.666
Epoch  80 Batch   24/44   train_loss = 2.644
Epoch  80 Batch   25/44   train_loss = 2.677
Epoch  80 Batch   26/44   train_loss = 2.536
Epoch  80 Batch   27/44   train_loss = 2.672
Epoch  80 Batch   28/44   train_loss = 2.635
Epoch  80 Batch   29/44   train_loss = 2.613
Epoch  80 Batch   30/44   train_loss = 2.679
Epoch  80 Batch   31/44   train_loss = 2.738
Epoch  80 Batch   32/44   train_loss = 2.689
Epoch  80 Batch   33/44   train_loss = 2.720
Epoch  80 Batch   34/44   train_loss = 2.602
Epoch  80 Batch   35/44   train_loss = 2.653
Epoch  80 Batch   36/44   train_loss = 2.825
Epoch  80 Batch   37/44   train_loss = 2.718
Epoch  80 Batch   38/44   train_loss = 2.705
Epoch  80 Batch   39/44   train_loss = 2.571
Epoch  80 Batch   40/44   train_loss = 2.648
Epoch  80 Batch   41/44   train_loss = 2.610
Epoch  80 Batch   42/44   train_loss = 2.529
Epoch  80 Batch   43/44   train_loss = 2.582
Epoch  81 Batch    0/44   train_loss = 2.594
Epoch  81 Batch    1/44   train_loss = 2.613
Epoch  81 Batch    2/44   train_loss = 2.641
Epoch  81 Batch    3/44   train_loss = 2.638
Epoch  81 Batch    4/44   train_loss = 2.553
Epoch  81 Batch    5/44   train_loss = 2.524
Epoch  81 Batch    6/44   train_loss = 2.575
Epoch  81 Batch    7/44   train_loss = 2.587
Epoch  81 Batch    8/44   train_loss = 2.578
Epoch  81 Batch    9/44   train_loss = 2.634
Epoch  81 Batch   10/44   train_loss = 2.573
Epoch  81 Batch   11/44   train_loss = 2.592
Epoch  81 Batch   12/44   train_loss = 2.669
Epoch  81 Batch   13/44   train_loss = 2.537
Epoch  81 Batch   14/44   train_loss = 2.605
Epoch  81 Batch   15/44   train_loss = 2.560
Epoch  81 Batch   16/44   train_loss = 2.625
Epoch  81 Batch   17/44   train_loss = 2.650
Epoch  81 Batch   18/44   train_loss = 2.691
Epoch  81 Batch   19/44   train_loss = 2.531
Epoch  81 Batch   20/44   train_loss = 2.565
Epoch  81 Batch   21/44   train_loss = 2.486
Epoch  81 Batch   22/44   train_loss = 2.667
Epoch  81 Batch   23/44   train_loss = 2.602
Epoch  81 Batch   24/44   train_loss = 2.598
Epoch  81 Batch   25/44   train_loss = 2.645
Epoch  81 Batch   26/44   train_loss = 2.501
Epoch  81 Batch   27/44   train_loss = 2.616
Epoch  81 Batch   28/44   train_loss = 2.571
Epoch  81 Batch   29/44   train_loss = 2.520
Epoch  81 Batch   30/44   train_loss = 2.598
Epoch  81 Batch   31/44   train_loss = 2.679
Epoch  81 Batch   32/44   train_loss = 2.647
Epoch  81 Batch   33/44   train_loss = 2.681
Epoch  81 Batch   34/44   train_loss = 2.547
Epoch  81 Batch   35/44   train_loss = 2.572
Epoch  81 Batch   36/44   train_loss = 2.728
Epoch  81 Batch   37/44   train_loss = 2.619
Epoch  81 Batch   38/44   train_loss = 2.633
Epoch  81 Batch   39/44   train_loss = 2.529
Epoch  81 Batch   40/44   train_loss = 2.620
Epoch  81 Batch   41/44   train_loss = 2.587
Epoch  81 Batch   42/44   train_loss = 2.468
Epoch  81 Batch   43/44   train_loss = 2.491
Epoch  82 Batch    0/44   train_loss = 2.496
Epoch  82 Batch    1/44   train_loss = 2.506
Epoch  82 Batch    2/44   train_loss = 2.580
Epoch  82 Batch    3/44   train_loss = 2.590
Epoch  82 Batch    4/44   train_loss = 2.535
Epoch  82 Batch    5/44   train_loss = 2.495
Epoch  82 Batch    6/44   train_loss = 2.525
Epoch  82 Batch    7/44   train_loss = 2.511
Epoch  82 Batch    8/44   train_loss = 2.497
Epoch  82 Batch    9/44   train_loss = 2.560
Epoch  82 Batch   10/44   train_loss = 2.511
Epoch  82 Batch   11/44   train_loss = 2.547
Epoch  82 Batch   12/44   train_loss = 2.622
Epoch  82 Batch   13/44   train_loss = 2.487
Epoch  82 Batch   14/44   train_loss = 2.539
Epoch  82 Batch   15/44   train_loss = 2.491
Epoch  82 Batch   16/44   train_loss = 2.560
Epoch  82 Batch   17/44   train_loss = 2.595
Epoch  82 Batch   18/44   train_loss = 2.649
Epoch  82 Batch   19/44   train_loss = 2.490
Epoch  82 Batch   20/44   train_loss = 2.522
Epoch  82 Batch   21/44   train_loss = 2.422
Epoch  82 Batch   22/44   train_loss = 2.586
Epoch  82 Batch   23/44   train_loss = 2.513
Epoch  82 Batch   24/44   train_loss = 2.522
Epoch  82 Batch   25/44   train_loss = 2.587
Epoch  82 Batch   26/44   train_loss = 2.463
Epoch  82 Batch   27/44   train_loss = 2.584
Epoch  82 Batch   28/44   train_loss = 2.527
Epoch  82 Batch   29/44   train_loss = 2.467
Epoch  82 Batch   30/44   train_loss = 2.523
Epoch  82 Batch   31/44   train_loss = 2.611
Epoch  82 Batch   32/44   train_loss = 2.599
Epoch  82 Batch   33/44   train_loss = 2.646
Epoch  82 Batch   34/44   train_loss = 2.519
Epoch  82 Batch   35/44   train_loss = 2.533
Epoch  82 Batch   36/44   train_loss = 2.667
Epoch  82 Batch   37/44   train_loss = 2.542
Epoch  82 Batch   38/44   train_loss = 2.556
Epoch  82 Batch   39/44   train_loss = 2.461
Epoch  82 Batch   40/44   train_loss = 2.566
Epoch  82 Batch   41/44   train_loss = 2.559
Epoch  82 Batch   42/44   train_loss = 2.454
Epoch  82 Batch   43/44   train_loss = 2.458
Epoch  83 Batch    0/44   train_loss = 2.436
Epoch  83 Batch    1/44   train_loss = 2.428
Epoch  83 Batch    2/44   train_loss = 2.496
Epoch  83 Batch    3/44   train_loss = 2.515
Epoch  83 Batch    4/44   train_loss = 2.479
Epoch  83 Batch    5/44   train_loss = 2.457
Epoch  83 Batch    6/44   train_loss = 2.497
Epoch  83 Batch    7/44   train_loss = 2.469
Epoch  83 Batch    8/44   train_loss = 2.438
Epoch  83 Batch    9/44   train_loss = 2.488
Epoch  83 Batch   10/44   train_loss = 2.443
Epoch  83 Batch   11/44   train_loss = 2.489
Epoch  83 Batch   12/44   train_loss = 2.579
Epoch  83 Batch   13/44   train_loss = 2.451
Epoch  83 Batch   14/44   train_loss = 2.493
Epoch  83 Batch   15/44   train_loss = 2.450
Epoch  83 Batch   16/44   train_loss = 2.504
Epoch  83 Batch   17/44   train_loss = 2.536
Epoch  83 Batch   18/44   train_loss = 2.595
Epoch  83 Batch   19/44   train_loss = 2.447
Epoch  83 Batch   20/44   train_loss = 2.488
Epoch  83 Batch   21/44   train_loss = 2.384
Epoch  83 Batch   22/44   train_loss = 2.535
Epoch  83 Batch   23/44   train_loss = 2.450
Epoch  83 Batch   24/44   train_loss = 2.458
Epoch  83 Batch   25/44   train_loss = 2.519
Epoch  83 Batch   26/44   train_loss = 2.408
Epoch  83 Batch   27/44   train_loss = 2.542
Epoch  83 Batch   28/44   train_loss = 2.492
Epoch  83 Batch   29/44   train_loss = 2.443
Epoch  83 Batch   30/44   train_loss = 2.467
Epoch  83 Batch   31/44   train_loss = 2.550
Epoch  83 Batch   32/44   train_loss = 2.544
Epoch  83 Batch   33/44   train_loss = 2.595
Epoch  83 Batch   34/44   train_loss = 2.476
Epoch  83 Batch   35/44   train_loss = 2.505
Epoch  83 Batch   36/44   train_loss = 2.640
Epoch  83 Batch   37/44   train_loss = 2.501
Epoch  83 Batch   38/44   train_loss = 2.509
Epoch  83 Batch   39/44   train_loss = 2.397
Epoch  83 Batch   40/44   train_loss = 2.494
Epoch  83 Batch   41/44   train_loss = 2.502
Epoch  83 Batch   42/44   train_loss = 2.421
Epoch  83 Batch   43/44   train_loss = 2.435
Epoch  84 Batch    0/44   train_loss = 2.410
Epoch  84 Batch    1/44   train_loss = 2.391
Epoch  84 Batch    2/44   train_loss = 2.439
Epoch  84 Batch    3/44   train_loss = 2.449
Epoch  84 Batch    4/44   train_loss = 2.406
Epoch  84 Batch    5/44   train_loss = 2.399
Epoch  84 Batch    6/44   train_loss = 2.456
Epoch  84 Batch    7/44   train_loss = 2.435
Epoch  84 Batch    8/44   train_loss = 2.399
Epoch  84 Batch    9/44   train_loss = 2.445
Epoch  84 Batch   10/44   train_loss = 2.384
Epoch  84 Batch   11/44   train_loss = 2.420
Epoch  84 Batch   12/44   train_loss = 2.517
Epoch  84 Batch   13/44   train_loss = 2.401
Epoch  84 Batch   14/44   train_loss = 2.454
Epoch  84 Batch   15/44   train_loss = 2.423
Epoch  84 Batch   16/44   train_loss = 2.477
Epoch  84 Batch   17/44   train_loss = 2.492
Epoch  84 Batch   18/44   train_loss = 2.547
Epoch  84 Batch   19/44   train_loss = 2.393
Epoch  84 Batch   20/44   train_loss = 2.440
Epoch  84 Batch   21/44   train_loss = 2.346
Epoch  84 Batch   22/44   train_loss = 2.502
Epoch  84 Batch   23/44   train_loss = 2.417
Epoch  84 Batch   24/44   train_loss = 2.419
Epoch  84 Batch   25/44   train_loss = 2.465
Epoch  84 Batch   26/44   train_loss = 2.348
Epoch  84 Batch   27/44   train_loss = 2.479
Epoch  84 Batch   28/44   train_loss = 2.439
Epoch  84 Batch   29/44   train_loss = 2.413
Epoch  84 Batch   30/44   train_loss = 2.431
Epoch  84 Batch   31/44   train_loss = 2.513
Epoch  84 Batch   32/44   train_loss = 2.496
Epoch  84 Batch   33/44   train_loss = 2.542
Epoch  84 Batch   34/44   train_loss = 2.420
Epoch  84 Batch   35/44   train_loss = 2.459
Epoch  84 Batch   36/44   train_loss = 2.613
Epoch  84 Batch   37/44   train_loss = 2.477
Epoch  84 Batch   38/44   train_loss = 2.487
Epoch  84 Batch   39/44   train_loss = 2.360
Epoch  84 Batch   40/44   train_loss = 2.441
Epoch  84 Batch   41/44   train_loss = 2.449
Epoch  84 Batch   42/44   train_loss = 2.371
Epoch  84 Batch   43/44   train_loss = 2.397
Epoch  85 Batch    0/44   train_loss = 2.384
Epoch  85 Batch    1/44   train_loss = 2.375
Epoch  85 Batch    2/44   train_loss = 2.413
Epoch  85 Batch    3/44   train_loss = 2.414
Epoch  85 Batch    4/44   train_loss = 2.349
Epoch  85 Batch    5/44   train_loss = 2.345
Epoch  85 Batch    6/44   train_loss = 2.407
Epoch  85 Batch    7/44   train_loss = 2.393
Epoch  85 Batch    8/44   train_loss = 2.370
Epoch  85 Batch    9/44   train_loss = 2.425
Epoch  85 Batch   10/44   train_loss = 2.355
Epoch  85 Batch   11/44   train_loss = 2.382
Epoch  85 Batch   12/44   train_loss = 2.461
Epoch  85 Batch   13/44   train_loss = 2.345
Epoch  85 Batch   14/44   train_loss = 2.405
Epoch  85 Batch   15/44   train_loss = 2.387
Epoch  85 Batch   16/44   train_loss = 2.460
Epoch  85 Batch   17/44   train_loss = 2.473
Epoch  85 Batch   18/44   train_loss = 2.527
Epoch  85 Batch   19/44   train_loss = 2.358
Epoch  85 Batch   20/44   train_loss = 2.401
Epoch  85 Batch   21/44   train_loss = 2.303
Epoch  85 Batch   22/44   train_loss = 2.465
Epoch  85 Batch   23/44   train_loss = 2.388
Epoch  85 Batch   24/44   train_loss = 2.398
Epoch  85 Batch   25/44   train_loss = 2.437
Epoch  85 Batch   26/44   train_loss = 2.313
Epoch  85 Batch   27/44   train_loss = 2.427
Epoch  85 Batch   28/44   train_loss = 2.383
Epoch  85 Batch   29/44   train_loss = 2.362
Epoch  85 Batch   30/44   train_loss = 2.391
Epoch  85 Batch   31/44   train_loss = 2.484
Epoch  85 Batch   32/44   train_loss = 2.466
Epoch  85 Batch   33/44   train_loss = 2.505
Epoch  85 Batch   34/44   train_loss = 2.375
Epoch  85 Batch   35/44   train_loss = 2.406
Epoch  85 Batch   36/44   train_loss = 2.568
Epoch  85 Batch   37/44   train_loss = 2.438
Epoch  85 Batch   38/44   train_loss = 2.461
Epoch  85 Batch   39/44   train_loss = 2.337
Epoch  85 Batch   40/44   train_loss = 2.414
Epoch  85 Batch   41/44   train_loss = 2.416
Epoch  85 Batch   42/44   train_loss = 2.330
Epoch  85 Batch   43/44   train_loss = 2.351
Epoch  86 Batch    0/44   train_loss = 2.347
Epoch  86 Batch    1/44   train_loss = 2.352
Epoch  86 Batch    2/44   train_loss = 2.401
Epoch  86 Batch    3/44   train_loss = 2.406
Epoch  86 Batch    4/44   train_loss = 2.326
Epoch  86 Batch    5/44   train_loss = 2.313
Epoch  86 Batch    6/44   train_loss = 2.365
Epoch  86 Batch    7/44   train_loss = 2.343
Epoch  86 Batch    8/44   train_loss = 2.333
Epoch  86 Batch    9/44   train_loss = 2.400
Epoch  86 Batch   10/44   train_loss = 2.338
Epoch  86 Batch   11/44   train_loss = 2.367
Epoch  86 Batch   12/44   train_loss = 2.435
Epoch  86 Batch   13/44   train_loss = 2.303
Epoch  86 Batch   14/44   train_loss = 2.356
Epoch  86 Batch   15/44   train_loss = 2.336
Epoch  86 Batch   16/44   train_loss = 2.420
Epoch  86 Batch   17/44   train_loss = 2.449
Epoch  86 Batch   18/44   train_loss = 2.522
Epoch  86 Batch   19/44   train_loss = 2.350
Epoch  86 Batch   20/44   train_loss = 2.391
Epoch  86 Batch   21/44   train_loss = 2.274
Epoch  86 Batch   22/44   train_loss = 2.430
Epoch  86 Batch   23/44   train_loss = 2.353
Epoch  86 Batch   24/44   train_loss = 2.377
Epoch  86 Batch   25/44   train_loss = 2.423
Epoch  86 Batch   26/44   train_loss = 2.304
Epoch  86 Batch   27/44   train_loss = 2.406
Epoch  86 Batch   28/44   train_loss = 2.348
Epoch  86 Batch   29/44   train_loss = 2.316
Epoch  86 Batch   30/44   train_loss = 2.347
Epoch  86 Batch   31/44   train_loss = 2.449
Epoch  86 Batch   32/44   train_loss = 2.449
Epoch  86 Batch   33/44   train_loss = 2.488
Epoch  86 Batch   34/44   train_loss = 2.358
Epoch  86 Batch   35/44   train_loss = 2.372
Epoch  86 Batch   36/44   train_loss = 2.527
Epoch  86 Batch   37/44   train_loss = 2.381
Epoch  86 Batch   38/44   train_loss = 2.417
Epoch  86 Batch   39/44   train_loss = 2.303
Epoch  86 Batch   40/44   train_loss = 2.391
Epoch  86 Batch   41/44   train_loss = 2.404
Epoch  86 Batch   42/44   train_loss = 2.307
Epoch  86 Batch   43/44   train_loss = 2.309
Epoch  87 Batch    0/44   train_loss = 2.298
Epoch  87 Batch    1/44   train_loss = 2.299
Epoch  87 Batch    2/44   train_loss = 2.364
Epoch  87 Batch    3/44   train_loss = 2.388
Epoch  87 Batch    4/44   train_loss = 2.315
Epoch  87 Batch    5/44   train_loss = 2.305
Epoch  87 Batch    6/44   train_loss = 2.346
Epoch  87 Batch    7/44   train_loss = 2.297
Epoch  87 Batch    8/44   train_loss = 2.292
Epoch  87 Batch    9/44   train_loss = 2.350
Epoch  87 Batch   10/44   train_loss = 2.307
Epoch  87 Batch   11/44   train_loss = 2.350
Epoch  87 Batch   12/44   train_loss = 2.432
Epoch  87 Batch   13/44   train_loss = 2.295
Epoch  87 Batch   14/44   train_loss = 2.342
Epoch  87 Batch   15/44   train_loss = 2.294
Epoch  87 Batch   16/44   train_loss = 2.366
Epoch  87 Batch   17/44   train_loss = 2.401
Epoch  87 Batch   18/44   train_loss = 2.497
Epoch  87 Batch   19/44   train_loss = 2.341
Epoch  87 Batch   20/44   train_loss = 2.398
Epoch  87 Batch   21/44   train_loss = 2.275
Epoch  87 Batch   22/44   train_loss = 2.418
Epoch  87 Batch   23/44   train_loss = 2.317
Epoch  87 Batch   24/44   train_loss = 2.339
Epoch  87 Batch   25/44   train_loss = 2.392
Epoch  87 Batch   26/44   train_loss = 2.293
Epoch  87 Batch   27/44   train_loss = 2.406
Epoch  87 Batch   28/44   train_loss = 2.345
Epoch  87 Batch   29/44   train_loss = 2.295
Epoch  87 Batch   30/44   train_loss = 2.319
Epoch  87 Batch   31/44   train_loss = 2.411
Epoch  87 Batch   32/44   train_loss = 2.414
Epoch  87 Batch   33/44   train_loss = 2.464
Epoch  87 Batch   34/44   train_loss = 2.354
Epoch  87 Batch   35/44   train_loss = 2.371
Epoch  87 Batch   36/44   train_loss = 2.527
Epoch  87 Batch   37/44   train_loss = 2.355
Epoch  87 Batch   38/44   train_loss = 2.379
Epoch  87 Batch   39/44   train_loss = 2.258
Epoch  87 Batch   40/44   train_loss = 2.348
Epoch  87 Batch   41/44   train_loss = 2.387
Epoch  87 Batch   42/44   train_loss = 2.296
Epoch  87 Batch   43/44   train_loss = 2.299
Epoch  88 Batch    0/44   train_loss = 2.287
Epoch  88 Batch    1/44   train_loss = 2.260
Epoch  88 Batch    2/44   train_loss = 2.314
Epoch  88 Batch    3/44   train_loss = 2.338
Epoch  88 Batch    4/44   train_loss = 2.274
Epoch  88 Batch    5/44   train_loss = 2.283
Epoch  88 Batch    6/44   train_loss = 2.338
Epoch  88 Batch    7/44   train_loss = 2.289
Epoch  88 Batch    8/44   train_loss = 2.270
Epoch  88 Batch    9/44   train_loss = 2.303
Epoch  88 Batch   10/44   train_loss = 2.249
Epoch  88 Batch   11/44   train_loss = 2.298
Epoch  88 Batch   12/44   train_loss = 2.404
Epoch  88 Batch   13/44   train_loss = 2.287
Epoch  88 Batch   14/44   train_loss = 2.347
Epoch  88 Batch   15/44   train_loss = 2.288
Epoch  88 Batch   16/44   train_loss = 2.344
Epoch  88 Batch   17/44   train_loss = 2.354
Epoch  88 Batch   18/44   train_loss = 2.439
Epoch  88 Batch   19/44   train_loss = 2.299
Epoch  88 Batch   20/44   train_loss = 2.381
Epoch  88 Batch   21/44   train_loss = 2.286
Epoch  88 Batch   22/44   train_loss = 2.448
Epoch  88 Batch   23/44   train_loss = 2.328
Epoch  88 Batch   24/44   train_loss = 2.324
Epoch  88 Batch   25/44   train_loss = 2.360
Epoch  88 Batch   26/44   train_loss = 2.249
Epoch  88 Batch   27/44   train_loss = 2.374
Epoch  88 Batch   28/44   train_loss = 2.336
Epoch  88 Batch   29/44   train_loss = 2.296
Epoch  88 Batch   30/44   train_loss = 2.323
Epoch  88 Batch   31/44   train_loss = 2.404
Epoch  88 Batch   32/44   train_loss = 2.378
Epoch  88 Batch   33/44   train_loss = 2.424
Epoch  88 Batch   34/44   train_loss = 2.315
Epoch  88 Batch   35/44   train_loss = 2.358
Epoch  88 Batch   36/44   train_loss = 2.531
Epoch  88 Batch   37/44   train_loss = 2.363
Epoch  88 Batch   38/44   train_loss = 2.379
Epoch  88 Batch   39/44   train_loss = 2.240
Epoch  88 Batch   40/44   train_loss = 2.321
Epoch  88 Batch   41/44   train_loss = 2.351
Epoch  88 Batch   42/44   train_loss = 2.264
Epoch  88 Batch   43/44   train_loss = 2.290
Epoch  89 Batch    0/44   train_loss = 2.302
Epoch  89 Batch    1/44   train_loss = 2.270
Epoch  89 Batch    2/44   train_loss = 2.311
Epoch  89 Batch    3/44   train_loss = 2.306
Epoch  89 Batch    4/44   train_loss = 2.230
Epoch  89 Batch    5/44   train_loss = 2.230
Epoch  89 Batch    6/44   train_loss = 2.294
Epoch  89 Batch    7/44   train_loss = 2.266
Epoch  89 Batch    8/44   train_loss = 2.262
Epoch  89 Batch    9/44   train_loss = 2.294
Epoch  89 Batch   10/44   train_loss = 2.222
Epoch  89 Batch   11/44   train_loss = 2.248
Epoch  89 Batch   12/44   train_loss = 2.337
Epoch  89 Batch   13/44   train_loss = 2.235
Epoch  89 Batch   14/44   train_loss = 2.306
Epoch  89 Batch   15/44   train_loss = 2.281
Epoch  89 Batch   16/44   train_loss = 2.363
Epoch  89 Batch   17/44   train_loss = 2.361
Epoch  89 Batch   18/44   train_loss = 2.424
Epoch  89 Batch   19/44   train_loss = 2.250
Epoch  89 Batch   20/44   train_loss = 2.309
Epoch  89 Batch   21/44   train_loss = 2.233
Epoch  89 Batch   22/44   train_loss = 2.425
Epoch  89 Batch   23/44   train_loss = 2.336
Epoch  89 Batch   24/44   train_loss = 2.333
Epoch  89 Batch   25/44   train_loss = 2.375
Epoch  89 Batch   26/44   train_loss = 2.234
Epoch  89 Batch   27/44   train_loss = 2.340
Epoch  89 Batch   28/44   train_loss = 2.288
Epoch  89 Batch   29/44   train_loss = 2.250
Epoch  89 Batch   30/44   train_loss = 2.293
Epoch  89 Batch   31/44   train_loss = 2.399
Epoch  89 Batch   32/44   train_loss = 2.372
Epoch  89 Batch   33/44   train_loss = 2.428
Epoch  89 Batch   34/44   train_loss = 2.290
Epoch  89 Batch   35/44   train_loss = 2.336
Epoch  89 Batch   36/44   train_loss = 2.495
Epoch  89 Batch   37/44   train_loss = 2.341
Epoch  89 Batch   38/44   train_loss = 2.364
Epoch  89 Batch   39/44   train_loss = 2.236
Epoch  89 Batch   40/44   train_loss = 2.320
Epoch  89 Batch   41/44   train_loss = 2.340
Epoch  89 Batch   42/44   train_loss = 2.241
Epoch  89 Batch   43/44   train_loss = 2.255
Epoch  90 Batch    0/44   train_loss = 2.271
Epoch  90 Batch    1/44   train_loss = 2.261
Epoch  90 Batch    2/44   train_loss = 2.315
Epoch  90 Batch    3/44   train_loss = 2.309
Epoch  90 Batch    4/44   train_loss = 2.228
Epoch  90 Batch    5/44   train_loss = 2.208
Epoch  90 Batch    6/44   train_loss = 2.256
Epoch  90 Batch    7/44   train_loss = 2.218
Epoch  90 Batch    8/44   train_loss = 2.207
Epoch  90 Batch    9/44   train_loss = 2.250
Epoch  90 Batch   10/44   train_loss = 2.199
Epoch  90 Batch   11/44   train_loss = 2.232
Epoch  90 Batch   12/44   train_loss = 2.309
Epoch  90 Batch   13/44   train_loss = 2.203
Epoch  90 Batch   14/44   train_loss = 2.242
Epoch  90 Batch   15/44   train_loss = 2.218
Epoch  90 Batch   16/44   train_loss = 2.302
Epoch  90 Batch   17/44   train_loss = 2.330
Epoch  90 Batch   18/44   train_loss = 2.412
Epoch  90 Batch   19/44   train_loss = 2.247
Epoch  90 Batch   20/44   train_loss = 2.288
Epoch  90 Batch   21/44   train_loss = 2.190
Epoch  90 Batch   22/44   train_loss = 2.357
Epoch  90 Batch   23/44   train_loss = 2.267
Epoch  90 Batch   24/44   train_loss = 2.272
Epoch  90 Batch   25/44   train_loss = 2.340
Epoch  90 Batch   26/44   train_loss = 2.226
Epoch  90 Batch   27/44   train_loss = 2.354
Epoch  90 Batch   28/44   train_loss = 2.286
Epoch  90 Batch   29/44   train_loss = 2.234
Epoch  90 Batch   30/44   train_loss = 2.240
Epoch  90 Batch   31/44   train_loss = 2.340
Epoch  90 Batch   32/44   train_loss = 2.317
Epoch  90 Batch   33/44   train_loss = 2.380
Epoch  90 Batch   34/44   train_loss = 2.263
Epoch  90 Batch   35/44   train_loss = 2.326
Epoch  90 Batch   36/44   train_loss = 2.497
Epoch  90 Batch   37/44   train_loss = 2.344
Epoch  90 Batch   38/44   train_loss = 2.357
Epoch  90 Batch   39/44   train_loss = 2.205
Epoch  90 Batch   40/44   train_loss = 2.281
Epoch  90 Batch   41/44   train_loss = 2.304
Epoch  90 Batch   42/44   train_loss = 2.224
Epoch  90 Batch   43/44   train_loss = 2.241
Epoch  91 Batch    0/44   train_loss = 2.263
Epoch  91 Batch    1/44   train_loss = 2.263
Epoch  91 Batch    2/44   train_loss = 2.323
Epoch  91 Batch    3/44   train_loss = 2.308
Epoch  91 Batch    4/44   train_loss = 2.223
Epoch  91 Batch    5/44   train_loss = 2.198
Epoch  91 Batch    6/44   train_loss = 2.232
Epoch  91 Batch    7/44   train_loss = 2.194
Epoch  91 Batch    8/44   train_loss = 2.185
Epoch  91 Batch    9/44   train_loss = 2.224
Epoch  91 Batch   10/44   train_loss = 2.167
Epoch  91 Batch   11/44   train_loss = 2.203
Epoch  91 Batch   12/44   train_loss = 2.262
Epoch  91 Batch   13/44   train_loss = 2.160
Epoch  91 Batch   14/44   train_loss = 2.204
Epoch  91 Batch   15/44   train_loss = 2.192
Epoch  91 Batch   16/44   train_loss = 2.279
Epoch  91 Batch   17/44   train_loss = 2.292
Epoch  91 Batch   18/44   train_loss = 2.376
Epoch  91 Batch   19/44   train_loss = 2.205
Epoch  91 Batch   20/44   train_loss = 2.245
Epoch  91 Batch   21/44   train_loss = 2.157
Epoch  91 Batch   22/44   train_loss = 2.338
Epoch  91 Batch   23/44   train_loss = 2.254
Epoch  91 Batch   24/44   train_loss = 2.252
Epoch  91 Batch   25/44   train_loss = 2.303
Epoch  91 Batch   26/44   train_loss = 2.176
Epoch  91 Batch   27/44   train_loss = 2.295
Epoch  91 Batch   28/44   train_loss = 2.246
Epoch  91 Batch   29/44   train_loss = 2.214
Epoch  91 Batch   30/44   train_loss = 2.243
Epoch  91 Batch   31/44   train_loss = 2.338
Epoch  91 Batch   32/44   train_loss = 2.302
Epoch  91 Batch   33/44   train_loss = 2.329
Epoch  91 Batch   34/44   train_loss = 2.207
Epoch  91 Batch   35/44   train_loss = 2.242
Epoch  91 Batch   36/44   train_loss = 2.419
Epoch  91 Batch   37/44   train_loss = 2.304
Epoch  91 Batch   38/44   train_loss = 2.364
Epoch  91 Batch   39/44   train_loss = 2.230
Epoch  91 Batch   40/44   train_loss = 2.312
Epoch  91 Batch   41/44   train_loss = 2.297
Epoch  91 Batch   42/44   train_loss = 2.177
Epoch  91 Batch   43/44   train_loss = 2.170
Epoch  92 Batch    0/44   train_loss = 2.198
Epoch  92 Batch    1/44   train_loss = 2.218
Epoch  92 Batch    2/44   train_loss = 2.322
Epoch  92 Batch    3/44   train_loss = 2.344
Epoch  92 Batch    4/44   train_loss = 2.267
Epoch  92 Batch    5/44   train_loss = 2.235
Epoch  92 Batch    6/44   train_loss = 2.244
Epoch  92 Batch    7/44   train_loss = 2.171
Epoch  92 Batch    8/44   train_loss = 2.145
Epoch  92 Batch    9/44   train_loss = 2.182
Epoch  92 Batch   10/44   train_loss = 2.135
Epoch  92 Batch   11/44   train_loss = 2.190
Epoch  92 Batch   12/44   train_loss = 2.274
Epoch  92 Batch   13/44   train_loss = 2.155
Epoch  92 Batch   14/44   train_loss = 2.192
Epoch  92 Batch   15/44   train_loss = 2.147
Epoch  92 Batch   16/44   train_loss = 2.225
Epoch  92 Batch   17/44   train_loss = 2.243
Epoch  92 Batch   18/44   train_loss = 2.354
Epoch  92 Batch   19/44   train_loss = 2.194
Epoch  92 Batch   20/44   train_loss = 2.235
Epoch  92 Batch   21/44   train_loss = 2.132
Epoch  92 Batch   22/44   train_loss = 2.290
Epoch  92 Batch   23/44   train_loss = 2.202
Epoch  92 Batch   24/44   train_loss = 2.205
Epoch  92 Batch   25/44   train_loss = 2.270
Epoch  92 Batch   26/44   train_loss = 2.158
Epoch  92 Batch   27/44   train_loss = 2.283
Epoch  92 Batch   28/44   train_loss = 2.219
Epoch  92 Batch   29/44   train_loss = 2.172
Epoch  92 Batch   30/44   train_loss = 2.164
Epoch  92 Batch   31/44   train_loss = 2.260
Epoch  92 Batch   32/44   train_loss = 2.241
Epoch  92 Batch   33/44   train_loss = 2.292
Epoch  92 Batch   34/44   train_loss = 2.183
Epoch  92 Batch   35/44   train_loss = 2.207
Epoch  92 Batch   36/44   train_loss = 2.359
Epoch  92 Batch   37/44   train_loss = 2.216
Epoch  92 Batch   38/44   train_loss = 2.262
Epoch  92 Batch   39/44   train_loss = 2.135
Epoch  92 Batch   40/44   train_loss = 2.255
Epoch  92 Batch   41/44   train_loss = 2.288
Epoch  92 Batch   42/44   train_loss = 2.192
Epoch  92 Batch   43/44   train_loss = 2.179
Epoch  93 Batch    0/44   train_loss = 2.173
Epoch  93 Batch    1/44   train_loss = 2.146
Epoch  93 Batch    2/44   train_loss = 2.220
Epoch  93 Batch    3/44   train_loss = 2.256
Epoch  93 Batch    4/44   train_loss = 2.218
Epoch  93 Batch    5/44   train_loss = 2.246
Epoch  93 Batch    6/44   train_loss = 2.286
Epoch  93 Batch    7/44   train_loss = 2.218
Epoch  93 Batch    8/44   train_loss = 2.173
Epoch  93 Batch    9/44   train_loss = 2.156
Epoch  93 Batch   10/44   train_loss = 2.076
Epoch  93 Batch   11/44   train_loss = 2.113
Epoch  93 Batch   12/44   train_loss = 2.211
Epoch  93 Batch   13/44   train_loss = 2.120
Epoch  93 Batch   14/44   train_loss = 2.200
Epoch  93 Batch   15/44   train_loss = 2.165
Epoch  93 Batch   16/44   train_loss = 2.222
Epoch  93 Batch   17/44   train_loss = 2.199
Epoch  93 Batch   18/44   train_loss = 2.297
Epoch  93 Batch   19/44   train_loss = 2.132
Epoch  93 Batch   20/44   train_loss = 2.178
Epoch  93 Batch   21/44   train_loss = 2.101
Epoch  93 Batch   22/44   train_loss = 2.277
Epoch  93 Batch   23/44   train_loss = 2.200
Epoch  93 Batch   24/44   train_loss = 2.191
Epoch  93 Batch   25/44   train_loss = 2.241
Epoch  93 Batch   26/44   train_loss = 2.117
Epoch  93 Batch   27/44   train_loss = 2.251
Epoch  93 Batch   28/44   train_loss = 2.188
Epoch  93 Batch   29/44   train_loss = 2.161
Epoch  93 Batch   30/44   train_loss = 2.140
Epoch  93 Batch   31/44   train_loss = 2.225
Epoch  93 Batch   32/44   train_loss = 2.199
Epoch  93 Batch   33/44   train_loss = 2.239
Epoch  93 Batch   34/44   train_loss = 2.123
Epoch  93 Batch   35/44   train_loss = 2.159
Epoch  93 Batch   36/44   train_loss = 2.326
Epoch  93 Batch   37/44   train_loss = 2.183
Epoch  93 Batch   38/44   train_loss = 2.228
Epoch  93 Batch   39/44   train_loss = 2.084
Epoch  93 Batch   40/44   train_loss = 2.175
Epoch  93 Batch   41/44   train_loss = 2.207
Epoch  93 Batch   42/44   train_loss = 2.125
Epoch  93 Batch   43/44   train_loss = 2.142
Epoch  94 Batch    0/44   train_loss = 2.162
Epoch  94 Batch    1/44   train_loss = 2.136
Epoch  94 Batch    2/44   train_loss = 2.183
Epoch  94 Batch    3/44   train_loss = 2.197
Epoch  94 Batch    4/44   train_loss = 2.125
Epoch  94 Batch    5/44   train_loss = 2.170
Epoch  94 Batch    6/44   train_loss = 2.229
Epoch  94 Batch    7/44   train_loss = 2.188
Epoch  94 Batch    8/44   train_loss = 2.182
Epoch  94 Batch    9/44   train_loss = 2.167
Epoch  94 Batch   10/44   train_loss = 2.078
Epoch  94 Batch   11/44   train_loss = 2.089
Epoch  94 Batch   12/44   train_loss = 2.166
Epoch  94 Batch   13/44   train_loss = 2.054
Epoch  94 Batch   14/44   train_loss = 2.119
Epoch  94 Batch   15/44   train_loss = 2.109
Epoch  94 Batch   16/44   train_loss = 2.197
Epoch  94 Batch   17/44   train_loss = 2.193
Epoch  94 Batch   18/44   train_loss = 2.295
Epoch  94 Batch   19/44   train_loss = 2.107
Epoch  94 Batch   20/44   train_loss = 2.128
Epoch  94 Batch   21/44   train_loss = 2.037
Epoch  94 Batch   22/44   train_loss = 2.216
Epoch  94 Batch   23/44   train_loss = 2.155
Epoch  94 Batch   24/44   train_loss = 2.162
Epoch  94 Batch   25/44   train_loss = 2.227
Epoch  94 Batch   26/44   train_loss = 2.104
Epoch  94 Batch   27/44   train_loss = 2.237
Epoch  94 Batch   28/44   train_loss = 2.164
Epoch  94 Batch   29/44   train_loss = 2.137
Epoch  94 Batch   30/44   train_loss = 2.122
Epoch  94 Batch   31/44   train_loss = 2.205
Epoch  94 Batch   32/44   train_loss = 2.187
Epoch  94 Batch   33/44   train_loss = 2.218
Epoch  94 Batch   34/44   train_loss = 2.094
Epoch  94 Batch   35/44   train_loss = 2.128
Epoch  94 Batch   36/44   train_loss = 2.287
Epoch  94 Batch   37/44   train_loss = 2.153
Epoch  94 Batch   38/44   train_loss = 2.194
Epoch  94 Batch   39/44   train_loss = 2.051
Epoch  94 Batch   40/44   train_loss = 2.136
Epoch  94 Batch   41/44   train_loss = 2.161
Epoch  94 Batch   42/44   train_loss = 2.075
Epoch  94 Batch   43/44   train_loss = 2.094
Epoch  95 Batch    0/44   train_loss = 2.113
Epoch  95 Batch    1/44   train_loss = 2.110
Epoch  95 Batch    2/44   train_loss = 2.159
Epoch  95 Batch    3/44   train_loss = 2.174
Epoch  95 Batch    4/44   train_loss = 2.085
Epoch  95 Batch    5/44   train_loss = 2.123
Epoch  95 Batch    6/44   train_loss = 2.175
Epoch  95 Batch    7/44   train_loss = 2.139
Epoch  95 Batch    8/44   train_loss = 2.136
Epoch  95 Batch    9/44   train_loss = 2.132
Epoch  95 Batch   10/44   train_loss = 2.059
Epoch  95 Batch   11/44   train_loss = 2.085
Epoch  95 Batch   12/44   train_loss = 2.158
Epoch  95 Batch   13/44   train_loss = 2.032
Epoch  95 Batch   14/44   train_loss = 2.079
Epoch  95 Batch   15/44   train_loss = 2.060
Epoch  95 Batch   16/44   train_loss = 2.134
Epoch  95 Batch   17/44   train_loss = 2.145
Epoch  95 Batch   18/44   train_loss = 2.249
Epoch  95 Batch   19/44   train_loss = 2.080
Epoch  95 Batch   20/44   train_loss = 2.107
Epoch  95 Batch   21/44   train_loss = 2.003
Epoch  95 Batch   22/44   train_loss = 2.172
Epoch  95 Batch   23/44   train_loss = 2.099
Epoch  95 Batch   24/44   train_loss = 2.105
Epoch  95 Batch   25/44   train_loss = 2.184
Epoch  95 Batch   26/44   train_loss = 2.076
Epoch  95 Batch   27/44   train_loss = 2.216
Epoch  95 Batch   28/44   train_loss = 2.155
Epoch  95 Batch   29/44   train_loss = 2.120
Epoch  95 Batch   30/44   train_loss = 2.118
Epoch  95 Batch   31/44   train_loss = 2.193
Epoch  95 Batch   32/44   train_loss = 2.173
Epoch  95 Batch   33/44   train_loss = 2.189
Epoch  95 Batch   34/44   train_loss = 2.073
Epoch  95 Batch   35/44   train_loss = 2.099
Epoch  95 Batch   36/44   train_loss = 2.260
Epoch  95 Batch   37/44   train_loss = 2.143
Epoch  95 Batch   38/44   train_loss = 2.181
Epoch  95 Batch   39/44   train_loss = 2.033
Epoch  95 Batch   40/44   train_loss = 2.113
Epoch  95 Batch   41/44   train_loss = 2.126
Epoch  95 Batch   42/44   train_loss = 2.028
Epoch  95 Batch   43/44   train_loss = 2.046
Epoch  96 Batch    0/44   train_loss = 2.069
Epoch  96 Batch    1/44   train_loss = 2.077
Epoch  96 Batch    2/44   train_loss = 2.142
Epoch  96 Batch    3/44   train_loss = 2.158
Epoch  96 Batch    4/44   train_loss = 2.069
Epoch  96 Batch    5/44   train_loss = 2.108
Epoch  96 Batch    6/44   train_loss = 2.147
Epoch  96 Batch    7/44   train_loss = 2.114
Epoch  96 Batch    8/44   train_loss = 2.112
Epoch  96 Batch    9/44   train_loss = 2.112
Epoch  96 Batch   10/44   train_loss = 2.031
Epoch  96 Batch   11/44   train_loss = 2.063
Epoch  96 Batch   12/44   train_loss = 2.126
Epoch  96 Batch   13/44   train_loss = 2.006
Epoch  96 Batch   14/44   train_loss = 2.063
Epoch  96 Batch   15/44   train_loss = 2.045
Epoch  96 Batch   16/44   train_loss = 2.122
Epoch  96 Batch   17/44   train_loss = 2.126
Epoch  96 Batch   18/44   train_loss = 2.218
Epoch  96 Batch   19/44   train_loss = 2.036
Epoch  96 Batch   20/44   train_loss = 2.073
Epoch  96 Batch   21/44   train_loss = 1.964
Epoch  96 Batch   22/44   train_loss = 2.134
Epoch  96 Batch   23/44   train_loss = 2.066
Epoch  96 Batch   24/44   train_loss = 2.075
Epoch  96 Batch   25/44   train_loss = 2.155
Epoch  96 Batch   26/44   train_loss = 2.051
Epoch  96 Batch   27/44   train_loss = 2.187
Epoch  96 Batch   28/44   train_loss = 2.131
Epoch  96 Batch   29/44   train_loss = 2.083
Epoch  96 Batch   30/44   train_loss = 2.096
Epoch  96 Batch   31/44   train_loss = 2.178
Epoch  96 Batch   32/44   train_loss = 2.159
Epoch  96 Batch   33/44   train_loss = 2.176
Epoch  96 Batch   34/44   train_loss = 2.065
Epoch  96 Batch   35/44   train_loss = 2.071
Epoch  96 Batch   36/44   train_loss = 2.223
Epoch  96 Batch   37/44   train_loss = 2.114
Epoch  96 Batch   38/44   train_loss = 2.155
Epoch  96 Batch   39/44   train_loss = 2.021
Epoch  96 Batch   40/44   train_loss = 2.117
Epoch  96 Batch   41/44   train_loss = 2.129
Epoch  96 Batch   42/44   train_loss = 2.013
Epoch  96 Batch   43/44   train_loss = 2.014
Epoch  97 Batch    0/44   train_loss = 2.025
Epoch  97 Batch    1/44   train_loss = 2.020
Epoch  97 Batch    2/44   train_loss = 2.105
Epoch  97 Batch    3/44   train_loss = 2.142
Epoch  97 Batch    4/44   train_loss = 2.065
Epoch  97 Batch    5/44   train_loss = 2.112
Epoch  97 Batch    6/44   train_loss = 2.141
Epoch  97 Batch    7/44   train_loss = 2.102
Epoch  97 Batch    8/44   train_loss = 2.093
Epoch  97 Batch    9/44   train_loss = 2.101
Epoch  97 Batch   10/44   train_loss = 2.023
Epoch  97 Batch   11/44   train_loss = 2.061
Epoch  97 Batch   12/44   train_loss = 2.118
Epoch  97 Batch   13/44   train_loss = 1.979
Epoch  97 Batch   14/44   train_loss = 2.037
Epoch  97 Batch   15/44   train_loss = 2.007
Epoch  97 Batch   16/44   train_loss = 2.097
Epoch  97 Batch   17/44   train_loss = 2.118
Epoch  97 Batch   18/44   train_loss = 2.223
Epoch  97 Batch   19/44   train_loss = 2.046
Epoch  97 Batch   20/44   train_loss = 2.084
Epoch  97 Batch   21/44   train_loss = 1.950
Epoch  97 Batch   22/44   train_loss = 2.093
Epoch  97 Batch   23/44   train_loss = 2.008
Epoch  97 Batch   24/44   train_loss = 2.021
Epoch  97 Batch   25/44   train_loss = 2.123
Epoch  97 Batch   26/44   train_loss = 2.038
Epoch  97 Batch   27/44   train_loss = 2.189
Epoch  97 Batch   28/44   train_loss = 2.135
Epoch  97 Batch   29/44   train_loss = 2.075
Epoch  97 Batch   30/44   train_loss = 2.078
Epoch  97 Batch   31/44   train_loss = 2.149
Epoch  97 Batch   32/44   train_loss = 2.133
Epoch  97 Batch   33/44   train_loss = 2.159
Epoch  97 Batch   34/44   train_loss = 2.064
Epoch  97 Batch   35/44   train_loss = 2.073
Epoch  97 Batch   36/44   train_loss = 2.218
Epoch  97 Batch   37/44   train_loss = 2.091
Epoch  97 Batch   38/44   train_loss = 2.113
Epoch  97 Batch   39/44   train_loss = 1.985
Epoch  97 Batch   40/44   train_loss = 2.097
Epoch  97 Batch   41/44   train_loss = 2.127
Epoch  97 Batch   42/44   train_loss = 2.022
Epoch  97 Batch   43/44   train_loss = 2.020
Epoch  98 Batch    0/44   train_loss = 2.021
Epoch  98 Batch    1/44   train_loss = 1.988
Epoch  98 Batch    2/44   train_loss = 2.047
Epoch  98 Batch    3/44   train_loss = 2.080
Epoch  98 Batch    4/44   train_loss = 2.014
Epoch  98 Batch    5/44   train_loss = 2.085
Epoch  98 Batch    6/44   train_loss = 2.145
Epoch  98 Batch    7/44   train_loss = 2.101
Epoch  98 Batch    8/44   train_loss = 2.099
Epoch  98 Batch    9/44   train_loss = 2.087
Epoch  98 Batch   10/44   train_loss = 2.006
Epoch  98 Batch   11/44   train_loss = 2.048
Epoch  98 Batch   12/44   train_loss = 2.118
Epoch  98 Batch   13/44   train_loss = 1.978
Epoch  98 Batch   14/44   train_loss = 2.029
Epoch  98 Batch   15/44   train_loss = 1.989
Epoch  98 Batch   16/44   train_loss = 2.060
Epoch  98 Batch   17/44   train_loss = 2.075
Epoch  98 Batch   18/44   train_loss = 2.190
Epoch  98 Batch   19/44   train_loss = 2.043
Epoch  98 Batch   20/44   train_loss = 2.107
Epoch  98 Batch   21/44   train_loss = 1.987
Epoch  98 Batch   22/44   train_loss = 2.112
Epoch  98 Batch   23/44   train_loss = 1.994
Epoch  98 Batch   24/44   train_loss = 1.982
Epoch  98 Batch   25/44   train_loss = 2.053
Epoch  98 Batch   26/44   train_loss = 1.971
Epoch  98 Batch   27/44   train_loss = 2.145
Epoch  98 Batch   28/44   train_loss = 2.125
Epoch  98 Batch   29/44   train_loss = 2.094
Epoch  98 Batch   30/44   train_loss = 2.123
Epoch  98 Batch   31/44   train_loss = 2.184
Epoch  98 Batch   32/44   train_loss = 2.134
Epoch  98 Batch   33/44   train_loss = 2.133
Epoch  98 Batch   34/44   train_loss = 2.040
Epoch  98 Batch   35/44   train_loss = 2.064
Epoch  98 Batch   36/44   train_loss = 2.228
Epoch  98 Batch   37/44   train_loss = 2.108
Epoch  98 Batch   38/44   train_loss = 2.116
Epoch  98 Batch   39/44   train_loss = 1.965
Epoch  98 Batch   40/44   train_loss = 2.062
Epoch  98 Batch   41/44   train_loss = 2.094
Epoch  98 Batch   42/44   train_loss = 2.007
Epoch  98 Batch   43/44   train_loss = 2.030
Epoch  99 Batch    0/44   train_loss = 2.048
Epoch  99 Batch    1/44   train_loss = 2.021
Epoch  99 Batch    2/44   train_loss = 2.053
Epoch  99 Batch    3/44   train_loss = 2.043
Epoch  99 Batch    4/44   train_loss = 1.945
Epoch  99 Batch    5/44   train_loss = 2.004
Epoch  99 Batch    6/44   train_loss = 2.081
Epoch  99 Batch    7/44   train_loss = 2.059
Epoch  99 Batch    8/44   train_loss = 2.094
Epoch  99 Batch    9/44   train_loss = 2.100
Epoch  99 Batch   10/44   train_loss = 2.027
Epoch  99 Batch   11/44   train_loss = 2.040
Epoch  99 Batch   12/44   train_loss = 2.099
Epoch  99 Batch   13/44   train_loss = 1.961
Epoch  99 Batch   14/44   train_loss = 2.010
Epoch  99 Batch   15/44   train_loss = 1.991
Epoch  99 Batch   16/44   train_loss = 2.046
Epoch  99 Batch   17/44   train_loss = 2.039
Epoch  99 Batch   18/44   train_loss = 2.144
Epoch  99 Batch   19/44   train_loss = 1.992
Epoch  99 Batch   20/44   train_loss = 2.065
Epoch  99 Batch   21/44   train_loss = 1.974
Epoch  99 Batch   22/44   train_loss = 2.147
Epoch  99 Batch   23/44   train_loss = 2.043
Epoch  99 Batch   24/44   train_loss = 2.025
Epoch  99 Batch   25/44   train_loss = 2.063
Epoch  99 Batch   26/44   train_loss = 1.935
Epoch  99 Batch   27/44   train_loss = 2.062
Epoch  99 Batch   28/44   train_loss = 2.025
Epoch  99 Batch   29/44   train_loss = 2.026
Epoch  99 Batch   30/44   train_loss = 2.100
Epoch  99 Batch   31/44   train_loss = 2.211
Epoch  99 Batch   32/44   train_loss = 2.187
Epoch  99 Batch   33/44   train_loss = 2.159
Epoch  99 Batch   34/44   train_loss = 2.037
Epoch  99 Batch   35/44   train_loss = 2.032
Epoch  99 Batch   36/44   train_loss = 2.179
Epoch  99 Batch   37/44   train_loss = 2.077
Epoch  99 Batch   38/44   train_loss = 2.117
Epoch  99 Batch   39/44   train_loss = 1.982
Epoch  99 Batch   40/44   train_loss = 2.077
Epoch  99 Batch   41/44   train_loss = 2.078
Epoch  99 Batch   42/44   train_loss = 1.953
Epoch  99 Batch   43/44   train_loss = 1.971
Epoch 100 Batch    0/44   train_loss = 1.995
Epoch 100 Batch    1/44   train_loss = 2.011
Epoch 100 Batch    2/44   train_loss = 2.069
Epoch 100 Batch    3/44   train_loss = 2.082
Epoch 100 Batch    4/44   train_loss = 1.965
Epoch 100 Batch    5/44   train_loss = 1.973
Epoch 100 Batch    6/44   train_loss = 2.017
Epoch 100 Batch    7/44   train_loss = 1.969
Epoch 100 Batch    8/44   train_loss = 2.002
Epoch 100 Batch    9/44   train_loss = 2.042
Epoch 100 Batch   10/44   train_loss = 2.004
Epoch 100 Batch   11/44   train_loss = 2.033
Epoch 100 Batch   12/44   train_loss = 2.086
Epoch 100 Batch   13/44   train_loss = 1.962
Epoch 100 Batch   14/44   train_loss = 1.965
Epoch 100 Batch   15/44   train_loss = 1.946
Epoch 100 Batch   16/44   train_loss = 1.994
Epoch 100 Batch   17/44   train_loss = 2.003
Epoch 100 Batch   18/44   train_loss = 2.113
Epoch 100 Batch   19/44   train_loss = 1.960
Epoch 100 Batch   20/44   train_loss = 2.008
Epoch 100 Batch   21/44   train_loss = 1.901
Epoch 100 Batch   22/44   train_loss = 2.079
Epoch 100 Batch   23/44   train_loss = 1.998
Epoch 100 Batch   24/44   train_loss = 2.012
Epoch 100 Batch   25/44   train_loss = 2.093
Epoch 100 Batch   26/44   train_loss = 1.970
Epoch 100 Batch   27/44   train_loss = 2.079
Epoch 100 Batch   28/44   train_loss = 1.991
Epoch 100 Batch   29/44   train_loss = 1.955
Epoch 100 Batch   30/44   train_loss = 1.991
Epoch 100 Batch   31/44   train_loss = 2.113
Epoch 100 Batch   32/44   train_loss = 2.134
Epoch 100 Batch   33/44   train_loss = 2.144
Epoch 100 Batch   34/44   train_loss = 2.046
Epoch 100 Batch   35/44   train_loss = 2.025
Epoch 100 Batch   36/44   train_loss = 2.146
Epoch 100 Batch   37/44   train_loss = 2.016
Epoch 100 Batch   38/44   train_loss = 2.045
Epoch 100 Batch   39/44   train_loss = 1.922
Epoch 100 Batch   40/44   train_loss = 2.039
Epoch 100 Batch   41/44   train_loss = 2.082
Epoch 100 Batch   42/44   train_loss = 1.955
Epoch 100 Batch   43/44   train_loss = 1.957
Epoch 101 Batch    0/44   train_loss = 1.944
Epoch 101 Batch    1/44   train_loss = 1.943
Epoch 101 Batch    2/44   train_loss = 1.997
Epoch 101 Batch    3/44   train_loss = 2.046
Epoch 101 Batch    4/44   train_loss = 1.953
Epoch 101 Batch    5/44   train_loss = 1.976
Epoch 101 Batch    6/44   train_loss = 2.029
Epoch 101 Batch    7/44   train_loss = 1.963
Epoch 101 Batch    8/44   train_loss = 1.953
Epoch 101 Batch    9/44   train_loss = 1.972
Epoch 101 Batch   10/44   train_loss = 1.907
Epoch 101 Batch   11/44   train_loss = 1.952
Epoch 101 Batch   12/44   train_loss = 2.032
Epoch 101 Batch   13/44   train_loss = 1.940
Epoch 101 Batch   14/44   train_loss = 1.956
Epoch 101 Batch   15/44   train_loss = 1.938
Epoch 101 Batch   16/44   train_loss = 1.952
Epoch 101 Batch   17/44   train_loss = 1.943
Epoch 101 Batch   18/44   train_loss = 2.047
Epoch 101 Batch   19/44   train_loss = 1.904
Epoch 101 Batch   20/44   train_loss = 1.959
Epoch 101 Batch   21/44   train_loss = 1.856
Epoch 101 Batch   22/44   train_loss = 2.027
Epoch 101 Batch   23/44   train_loss = 1.935
Epoch 101 Batch   24/44   train_loss = 1.938
Epoch 101 Batch   25/44   train_loss = 2.023
Epoch 101 Batch   26/44   train_loss = 1.917
Epoch 101 Batch   27/44   train_loss = 2.048
Epoch 101 Batch   28/44   train_loss = 1.979
Epoch 101 Batch   29/44   train_loss = 1.932
Epoch 101 Batch   30/44   train_loss = 1.937
Epoch 101 Batch   31/44   train_loss = 2.034
Epoch 101 Batch   32/44   train_loss = 2.040
Epoch 101 Batch   33/44   train_loss = 2.061
Epoch 101 Batch   34/44   train_loss = 1.979
Epoch 101 Batch   35/44   train_loss = 1.980
Epoch 101 Batch   36/44   train_loss = 2.120
Epoch 101 Batch   37/44   train_loss = 1.993
Epoch 101 Batch   38/44   train_loss = 2.011
Epoch 101 Batch   39/44   train_loss = 1.857
Epoch 101 Batch   40/44   train_loss = 1.953
Epoch 101 Batch   41/44   train_loss = 2.006
Epoch 101 Batch   42/44   train_loss = 1.910
Epoch 101 Batch   43/44   train_loss = 1.933
Epoch 102 Batch    0/44   train_loss = 1.948
Epoch 102 Batch    1/44   train_loss = 1.938
Epoch 102 Batch    2/44   train_loss = 1.964
Epoch 102 Batch    3/44   train_loss = 1.992
Epoch 102 Batch    4/44   train_loss = 1.888
Epoch 102 Batch    5/44   train_loss = 1.927
Epoch 102 Batch    6/44   train_loss = 1.993
Epoch 102 Batch    7/44   train_loss = 1.954
Epoch 102 Batch    8/44   train_loss = 1.960
Epoch 102 Batch    9/44   train_loss = 1.973
Epoch 102 Batch   10/44   train_loss = 1.875
Epoch 102 Batch   11/44   train_loss = 1.911
Epoch 102 Batch   12/44   train_loss = 1.978
Epoch 102 Batch   13/44   train_loss = 1.878
Epoch 102 Batch   14/44   train_loss = 1.910
Epoch 102 Batch   15/44   train_loss = 1.920
Epoch 102 Batch   16/44   train_loss = 1.935
Epoch 102 Batch   17/44   train_loss = 1.929
Epoch 102 Batch   18/44   train_loss = 2.013
Epoch 102 Batch   19/44   train_loss = 1.854
Epoch 102 Batch   20/44   train_loss = 1.906
Epoch 102 Batch   21/44   train_loss = 1.801
Epoch 102 Batch   22/44   train_loss = 1.989
Epoch 102 Batch   23/44   train_loss = 1.893
Epoch 102 Batch   24/44   train_loss = 1.899
Epoch 102 Batch   25/44   train_loss = 1.972
Epoch 102 Batch   26/44   train_loss = 1.864
Epoch 102 Batch   27/44   train_loss = 1.994
Epoch 102 Batch   28/44   train_loss = 1.939
Epoch 102 Batch   29/44   train_loss = 1.897
Epoch 102 Batch   30/44   train_loss = 1.906
Epoch 102 Batch   31/44   train_loss = 1.995
Epoch 102 Batch   32/44   train_loss = 1.995
Epoch 102 Batch   33/44   train_loss = 2.002
Epoch 102 Batch   34/44   train_loss = 1.913
Epoch 102 Batch   35/44   train_loss = 1.915
Epoch 102 Batch   36/44   train_loss = 2.063
Epoch 102 Batch   37/44   train_loss = 1.953
Epoch 102 Batch   38/44   train_loss = 1.982
Epoch 102 Batch   39/44   train_loss = 1.828
Epoch 102 Batch   40/44   train_loss = 1.902
Epoch 102 Batch   41/44   train_loss = 1.944
Epoch 102 Batch   42/44   train_loss = 1.837
Epoch 102 Batch   43/44   train_loss = 1.855
Epoch 103 Batch    0/44   train_loss = 1.903
Epoch 103 Batch    1/44   train_loss = 1.906
Epoch 103 Batch    2/44   train_loss = 1.951
Epoch 103 Batch    3/44   train_loss = 1.973
Epoch 103 Batch    4/44   train_loss = 1.848
Epoch 103 Batch    5/44   train_loss = 1.875
Epoch 103 Batch    6/44   train_loss = 1.930
Epoch 103 Batch    7/44   train_loss = 1.895
Epoch 103 Batch    8/44   train_loss = 1.913
Epoch 103 Batch    9/44   train_loss = 1.954
Epoch 103 Batch   10/44   train_loss = 1.870
Epoch 103 Batch   11/44   train_loss = 1.912
Epoch 103 Batch   12/44   train_loss = 1.971
Epoch 103 Batch   13/44   train_loss = 1.836
Epoch 103 Batch   14/44   train_loss = 1.864
Epoch 103 Batch   15/44   train_loss = 1.869
Epoch 103 Batch   16/44   train_loss = 1.886
Epoch 103 Batch   17/44   train_loss = 1.908
Epoch 103 Batch   18/44   train_loss = 1.994
Epoch 103 Batch   19/44   train_loss = 1.844
Epoch 103 Batch   20/44   train_loss = 1.887
Epoch 103 Batch   21/44   train_loss = 1.769
Epoch 103 Batch   22/44   train_loss = 1.946
Epoch 103 Batch   23/44   train_loss = 1.850
Epoch 103 Batch   24/44   train_loss = 1.864
Epoch 103 Batch   25/44   train_loss = 1.940
Epoch 103 Batch   26/44   train_loss = 1.836
Epoch 103 Batch   27/44   train_loss = 1.964
Epoch 103 Batch   28/44   train_loss = 1.907
Epoch 103 Batch   29/44   train_loss = 1.861
Epoch 103 Batch   30/44   train_loss = 1.875
Epoch 103 Batch   31/44   train_loss = 1.964
Epoch 103 Batch   32/44   train_loss = 1.971
Epoch 103 Batch   33/44   train_loss = 1.982
Epoch 103 Batch   34/44   train_loss = 1.887
Epoch 103 Batch   35/44   train_loss = 1.886
Epoch 103 Batch   36/44   train_loss = 2.016
Epoch 103 Batch   37/44   train_loss = 1.904
Epoch 103 Batch   38/44   train_loss = 1.935
Epoch 103 Batch   39/44   train_loss = 1.788
Epoch 103 Batch   40/44   train_loss = 1.870
Epoch 103 Batch   41/44   train_loss = 1.911
Epoch 103 Batch   42/44   train_loss = 1.795
Epoch 103 Batch   43/44   train_loss = 1.803
Epoch 104 Batch    0/44   train_loss = 1.847
Epoch 104 Batch    1/44   train_loss = 1.848
Epoch 104 Batch    2/44   train_loss = 1.909
Epoch 104 Batch    3/44   train_loss = 1.941
Epoch 104 Batch    4/44   train_loss = 1.824
Epoch 104 Batch    5/44   train_loss = 1.849
Epoch 104 Batch    6/44   train_loss = 1.894
Epoch 104 Batch    7/44   train_loss = 1.841
Epoch 104 Batch    8/44   train_loss = 1.852
Epoch 104 Batch    9/44   train_loss = 1.893
Epoch 104 Batch   10/44   train_loss = 1.827
Epoch 104 Batch   11/44   train_loss = 1.888
Epoch 104 Batch   12/44   train_loss = 1.956
Epoch 104 Batch   13/44   train_loss = 1.819
Epoch 104 Batch   14/44   train_loss = 1.851
Epoch 104 Batch   15/44   train_loss = 1.840
Epoch 104 Batch   16/44   train_loss = 1.851
Epoch 104 Batch   17/44   train_loss = 1.868
Epoch 104 Batch   18/44   train_loss = 1.953
Epoch 104 Batch   19/44   train_loss = 1.815
Epoch 104 Batch   20/44   train_loss = 1.871
Epoch 104 Batch   21/44   train_loss = 1.755
Epoch 104 Batch   22/44   train_loss = 1.924
Epoch 104 Batch   23/44   train_loss = 1.818
Epoch 104 Batch   24/44   train_loss = 1.829
Epoch 104 Batch   25/44   train_loss = 1.902
Epoch 104 Batch   26/44   train_loss = 1.806
Epoch 104 Batch   27/44   train_loss = 1.939
Epoch 104 Batch   28/44   train_loss = 1.887
Epoch 104 Batch   29/44   train_loss = 1.839
Epoch 104 Batch   30/44   train_loss = 1.854
Epoch 104 Batch   31/44   train_loss = 1.938
Epoch 104 Batch   32/44   train_loss = 1.944
Epoch 104 Batch   33/44   train_loss = 1.961
Epoch 104 Batch   34/44   train_loss = 1.873
Epoch 104 Batch   35/44   train_loss = 1.881
Epoch 104 Batch   36/44   train_loss = 2.009
Epoch 104 Batch   37/44   train_loss = 1.889
Epoch 104 Batch   38/44   train_loss = 1.912
Epoch 104 Batch   39/44   train_loss = 1.754
Epoch 104 Batch   40/44   train_loss = 1.839
Epoch 104 Batch   41/44   train_loss = 1.880
Epoch 104 Batch   42/44   train_loss = 1.765
Epoch 104 Batch   43/44   train_loss = 1.776
Epoch 105 Batch    0/44   train_loss = 1.817
Epoch 105 Batch    1/44   train_loss = 1.808
Epoch 105 Batch    2/44   train_loss = 1.864
Epoch 105 Batch    3/44   train_loss = 1.898
Epoch 105 Batch    4/44   train_loss = 1.793
Epoch 105 Batch    5/44   train_loss = 1.835
Epoch 105 Batch    6/44   train_loss = 1.883
Epoch 105 Batch    7/44   train_loss = 1.824
Epoch 105 Batch    8/44   train_loss = 1.831
Epoch 105 Batch    9/44   train_loss = 1.846
Epoch 105 Batch   10/44   train_loss = 1.774
Epoch 105 Batch   11/44   train_loss = 1.838
Epoch 105 Batch   12/44   train_loss = 1.906
Epoch 105 Batch   13/44   train_loss = 1.786
Epoch 105 Batch   14/44   train_loss = 1.834
Epoch 105 Batch   15/44   train_loss = 1.826
Epoch 105 Batch   16/44   train_loss = 1.840
Epoch 105 Batch   17/44   train_loss = 1.845
Epoch 105 Batch   18/44   train_loss = 1.915
Epoch 105 Batch   19/44   train_loss = 1.774
Epoch 105 Batch   20/44   train_loss = 1.843
Epoch 105 Batch   21/44   train_loss = 1.741
Epoch 105 Batch   22/44   train_loss = 1.919
Epoch 105 Batch   23/44   train_loss = 1.815
Epoch 105 Batch   24/44   train_loss = 1.817
Epoch 105 Batch   25/44   train_loss = 1.875
Epoch 105 Batch   26/44   train_loss = 1.764
Epoch 105 Batch   27/44   train_loss = 1.906
Epoch 105 Batch   28/44   train_loss = 1.859
Epoch 105 Batch   29/44   train_loss = 1.825
Epoch 105 Batch   30/44   train_loss = 1.850
Epoch 105 Batch   31/44   train_loss = 1.934
Epoch 105 Batch   32/44   train_loss = 1.931
Epoch 105 Batch   33/44   train_loss = 1.942
Epoch 105 Batch   34/44   train_loss = 1.844
Epoch 105 Batch   35/44   train_loss = 1.865
Epoch 105 Batch   36/44   train_loss = 1.998
Epoch 105 Batch   37/44   train_loss = 1.886
Epoch 105 Batch   38/44   train_loss = 1.914
Epoch 105 Batch   39/44   train_loss = 1.747
Epoch 105 Batch   40/44   train_loss = 1.827
Epoch 105 Batch   41/44   train_loss = 1.862
Epoch 105 Batch   42/44   train_loss = 1.733
Epoch 105 Batch   43/44   train_loss = 1.748
Epoch 106 Batch    0/44   train_loss = 1.798
Epoch 106 Batch    1/44   train_loss = 1.790
Epoch 106 Batch    2/44   train_loss = 1.843
Epoch 106 Batch    3/44   train_loss = 1.863
Epoch 106 Batch    4/44   train_loss = 1.761
Epoch 106 Batch    5/44   train_loss = 1.800
Epoch 106 Batch    6/44   train_loss = 1.847
Epoch 106 Batch    7/44   train_loss = 1.803
Epoch 106 Batch    8/44   train_loss = 1.821
Epoch 106 Batch    9/44   train_loss = 1.829
Epoch 106 Batch   10/44   train_loss = 1.758
Epoch 106 Batch   11/44   train_loss = 1.805
Epoch 106 Batch   12/44   train_loss = 1.857
Epoch 106 Batch   13/44   train_loss = 1.741
Epoch 106 Batch   14/44   train_loss = 1.796
Epoch 106 Batch   15/44   train_loss = 1.805
Epoch 106 Batch   16/44   train_loss = 1.832
Epoch 106 Batch   17/44   train_loss = 1.837
Epoch 106 Batch   18/44   train_loss = 1.898
Epoch 106 Batch   19/44   train_loss = 1.742
Epoch 106 Batch   20/44   train_loss = 1.815
Epoch 106 Batch   21/44   train_loss = 1.710
Epoch 106 Batch   22/44   train_loss = 1.892
Epoch 106 Batch   23/44   train_loss = 1.815
Epoch 106 Batch   24/44   train_loss = 1.827
Epoch 106 Batch   25/44   train_loss = 1.885
Epoch 106 Batch   26/44   train_loss = 1.744
Epoch 106 Batch   27/44   train_loss = 1.874
Epoch 106 Batch   28/44   train_loss = 1.818
Epoch 106 Batch   29/44   train_loss = 1.786
Epoch 106 Batch   30/44   train_loss = 1.822
Epoch 106 Batch   31/44   train_loss = 1.922
Epoch 106 Batch   32/44   train_loss = 1.933
Epoch 106 Batch   33/44   train_loss = 1.945
Epoch 106 Batch   34/44   train_loss = 1.840
Epoch 106 Batch   35/44   train_loss = 1.851
Epoch 106 Batch   36/44   train_loss = 1.980
Epoch 106 Batch   37/44   train_loss = 1.871
Epoch 106 Batch   38/44   train_loss = 1.914
Epoch 106 Batch   39/44   train_loss = 1.757
Epoch 106 Batch   40/44   train_loss = 1.840
Epoch 106 Batch   41/44   train_loss = 1.858
Epoch 106 Batch   42/44   train_loss = 1.720
Epoch 106 Batch   43/44   train_loss = 1.724
Epoch 107 Batch    0/44   train_loss = 1.769
Epoch 107 Batch    1/44   train_loss = 1.774
Epoch 107 Batch    2/44   train_loss = 1.831
Epoch 107 Batch    3/44   train_loss = 1.857
Epoch 107 Batch    4/44   train_loss = 1.752
Epoch 107 Batch    5/44   train_loss = 1.781
Epoch 107 Batch    6/44   train_loss = 1.809
Epoch 107 Batch    7/44   train_loss = 1.758
Epoch 107 Batch    8/44   train_loss = 1.786
Epoch 107 Batch    9/44   train_loss = 1.805
Epoch 107 Batch   10/44   train_loss = 1.754
Epoch 107 Batch   11/44   train_loss = 1.802
Epoch 107 Batch   12/44   train_loss = 1.842
Epoch 107 Batch   13/44   train_loss = 1.723
Epoch 107 Batch   14/44   train_loss = 1.763
Epoch 107 Batch   15/44   train_loss = 1.765
Epoch 107 Batch   16/44   train_loss = 1.789
Epoch 107 Batch   17/44   train_loss = 1.810
Epoch 107 Batch   18/44   train_loss = 1.890
Epoch 107 Batch   19/44   train_loss = 1.730
Epoch 107 Batch   20/44   train_loss = 1.795
Epoch 107 Batch   21/44   train_loss = 1.674
Epoch 107 Batch   22/44   train_loss = 1.842
Epoch 107 Batch   23/44   train_loss = 1.769
Epoch 107 Batch   24/44   train_loss = 1.797
Epoch 107 Batch   25/44   train_loss = 1.892
Epoch 107 Batch   26/44   train_loss = 1.762
Epoch 107 Batch   27/44   train_loss = 1.879
Epoch 107 Batch   28/44   train_loss = 1.806
Epoch 107 Batch   29/44   train_loss = 1.749
Epoch 107 Batch   30/44   train_loss = 1.751
Epoch 107 Batch   31/44   train_loss = 1.857
Epoch 107 Batch   32/44   train_loss = 1.895
Epoch 107 Batch   33/44   train_loss = 1.935
Epoch 107 Batch   34/44   train_loss = 1.855
Epoch 107 Batch   35/44   train_loss = 1.861
Epoch 107 Batch   36/44   train_loss = 1.978
Epoch 107 Batch   37/44   train_loss = 1.844
Epoch 107 Batch   38/44   train_loss = 1.884
Epoch 107 Batch   39/44   train_loss = 1.744
Epoch 107 Batch   40/44   train_loss = 1.837
Epoch 107 Batch   41/44   train_loss = 1.867
Epoch 107 Batch   42/44   train_loss = 1.744
Epoch 107 Batch   43/44   train_loss = 1.734
Epoch 108 Batch    0/44   train_loss = 1.762
Epoch 108 Batch    1/44   train_loss = 1.748
Epoch 108 Batch    2/44   train_loss = 1.799
Epoch 108 Batch    3/44   train_loss = 1.829
Epoch 108 Batch    4/44   train_loss = 1.745
Epoch 108 Batch    5/44   train_loss = 1.792
Epoch 108 Batch    6/44   train_loss = 1.823
Epoch 108 Batch    7/44   train_loss = 1.758
Epoch 108 Batch    8/44   train_loss = 1.759
Epoch 108 Batch    9/44   train_loss = 1.763
Epoch 108 Batch   10/44   train_loss = 1.705
Epoch 108 Batch   11/44   train_loss = 1.776
Epoch 108 Batch   12/44   train_loss = 1.843
Epoch 108 Batch   13/44   train_loss = 1.751
Epoch 108 Batch   14/44   train_loss = 1.784
Epoch 108 Batch   15/44   train_loss = 1.759
Epoch 108 Batch   16/44   train_loss = 1.764
Epoch 108 Batch   17/44   train_loss = 1.766
Epoch 108 Batch   18/44   train_loss = 1.859
Epoch 108 Batch   19/44   train_loss = 1.705
Epoch 108 Batch   20/44   train_loss = 1.777
Epoch 108 Batch   21/44   train_loss = 1.657
Epoch 108 Batch   22/44   train_loss = 1.816
Epoch 108 Batch   23/44   train_loss = 1.742
Epoch 108 Batch   24/44   train_loss = 1.750
Epoch 108 Batch   25/44   train_loss = 1.845
Epoch 108 Batch   26/44   train_loss = 1.735
Epoch 108 Batch   27/44   train_loss = 1.883
Epoch 108 Batch   28/44   train_loss = 1.825
Epoch 108 Batch   29/44   train_loss = 1.774
Epoch 108 Batch   30/44   train_loss = 1.746
Epoch 108 Batch   31/44   train_loss = 1.814
Epoch 108 Batch   32/44   train_loss = 1.834
Epoch 108 Batch   33/44   train_loss = 1.864
Epoch 108 Batch   34/44   train_loss = 1.796
Epoch 108 Batch   35/44   train_loss = 1.844
Epoch 108 Batch   36/44   train_loss = 1.989
Epoch 108 Batch   37/44   train_loss = 1.861
Epoch 108 Batch   38/44   train_loss = 1.887
Epoch 108 Batch   39/44   train_loss = 1.723
Epoch 108 Batch   40/44   train_loss = 1.787
Epoch 108 Batch   41/44   train_loss = 1.809
Epoch 108 Batch   42/44   train_loss = 1.721
Epoch 108 Batch   43/44   train_loss = 1.734
Epoch 109 Batch    0/44   train_loss = 1.782
Epoch 109 Batch    1/44   train_loss = 1.773
Epoch 109 Batch    2/44   train_loss = 1.806
Epoch 109 Batch    3/44   train_loss = 1.806
Epoch 109 Batch    4/44   train_loss = 1.699
Epoch 109 Batch    5/44   train_loss = 1.748
Epoch 109 Batch    6/44   train_loss = 1.803
Epoch 109 Batch    7/44   train_loss = 1.770
Epoch 109 Batch    8/44   train_loss = 1.769
Epoch 109 Batch    9/44   train_loss = 1.782
Epoch 109 Batch   10/44   train_loss = 1.689
Epoch 109 Batch   11/44   train_loss = 1.736
Epoch 109 Batch   12/44   train_loss = 1.787
Epoch 109 Batch   13/44   train_loss = 1.702
Epoch 109 Batch   14/44   train_loss = 1.770
Epoch 109 Batch   15/44   train_loss = 1.776
Epoch 109 Batch   16/44   train_loss = 1.791
Epoch 109 Batch   17/44   train_loss = 1.774
Epoch 109 Batch   18/44   train_loss = 1.839
Epoch 109 Batch   19/44   train_loss = 1.669
Epoch 109 Batch   20/44   train_loss = 1.727
Epoch 109 Batch   21/44   train_loss = 1.610
Epoch 109 Batch   22/44   train_loss = 1.781
Epoch 109 Batch   23/44   train_loss = 1.717
Epoch 109 Batch   24/44   train_loss = 1.722
Epoch 109 Batch   25/44   train_loss = 1.809
Epoch 109 Batch   26/44   train_loss = 1.700
Epoch 109 Batch   27/44   train_loss = 1.847
Epoch 109 Batch   28/44   train_loss = 1.785
Epoch 109 Batch   29/44   train_loss = 1.757
Epoch 109 Batch   30/44   train_loss = 1.748
Epoch 109 Batch   31/44   train_loss = 1.828
Epoch 109 Batch   32/44   train_loss = 1.825
Epoch 109 Batch   33/44   train_loss = 1.829
Epoch 109 Batch   34/44   train_loss = 1.725
Epoch 109 Batch   35/44   train_loss = 1.772
Epoch 109 Batch   36/44   train_loss = 1.919
Epoch 109 Batch   37/44   train_loss = 1.822
Epoch 109 Batch   38/44   train_loss = 1.875
Epoch 109 Batch   39/44   train_loss = 1.733
Epoch 109 Batch   40/44   train_loss = 1.795
Epoch 109 Batch   41/44   train_loss = 1.782
Epoch 109 Batch   42/44   train_loss = 1.676
Epoch 109 Batch   43/44   train_loss = 1.658
Epoch 110 Batch    0/44   train_loss = 1.710
Epoch 110 Batch    1/44   train_loss = 1.734
Epoch 110 Batch    2/44   train_loss = 1.804
Epoch 110 Batch    3/44   train_loss = 1.825
Epoch 110 Batch    4/44   train_loss = 1.707
Epoch 110 Batch    5/44   train_loss = 1.737
Epoch 110 Batch    6/44   train_loss = 1.760
Epoch 110 Batch    7/44   train_loss = 1.714
Epoch 110 Batch    8/44   train_loss = 1.730
Epoch 110 Batch    9/44   train_loss = 1.777
Epoch 110 Batch   10/44   train_loss = 1.698
Epoch 110 Batch   11/44   train_loss = 1.749
Epoch 110 Batch   12/44   train_loss = 1.784
Epoch 110 Batch   13/44   train_loss = 1.655
Epoch 110 Batch   14/44   train_loss = 1.707
Epoch 110 Batch   15/44   train_loss = 1.711
Epoch 110 Batch   16/44   train_loss = 1.756
Epoch 110 Batch   17/44   train_loss = 1.767
Epoch 110 Batch   18/44   train_loss = 1.849
Epoch 110 Batch   19/44   train_loss = 1.686
Epoch 110 Batch   20/44   train_loss = 1.721
Epoch 110 Batch   21/44   train_loss = 1.584
Epoch 110 Batch   22/44   train_loss = 1.739
Epoch 110 Batch   23/44   train_loss = 1.659
Epoch 110 Batch   24/44   train_loss = 1.675
Epoch 110 Batch   25/44   train_loss = 1.765
Epoch 110 Batch   26/44   train_loss = 1.671
Epoch 110 Batch   27/44   train_loss = 1.823
Epoch 110 Batch   28/44   train_loss = 1.753
Epoch 110 Batch   29/44   train_loss = 1.713
Epoch 110 Batch   30/44   train_loss = 1.700
Epoch 110 Batch   31/44   train_loss = 1.775
Epoch 110 Batch   32/44   train_loss = 1.790
Epoch 110 Batch   33/44   train_loss = 1.800
Epoch 110 Batch   34/44   train_loss = 1.705
Epoch 110 Batch   35/44   train_loss = 1.746
Epoch 110 Batch   36/44   train_loss = 1.878
Epoch 110 Batch   37/44   train_loss = 1.761
Epoch 110 Batch   38/44   train_loss = 1.816
Epoch 110 Batch   39/44   train_loss = 1.683
Epoch 110 Batch   40/44   train_loss = 1.762
Epoch 110 Batch   41/44   train_loss = 1.766
Epoch 110 Batch   42/44   train_loss = 1.669
Epoch 110 Batch   43/44   train_loss = 1.639
Epoch 111 Batch    0/44   train_loss = 1.669
Epoch 111 Batch    1/44   train_loss = 1.663
Epoch 111 Batch    2/44   train_loss = 1.716
Epoch 111 Batch    3/44   train_loss = 1.750
Epoch 111 Batch    4/44   train_loss = 1.663
Epoch 111 Batch    5/44   train_loss = 1.728
Epoch 111 Batch    6/44   train_loss = 1.776
Epoch 111 Batch    7/44   train_loss = 1.712
Epoch 111 Batch    8/44   train_loss = 1.699
Epoch 111 Batch    9/44   train_loss = 1.719
Epoch 111 Batch   10/44   train_loss = 1.638
Epoch 111 Batch   11/44   train_loss = 1.707
Epoch 111 Batch   12/44   train_loss = 1.773
Epoch 111 Batch   13/44   train_loss = 1.654
Epoch 111 Batch   14/44   train_loss = 1.712
Epoch 111 Batch   15/44   train_loss = 1.692
Epoch 111 Batch   16/44   train_loss = 1.702
Epoch 111 Batch   17/44   train_loss = 1.710
Epoch 111 Batch   18/44   train_loss = 1.810
Epoch 111 Batch   19/44   train_loss = 1.663
Epoch 111 Batch   20/44   train_loss = 1.730
Epoch 111 Batch   21/44   train_loss = 1.603
Epoch 111 Batch   22/44   train_loss = 1.744
Epoch 111 Batch   23/44   train_loss = 1.634
Epoch 111 Batch   24/44   train_loss = 1.643
Epoch 111 Batch   25/44   train_loss = 1.710
Epoch 111 Batch   26/44   train_loss = 1.615
Epoch 111 Batch   27/44   train_loss = 1.788
Epoch 111 Batch   28/44   train_loss = 1.731
Epoch 111 Batch   29/44   train_loss = 1.700
Epoch 111 Batch   30/44   train_loss = 1.698
Epoch 111 Batch   31/44   train_loss = 1.753
Epoch 111 Batch   32/44   train_loss = 1.763
Epoch 111 Batch   33/44   train_loss = 1.762
Epoch 111 Batch   34/44   train_loss = 1.674
Epoch 111 Batch   35/44   train_loss = 1.711
Epoch 111 Batch   36/44   train_loss = 1.857
Epoch 111 Batch   37/44   train_loss = 1.733
Epoch 111 Batch   38/44   train_loss = 1.789
Epoch 111 Batch   39/44   train_loss = 1.648
Epoch 111 Batch   40/44   train_loss = 1.720
Epoch 111 Batch   41/44   train_loss = 1.723
Epoch 111 Batch   42/44   train_loss = 1.630
Epoch 111 Batch   43/44   train_loss = 1.617
Epoch 112 Batch    0/44   train_loss = 1.656
Epoch 112 Batch    1/44   train_loss = 1.641
Epoch 112 Batch    2/44   train_loss = 1.680
Epoch 112 Batch    3/44   train_loss = 1.684
Epoch 112 Batch    4/44   train_loss = 1.595
Epoch 112 Batch    5/44   train_loss = 1.665
Epoch 112 Batch    6/44   train_loss = 1.725
Epoch 112 Batch    7/44   train_loss = 1.692
Epoch 112 Batch    8/44   train_loss = 1.694
Epoch 112 Batch    9/44   train_loss = 1.705
Epoch 112 Batch   10/44   train_loss = 1.614
Epoch 112 Batch   11/44   train_loss = 1.651
Epoch 112 Batch   12/44   train_loss = 1.715
Epoch 112 Batch   13/44   train_loss = 1.604
Epoch 112 Batch   14/44   train_loss = 1.672
Epoch 112 Batch   15/44   train_loss = 1.681
Epoch 112 Batch   16/44   train_loss = 1.693
Epoch 112 Batch   17/44   train_loss = 1.695
Epoch 112 Batch   18/44   train_loss = 1.784
Epoch 112 Batch   19/44   train_loss = 1.627
Epoch 112 Batch   20/44   train_loss = 1.687
Epoch 112 Batch   21/44   train_loss = 1.572
Epoch 112 Batch   22/44   train_loss = 1.731
Epoch 112 Batch   23/44   train_loss = 1.629
Epoch 112 Batch   24/44   train_loss = 1.652
Epoch 112 Batch   25/44   train_loss = 1.699
Epoch 112 Batch   26/44   train_loss = 1.577
Epoch 112 Batch   27/44   train_loss = 1.732
Epoch 112 Batch   28/44   train_loss = 1.671
Epoch 112 Batch   29/44   train_loss = 1.646
Epoch 112 Batch   30/44   train_loss = 1.672
Epoch 112 Batch   31/44   train_loss = 1.740
Epoch 112 Batch   32/44   train_loss = 1.770
Epoch 112 Batch   33/44   train_loss = 1.767
Epoch 112 Batch   34/44   train_loss = 1.663
Epoch 112 Batch   35/44   train_loss = 1.689
Epoch 112 Batch   36/44   train_loss = 1.824
Epoch 112 Batch   37/44   train_loss = 1.696
Epoch 112 Batch   38/44   train_loss = 1.763
Epoch 112 Batch   39/44   train_loss = 1.624
Epoch 112 Batch   40/44   train_loss = 1.711
Epoch 112 Batch   41/44   train_loss = 1.714
Epoch 112 Batch   42/44   train_loss = 1.607
Epoch 112 Batch   43/44   train_loss = 1.589
Epoch 113 Batch    0/44   train_loss = 1.627
Epoch 113 Batch    1/44   train_loss = 1.607
Epoch 113 Batch    2/44   train_loss = 1.654
Epoch 113 Batch    3/44   train_loss = 1.658
Epoch 113 Batch    4/44   train_loss = 1.573
Epoch 113 Batch    5/44   train_loss = 1.621
Epoch 113 Batch    6/44   train_loss = 1.671
Epoch 113 Batch    7/44   train_loss = 1.639
Epoch 113 Batch    8/44   train_loss = 1.650
Epoch 113 Batch    9/44   train_loss = 1.680
Epoch 113 Batch   10/44   train_loss = 1.596
Epoch 113 Batch   11/44   train_loss = 1.635
Epoch 113 Batch   12/44   train_loss = 1.694
Epoch 113 Batch   13/44   train_loss = 1.576
Epoch 113 Batch   14/44   train_loss = 1.616
Epoch 113 Batch   15/44   train_loss = 1.625
Epoch 113 Batch   16/44   train_loss = 1.640
Epoch 113 Batch   17/44   train_loss = 1.658
Epoch 113 Batch   18/44   train_loss = 1.764
Epoch 113 Batch   19/44   train_loss = 1.615
Epoch 113 Batch   20/44   train_loss = 1.674
Epoch 113 Batch   21/44   train_loss = 1.549
Epoch 113 Batch   22/44   train_loss = 1.687
Epoch 113 Batch   23/44   train_loss = 1.590
Epoch 113 Batch   24/44   train_loss = 1.619
Epoch 113 Batch   25/44   train_loss = 1.679
Epoch 113 Batch   26/44   train_loss = 1.567
Epoch 113 Batch   27/44   train_loss = 1.711
Epoch 113 Batch   28/44   train_loss = 1.655
Epoch 113 Batch   29/44   train_loss = 1.605
Epoch 113 Batch   30/44   train_loss = 1.615
Epoch 113 Batch   31/44   train_loss = 1.685
Epoch 113 Batch   32/44   train_loss = 1.734
Epoch 113 Batch   33/44   train_loss = 1.756
Epoch 113 Batch   34/44   train_loss = 1.667
Epoch 113 Batch   35/44   train_loss = 1.696
Epoch 113 Batch   36/44   train_loss = 1.824
Epoch 113 Batch   37/44   train_loss = 1.683
Epoch 113 Batch   38/44   train_loss = 1.729
Epoch 113 Batch   39/44   train_loss = 1.585
Epoch 113 Batch   40/44   train_loss = 1.678
Epoch 113 Batch   41/44   train_loss = 1.699
Epoch 113 Batch   42/44   train_loss = 1.609
Epoch 113 Batch   43/44   train_loss = 1.590
Epoch 114 Batch    0/44   train_loss = 1.624
Epoch 114 Batch    1/44   train_loss = 1.598
Epoch 114 Batch    2/44   train_loss = 1.630
Epoch 114 Batch    3/44   train_loss = 1.628
Epoch 114 Batch    4/44   train_loss = 1.551
Epoch 114 Batch    5/44   train_loss = 1.598
Epoch 114 Batch    6/44   train_loss = 1.657
Epoch 114 Batch    7/44   train_loss = 1.626
Epoch 114 Batch    8/44   train_loss = 1.626
Epoch 114 Batch    9/44   train_loss = 1.650
Epoch 114 Batch   10/44   train_loss = 1.563
Epoch 114 Batch   11/44   train_loss = 1.608
Epoch 114 Batch   12/44   train_loss = 1.677
Epoch 114 Batch   13/44   train_loss = 1.560
Epoch 114 Batch   14/44   train_loss = 1.609
Epoch 114 Batch   15/44   train_loss = 1.609
Epoch 114 Batch   16/44   train_loss = 1.610
Epoch 114 Batch   17/44   train_loss = 1.621
Epoch 114 Batch   18/44   train_loss = 1.716
Epoch 114 Batch   19/44   train_loss = 1.583
Epoch 114 Batch   20/44   train_loss = 1.649
Epoch 114 Batch   21/44   train_loss = 1.533
Epoch 114 Batch   22/44   train_loss = 1.662
Epoch 114 Batch   23/44   train_loss = 1.571
Epoch 114 Batch   24/44   train_loss = 1.574
Epoch 114 Batch   25/44   train_loss = 1.629
Epoch 114 Batch   26/44   train_loss = 1.524
Epoch 114 Batch   27/44   train_loss = 1.678
Epoch 114 Batch   28/44   train_loss = 1.637
Epoch 114 Batch   29/44   train_loss = 1.590
Epoch 114 Batch   30/44   train_loss = 1.591
Epoch 114 Batch   31/44   train_loss = 1.656
Epoch 114 Batch   32/44   train_loss = 1.680
Epoch 114 Batch   33/44   train_loss = 1.690
Epoch 114 Batch   34/44   train_loss = 1.604
Epoch 114 Batch   35/44   train_loss = 1.649
Epoch 114 Batch   36/44   train_loss = 1.803
Epoch 114 Batch   37/44   train_loss = 1.675
Epoch 114 Batch   38/44   train_loss = 1.721
Epoch 114 Batch   39/44   train_loss = 1.573
Epoch 114 Batch   40/44   train_loss = 1.643
Epoch 114 Batch   41/44   train_loss = 1.659
Epoch 114 Batch   42/44   train_loss = 1.583
Epoch 114 Batch   43/44   train_loss = 1.564
Epoch 115 Batch    0/44   train_loss = 1.608
Epoch 115 Batch    1/44   train_loss = 1.596
Epoch 115 Batch    2/44   train_loss = 1.619
Epoch 115 Batch    3/44   train_loss = 1.621
Epoch 115 Batch    4/44   train_loss = 1.534
Epoch 115 Batch    5/44   train_loss = 1.567
Epoch 115 Batch    6/44   train_loss = 1.624
Epoch 115 Batch    7/44   train_loss = 1.602
Epoch 115 Batch    8/44   train_loss = 1.617
Epoch 115 Batch    9/44   train_loss = 1.652
Epoch 115 Batch   10/44   train_loss = 1.566
Epoch 115 Batch   11/44   train_loss = 1.614
Epoch 115 Batch   12/44   train_loss = 1.655
Epoch 115 Batch   13/44   train_loss = 1.525
Epoch 115 Batch   14/44   train_loss = 1.574
Epoch 115 Batch   15/44   train_loss = 1.585
Epoch 115 Batch   16/44   train_loss = 1.602
Epoch 115 Batch   17/44   train_loss = 1.613
Epoch 115 Batch   18/44   train_loss = 1.699
Epoch 115 Batch   19/44   train_loss = 1.564
Epoch 115 Batch   20/44   train_loss = 1.614
Epoch 115 Batch   21/44   train_loss = 1.503
Epoch 115 Batch   22/44   train_loss = 1.640
Epoch 115 Batch   23/44   train_loss = 1.559
Epoch 115 Batch   24/44   train_loss = 1.549
Epoch 115 Batch   25/44   train_loss = 1.605
Epoch 115 Batch   26/44   train_loss = 1.495
Epoch 115 Batch   27/44   train_loss = 1.640
Epoch 115 Batch   28/44   train_loss = 1.587
Epoch 115 Batch   29/44   train_loss = 1.551
Epoch 115 Batch   30/44   train_loss = 1.558
Epoch 115 Batch   31/44   train_loss = 1.647
Epoch 115 Batch   32/44   train_loss = 1.670
Epoch 115 Batch   33/44   train_loss = 1.658
Epoch 115 Batch   34/44   train_loss = 1.568
Epoch 115 Batch   35/44   train_loss = 1.595
Epoch 115 Batch   36/44   train_loss = 1.731
Epoch 115 Batch   37/44   train_loss = 1.627
Epoch 115 Batch   38/44   train_loss = 1.685
Epoch 115 Batch   39/44   train_loss = 1.554
Epoch 115 Batch   40/44   train_loss = 1.623
Epoch 115 Batch   41/44   train_loss = 1.643
Epoch 115 Batch   42/44   train_loss = 1.553
Epoch 115 Batch   43/44   train_loss = 1.526
Epoch 116 Batch    0/44   train_loss = 1.571
Epoch 116 Batch    1/44   train_loss = 1.564
Epoch 116 Batch    2/44   train_loss = 1.603
Epoch 116 Batch    3/44   train_loss = 1.621
Epoch 116 Batch    4/44   train_loss = 1.535
Epoch 116 Batch    5/44   train_loss = 1.562
Epoch 116 Batch    6/44   train_loss = 1.592
Epoch 116 Batch    7/44   train_loss = 1.554
Epoch 116 Batch    8/44   train_loss = 1.566
Epoch 116 Batch    9/44   train_loss = 1.609
Epoch 116 Batch   10/44   train_loss = 1.545
Epoch 116 Batch   11/44   train_loss = 1.621
Epoch 116 Batch   12/44   train_loss = 1.675
Epoch 116 Batch   13/44   train_loss = 1.526
Epoch 116 Batch   14/44   train_loss = 1.555
Epoch 116 Batch   15/44   train_loss = 1.544
Epoch 116 Batch   16/44   train_loss = 1.553
Epoch 116 Batch   17/44   train_loss = 1.572
Epoch 116 Batch   18/44   train_loss = 1.672
Epoch 116 Batch   19/44   train_loss = 1.559
Epoch 116 Batch   20/44   train_loss = 1.608
Epoch 116 Batch   21/44   train_loss = 1.494
Epoch 116 Batch   22/44   train_loss = 1.631
Epoch 116 Batch   23/44   train_loss = 1.540
Epoch 116 Batch   24/44   train_loss = 1.522
Epoch 116 Batch   25/44   train_loss = 1.588
Epoch 116 Batch   26/44   train_loss = 1.490
Epoch 116 Batch   27/44   train_loss = 1.628
Epoch 116 Batch   28/44   train_loss = 1.561
Epoch 116 Batch   29/44   train_loss = 1.517
Epoch 116 Batch   30/44   train_loss = 1.529
Epoch 116 Batch   31/44   train_loss = 1.613
Epoch 116 Batch   32/44   train_loss = 1.637
Epoch 116 Batch   33/44   train_loss = 1.640
Epoch 116 Batch   34/44   train_loss = 1.556
Epoch 116 Batch   35/44   train_loss = 1.579
Epoch 116 Batch   36/44   train_loss = 1.709
Epoch 116 Batch   37/44   train_loss = 1.596
Epoch 116 Batch   38/44   train_loss = 1.637
Epoch 116 Batch   39/44   train_loss = 1.505
Epoch 116 Batch   40/44   train_loss = 1.583
Epoch 116 Batch   41/44   train_loss = 1.619
Epoch 116 Batch   42/44   train_loss = 1.534
Epoch 116 Batch   43/44   train_loss = 1.507
Epoch 117 Batch    0/44   train_loss = 1.547
Epoch 117 Batch    1/44   train_loss = 1.524
Epoch 117 Batch    2/44   train_loss = 1.558
Epoch 117 Batch    3/44   train_loss = 1.578
Epoch 117 Batch    4/44   train_loss = 1.501
Epoch 117 Batch    5/44   train_loss = 1.551
Epoch 117 Batch    6/44   train_loss = 1.589
Epoch 117 Batch    7/44   train_loss = 1.545
Epoch 117 Batch    8/44   train_loss = 1.539
Epoch 117 Batch    9/44   train_loss = 1.568
Epoch 117 Batch   10/44   train_loss = 1.483
Epoch 117 Batch   11/44   train_loss = 1.568
Epoch 117 Batch   12/44   train_loss = 1.645
Epoch 117 Batch   13/44   train_loss = 1.517
Epoch 117 Batch   14/44   train_loss = 1.563
Epoch 117 Batch   15/44   train_loss = 1.558
Epoch 117 Batch   16/44   train_loss = 1.544
Epoch 117 Batch   17/44   train_loss = 1.534
Epoch 117 Batch   18/44   train_loss = 1.614
Epoch 117 Batch   19/44   train_loss = 1.506
Epoch 117 Batch   20/44   train_loss = 1.561
Epoch 117 Batch   21/44   train_loss = 1.479
Epoch 117 Batch   22/44   train_loss = 1.636
Epoch 117 Batch   23/44   train_loss = 1.544
Epoch 117 Batch   24/44   train_loss = 1.525
Epoch 117 Batch   25/44   train_loss = 1.587
Epoch 117 Batch   26/44   train_loss = 1.484
Epoch 117 Batch   27/44   train_loss = 1.611
Epoch 117 Batch   28/44   train_loss = 1.544
Epoch 117 Batch   29/44   train_loss = 1.506
Epoch 117 Batch   30/44   train_loss = 1.523
Epoch 117 Batch   31/44   train_loss = 1.589
Epoch 117 Batch   32/44   train_loss = 1.607
Epoch 117 Batch   33/44   train_loss = 1.616
Epoch 117 Batch   34/44   train_loss = 1.533
Epoch 117 Batch   35/44   train_loss = 1.556
Epoch 117 Batch   36/44   train_loss = 1.704
Epoch 117 Batch   37/44   train_loss = 1.593
Epoch 117 Batch   38/44   train_loss = 1.622
Epoch 117 Batch   39/44   train_loss = 1.472
Epoch 117 Batch   40/44   train_loss = 1.554
Epoch 117 Batch   41/44   train_loss = 1.582
Epoch 117 Batch   42/44   train_loss = 1.502
Epoch 117 Batch   43/44   train_loss = 1.491
Epoch 118 Batch    0/44   train_loss = 1.538
Epoch 118 Batch    1/44   train_loss = 1.511
Epoch 118 Batch    2/44   train_loss = 1.548
Epoch 118 Batch    3/44   train_loss = 1.544
Epoch 118 Batch    4/44   train_loss = 1.461
Epoch 118 Batch    5/44   train_loss = 1.504
Epoch 118 Batch    6/44   train_loss = 1.546
Epoch 118 Batch    7/44   train_loss = 1.508
Epoch 118 Batch    8/44   train_loss = 1.514
Epoch 118 Batch    9/44   train_loss = 1.559
Epoch 118 Batch   10/44   train_loss = 1.457
Epoch 118 Batch   11/44   train_loss = 1.527
Epoch 118 Batch   12/44   train_loss = 1.583
Epoch 118 Batch   13/44   train_loss = 1.463
Epoch 118 Batch   14/44   train_loss = 1.521
Epoch 118 Batch   15/44   train_loss = 1.538
Epoch 118 Batch   16/44   train_loss = 1.552
Epoch 118 Batch   17/44   train_loss = 1.541
Epoch 118 Batch   18/44   train_loss = 1.603
Epoch 118 Batch   19/44   train_loss = 1.470
Epoch 118 Batch   20/44   train_loss = 1.506
Epoch 118 Batch   21/44   train_loss = 1.410
Epoch 118 Batch   22/44   train_loss = 1.581
Epoch 118 Batch   23/44   train_loss = 1.515
Epoch 118 Batch   24/44   train_loss = 1.533
Epoch 118 Batch   25/44   train_loss = 1.601
Epoch 118 Batch   26/44   train_loss = 1.494
Epoch 118 Batch   27/44   train_loss = 1.593
Epoch 118 Batch   28/44   train_loss = 1.518
Epoch 118 Batch   29/44   train_loss = 1.483
Epoch 118 Batch   30/44   train_loss = 1.499
Epoch 118 Batch   31/44   train_loss = 1.573
Epoch 118 Batch   32/44   train_loss = 1.604
Epoch 118 Batch   33/44   train_loss = 1.615
Epoch 118 Batch   34/44   train_loss = 1.525
Epoch 118 Batch   35/44   train_loss = 1.542
Epoch 118 Batch   36/44   train_loss = 1.695
Epoch 118 Batch   37/44   train_loss = 1.580
Epoch 118 Batch   38/44   train_loss = 1.604
Epoch 118 Batch   39/44   train_loss = 1.461
Epoch 118 Batch   40/44   train_loss = 1.536
Epoch 118 Batch   41/44   train_loss = 1.567
Epoch 118 Batch   42/44   train_loss = 1.482
Epoch 118 Batch   43/44   train_loss = 1.463
Epoch 119 Batch    0/44   train_loss = 1.507
Epoch 119 Batch    1/44   train_loss = 1.478
Epoch 119 Batch    2/44   train_loss = 1.533
Epoch 119 Batch    3/44   train_loss = 1.529
Epoch 119 Batch    4/44   train_loss = 1.451
Epoch 119 Batch    5/44   train_loss = 1.471
Epoch 119 Batch    6/44   train_loss = 1.512
Epoch 119 Batch    7/44   train_loss = 1.460
Epoch 119 Batch    8/44   train_loss = 1.463
Epoch 119 Batch    9/44   train_loss = 1.525
Epoch 119 Batch   10/44   train_loss = 1.426
Epoch 119 Batch   11/44   train_loss = 1.492
Epoch 119 Batch   12/44   train_loss = 1.546
Epoch 119 Batch   13/44   train_loss = 1.430
Epoch 119 Batch   14/44   train_loss = 1.478
Epoch 119 Batch   15/44   train_loss = 1.482
Epoch 119 Batch   16/44   train_loss = 1.508
Epoch 119 Batch   17/44   train_loss = 1.506
Epoch 119 Batch   18/44   train_loss = 1.583
Epoch 119 Batch   19/44   train_loss = 1.458
Epoch 119 Batch   20/44   train_loss = 1.494
Epoch 119 Batch   21/44   train_loss = 1.371
Epoch 119 Batch   22/44   train_loss = 1.515
Epoch 119 Batch   23/44   train_loss = 1.442
Epoch 119 Batch   24/44   train_loss = 1.462
Epoch 119 Batch   25/44   train_loss = 1.554
Epoch 119 Batch   26/44   train_loss = 1.481
Epoch 119 Batch   27/44   train_loss = 1.594
Epoch 119 Batch   28/44   train_loss = 1.532
Epoch 119 Batch   29/44   train_loss = 1.479
Epoch 119 Batch   30/44   train_loss = 1.460
Epoch 119 Batch   31/44   train_loss = 1.518
Epoch 119 Batch   32/44   train_loss = 1.565
Epoch 119 Batch   33/44   train_loss = 1.577
Epoch 119 Batch   34/44   train_loss = 1.507
Epoch 119 Batch   35/44   train_loss = 1.537
Epoch 119 Batch   36/44   train_loss = 1.691
Epoch 119 Batch   37/44   train_loss = 1.569
Epoch 119 Batch   38/44   train_loss = 1.577
Epoch 119 Batch   39/44   train_loss = 1.432
Epoch 119 Batch   40/44   train_loss = 1.495
Epoch 119 Batch   41/44   train_loss = 1.542
Epoch 119 Batch   42/44   train_loss = 1.464
Epoch 119 Batch   43/44   train_loss = 1.457
Epoch 120 Batch    0/44   train_loss = 1.500
Epoch 120 Batch    1/44   train_loss = 1.475
Epoch 120 Batch    2/44   train_loss = 1.516
Epoch 120 Batch    3/44   train_loss = 1.514
Epoch 120 Batch    4/44   train_loss = 1.428
Epoch 120 Batch    5/44   train_loss = 1.453
Epoch 120 Batch    6/44   train_loss = 1.496
Epoch 120 Batch    7/44   train_loss = 1.449
Epoch 120 Batch    8/44   train_loss = 1.439
Epoch 120 Batch    9/44   train_loss = 1.494
Epoch 120 Batch   10/44   train_loss = 1.387
Epoch 120 Batch   11/44   train_loss = 1.453
Epoch 120 Batch   12/44   train_loss = 1.509
Epoch 120 Batch   13/44   train_loss = 1.408
Epoch 120 Batch   14/44   train_loss = 1.459
Epoch 120 Batch   15/44   train_loss = 1.452
Epoch 120 Batch   16/44   train_loss = 1.476
Epoch 120 Batch   17/44   train_loss = 1.465
Epoch 120 Batch   18/44   train_loss = 1.539
Epoch 120 Batch   19/44   train_loss = 1.417
Epoch 120 Batch   20/44   train_loss = 1.470
Epoch 120 Batch   21/44   train_loss = 1.350
Epoch 120 Batch   22/44   train_loss = 1.494
Epoch 120 Batch   23/44   train_loss = 1.417
Epoch 120 Batch   24/44   train_loss = 1.410
Epoch 120 Batch   25/44   train_loss = 1.482
Epoch 120 Batch   26/44   train_loss = 1.418
Epoch 120 Batch   27/44   train_loss = 1.542
Epoch 120 Batch   28/44   train_loss = 1.506
Epoch 120 Batch   29/44   train_loss = 1.479
Epoch 120 Batch   30/44   train_loss = 1.465
Epoch 120 Batch   31/44   train_loss = 1.509
Epoch 120 Batch   32/44   train_loss = 1.541
Epoch 120 Batch   33/44   train_loss = 1.518
Epoch 120 Batch   34/44   train_loss = 1.457
Epoch 120 Batch   35/44   train_loss = 1.486
Epoch 120 Batch   36/44   train_loss = 1.653
Epoch 120 Batch   37/44   train_loss = 1.548
Epoch 120 Batch   38/44   train_loss = 1.563
Epoch 120 Batch   39/44   train_loss = 1.426
Epoch 120 Batch   40/44   train_loss = 1.470
Epoch 120 Batch   41/44   train_loss = 1.503
Epoch 120 Batch   42/44   train_loss = 1.420
Epoch 120 Batch   43/44   train_loss = 1.414
Epoch 121 Batch    0/44   train_loss = 1.474
Epoch 121 Batch    1/44   train_loss = 1.470
Epoch 121 Batch    2/44   train_loss = 1.521
Epoch 121 Batch    3/44   train_loss = 1.529
Epoch 121 Batch    4/44   train_loss = 1.426
Epoch 121 Batch    5/44   train_loss = 1.445
Epoch 121 Batch    6/44   train_loss = 1.468
Epoch 121 Batch    7/44   train_loss = 1.428
Epoch 121 Batch    8/44   train_loss = 1.419
Epoch 121 Batch    9/44   train_loss = 1.471
Epoch 121 Batch   10/44   train_loss = 1.368
Epoch 121 Batch   11/44   train_loss = 1.435
Epoch 121 Batch   12/44   train_loss = 1.491
Epoch 121 Batch   13/44   train_loss = 1.375
Epoch 121 Batch   14/44   train_loss = 1.429
Epoch 121 Batch   15/44   train_loss = 1.417
Epoch 121 Batch   16/44   train_loss = 1.447
Epoch 121 Batch   17/44   train_loss = 1.443
Epoch 121 Batch   18/44   train_loss = 1.506
Epoch 121 Batch   19/44   train_loss = 1.386
Epoch 121 Batch   20/44   train_loss = 1.432
Epoch 121 Batch   21/44   train_loss = 1.313
Epoch 121 Batch   22/44   train_loss = 1.447
Epoch 121 Batch   23/44   train_loss = 1.388
Epoch 121 Batch   24/44   train_loss = 1.380
Epoch 121 Batch   25/44   train_loss = 1.447
Epoch 121 Batch   26/44   train_loss = 1.380
Epoch 121 Batch   27/44   train_loss = 1.493
Epoch 121 Batch   28/44   train_loss = 1.444
Epoch 121 Batch   29/44   train_loss = 1.430
Epoch 121 Batch   30/44   train_loss = 1.420
Epoch 121 Batch   31/44   train_loss = 1.484
Epoch 121 Batch   32/44   train_loss = 1.528
Epoch 121 Batch   33/44   train_loss = 1.498
Epoch 121 Batch   34/44   train_loss = 1.428
Epoch 121 Batch   35/44   train_loss = 1.445
Epoch 121 Batch   36/44   train_loss = 1.593
Epoch 121 Batch   37/44   train_loss = 1.499
Epoch 121 Batch   38/44   train_loss = 1.522
Epoch 121 Batch   39/44   train_loss = 1.404
Epoch 121 Batch   40/44   train_loss = 1.452
Epoch 121 Batch   41/44   train_loss = 1.486
Epoch 121 Batch   42/44   train_loss = 1.394
Epoch 121 Batch   43/44   train_loss = 1.366
Epoch 122 Batch    0/44   train_loss = 1.421
Epoch 122 Batch    1/44   train_loss = 1.421
Epoch 122 Batch    2/44   train_loss = 1.481
Epoch 122 Batch    3/44   train_loss = 1.513
Epoch 122 Batch    4/44   train_loss = 1.428
Epoch 122 Batch    5/44   train_loss = 1.459
Epoch 122 Batch    6/44   train_loss = 1.476
Epoch 122 Batch    7/44   train_loss = 1.424
Epoch 122 Batch    8/44   train_loss = 1.400
Epoch 122 Batch    9/44   train_loss = 1.432
Epoch 122 Batch   10/44   train_loss = 1.335
Epoch 122 Batch   11/44   train_loss = 1.407
Epoch 122 Batch   12/44   train_loss = 1.476
Epoch 122 Batch   13/44   train_loss = 1.363
Epoch 122 Batch   14/44   train_loss = 1.419
Epoch 122 Batch   15/44   train_loss = 1.398
Epoch 122 Batch   16/44   train_loss = 1.414
Epoch 122 Batch   17/44   train_loss = 1.410
Epoch 122 Batch   18/44   train_loss = 1.483
Epoch 122 Batch   19/44   train_loss = 1.376
Epoch 122 Batch   20/44   train_loss = 1.417
Epoch 122 Batch   21/44   train_loss = 1.313
Epoch 122 Batch   22/44   train_loss = 1.425
Epoch 122 Batch   23/44   train_loss = 1.356
Epoch 122 Batch   24/44   train_loss = 1.341
Epoch 122 Batch   25/44   train_loss = 1.405
Epoch 122 Batch   26/44   train_loss = 1.348
Epoch 122 Batch   27/44   train_loss = 1.468
Epoch 122 Batch   28/44   train_loss = 1.415
Epoch 122 Batch   29/44   train_loss = 1.399
Epoch 122 Batch   30/44   train_loss = 1.390
Epoch 122 Batch   31/44   train_loss = 1.439
Epoch 122 Batch   32/44   train_loss = 1.487
Epoch 122 Batch   33/44   train_loss = 1.466
Epoch 122 Batch   34/44   train_loss = 1.401
Epoch 122 Batch   35/44   train_loss = 1.421
Epoch 122 Batch   36/44   train_loss = 1.565
Epoch 122 Batch   37/44   train_loss = 1.460
Epoch 122 Batch   38/44   train_loss = 1.475
Epoch 122 Batch   39/44   train_loss = 1.350
Epoch 122 Batch   40/44   train_loss = 1.407
Epoch 122 Batch   41/44   train_loss = 1.455
Epoch 122 Batch   42/44   train_loss = 1.371
Epoch 122 Batch   43/44   train_loss = 1.341
Epoch 123 Batch    0/44   train_loss = 1.392
Epoch 123 Batch    1/44   train_loss = 1.385
Epoch 123 Batch    2/44   train_loss = 1.421
Epoch 123 Batch    3/44   train_loss = 1.453
Epoch 123 Batch    4/44   train_loss = 1.379
Epoch 123 Batch    5/44   train_loss = 1.433
Epoch 123 Batch    6/44   train_loss = 1.464
Epoch 123 Batch    7/44   train_loss = 1.438
Epoch 123 Batch    8/44   train_loss = 1.426
Epoch 123 Batch    9/44   train_loss = 1.436
Epoch 123 Batch   10/44   train_loss = 1.323
Epoch 123 Batch   11/44   train_loss = 1.377
Epoch 123 Batch   12/44   train_loss = 1.431
Epoch 123 Batch   13/44   train_loss = 1.323
Epoch 123 Batch   14/44   train_loss = 1.393
Epoch 123 Batch   15/44   train_loss = 1.391
Epoch 123 Batch   16/44   train_loss = 1.409
Epoch 123 Batch   17/44   train_loss = 1.403
Epoch 123 Batch   18/44   train_loss = 1.464
Epoch 123 Batch   19/44   train_loss = 1.352
Epoch 123 Batch   20/44   train_loss = 1.390
Epoch 123 Batch   21/44   train_loss = 1.306
Epoch 123 Batch   22/44   train_loss = 1.424
Epoch 123 Batch   23/44   train_loss = 1.360
Epoch 123 Batch   24/44   train_loss = 1.341
Epoch 123 Batch   25/44   train_loss = 1.390
Epoch 123 Batch   26/44   train_loss = 1.316
Epoch 123 Batch   27/44   train_loss = 1.427
Epoch 123 Batch   28/44   train_loss = 1.373
Epoch 123 Batch   29/44   train_loss = 1.371
Epoch 123 Batch   30/44   train_loss = 1.384
Epoch 123 Batch   31/44   train_loss = 1.439
Epoch 123 Batch   32/44   train_loss = 1.485
Epoch 123 Batch   33/44   train_loss = 1.449
Epoch 123 Batch   34/44   train_loss = 1.373
Epoch 123 Batch   35/44   train_loss = 1.378
Epoch 123 Batch   36/44   train_loss = 1.527
Epoch 123 Batch   37/44   train_loss = 1.426
Epoch 123 Batch   38/44   train_loss = 1.446
Epoch 123 Batch   39/44   train_loss = 1.325
Epoch 123 Batch   40/44   train_loss = 1.371
Epoch 123 Batch   41/44   train_loss = 1.426
Epoch 123 Batch   42/44   train_loss = 1.335
Epoch 123 Batch   43/44   train_loss = 1.302
Epoch 124 Batch    0/44   train_loss = 1.361
Epoch 124 Batch    1/44   train_loss = 1.357
Epoch 124 Batch    2/44   train_loss = 1.388
Epoch 124 Batch    3/44   train_loss = 1.410
Epoch 124 Batch    4/44   train_loss = 1.339
Epoch 124 Batch    5/44   train_loss = 1.379
Epoch 124 Batch    6/44   train_loss = 1.411
Epoch 124 Batch    7/44   train_loss = 1.398
Epoch 124 Batch    8/44   train_loss = 1.413
Epoch 124 Batch    9/44   train_loss = 1.438
Epoch 124 Batch   10/44   train_loss = 1.334
Epoch 124 Batch   11/44   train_loss = 1.377
Epoch 124 Batch   12/44   train_loss = 1.413
Epoch 124 Batch   13/44   train_loss = 1.297
Epoch 124 Batch   14/44   train_loss = 1.343
Epoch 124 Batch   15/44   train_loss = 1.344
Epoch 124 Batch   16/44   train_loss = 1.369
Epoch 124 Batch   17/44   train_loss = 1.387
Epoch 124 Batch   18/44   train_loss = 1.473
Epoch 124 Batch   19/44   train_loss = 1.351
Epoch 124 Batch   20/44   train_loss = 1.377
Epoch 124 Batch   21/44   train_loss = 1.272
Epoch 124 Batch   22/44   train_loss = 1.384
Epoch 124 Batch   23/44   train_loss = 1.329
Epoch 124 Batch   24/44   train_loss = 1.338
Epoch 124 Batch   25/44   train_loss = 1.409
Epoch 124 Batch   26/44   train_loss = 1.330
Epoch 124 Batch   27/44   train_loss = 1.431
Epoch 124 Batch   28/44   train_loss = 1.344
Epoch 124 Batch   29/44   train_loss = 1.330
Epoch 124 Batch   30/44   train_loss = 1.334
Epoch 124 Batch   31/44   train_loss = 1.406
Epoch 124 Batch   32/44   train_loss = 1.468
Epoch 124 Batch   33/44   train_loss = 1.457
Epoch 124 Batch   34/44   train_loss = 1.377
Epoch 124 Batch   35/44   train_loss = 1.376
Epoch 124 Batch   36/44   train_loss = 1.525
Epoch 124 Batch   37/44   train_loss = 1.395
Epoch 124 Batch   38/44   train_loss = 1.417
Epoch 124 Batch   39/44   train_loss = 1.297
Epoch 124 Batch   40/44   train_loss = 1.355
Epoch 124 Batch   41/44   train_loss = 1.416
Epoch 124 Batch   42/44   train_loss = 1.327
Epoch 124 Batch   43/44   train_loss = 1.292
Epoch 125 Batch    0/44   train_loss = 1.339
Epoch 125 Batch    1/44   train_loss = 1.320
Epoch 125 Batch    2/44   train_loss = 1.351
Epoch 125 Batch    3/44   train_loss = 1.372
Epoch 125 Batch    4/44   train_loss = 1.315
Epoch 125 Batch    5/44   train_loss = 1.347
Epoch 125 Batch    6/44   train_loss = 1.372
Epoch 125 Batch    7/44   train_loss = 1.356
Epoch 125 Batch    8/44   train_loss = 1.375
Epoch 125 Batch    9/44   train_loss = 1.403
Epoch 125 Batch   10/44   train_loss = 1.309
Epoch 125 Batch   11/44   train_loss = 1.361
Epoch 125 Batch   12/44   train_loss = 1.408
Epoch 125 Batch   13/44   train_loss = 1.297
Epoch 125 Batch   14/44   train_loss = 1.340
Epoch 125 Batch   15/44   train_loss = 1.325
Epoch 125 Batch   16/44   train_loss = 1.329
Epoch 125 Batch   17/44   train_loss = 1.344
Epoch 125 Batch   18/44   train_loss = 1.424
Epoch 125 Batch   19/44   train_loss = 1.327
Epoch 125 Batch   20/44   train_loss = 1.369
Epoch 125 Batch   21/44   train_loss = 1.259
Epoch 125 Batch   22/44   train_loss = 1.373
Epoch 125 Batch   23/44   train_loss = 1.299
Epoch 125 Batch   24/44   train_loss = 1.290
Epoch 125 Batch   25/44   train_loss = 1.368
Epoch 125 Batch   26/44   train_loss = 1.305
Epoch 125 Batch   27/44   train_loss = 1.428
Epoch 125 Batch   28/44   train_loss = 1.362
Epoch 125 Batch   29/44   train_loss = 1.343
Epoch 125 Batch   30/44   train_loss = 1.318
Epoch 125 Batch   31/44   train_loss = 1.370
Epoch 125 Batch   32/44   train_loss = 1.412
Epoch 125 Batch   33/44   train_loss = 1.415
Epoch 125 Batch   34/44   train_loss = 1.352
Epoch 125 Batch   35/44   train_loss = 1.371
Epoch 125 Batch   36/44   train_loss = 1.540
Epoch 125 Batch   37/44   train_loss = 1.396
Epoch 125 Batch   38/44   train_loss = 1.412
Epoch 125 Batch   39/44   train_loss = 1.287
Epoch 125 Batch   40/44   train_loss = 1.329
Epoch 125 Batch   41/44   train_loss = 1.381
Epoch 125 Batch   42/44   train_loss = 1.300
Epoch 125 Batch   43/44   train_loss = 1.273
Epoch 126 Batch    0/44   train_loss = 1.336
Epoch 126 Batch    1/44   train_loss = 1.319
Epoch 126 Batch    2/44   train_loss = 1.348
Epoch 126 Batch    3/44   train_loss = 1.359
Epoch 126 Batch    4/44   train_loss = 1.288
Epoch 126 Batch    5/44   train_loss = 1.306
Epoch 126 Batch    6/44   train_loss = 1.341
Epoch 126 Batch    7/44   train_loss = 1.326
Epoch 126 Batch    8/44   train_loss = 1.347
Epoch 126 Batch    9/44   train_loss = 1.386
Epoch 126 Batch   10/44   train_loss = 1.289
Epoch 126 Batch   11/44   train_loss = 1.335
Epoch 126 Batch   12/44   train_loss = 1.375
Epoch 126 Batch   13/44   train_loss = 1.265
Epoch 126 Batch   14/44   train_loss = 1.316
Epoch 126 Batch   15/44   train_loss = 1.313
Epoch 126 Batch   16/44   train_loss = 1.317
Epoch 126 Batch   17/44   train_loss = 1.327
Epoch 126 Batch   18/44   train_loss = 1.383
Epoch 126 Batch   19/44   train_loss = 1.281
Epoch 126 Batch   20/44   train_loss = 1.321
Epoch 126 Batch   21/44   train_loss = 1.220
Epoch 126 Batch   22/44   train_loss = 1.337
Epoch 126 Batch   23/44   train_loss = 1.279
Epoch 126 Batch   24/44   train_loss = 1.264
Epoch 126 Batch   25/44   train_loss = 1.340
Epoch 126 Batch   26/44   train_loss = 1.272
Epoch 126 Batch   27/44   train_loss = 1.383
Epoch 126 Batch   28/44   train_loss = 1.321
Epoch 126 Batch   29/44   train_loss = 1.323
Epoch 126 Batch   30/44   train_loss = 1.319
Epoch 126 Batch   31/44   train_loss = 1.382
Epoch 126 Batch   32/44   train_loss = 1.404
Epoch 126 Batch   33/44   train_loss = 1.384
Epoch 126 Batch   34/44   train_loss = 1.313
Epoch 126 Batch   35/44   train_loss = 1.330
Epoch 126 Batch   36/44   train_loss = 1.488
Epoch 126 Batch   37/44   train_loss = 1.370
Epoch 126 Batch   38/44   train_loss = 1.407
Epoch 126 Batch   39/44   train_loss = 1.297
Epoch 126 Batch   40/44   train_loss = 1.340
Epoch 126 Batch   41/44   train_loss = 1.378
Epoch 126 Batch   42/44   train_loss = 1.274
Epoch 126 Batch   43/44   train_loss = 1.238
Epoch 127 Batch    0/44   train_loss = 1.300
Epoch 127 Batch    1/44   train_loss = 1.288
Epoch 127 Batch    2/44   train_loss = 1.338
Epoch 127 Batch    3/44   train_loss = 1.372
Epoch 127 Batch    4/44   train_loss = 1.293
Epoch 127 Batch    5/44   train_loss = 1.301
Epoch 127 Batch    6/44   train_loss = 1.326
Epoch 127 Batch    7/44   train_loss = 1.295
Epoch 127 Batch    8/44   train_loss = 1.299
Epoch 127 Batch    9/44   train_loss = 1.350
Epoch 127 Batch   10/44   train_loss = 1.267
Epoch 127 Batch   11/44   train_loss = 1.324
Epoch 127 Batch   12/44   train_loss = 1.374
Epoch 127 Batch   13/44   train_loss = 1.255
Epoch 127 Batch   14/44   train_loss = 1.297
Epoch 127 Batch   15/44   train_loss = 1.291
Epoch 127 Batch   16/44   train_loss = 1.284
Epoch 127 Batch   17/44   train_loss = 1.291
Epoch 127 Batch   18/44   train_loss = 1.361
Epoch 127 Batch   19/44   train_loss = 1.263
Epoch 127 Batch   20/44   train_loss = 1.301
Epoch 127 Batch   21/44   train_loss = 1.199
Epoch 127 Batch   22/44   train_loss = 1.309
Epoch 127 Batch   23/44   train_loss = 1.245
Epoch 127 Batch   24/44   train_loss = 1.228
Epoch 127 Batch   25/44   train_loss = 1.302
Epoch 127 Batch   26/44   train_loss = 1.245
Epoch 127 Batch   27/44   train_loss = 1.352
Epoch 127 Batch   28/44   train_loss = 1.292
Epoch 127 Batch   29/44   train_loss = 1.292
Epoch 127 Batch   30/44   train_loss = 1.280
Epoch 127 Batch   31/44   train_loss = 1.353
Epoch 127 Batch   32/44   train_loss = 1.393
Epoch 127 Batch   33/44   train_loss = 1.369
Epoch 127 Batch   34/44   train_loss = 1.302
Epoch 127 Batch   35/44   train_loss = 1.317
Epoch 127 Batch   36/44   train_loss = 1.450
Epoch 127 Batch   37/44   train_loss = 1.342
Epoch 127 Batch   38/44   train_loss = 1.377
Epoch 127 Batch   39/44   train_loss = 1.264
Epoch 127 Batch   40/44   train_loss = 1.312
Epoch 127 Batch   41/44   train_loss = 1.365
Epoch 127 Batch   42/44   train_loss = 1.271
Epoch 127 Batch   43/44   train_loss = 1.236
Epoch 128 Batch    0/44   train_loss = 1.282
Epoch 128 Batch    1/44   train_loss = 1.266
Epoch 128 Batch    2/44   train_loss = 1.308
Epoch 128 Batch    3/44   train_loss = 1.344
Epoch 128 Batch    4/44   train_loss = 1.257
Epoch 128 Batch    5/44   train_loss = 1.289
Epoch 128 Batch    6/44   train_loss = 1.318
Epoch 128 Batch    7/44   train_loss = 1.290
Epoch 128 Batch    8/44   train_loss = 1.286
Epoch 128 Batch    9/44   train_loss = 1.330
Epoch 128 Batch   10/44   train_loss = 1.247
Epoch 128 Batch   11/44   train_loss = 1.287
Epoch 128 Batch   12/44   train_loss = 1.348
Epoch 128 Batch   13/44   train_loss = 1.244
Epoch 128 Batch   14/44   train_loss = 1.284
Epoch 128 Batch   15/44   train_loss = 1.296
Epoch 128 Batch   16/44   train_loss = 1.290
Epoch 128 Batch   17/44   train_loss = 1.279
Epoch 128 Batch   18/44   train_loss = 1.336
Epoch 128 Batch   19/44   train_loss = 1.223
Epoch 128 Batch   20/44   train_loss = 1.259
Epoch 128 Batch   21/44   train_loss = 1.174
Epoch 128 Batch   22/44   train_loss = 1.301
Epoch 128 Batch   23/44   train_loss = 1.239
Epoch 128 Batch   24/44   train_loss = 1.232
Epoch 128 Batch   25/44   train_loss = 1.295
Epoch 128 Batch   26/44   train_loss = 1.226
Epoch 128 Batch   27/44   train_loss = 1.319
Epoch 128 Batch   28/44   train_loss = 1.262
Epoch 128 Batch   29/44   train_loss = 1.267
Epoch 128 Batch   30/44   train_loss = 1.266
Epoch 128 Batch   31/44   train_loss = 1.350
Epoch 128 Batch   32/44   train_loss = 1.394
Epoch 128 Batch   33/44   train_loss = 1.365
Epoch 128 Batch   34/44   train_loss = 1.288
Epoch 128 Batch   35/44   train_loss = 1.294
Epoch 128 Batch   36/44   train_loss = 1.424
Epoch 128 Batch   37/44   train_loss = 1.319
Epoch 128 Batch   38/44   train_loss = 1.357
Epoch 128 Batch   39/44   train_loss = 1.244
Epoch 128 Batch   40/44   train_loss = 1.307
Epoch 128 Batch   41/44   train_loss = 1.356
Epoch 128 Batch   42/44   train_loss = 1.262
Epoch 128 Batch   43/44   train_loss = 1.225
Epoch 129 Batch    0/44   train_loss = 1.262
Epoch 129 Batch    1/44   train_loss = 1.256
Epoch 129 Batch    2/44   train_loss = 1.290
Epoch 129 Batch    3/44   train_loss = 1.322
Epoch 129 Batch    4/44   train_loss = 1.238
Epoch 129 Batch    5/44   train_loss = 1.282
Epoch 129 Batch    6/44   train_loss = 1.300
Epoch 129 Batch    7/44   train_loss = 1.269
Epoch 129 Batch    8/44   train_loss = 1.275
Epoch 129 Batch    9/44   train_loss = 1.315
Epoch 129 Batch   10/44   train_loss = 1.237
Epoch 129 Batch   11/44   train_loss = 1.270
Epoch 129 Batch   12/44   train_loss = 1.330
Epoch 129 Batch   13/44   train_loss = 1.221
Epoch 129 Batch   14/44   train_loss = 1.262
Epoch 129 Batch   15/44   train_loss = 1.275
Epoch 129 Batch   16/44   train_loss = 1.271
Epoch 129 Batch   17/44   train_loss = 1.275
Epoch 129 Batch   18/44   train_loss = 1.332
Epoch 129 Batch   19/44   train_loss = 1.211
Epoch 129 Batch   20/44   train_loss = 1.233
Epoch 129 Batch   21/44   train_loss = 1.137
Epoch 129 Batch   22/44   train_loss = 1.264
Epoch 129 Batch   23/44   train_loss = 1.200
Epoch 129 Batch   24/44   train_loss = 1.214
Epoch 129 Batch   25/44   train_loss = 1.297
Epoch 129 Batch   26/44   train_loss = 1.225
Epoch 129 Batch   27/44   train_loss = 1.318
Epoch 129 Batch   28/44   train_loss = 1.240
Epoch 129 Batch   29/44   train_loss = 1.221
Epoch 129 Batch   30/44   train_loss = 1.216
Epoch 129 Batch   31/44   train_loss = 1.288
Epoch 129 Batch   32/44   train_loss = 1.358
Epoch 129 Batch   33/44   train_loss = 1.357
Epoch 129 Batch   34/44   train_loss = 1.301
Epoch 129 Batch   35/44   train_loss = 1.308
Epoch 129 Batch   36/44   train_loss = 1.428
Epoch 129 Batch   37/44   train_loss = 1.302
Epoch 129 Batch   38/44   train_loss = 1.318
Epoch 129 Batch   39/44   train_loss = 1.206
Epoch 129 Batch   40/44   train_loss = 1.277
Epoch 129 Batch   41/44   train_loss = 1.347
Epoch 129 Batch   42/44   train_loss = 1.277
Epoch 129 Batch   43/44   train_loss = 1.248
Epoch 130 Batch    0/44   train_loss = 1.278
Epoch 130 Batch    1/44   train_loss = 1.249
Epoch 130 Batch    2/44   train_loss = 1.265
Epoch 130 Batch    3/44   train_loss = 1.282
Epoch 130 Batch    4/44   train_loss = 1.213
Epoch 130 Batch    5/44   train_loss = 1.280
Epoch 130 Batch    6/44   train_loss = 1.311
Epoch 130 Batch    7/44   train_loss = 1.283
Epoch 130 Batch    8/44   train_loss = 1.290
Epoch 130 Batch    9/44   train_loss = 1.313
Epoch 130 Batch   10/44   train_loss = 1.218
Epoch 130 Batch   11/44   train_loss = 1.247
Epoch 130 Batch   12/44   train_loss = 1.306
Epoch 130 Batch   13/44   train_loss = 1.201
Epoch 130 Batch   14/44   train_loss = 1.255
Epoch 130 Batch   15/44   train_loss = 1.271
Epoch 130 Batch   16/44   train_loss = 1.266
Epoch 130 Batch   17/44   train_loss = 1.272
Epoch 130 Batch   18/44   train_loss = 1.314
Epoch 130 Batch   19/44   train_loss = 1.191
Epoch 130 Batch   20/44   train_loss = 1.213
Epoch 130 Batch   21/44   train_loss = 1.119
Epoch 130 Batch   22/44   train_loss = 1.250
Epoch 130 Batch   23/44   train_loss = 1.170
Epoch 130 Batch   24/44   train_loss = 1.180
Epoch 130 Batch   25/44   train_loss = 1.265
Epoch 130 Batch   26/44   train_loss = 1.196
Epoch 130 Batch   27/44   train_loss = 1.290
Epoch 130 Batch   28/44   train_loss = 1.225
Epoch 130 Batch   29/44   train_loss = 1.208
Epoch 130 Batch   30/44   train_loss = 1.205
Epoch 130 Batch   31/44   train_loss = 1.245
Epoch 130 Batch   32/44   train_loss = 1.304
Epoch 130 Batch   33/44   train_loss = 1.300
Epoch 130 Batch   34/44   train_loss = 1.255
Epoch 130 Batch   35/44   train_loss = 1.280
Epoch 130 Batch   36/44   train_loss = 1.421
Epoch 130 Batch   37/44   train_loss = 1.306
Epoch 130 Batch   38/44   train_loss = 1.326
Epoch 130 Batch   39/44   train_loss = 1.190
Epoch 130 Batch   40/44   train_loss = 1.248
Epoch 130 Batch   41/44   train_loss = 1.282
Epoch 130 Batch   42/44   train_loss = 1.214
Epoch 130 Batch   43/44   train_loss = 1.209
Epoch 131 Batch    0/44   train_loss = 1.270
Epoch 131 Batch    1/44   train_loss = 1.260
Epoch 131 Batch    2/44   train_loss = 1.296
Epoch 131 Batch    3/44   train_loss = 1.296
Epoch 131 Batch    4/44   train_loss = 1.200
Epoch 131 Batch    5/44   train_loss = 1.233
Epoch 131 Batch    6/44   train_loss = 1.258
Epoch 131 Batch    7/44   train_loss = 1.244
Epoch 131 Batch    8/44   train_loss = 1.284
Epoch 131 Batch    9/44   train_loss = 1.332
Epoch 131 Batch   10/44   train_loss = 1.249
Epoch 131 Batch   11/44   train_loss = 1.274
Epoch 131 Batch   12/44   train_loss = 1.315
Epoch 131 Batch   13/44   train_loss = 1.187
Epoch 131 Batch   14/44   train_loss = 1.218
Epoch 131 Batch   15/44   train_loss = 1.236
Epoch 131 Batch   16/44   train_loss = 1.250
Epoch 131 Batch   17/44   train_loss = 1.296
Epoch 131 Batch   18/44   train_loss = 1.363
Epoch 131 Batch   19/44   train_loss = 1.233
Epoch 131 Batch   20/44   train_loss = 1.240
Epoch 131 Batch   21/44   train_loss = 1.116
Epoch 131 Batch   22/44   train_loss = 1.219
Epoch 131 Batch   23/44   train_loss = 1.140
Epoch 131 Batch   24/44   train_loss = 1.160
Epoch 131 Batch   25/44   train_loss = 1.259
Epoch 131 Batch   26/44   train_loss = 1.203
Epoch 131 Batch   27/44   train_loss = 1.294
Epoch 131 Batch   28/44   train_loss = 1.227
Epoch 131 Batch   29/44   train_loss = 1.193
Epoch 131 Batch   30/44   train_loss = 1.184
Epoch 131 Batch   31/44   train_loss = 1.211
Epoch 131 Batch   32/44   train_loss = 1.269
Epoch 131 Batch   33/44   train_loss = 1.267
Epoch 131 Batch   34/44   train_loss = 1.224
Epoch 131 Batch   35/44   train_loss = 1.251
Epoch 131 Batch   36/44   train_loss = 1.387
Epoch 131 Batch   37/44   train_loss = 1.263
Epoch 131 Batch   38/44   train_loss = 1.302
Epoch 131 Batch   39/44   train_loss = 1.183
Epoch 131 Batch   40/44   train_loss = 1.247
Epoch 131 Batch   41/44   train_loss = 1.272
Epoch 131 Batch   42/44   train_loss = 1.192
Epoch 131 Batch   43/44   train_loss = 1.177
Epoch 132 Batch    0/44   train_loss = 1.217
Epoch 132 Batch    1/44   train_loss = 1.206
Epoch 132 Batch    2/44   train_loss = 1.259
Epoch 132 Batch    3/44   train_loss = 1.289
Epoch 132 Batch    4/44   train_loss = 1.207
Epoch 132 Batch    5/44   train_loss = 1.234
Epoch 132 Batch    6/44   train_loss = 1.251
Epoch 132 Batch    7/44   train_loss = 1.206
Epoch 132 Batch    8/44   train_loss = 1.220
Epoch 132 Batch    9/44   train_loss = 1.270
Epoch 132 Batch   10/44   train_loss = 1.206
Epoch 132 Batch   11/44   train_loss = 1.263
Epoch 132 Batch   12/44   train_loss = 1.324
Epoch 132 Batch   13/44   train_loss = 1.221
Epoch 132 Batch   14/44   train_loss = 1.244
Epoch 132 Batch   15/44   train_loss = 1.229
Epoch 132 Batch   16/44   train_loss = 1.212
Epoch 132 Batch   17/44   train_loss = 1.232
Epoch 132 Batch   18/44   train_loss = 1.322
Epoch 132 Batch   19/44   train_loss = 1.233
Epoch 132 Batch   20/44   train_loss = 1.289
Epoch 132 Batch   21/44   train_loss = 1.172
Epoch 132 Batch   22/44   train_loss = 1.255
Epoch 132 Batch   23/44   train_loss = 1.151
Epoch 132 Batch   24/44   train_loss = 1.139
Epoch 132 Batch   25/44   train_loss = 1.211
Epoch 132 Batch   26/44   train_loss = 1.160
Epoch 132 Batch   27/44   train_loss = 1.286
Epoch 132 Batch   28/44   train_loss = 1.249
Epoch 132 Batch   29/44   train_loss = 1.244
Epoch 132 Batch   30/44   train_loss = 1.230
Epoch 132 Batch   31/44   train_loss = 1.248
Epoch 132 Batch   32/44   train_loss = 1.279
Epoch 132 Batch   33/44   train_loss = 1.240
Epoch 132 Batch   34/44   train_loss = 1.193
Epoch 132 Batch   35/44   train_loss = 1.234
Epoch 132 Batch   36/44   train_loss = 1.384
Epoch 132 Batch   37/44   train_loss = 1.268
Epoch 132 Batch   38/44   train_loss = 1.304
Epoch 132 Batch   39/44   train_loss = 1.184
Epoch 132 Batch   40/44   train_loss = 1.237
Epoch 132 Batch   41/44   train_loss = 1.269
Epoch 132 Batch   42/44   train_loss = 1.197
Epoch 132 Batch   43/44   train_loss = 1.176
Epoch 133 Batch    0/44   train_loss = 1.211
Epoch 133 Batch    1/44   train_loss = 1.199
Epoch 133 Batch    2/44   train_loss = 1.236
Epoch 133 Batch    3/44   train_loss = 1.252
Epoch 133 Batch    4/44   train_loss = 1.171
Epoch 133 Batch    5/44   train_loss = 1.212
Epoch 133 Batch    6/44   train_loss = 1.228
Epoch 133 Batch    7/44   train_loss = 1.208
Epoch 133 Batch    8/44   train_loss = 1.216
Epoch 133 Batch    9/44   train_loss = 1.248
Epoch 133 Batch   10/44   train_loss = 1.159
Epoch 133 Batch   11/44   train_loss = 1.198
Epoch 133 Batch   12/44   train_loss = 1.258
Epoch 133 Batch   13/44   train_loss = 1.165
Epoch 133 Batch   14/44   train_loss = 1.210
Epoch 133 Batch   15/44   train_loss = 1.220
Epoch 133 Batch   16/44   train_loss = 1.213
Epoch 133 Batch   17/44   train_loss = 1.219
Epoch 133 Batch   18/44   train_loss = 1.288
Epoch 133 Batch   19/44   train_loss = 1.176
Epoch 133 Batch   20/44   train_loss = 1.229
Epoch 133 Batch   21/44   train_loss = 1.130
Epoch 133 Batch   22/44   train_loss = 1.254
Epoch 133 Batch   23/44   train_loss = 1.179
Epoch 133 Batch   24/44   train_loss = 1.170
Epoch 133 Batch   25/44   train_loss = 1.225
Epoch 133 Batch   26/44   train_loss = 1.142
Epoch 133 Batch   27/44   train_loss = 1.231
Epoch 133 Batch   28/44   train_loss = 1.181
Epoch 133 Batch   29/44   train_loss = 1.195
Epoch 133 Batch   30/44   train_loss = 1.222
Epoch 133 Batch   31/44   train_loss = 1.295
Epoch 133 Batch   32/44   train_loss = 1.359
Epoch 133 Batch   33/44   train_loss = 1.302
Epoch 133 Batch   34/44   train_loss = 1.207
Epoch 133 Batch   35/44   train_loss = 1.213
Epoch 133 Batch   36/44   train_loss = 1.323
Epoch 133 Batch   37/44   train_loss = 1.232
Epoch 133 Batch   38/44   train_loss = 1.290
Epoch 133 Batch   39/44   train_loss = 1.202
Epoch 133 Batch   40/44   train_loss = 1.275
Epoch 133 Batch   41/44   train_loss = 1.320
Epoch 133 Batch   42/44   train_loss = 1.221
Epoch 133 Batch   43/44   train_loss = 1.174
Epoch 134 Batch    0/44   train_loss = 1.207
Epoch 134 Batch    1/44   train_loss = 1.188
Epoch 134 Batch    2/44   train_loss = 1.237
Epoch 134 Batch    3/44   train_loss = 1.260
Epoch 134 Batch    4/44   train_loss = 1.182
Epoch 134 Batch    5/44   train_loss = 1.231
Epoch 134 Batch    6/44   train_loss = 1.223
Epoch 134 Batch    7/44   train_loss = 1.188
Epoch 134 Batch    8/44   train_loss = 1.204
Epoch 134 Batch    9/44   train_loss = 1.236
Epoch 134 Batch   10/44   train_loss = 1.160
Epoch 134 Batch   11/44   train_loss = 1.200
Epoch 134 Batch   12/44   train_loss = 1.255
Epoch 134 Batch   13/44   train_loss = 1.149
Epoch 134 Batch   14/44   train_loss = 1.177
Epoch 134 Batch   15/44   train_loss = 1.178
Epoch 134 Batch   16/44   train_loss = 1.166
Epoch 134 Batch   17/44   train_loss = 1.184
Epoch 134 Batch   18/44   train_loss = 1.267
Epoch 134 Batch   19/44   train_loss = 1.153
Epoch 134 Batch   20/44   train_loss = 1.204
Epoch 134 Batch   21/44   train_loss = 1.092
Epoch 134 Batch   22/44   train_loss = 1.208
Epoch 134 Batch   23/44   train_loss = 1.130
Epoch 134 Batch   24/44   train_loss = 1.136
Epoch 134 Batch   25/44   train_loss = 1.207
Epoch 134 Batch   26/44   train_loss = 1.144
Epoch 134 Batch   27/44   train_loss = 1.219
Epoch 134 Batch   28/44   train_loss = 1.153
Epoch 134 Batch   29/44   train_loss = 1.139
Epoch 134 Batch   30/44   train_loss = 1.135
Epoch 134 Batch   31/44   train_loss = 1.204
Epoch 134 Batch   32/44   train_loss = 1.293
Epoch 134 Batch   33/44   train_loss = 1.306
Epoch 134 Batch   34/44   train_loss = 1.257
Epoch 134 Batch   35/44   train_loss = 1.280
Epoch 134 Batch   36/44   train_loss = 1.365
Epoch 134 Batch   37/44   train_loss = 1.245
Epoch 134 Batch   38/44   train_loss = 1.251
Epoch 134 Batch   39/44   train_loss = 1.145
Epoch 134 Batch   40/44   train_loss = 1.208
Epoch 134 Batch   41/44   train_loss = 1.301
Epoch 134 Batch   42/44   train_loss = 1.236
Epoch 134 Batch   43/44   train_loss = 1.227
Epoch 135 Batch    0/44   train_loss = 1.276
Epoch 135 Batch    1/44   train_loss = 1.224
Epoch 135 Batch    2/44   train_loss = 1.266
Epoch 135 Batch    3/44   train_loss = 1.250
Epoch 135 Batch    4/44   train_loss = 1.178
Epoch 135 Batch    5/44   train_loss = 1.232
Epoch 135 Batch    6/44   train_loss = 1.249
Epoch 135 Batch    7/44   train_loss = 1.217
Epoch 135 Batch    8/44   train_loss = 1.250
Epoch 135 Batch    9/44   train_loss = 1.245
Epoch 135 Batch   10/44   train_loss = 1.162
Epoch 135 Batch   11/44   train_loss = 1.199
Epoch 135 Batch   12/44   train_loss = 1.258
Epoch 135 Batch   13/44   train_loss = 1.163
Epoch 135 Batch   14/44   train_loss = 1.203
Epoch 135 Batch   15/44   train_loss = 1.214
Epoch 135 Batch   16/44   train_loss = 1.183
Epoch 135 Batch   17/44   train_loss = 1.180
Epoch 135 Batch   18/44   train_loss = 1.247
Epoch 135 Batch   19/44   train_loss = 1.132
Epoch 135 Batch   20/44   train_loss = 1.181
Epoch 135 Batch   21/44   train_loss = 1.079
Epoch 135 Batch   22/44   train_loss = 1.185
Epoch 135 Batch   23/44   train_loss = 1.114
Epoch 135 Batch   24/44   train_loss = 1.114
Epoch 135 Batch   25/44   train_loss = 1.181
Epoch 135 Batch   26/44   train_loss = 1.106
Epoch 135 Batch   27/44   train_loss = 1.181
Epoch 135 Batch   28/44   train_loss = 1.129
Epoch 135 Batch   29/44   train_loss = 1.117
Epoch 135 Batch   30/44   train_loss = 1.103
Epoch 135 Batch   31/44   train_loss = 1.151
Epoch 135 Batch   32/44   train_loss = 1.209
Epoch 135 Batch   33/44   train_loss = 1.220
Epoch 135 Batch   34/44   train_loss = 1.185
Epoch 135 Batch   35/44   train_loss = 1.222
Epoch 135 Batch   36/44   train_loss = 1.350
Epoch 135 Batch   37/44   train_loss = 1.247
Epoch 135 Batch   38/44   train_loss = 1.253
Epoch 135 Batch   39/44   train_loss = 1.132
Epoch 135 Batch   40/44   train_loss = 1.174
Epoch 135 Batch   41/44   train_loss = 1.226
Epoch 135 Batch   42/44   train_loss = 1.169
Epoch 135 Batch   43/44   train_loss = 1.179
Epoch 136 Batch    0/44   train_loss = 1.242
Epoch 136 Batch    1/44   train_loss = 1.219
Epoch 136 Batch    2/44   train_loss = 1.297
Epoch 136 Batch    3/44   train_loss = 1.273
Epoch 136 Batch    4/44   train_loss = 1.192
Epoch 136 Batch    5/44   train_loss = 1.200
Epoch 136 Batch    6/44   train_loss = 1.218
Epoch 136 Batch    7/44   train_loss = 1.185
Epoch 136 Batch    8/44   train_loss = 1.224
Epoch 136 Batch    9/44   train_loss = 1.244
Epoch 136 Batch   10/44   train_loss = 1.179
Epoch 136 Batch   11/44   train_loss = 1.212
Epoch 136 Batch   12/44   train_loss = 1.250
Epoch 136 Batch   13/44   train_loss = 1.155
Epoch 136 Batch   14/44   train_loss = 1.195
Epoch 136 Batch   15/44   train_loss = 1.231
Epoch 136 Batch   16/44   train_loss = 1.212
Epoch 136 Batch   17/44   train_loss = 1.218
Epoch 136 Batch   18/44   train_loss = 1.278
Epoch 136 Batch   19/44   train_loss = 1.158
Epoch 136 Batch   20/44   train_loss = 1.191
Epoch 136 Batch   21/44   train_loss = 1.076
Epoch 136 Batch   22/44   train_loss = 1.169
Epoch 136 Batch   23/44   train_loss = 1.109
Epoch 136 Batch   24/44   train_loss = 1.116
Epoch 136 Batch   25/44   train_loss = 1.189
Epoch 136 Batch   26/44   train_loss = 1.112
Epoch 136 Batch   27/44   train_loss = 1.188
Epoch 136 Batch   28/44   train_loss = 1.122
Epoch 136 Batch   29/44   train_loss = 1.108
Epoch 136 Batch   30/44   train_loss = 1.096
Epoch 136 Batch   31/44   train_loss = 1.136
Epoch 136 Batch   32/44   train_loss = 1.194
Epoch 136 Batch   33/44   train_loss = 1.192
Epoch 136 Batch   34/44   train_loss = 1.146
Epoch 136 Batch   35/44   train_loss = 1.167
Epoch 136 Batch   36/44   train_loss = 1.299
Epoch 136 Batch   37/44   train_loss = 1.199
Epoch 136 Batch   38/44   train_loss = 1.223
Epoch 136 Batch   39/44   train_loss = 1.115
Epoch 136 Batch   40/44   train_loss = 1.160
Epoch 136 Batch   41/44   train_loss = 1.190
Epoch 136 Batch   42/44   train_loss = 1.125
Epoch 136 Batch   43/44   train_loss = 1.119
Epoch 137 Batch    0/44   train_loss = 1.169
Epoch 137 Batch    1/44   train_loss = 1.156
Epoch 137 Batch    2/44   train_loss = 1.239
Epoch 137 Batch    3/44   train_loss = 1.228
Epoch 137 Batch    4/44   train_loss = 1.164
Epoch 137 Batch    5/44   train_loss = 1.184
Epoch 137 Batch    6/44   train_loss = 1.201
Epoch 137 Batch    7/44   train_loss = 1.162
Epoch 137 Batch    8/44   train_loss = 1.167
Epoch 137 Batch    9/44   train_loss = 1.206
Epoch 137 Batch   10/44   train_loss = 1.139
Epoch 137 Batch   11/44   train_loss = 1.186
Epoch 137 Batch   12/44   train_loss = 1.238
Epoch 137 Batch   13/44   train_loss = 1.155
Epoch 137 Batch   14/44   train_loss = 1.195
Epoch 137 Batch   15/44   train_loss = 1.212
Epoch 137 Batch   16/44   train_loss = 1.190
Epoch 137 Batch   17/44   train_loss = 1.191
Epoch 137 Batch   18/44   train_loss = 1.267
Epoch 137 Batch   19/44   train_loss = 1.165
Epoch 137 Batch   20/44   train_loss = 1.214
Epoch 137 Batch   21/44   train_loss = 1.112
Epoch 137 Batch   22/44   train_loss = 1.189
Epoch 137 Batch   23/44   train_loss = 1.118
Epoch 137 Batch   24/44   train_loss = 1.119
Epoch 137 Batch   25/44   train_loss = 1.184
Epoch 137 Batch   26/44   train_loss = 1.114
Epoch 137 Batch   27/44   train_loss = 1.198
Epoch 137 Batch   28/44   train_loss = 1.137
Epoch 137 Batch   29/44   train_loss = 1.138
Epoch 137 Batch   30/44   train_loss = 1.102
Epoch 137 Batch   31/44   train_loss = 1.149
Epoch 137 Batch   32/44   train_loss = 1.188
Epoch 137 Batch   33/44   train_loss = 1.180
Epoch 137 Batch   34/44   train_loss = 1.139
Epoch 137 Batch   35/44   train_loss = 1.156
Epoch 137 Batch   36/44   train_loss = 1.280
Epoch 137 Batch   37/44   train_loss = 1.176
Epoch 137 Batch   38/44   train_loss = 1.201
Epoch 137 Batch   39/44   train_loss = 1.095
Epoch 137 Batch   40/44   train_loss = 1.139
Epoch 137 Batch   41/44   train_loss = 1.193
Epoch 137 Batch   42/44   train_loss = 1.116
Epoch 137 Batch   43/44   train_loss = 1.103
Epoch 138 Batch    0/44   train_loss = 1.145
Epoch 138 Batch    1/44   train_loss = 1.122
Epoch 138 Batch    2/44   train_loss = 1.193
Epoch 138 Batch    3/44   train_loss = 1.189
Epoch 138 Batch    4/44   train_loss = 1.121
Epoch 138 Batch    5/44   train_loss = 1.154
Epoch 138 Batch    6/44   train_loss = 1.171
Epoch 138 Batch    7/44   train_loss = 1.140
Epoch 138 Batch    8/44   train_loss = 1.147
Epoch 138 Batch    9/44   train_loss = 1.181
Epoch 138 Batch   10/44   train_loss = 1.091
Epoch 138 Batch   11/44   train_loss = 1.144
Epoch 138 Batch   12/44   train_loss = 1.195
Epoch 138 Batch   13/44   train_loss = 1.117
Epoch 138 Batch   14/44   train_loss = 1.174
Epoch 138 Batch   15/44   train_loss = 1.177
Epoch 138 Batch   16/44   train_loss = 1.176
Epoch 138 Batch   17/44   train_loss = 1.160
Epoch 138 Batch   18/44   train_loss = 1.222
Epoch 138 Batch   19/44   train_loss = 1.131
Epoch 138 Batch   20/44   train_loss = 1.172
Epoch 138 Batch   21/44   train_loss = 1.087
Epoch 138 Batch   22/44   train_loss = 1.186
Epoch 138 Batch   23/44   train_loss = 1.118
Epoch 138 Batch   24/44   train_loss = 1.118
Epoch 138 Batch   25/44   train_loss = 1.176
Epoch 138 Batch   26/44   train_loss = 1.102
Epoch 138 Batch   27/44   train_loss = 1.183
Epoch 138 Batch   28/44   train_loss = 1.132
Epoch 138 Batch   29/44   train_loss = 1.149
Epoch 138 Batch   30/44   train_loss = 1.118
Epoch 138 Batch   31/44   train_loss = 1.174
Epoch 138 Batch   32/44   train_loss = 1.220
Epoch 138 Batch   33/44   train_loss = 1.198
Epoch 138 Batch   34/44   train_loss = 1.138
Epoch 138 Batch   35/44   train_loss = 1.154
Epoch 138 Batch   36/44   train_loss = 1.279
Epoch 138 Batch   37/44   train_loss = 1.178
Epoch 138 Batch   38/44   train_loss = 1.213
Epoch 138 Batch   39/44   train_loss = 1.116
Epoch 138 Batch   40/44   train_loss = 1.147
Epoch 138 Batch   41/44   train_loss = 1.201
Epoch 138 Batch   42/44   train_loss = 1.114
Epoch 138 Batch   43/44   train_loss = 1.108
Epoch 139 Batch    0/44   train_loss = 1.146
Epoch 139 Batch    1/44   train_loss = 1.105
Epoch 139 Batch    2/44   train_loss = 1.190
Epoch 139 Batch    3/44   train_loss = 1.191
Epoch 139 Batch    4/44   train_loss = 1.109
Epoch 139 Batch    5/44   train_loss = 1.136
Epoch 139 Batch    6/44   train_loss = 1.145
Epoch 139 Batch    7/44   train_loss = 1.117
Epoch 139 Batch    8/44   train_loss = 1.135
Epoch 139 Batch    9/44   train_loss = 1.175
Epoch 139 Batch   10/44   train_loss = 1.088
Epoch 139 Batch   11/44   train_loss = 1.140
Epoch 139 Batch   12/44   train_loss = 1.186
Epoch 139 Batch   13/44   train_loss = 1.092
Epoch 139 Batch   14/44   train_loss = 1.146
Epoch 139 Batch   15/44   train_loss = 1.137
Epoch 139 Batch   16/44   train_loss = 1.140
Epoch 139 Batch   17/44   train_loss = 1.142
Epoch 139 Batch   18/44   train_loss = 1.202
Epoch 139 Batch   19/44   train_loss = 1.114
Epoch 139 Batch   20/44   train_loss = 1.139
Epoch 139 Batch   21/44   train_loss = 1.052
Epoch 139 Batch   22/44   train_loss = 1.149
Epoch 139 Batch   23/44   train_loss = 1.071
Epoch 139 Batch   24/44   train_loss = 1.069
Epoch 139 Batch   25/44   train_loss = 1.149
Epoch 139 Batch   26/44   train_loss = 1.082
Epoch 139 Batch   27/44   train_loss = 1.165
Epoch 139 Batch   28/44   train_loss = 1.105
Epoch 139 Batch   29/44   train_loss = 1.110
Epoch 139 Batch   30/44   train_loss = 1.075
Epoch 139 Batch   31/44   train_loss = 1.128
Epoch 139 Batch   32/44   train_loss = 1.195
Epoch 139 Batch   33/44   train_loss = 1.199
Epoch 139 Batch   34/44   train_loss = 1.138
Epoch 139 Batch   35/44   train_loss = 1.163
Epoch 139 Batch   36/44   train_loss = 1.272
Epoch 139 Batch   37/44   train_loss = 1.152
Epoch 139 Batch   38/44   train_loss = 1.176
Epoch 139 Batch   39/44   train_loss = 1.085
Epoch 139 Batch   40/44   train_loss = 1.138
Epoch 139 Batch   41/44   train_loss = 1.199
Epoch 139 Batch   42/44   train_loss = 1.124
Epoch 139 Batch   43/44   train_loss = 1.130
Epoch 140 Batch    0/44   train_loss = 1.157
Epoch 140 Batch    1/44   train_loss = 1.109
Epoch 140 Batch    2/44   train_loss = 1.173
Epoch 140 Batch    3/44   train_loss = 1.188
Epoch 140 Batch    4/44   train_loss = 1.108
Epoch 140 Batch    5/44   train_loss = 1.147
Epoch 140 Batch    6/44   train_loss = 1.163
Epoch 140 Batch    7/44   train_loss = 1.122
Epoch 140 Batch    8/44   train_loss = 1.136
Epoch 140 Batch    9/44   train_loss = 1.169
Epoch 140 Batch   10/44   train_loss = 1.078
Epoch 140 Batch   11/44   train_loss = 1.124
Epoch 140 Batch   12/44   train_loss = 1.172
Epoch 140 Batch   13/44   train_loss = 1.083
Epoch 140 Batch   14/44   train_loss = 1.137
Epoch 140 Batch   15/44   train_loss = 1.130
Epoch 140 Batch   16/44   train_loss = 1.131
Epoch 140 Batch   17/44   train_loss = 1.129
Epoch 140 Batch   18/44   train_loss = 1.186
Epoch 140 Batch   19/44   train_loss = 1.096
Epoch 140 Batch   20/44   train_loss = 1.141
Epoch 140 Batch   21/44   train_loss = 1.060
Epoch 140 Batch   22/44   train_loss = 1.167
Epoch 140 Batch   23/44   train_loss = 1.074
Epoch 140 Batch   24/44   train_loss = 1.048
Epoch 140 Batch   25/44   train_loss = 1.109
Epoch 140 Batch   26/44   train_loss = 1.047
Epoch 140 Batch   27/44   train_loss = 1.128
Epoch 140 Batch   28/44   train_loss = 1.079
Epoch 140 Batch   29/44   train_loss = 1.096
Epoch 140 Batch   30/44   train_loss = 1.068
Epoch 140 Batch   31/44   train_loss = 1.099
Epoch 140 Batch   32/44   train_loss = 1.157
Epoch 140 Batch   33/44   train_loss = 1.138
Epoch 140 Batch   34/44   train_loss = 1.087
Epoch 140 Batch   35/44   train_loss = 1.126
Epoch 140 Batch   36/44   train_loss = 1.265
Epoch 140 Batch   37/44   train_loss = 1.150
Epoch 140 Batch   38/44   train_loss = 1.170
Epoch 140 Batch   39/44   train_loss = 1.059
Epoch 140 Batch   40/44   train_loss = 1.090
Epoch 140 Batch   41/44   train_loss = 1.143
Epoch 140 Batch   42/44   train_loss = 1.072
Epoch 140 Batch   43/44   train_loss = 1.105
Epoch 141 Batch    0/44   train_loss = 1.154
Epoch 141 Batch    1/44   train_loss = 1.126
Epoch 141 Batch    2/44   train_loss = 1.166
Epoch 141 Batch    3/44   train_loss = 1.172
Epoch 141 Batch    4/44   train_loss = 1.081
Epoch 141 Batch    5/44   train_loss = 1.120
Epoch 141 Batch    6/44   train_loss = 1.133
Epoch 141 Batch    7/44   train_loss = 1.095
Epoch 141 Batch    8/44   train_loss = 1.120
Epoch 141 Batch    9/44   train_loss = 1.167
Epoch 141 Batch   10/44   train_loss = 1.081
Epoch 141 Batch   11/44   train_loss = 1.125
Epoch 141 Batch   12/44   train_loss = 1.166
Epoch 141 Batch   13/44   train_loss = 1.082
Epoch 141 Batch   14/44   train_loss = 1.122
Epoch 141 Batch   15/44   train_loss = 1.111
Epoch 141 Batch   16/44   train_loss = 1.105
Epoch 141 Batch   17/44   train_loss = 1.110
Epoch 141 Batch   18/44   train_loss = 1.185
Epoch 141 Batch   19/44   train_loss = 1.094
Epoch 141 Batch   20/44   train_loss = 1.136
Epoch 141 Batch   21/44   train_loss = 1.052
Epoch 141 Batch   22/44   train_loss = 1.165
Epoch 141 Batch   23/44   train_loss = 1.091
Epoch 141 Batch   24/44   train_loss = 1.067
Epoch 141 Batch   25/44   train_loss = 1.124
Epoch 141 Batch   26/44   train_loss = 1.047
Epoch 141 Batch   27/44   train_loss = 1.112
Epoch 141 Batch   28/44   train_loss = 1.046
Epoch 141 Batch   29/44   train_loss = 1.066
Epoch 141 Batch   30/44   train_loss = 1.032
Epoch 141 Batch   31/44   train_loss = 1.079
Epoch 141 Batch   32/44   train_loss = 1.138
Epoch 141 Batch   33/44   train_loss = 1.115
Epoch 141 Batch   34/44   train_loss = 1.067
Epoch 141 Batch   35/44   train_loss = 1.093
Epoch 141 Batch   36/44   train_loss = 1.230
Epoch 141 Batch   37/44   train_loss = 1.114
Epoch 141 Batch   38/44   train_loss = 1.142
Epoch 141 Batch   39/44   train_loss = 1.040
Epoch 141 Batch   40/44   train_loss = 1.066
Epoch 141 Batch   41/44   train_loss = 1.111
Epoch 141 Batch   42/44   train_loss = 1.028
Epoch 141 Batch   43/44   train_loss = 1.042
Epoch 142 Batch    0/44   train_loss = 1.085
Epoch 142 Batch    1/44   train_loss = 1.065
Epoch 142 Batch    2/44   train_loss = 1.124
Epoch 142 Batch    3/44   train_loss = 1.143
Epoch 142 Batch    4/44   train_loss = 1.072
Epoch 142 Batch    5/44   train_loss = 1.118
Epoch 142 Batch    6/44   train_loss = 1.113
Epoch 142 Batch    7/44   train_loss = 1.069
Epoch 142 Batch    8/44   train_loss = 1.071
Epoch 142 Batch    9/44   train_loss = 1.111
Epoch 142 Batch   10/44   train_loss = 1.029
Epoch 142 Batch   11/44   train_loss = 1.085
Epoch 142 Batch   12/44   train_loss = 1.130
Epoch 142 Batch   13/44   train_loss = 1.067
Epoch 142 Batch   14/44   train_loss = 1.115
Epoch 142 Batch   15/44   train_loss = 1.099
Epoch 142 Batch   16/44   train_loss = 1.083
Epoch 142 Batch   17/44   train_loss = 1.085
Epoch 142 Batch   18/44   train_loss = 1.149
Epoch 142 Batch   19/44   train_loss = 1.052
Epoch 142 Batch   20/44   train_loss = 1.096
Epoch 142 Batch   21/44   train_loss = 1.025
Epoch 142 Batch   22/44   train_loss = 1.151
Epoch 142 Batch   23/44   train_loss = 1.082
Epoch 142 Batch   24/44   train_loss = 1.071
Epoch 142 Batch   25/44   train_loss = 1.135
Epoch 142 Batch   26/44   train_loss = 1.062
Epoch 142 Batch   27/44   train_loss = 1.135
Epoch 142 Batch   28/44   train_loss = 1.058
Epoch 142 Batch   29/44   train_loss = 1.084
Epoch 142 Batch   30/44   train_loss = 1.045
Epoch 142 Batch   31/44   train_loss = 1.071
Epoch 142 Batch   32/44   train_loss = 1.108
Epoch 142 Batch   33/44   train_loss = 1.089
Epoch 142 Batch   34/44   train_loss = 1.047
Epoch 142 Batch   35/44   train_loss = 1.077
Epoch 142 Batch   36/44   train_loss = 1.218
Epoch 142 Batch   37/44   train_loss = 1.108
Epoch 142 Batch   38/44   train_loss = 1.145
Epoch 142 Batch   39/44   train_loss = 1.054
Epoch 142 Batch   40/44   train_loss = 1.063
Epoch 142 Batch   41/44   train_loss = 1.117
Epoch 142 Batch   42/44   train_loss = 1.021
Epoch 142 Batch   43/44   train_loss = 1.020
Epoch 143 Batch    0/44   train_loss = 1.056
Epoch 143 Batch    1/44   train_loss = 1.022
Epoch 143 Batch    2/44   train_loss = 1.079
Epoch 143 Batch    3/44   train_loss = 1.099
Epoch 143 Batch    4/44   train_loss = 1.047
Epoch 143 Batch    5/44   train_loss = 1.101
Epoch 143 Batch    6/44   train_loss = 1.123
Epoch 143 Batch    7/44   train_loss = 1.070
Epoch 143 Batch    8/44   train_loss = 1.065
Epoch 143 Batch    9/44   train_loss = 1.089
Epoch 143 Batch   10/44   train_loss = 0.996
Epoch 143 Batch   11/44   train_loss = 1.035
Epoch 143 Batch   12/44   train_loss = 1.075
Epoch 143 Batch   13/44   train_loss = 1.013
Epoch 143 Batch   14/44   train_loss = 1.059
Epoch 143 Batch   15/44   train_loss = 1.062
Epoch 143 Batch   16/44   train_loss = 1.057
Epoch 143 Batch   17/44   train_loss = 1.070
Epoch 143 Batch   18/44   train_loss = 1.127
Epoch 143 Batch   19/44   train_loss = 1.026
Epoch 143 Batch   20/44   train_loss = 1.052
Epoch 143 Batch   21/44   train_loss = 0.978
Epoch 143 Batch   22/44   train_loss = 1.091
Epoch 143 Batch   23/44   train_loss = 1.026
Epoch 143 Batch   24/44   train_loss = 1.028
Epoch 143 Batch   25/44   train_loss = 1.108
Epoch 143 Batch   26/44   train_loss = 1.055
Epoch 143 Batch   27/44   train_loss = 1.120
Epoch 143 Batch   28/44   train_loss = 1.049
Epoch 143 Batch   29/44   train_loss = 1.096
Epoch 143 Batch   30/44   train_loss = 1.064
Epoch 143 Batch   31/44   train_loss = 1.100
Epoch 143 Batch   32/44   train_loss = 1.141
Epoch 143 Batch   33/44   train_loss = 1.106
Epoch 143 Batch   34/44   train_loss = 1.047
Epoch 143 Batch   35/44   train_loss = 1.052
Epoch 143 Batch   36/44   train_loss = 1.180
Epoch 143 Batch   37/44   train_loss = 1.083
Epoch 143 Batch   38/44   train_loss = 1.130
Epoch 143 Batch   39/44   train_loss = 1.065
Epoch 143 Batch   40/44   train_loss = 1.097
Epoch 143 Batch   41/44   train_loss = 1.156
Epoch 143 Batch   42/44   train_loss = 1.050
Epoch 143 Batch   43/44   train_loss = 1.035
Epoch 144 Batch    0/44   train_loss = 1.062
Epoch 144 Batch    1/44   train_loss = 1.017
Epoch 144 Batch    2/44   train_loss = 1.066
Epoch 144 Batch    3/44   train_loss = 1.086
Epoch 144 Batch    4/44   train_loss = 1.034
Epoch 144 Batch    5/44   train_loss = 1.084
Epoch 144 Batch    6/44   train_loss = 1.120
Epoch 144 Batch    7/44   train_loss = 1.085
Epoch 144 Batch    8/44   train_loss = 1.081
Epoch 144 Batch    9/44   train_loss = 1.098
Epoch 144 Batch   10/44   train_loss = 1.009
Epoch 144 Batch   11/44   train_loss = 1.037
Epoch 144 Batch   12/44   train_loss = 1.066
Epoch 144 Batch   13/44   train_loss = 0.995
Epoch 144 Batch   14/44   train_loss = 1.033
Epoch 144 Batch   15/44   train_loss = 1.036
Epoch 144 Batch   16/44   train_loss = 1.026
Epoch 144 Batch   17/44   train_loss = 1.035
Epoch 144 Batch   18/44   train_loss = 1.104
Epoch 144 Batch   19/44   train_loss = 1.017
Epoch 144 Batch   20/44   train_loss = 1.036
Epoch 144 Batch   21/44   train_loss = 0.959
Epoch 144 Batch   22/44   train_loss = 1.065
Epoch 144 Batch   23/44   train_loss = 0.984
Epoch 144 Batch   24/44   train_loss = 0.977
Epoch 144 Batch   25/44   train_loss = 1.051
Epoch 144 Batch   26/44   train_loss = 1.007
Epoch 144 Batch   27/44   train_loss = 1.090
Epoch 144 Batch   28/44   train_loss = 1.023
Epoch 144 Batch   29/44   train_loss = 1.060
Epoch 144 Batch   30/44   train_loss = 1.026
Epoch 144 Batch   31/44   train_loss = 1.056
Epoch 144 Batch   32/44   train_loss = 1.104
Epoch 144 Batch   33/44   train_loss = 1.103
Epoch 144 Batch   34/44   train_loss = 1.067
Epoch 144 Batch   35/44   train_loss = 1.066
Epoch 144 Batch   36/44   train_loss = 1.198
Epoch 144 Batch   37/44   train_loss = 1.079
Epoch 144 Batch   38/44   train_loss = 1.100
Epoch 144 Batch   39/44   train_loss = 1.002
Epoch 144 Batch   40/44   train_loss = 1.053
Epoch 144 Batch   41/44   train_loss = 1.120
Epoch 144 Batch   42/44   train_loss = 1.054
Epoch 144 Batch   43/44   train_loss = 1.078
Epoch 145 Batch    0/44   train_loss = 1.120
Epoch 145 Batch    1/44   train_loss = 1.084
Epoch 145 Batch    2/44   train_loss = 1.117
Epoch 145 Batch    3/44   train_loss = 1.105
Epoch 145 Batch    4/44   train_loss = 1.024
Epoch 145 Batch    5/44   train_loss = 1.064
Epoch 145 Batch    6/44   train_loss = 1.117
Epoch 145 Batch    7/44   train_loss = 1.101
Epoch 145 Batch    8/44   train_loss = 1.119
Epoch 145 Batch    9/44   train_loss = 1.143
Epoch 145 Batch   10/44   train_loss = 1.056
Epoch 145 Batch   11/44   train_loss = 1.060
Epoch 145 Batch   12/44   train_loss = 1.078
Epoch 145 Batch   13/44   train_loss = 1.004
Epoch 145 Batch   14/44   train_loss = 1.032
Epoch 145 Batch   15/44   train_loss = 1.035
Epoch 145 Batch   16/44   train_loss = 1.029
Epoch 145 Batch   17/44   train_loss = 1.039
Epoch 145 Batch   18/44   train_loss = 1.108
Epoch 145 Batch   19/44   train_loss = 1.031
Epoch 145 Batch   20/44   train_loss = 1.032
Epoch 145 Batch   21/44   train_loss = 0.957
Epoch 145 Batch   22/44   train_loss = 1.068
Epoch 145 Batch   23/44   train_loss = 0.972
Epoch 145 Batch   24/44   train_loss = 0.954
Epoch 145 Batch   25/44   train_loss = 1.019
Epoch 145 Batch   26/44   train_loss = 0.966
Epoch 145 Batch   27/44   train_loss = 1.059
Epoch 145 Batch   28/44   train_loss = 0.997
Epoch 145 Batch   29/44   train_loss = 1.032
Epoch 145 Batch   30/44   train_loss = 0.997
Epoch 145 Batch   31/44   train_loss = 1.022
Epoch 145 Batch   32/44   train_loss = 1.064
Epoch 145 Batch   33/44   train_loss = 1.055
Epoch 145 Batch   34/44   train_loss = 1.018
Epoch 145 Batch   35/44   train_loss = 1.016
Epoch 145 Batch   36/44   train_loss = 1.170
Epoch 145 Batch   37/44   train_loss = 1.074
Epoch 145 Batch   38/44   train_loss = 1.113
Epoch 145 Batch   39/44   train_loss = 1.007
Epoch 145 Batch   40/44   train_loss = 1.054
Epoch 145 Batch   41/44   train_loss = 1.086
Epoch 145 Batch   42/44   train_loss = 1.006
Epoch 145 Batch   43/44   train_loss = 1.019
Epoch 146 Batch    0/44   train_loss = 1.087
Epoch 146 Batch    1/44   train_loss = 1.073
Epoch 146 Batch    2/44   train_loss = 1.130
Epoch 146 Batch    3/44   train_loss = 1.130
Epoch 146 Batch    4/44   train_loss = 1.041
Epoch 146 Batch    5/44   train_loss = 1.062
Epoch 146 Batch    6/44   train_loss = 1.098
Epoch 146 Batch    7/44   train_loss = 1.088
Epoch 146 Batch    8/44   train_loss = 1.122
Epoch 146 Batch    9/44   train_loss = 1.168
Epoch 146 Batch   10/44   train_loss = 1.109
Epoch 146 Batch   11/44   train_loss = 1.146
Epoch 146 Batch   12/44   train_loss = 1.163
Epoch 146 Batch   13/44   train_loss = 1.046
Epoch 146 Batch   14/44   train_loss = 1.056
Epoch 146 Batch   15/44   train_loss = 1.037
Epoch 146 Batch   16/44   train_loss = 1.015
Epoch 146 Batch   17/44   train_loss = 1.032
Epoch 146 Batch   18/44   train_loss = 1.123
Epoch 146 Batch   19/44   train_loss = 1.068
Epoch 146 Batch   20/44   train_loss = 1.066
Epoch 146 Batch   21/44   train_loss = 0.993
Epoch 146 Batch   22/44   train_loss = 1.112
Epoch 146 Batch   23/44   train_loss = 0.995
Epoch 146 Batch   24/44   train_loss = 0.962
Epoch 146 Batch   25/44   train_loss = 1.018
Epoch 146 Batch   26/44   train_loss = 0.963
Epoch 146 Batch   27/44   train_loss = 1.050
Epoch 146 Batch   28/44   train_loss = 0.993
Epoch 146 Batch   29/44   train_loss = 1.026
Epoch 146 Batch   30/44   train_loss = 1.003
Epoch 146 Batch   31/44   train_loss = 1.041
Epoch 146 Batch   32/44   train_loss = 1.096
Epoch 146 Batch   33/44   train_loss = 1.055
Epoch 146 Batch   34/44   train_loss = 1.009
Epoch 146 Batch   35/44   train_loss = 0.982
Epoch 146 Batch   36/44   train_loss = 1.111
Epoch 146 Batch   37/44   train_loss = 1.016
Epoch 146 Batch   38/44   train_loss = 1.067
Epoch 146 Batch   39/44   train_loss = 0.976
Epoch 146 Batch   40/44   train_loss = 1.049
Epoch 146 Batch   41/44   train_loss = 1.095
Epoch 146 Batch   42/44   train_loss = 1.023
Epoch 146 Batch   43/44   train_loss = 1.020
Epoch 147 Batch    0/44   train_loss = 1.067
Epoch 147 Batch    1/44   train_loss = 1.036
Epoch 147 Batch    2/44   train_loss = 1.082
Epoch 147 Batch    3/44   train_loss = 1.095
Epoch 147 Batch    4/44   train_loss = 1.002
Epoch 147 Batch    5/44   train_loss = 1.038
Epoch 147 Batch    6/44   train_loss = 1.069
Epoch 147 Batch    7/44   train_loss = 1.047
Epoch 147 Batch    8/44   train_loss = 1.072
Epoch 147 Batch    9/44   train_loss = 1.129
Epoch 147 Batch   10/44   train_loss = 1.063
Epoch 147 Batch   11/44   train_loss = 1.135
Epoch 147 Batch   12/44   train_loss = 1.196
Epoch 147 Batch   13/44   train_loss = 1.091
Epoch 147 Batch   14/44   train_loss = 1.128
Epoch 147 Batch   15/44   train_loss = 1.089
Epoch 147 Batch   16/44   train_loss = 1.046
Epoch 147 Batch   17/44   train_loss = 1.023
Epoch 147 Batch   18/44   train_loss = 1.084
Epoch 147 Batch   19/44   train_loss = 1.039
Epoch 147 Batch   20/44   train_loss = 1.063
Epoch 147 Batch   21/44   train_loss = 1.027
Epoch 147 Batch   22/44   train_loss = 1.192
Epoch 147 Batch   23/44   train_loss = 1.072
Epoch 147 Batch   24/44   train_loss = 1.019
Epoch 147 Batch   25/44   train_loss = 1.073
Epoch 147 Batch   26/44   train_loss = 1.002
Epoch 147 Batch   27/44   train_loss = 1.059
Epoch 147 Batch   28/44   train_loss = 1.000
Epoch 147 Batch   29/44   train_loss = 1.029
Epoch 147 Batch   30/44   train_loss = 1.019
Epoch 147 Batch   31/44   train_loss = 1.080
Epoch 147 Batch   32/44   train_loss = 1.142
Epoch 147 Batch   33/44   train_loss = 1.113
Epoch 147 Batch   34/44   train_loss = 1.070
Epoch 147 Batch   35/44   train_loss = 1.032
Epoch 147 Batch   36/44   train_loss = 1.123
Epoch 147 Batch   37/44   train_loss = 1.001
Epoch 147 Batch   38/44   train_loss = 1.026
Epoch 147 Batch   39/44   train_loss = 0.930
Epoch 147 Batch   40/44   train_loss = 0.984
Epoch 147 Batch   41/44   train_loss = 1.045
Epoch 147 Batch   42/44   train_loss = 1.014
Epoch 147 Batch   43/44   train_loss = 1.038
Epoch 148 Batch    0/44   train_loss = 1.101
Epoch 148 Batch    1/44   train_loss = 1.066
Epoch 148 Batch    2/44   train_loss = 1.105
Epoch 148 Batch    3/44   train_loss = 1.100
Epoch 148 Batch    4/44   train_loss = 0.985
Epoch 148 Batch    5/44   train_loss = 1.007
Epoch 148 Batch    6/44   train_loss = 1.021
Epoch 148 Batch    7/44   train_loss = 0.995
Epoch 148 Batch    8/44   train_loss = 1.015
Epoch 148 Batch    9/44   train_loss = 1.084
Epoch 148 Batch   10/44   train_loss = 1.023
Epoch 148 Batch   11/44   train_loss = 1.099
Epoch 148 Batch   12/44   train_loss = 1.158
Epoch 148 Batch   13/44   train_loss = 1.081
Epoch 148 Batch   14/44   train_loss = 1.125
Epoch 148 Batch   15/44   train_loss = 1.099
Epoch 148 Batch   16/44   train_loss = 1.074
Epoch 148 Batch   17/44   train_loss = 1.043
Epoch 148 Batch   18/44   train_loss = 1.064
Epoch 148 Batch   19/44   train_loss = 0.995
Epoch 148 Batch   20/44   train_loss = 1.003
Epoch 148 Batch   21/44   train_loss = 0.971
Epoch 148 Batch   22/44   train_loss = 1.163
Epoch 148 Batch   23/44   train_loss = 1.098
Epoch 148 Batch   24/44   train_loss = 1.094
Epoch 148 Batch   25/44   train_loss = 1.159
Epoch 148 Batch   26/44   train_loss = 1.067
Epoch 148 Batch   27/44   train_loss = 1.076
Epoch 148 Batch   28/44   train_loss = 0.993
Epoch 148 Batch   29/44   train_loss = 1.001
Epoch 148 Batch   30/44   train_loss = 0.986
Epoch 148 Batch   31/44   train_loss = 1.054
Epoch 148 Batch   32/44   train_loss = 1.126
Epoch 148 Batch   33/44   train_loss = 1.116
Epoch 148 Batch   34/44   train_loss = 1.090
Epoch 148 Batch   35/44   train_loss = 1.098
Epoch 148 Batch   36/44   train_loss = 1.208
Epoch 148 Batch   37/44   train_loss = 1.087
Epoch 148 Batch   38/44   train_loss = 1.089
Epoch 148 Batch   39/44   train_loss = 0.961
Epoch 148 Batch   40/44   train_loss = 0.969
Epoch 148 Batch   41/44   train_loss = 0.989
Epoch 148 Batch   42/44   train_loss = 0.934
Epoch 148 Batch   43/44   train_loss = 0.960
Epoch 149 Batch    0/44   train_loss = 1.056
Epoch 149 Batch    1/44   train_loss = 1.069
Epoch 149 Batch    2/44   train_loss = 1.141
Epoch 149 Batch    3/44   train_loss = 1.165
Epoch 149 Batch    4/44   train_loss = 1.081
Epoch 149 Batch    5/44   train_loss = 1.081
Epoch 149 Batch    6/44   train_loss = 1.055
Epoch 149 Batch    7/44   train_loss = 0.992
Epoch 149 Batch    8/44   train_loss = 0.973
Epoch 149 Batch    9/44   train_loss = 1.011
Epoch 149 Batch   10/44   train_loss = 0.943
Epoch 149 Batch   11/44   train_loss = 1.008
Epoch 149 Batch   12/44   train_loss = 1.095
Epoch 149 Batch   13/44   train_loss = 1.035
Epoch 149 Batch   14/44   train_loss = 1.099
Epoch 149 Batch   15/44   train_loss = 1.107
Epoch 149 Batch   16/44   train_loss = 1.101
Epoch 149 Batch   17/44   train_loss = 1.071
Epoch 149 Batch   18/44   train_loss = 1.085
Epoch 149 Batch   19/44   train_loss = 0.992
Epoch 149 Batch   20/44   train_loss = 0.964
Epoch 149 Batch   21/44   train_loss = 0.895
Epoch 149 Batch   22/44   train_loss = 1.027
Epoch 149 Batch   23/44   train_loss = 0.989
Epoch 149 Batch   24/44   train_loss = 1.015
Epoch 149 Batch   25/44   train_loss = 1.146
Epoch 149 Batch   26/44   train_loss = 1.126
Epoch 149 Batch   27/44   train_loss = 1.155
Epoch 149 Batch   28/44   train_loss = 1.068
Epoch 149 Batch   29/44   train_loss = 1.031
Epoch 149 Batch   30/44   train_loss = 0.973
Epoch 149 Batch   31/44   train_loss = 0.979
Epoch 149 Batch   32/44   train_loss = 1.012
Epoch 149 Batch   33/44   train_loss = 1.016
Epoch 149 Batch   34/44   train_loss = 1.006
Epoch 149 Batch   35/44   train_loss = 1.045
Epoch 149 Batch   36/44   train_loss = 1.201
Epoch 149 Batch   37/44   train_loss = 1.120
Epoch 149 Batch   38/44   train_loss = 1.132
Epoch 149 Batch   39/44   train_loss = 1.033
Epoch 149 Batch   40/44   train_loss = 1.032
Epoch 149 Batch   41/44   train_loss = 1.035
Epoch 149 Batch   42/44   train_loss = 0.944
Epoch 149 Batch   43/44   train_loss = 0.928
Epoch 150 Batch    0/44   train_loss = 0.975
Epoch 150 Batch    1/44   train_loss = 0.960
Epoch 150 Batch    2/44   train_loss = 1.051
Epoch 150 Batch    3/44   train_loss = 1.088
Epoch 150 Batch    4/44   train_loss = 1.033
Epoch 150 Batch    5/44   train_loss = 1.084
Epoch 150 Batch    6/44   train_loss = 1.095
Epoch 150 Batch    7/44   train_loss = 1.073
Epoch 150 Batch    8/44   train_loss = 1.053
Epoch 150 Batch    9/44   train_loss = 1.041
Epoch 150 Batch   10/44   train_loss = 0.942
Epoch 150 Batch   11/44   train_loss = 0.966
Epoch 150 Batch   12/44   train_loss = 1.007
Epoch 150 Batch   13/44   train_loss = 0.933
Epoch 150 Batch   14/44   train_loss = 0.991
Epoch 150 Batch   15/44   train_loss = 1.020
Epoch 150 Batch   16/44   train_loss = 1.043
Epoch 150 Batch   17/44   train_loss = 1.049
Epoch 150 Batch   18/44   train_loss = 1.099
Epoch 150 Batch   19/44   train_loss = 1.006
Epoch 150 Batch   20/44   train_loss = 0.982
Epoch 150 Batch   21/44   train_loss = 0.899
Epoch 150 Batch   22/44   train_loss = 0.990
Epoch 150 Batch   23/44   train_loss = 0.906
Epoch 150 Batch   24/44   train_loss = 0.900
Epoch 150 Batch   25/44   train_loss = 1.002
Epoch 150 Batch   26/44   train_loss = 0.995
Epoch 150 Batch   27/44   train_loss = 1.066
Epoch 150 Batch   28/44   train_loss = 1.029
Epoch 150 Batch   29/44   train_loss = 1.050
Epoch 150 Batch   30/44   train_loss = 1.013
Epoch 150 Batch   31/44   train_loss = 1.027
Epoch 150 Batch   32/44   train_loss = 1.002
Epoch 150 Batch   33/44   train_loss = 0.973
Epoch 150 Batch   34/44   train_loss = 0.926
Epoch 150 Batch   35/44   train_loss = 0.933
Epoch 150 Batch   36/44   train_loss = 1.075
Epoch 150 Batch   37/44   train_loss = 1.009
Epoch 150 Batch   38/44   train_loss = 1.059
Epoch 150 Batch   39/44   train_loss = 0.975
Epoch 150 Batch   40/44   train_loss = 1.021
Epoch 150 Batch   41/44   train_loss = 1.058
Epoch 150 Batch   42/44   train_loss = 0.978
Epoch 150 Batch   43/44   train_loss = 0.965
Epoch 151 Batch    0/44   train_loss = 0.978
Epoch 151 Batch    1/44   train_loss = 0.931
Epoch 151 Batch    2/44   train_loss = 0.996
Epoch 151 Batch    3/44   train_loss = 1.006
Epoch 151 Batch    4/44   train_loss = 0.927
Epoch 151 Batch    5/44   train_loss = 0.978
Epoch 151 Batch    6/44   train_loss = 1.009
Epoch 151 Batch    7/44   train_loss = 1.018
Epoch 151 Batch    8/44   train_loss = 1.061
Epoch 151 Batch    9/44   train_loss = 1.067
Epoch 151 Batch   10/44   train_loss = 0.992
Epoch 151 Batch   11/44   train_loss = 1.013
Epoch 151 Batch   12/44   train_loss = 1.028
Epoch 151 Batch   13/44   train_loss = 0.929
Epoch 151 Batch   14/44   train_loss = 0.944
Epoch 151 Batch   15/44   train_loss = 0.951
Epoch 151 Batch   16/44   train_loss = 0.952
Epoch 151 Batch   17/44   train_loss = 0.963
Epoch 151 Batch   18/44   train_loss = 1.028
Epoch 151 Batch   19/44   train_loss = 0.975
Epoch 151 Batch   20/44   train_loss = 0.996
Epoch 151 Batch   21/44   train_loss = 0.915
Epoch 151 Batch   22/44   train_loss = 1.016
Epoch 151 Batch   23/44   train_loss = 0.906
Epoch 151 Batch   24/44   train_loss = 0.880
Epoch 151 Batch   25/44   train_loss = 0.943
Epoch 151 Batch   26/44   train_loss = 0.912
Epoch 151 Batch   27/44   train_loss = 0.962
Epoch 151 Batch   28/44   train_loss = 0.928
Epoch 151 Batch   29/44   train_loss = 0.967
Epoch 151 Batch   30/44   train_loss = 0.953
Epoch 151 Batch   31/44   train_loss = 1.005
Epoch 151 Batch   32/44   train_loss = 1.011
Epoch 151 Batch   33/44   train_loss = 0.992
Epoch 151 Batch   34/44   train_loss = 0.935
Epoch 151 Batch   35/44   train_loss = 0.922
Epoch 151 Batch   36/44   train_loss = 1.016
Epoch 151 Batch   37/44   train_loss = 0.924
Epoch 151 Batch   38/44   train_loss = 0.953
Epoch 151 Batch   39/44   train_loss = 0.878
Epoch 151 Batch   40/44   train_loss = 0.924
Epoch 151 Batch   41/44   train_loss = 0.986
Epoch 151 Batch   42/44   train_loss = 0.923
Epoch 151 Batch   43/44   train_loss = 0.938
Epoch 152 Batch    0/44   train_loss = 0.971
Epoch 152 Batch    1/44   train_loss = 0.930
Epoch 152 Batch    2/44   train_loss = 0.984
Epoch 152 Batch    3/44   train_loss = 0.980
Epoch 152 Batch    4/44   train_loss = 0.880
Epoch 152 Batch    5/44   train_loss = 0.906
Epoch 152 Batch    6/44   train_loss = 0.934
Epoch 152 Batch    7/44   train_loss = 0.924
Epoch 152 Batch    8/44   train_loss = 0.971
Epoch 152 Batch    9/44   train_loss = 1.003
Epoch 152 Batch   10/44   train_loss = 0.943
Epoch 152 Batch   11/44   train_loss = 0.987
Epoch 152 Batch   12/44   train_loss = 1.020
Epoch 152 Batch   13/44   train_loss = 0.932
Epoch 152 Batch   14/44   train_loss = 0.942
Epoch 152 Batch   15/44   train_loss = 0.937
Epoch 152 Batch   16/44   train_loss = 0.917
Epoch 152 Batch   17/44   train_loss = 0.913
Epoch 152 Batch   18/44   train_loss = 0.945
Epoch 152 Batch   19/44   train_loss = 0.902
Epoch 152 Batch   20/44   train_loss = 0.922
Epoch 152 Batch   21/44   train_loss = 0.867
Epoch 152 Batch   22/44   train_loss = 0.998
Epoch 152 Batch   23/44   train_loss = 0.927
Epoch 152 Batch   24/44   train_loss = 0.901
Epoch 152 Batch   25/44   train_loss = 0.965
Epoch 152 Batch   26/44   train_loss = 0.909
Epoch 152 Batch   27/44   train_loss = 0.917
Epoch 152 Batch   28/44   train_loss = 0.869
Epoch 152 Batch   29/44   train_loss = 0.897
Epoch 152 Batch   30/44   train_loss = 0.877
Epoch 152 Batch   31/44   train_loss = 0.925
Epoch 152 Batch   32/44   train_loss = 0.967
Epoch 152 Batch   33/44   train_loss = 0.984
Epoch 152 Batch   34/44   train_loss = 0.949
Epoch 152 Batch   35/44   train_loss = 0.933
Epoch 152 Batch   36/44   train_loss = 1.033
Epoch 152 Batch   37/44   train_loss = 0.928
Epoch 152 Batch   38/44   train_loss = 0.936
Epoch 152 Batch   39/44   train_loss = 0.840
Epoch 152 Batch   40/44   train_loss = 0.872
Epoch 152 Batch   41/44   train_loss = 0.920
Epoch 152 Batch   42/44   train_loss = 0.852
Epoch 152 Batch   43/44   train_loss = 0.872
Epoch 153 Batch    0/44   train_loss = 0.923
Epoch 153 Batch    1/44   train_loss = 0.890
Epoch 153 Batch    2/44   train_loss = 0.960
Epoch 153 Batch    3/44   train_loss = 0.969
Epoch 153 Batch    4/44   train_loss = 0.875
Epoch 153 Batch    5/44   train_loss = 0.902
Epoch 153 Batch    6/44   train_loss = 0.923
Epoch 153 Batch    7/44   train_loss = 0.884
Epoch 153 Batch    8/44   train_loss = 0.912
Epoch 153 Batch    9/44   train_loss = 0.951
Epoch 153 Batch   10/44   train_loss = 0.887
Epoch 153 Batch   11/44   train_loss = 0.927
Epoch 153 Batch   12/44   train_loss = 0.973
Epoch 153 Batch   13/44   train_loss = 0.903
Epoch 153 Batch   14/44   train_loss = 0.913
Epoch 153 Batch   15/44   train_loss = 0.926
Epoch 153 Batch   16/44   train_loss = 0.911
Epoch 153 Batch   17/44   train_loss = 0.907
Epoch 153 Batch   18/44   train_loss = 0.927
Epoch 153 Batch   19/44   train_loss = 0.867
Epoch 153 Batch   20/44   train_loss = 0.868
Epoch 153 Batch   21/44   train_loss = 0.802
Epoch 153 Batch   22/44   train_loss = 0.918
Epoch 153 Batch   23/44   train_loss = 0.863
Epoch 153 Batch   24/44   train_loss = 0.864
Epoch 153 Batch   25/44   train_loss = 0.964
Epoch 153 Batch   26/44   train_loss = 0.931
Epoch 153 Batch   27/44   train_loss = 0.951
Epoch 153 Batch   28/44   train_loss = 0.896
Epoch 153 Batch   29/44   train_loss = 0.893
Epoch 153 Batch   30/44   train_loss = 0.836
Epoch 153 Batch   31/44   train_loss = 0.864
Epoch 153 Batch   32/44   train_loss = 0.905
Epoch 153 Batch   33/44   train_loss = 0.938
Epoch 153 Batch   34/44   train_loss = 0.911
Epoch 153 Batch   35/44   train_loss = 0.921
Epoch 153 Batch   36/44   train_loss = 1.048
Epoch 153 Batch   37/44   train_loss = 0.944
Epoch 153 Batch   38/44   train_loss = 0.959
Epoch 153 Batch   39/44   train_loss = 0.853
Epoch 153 Batch   40/44   train_loss = 0.871
Epoch 153 Batch   41/44   train_loss = 0.902
Epoch 153 Batch   42/44   train_loss = 0.828
Epoch 153 Batch   43/44   train_loss = 0.826
Epoch 154 Batch    0/44   train_loss = 0.880
Epoch 154 Batch    1/44   train_loss = 0.851
Epoch 154 Batch    2/44   train_loss = 0.929
Epoch 154 Batch    3/44   train_loss = 0.950
Epoch 154 Batch    4/44   train_loss = 0.870
Epoch 154 Batch    5/44   train_loss = 0.899
Epoch 154 Batch    6/44   train_loss = 0.917
Epoch 154 Batch    7/44   train_loss = 0.876
Epoch 154 Batch    8/44   train_loss = 0.893
Epoch 154 Batch    9/44   train_loss = 0.925
Epoch 154 Batch   10/44   train_loss = 0.855
Epoch 154 Batch   11/44   train_loss = 0.885
Epoch 154 Batch   12/44   train_loss = 0.938
Epoch 154 Batch   13/44   train_loss = 0.873
Epoch 154 Batch   14/44   train_loss = 0.884
Epoch 154 Batch   15/44   train_loss = 0.906
Epoch 154 Batch   16/44   train_loss = 0.893
Epoch 154 Batch   17/44   train_loss = 0.901
Epoch 154 Batch   18/44   train_loss = 0.925
Epoch 154 Batch   19/44   train_loss = 0.864
Epoch 154 Batch   20/44   train_loss = 0.855
Epoch 154 Batch   21/44   train_loss = 0.782
Epoch 154 Batch   22/44   train_loss = 0.884
Epoch 154 Batch   23/44   train_loss = 0.811
Epoch 154 Batch   24/44   train_loss = 0.808
Epoch 154 Batch   25/44   train_loss = 0.904
Epoch 154 Batch   26/44   train_loss = 0.883
Epoch 154 Batch   27/44   train_loss = 0.927
Epoch 154 Batch   28/44   train_loss = 0.897
Epoch 154 Batch   29/44   train_loss = 0.919
Epoch 154 Batch   30/44   train_loss = 0.859
Epoch 154 Batch   31/44   train_loss = 0.874
Epoch 154 Batch   32/44   train_loss = 0.886
Epoch 154 Batch   33/44   train_loss = 0.909
Epoch 154 Batch   34/44   train_loss = 0.866
Epoch 154 Batch   35/44   train_loss = 0.876
Epoch 154 Batch   36/44   train_loss = 1.015
Epoch 154 Batch   37/44   train_loss = 0.925
Epoch 154 Batch   38/44   train_loss = 0.967
Epoch 154 Batch   39/44   train_loss = 0.870
Epoch 154 Batch   40/44   train_loss = 0.896
Epoch 154 Batch   41/44   train_loss = 0.921
Epoch 154 Batch   42/44   train_loss = 0.835
Epoch 154 Batch   43/44   train_loss = 0.812
Epoch 155 Batch    0/44   train_loss = 0.861
Epoch 155 Batch    1/44   train_loss = 0.824
Epoch 155 Batch    2/44   train_loss = 0.913
Epoch 155 Batch    3/44   train_loss = 0.927
Epoch 155 Batch    4/44   train_loss = 0.861
Epoch 155 Batch    5/44   train_loss = 0.897
Epoch 155 Batch    6/44   train_loss = 0.912
Epoch 155 Batch    7/44   train_loss = 0.874
Epoch 155 Batch    8/44   train_loss = 0.885
Epoch 155 Batch    9/44   train_loss = 0.911
Epoch 155 Batch   10/44   train_loss = 0.847
Epoch 155 Batch   11/44   train_loss = 0.876
Epoch 155 Batch   12/44   train_loss = 0.935
Epoch 155 Batch   13/44   train_loss = 0.862
Epoch 155 Batch   14/44   train_loss = 0.877
Epoch 155 Batch   15/44   train_loss = 0.899
Epoch 155 Batch   16/44   train_loss = 0.884
Epoch 155 Batch   17/44   train_loss = 0.895
Epoch 155 Batch   18/44   train_loss = 0.913
Epoch 155 Batch   19/44   train_loss = 0.862
Epoch 155 Batch   20/44   train_loss = 0.846
Epoch 155 Batch   21/44   train_loss = 0.775
Epoch 155 Batch   22/44   train_loss = 0.885
Epoch 155 Batch   23/44   train_loss = 0.796
Epoch 155 Batch   24/44   train_loss = 0.793
Epoch 155 Batch   25/44   train_loss = 0.877
Epoch 155 Batch   26/44   train_loss = 0.843
Epoch 155 Batch   27/44   train_loss = 0.888
Epoch 155 Batch   28/44   train_loss = 0.849
Epoch 155 Batch   29/44   train_loss = 0.881
Epoch 155 Batch   30/44   train_loss = 0.848
Epoch 155 Batch   31/44   train_loss = 0.876
Epoch 155 Batch   32/44   train_loss = 0.893
Epoch 155 Batch   33/44   train_loss = 0.919
Epoch 155 Batch   34/44   train_loss = 0.856
Epoch 155 Batch   35/44   train_loss = 0.854
Epoch 155 Batch   36/44   train_loss = 0.974
Epoch 155 Batch   37/44   train_loss = 0.885
Epoch 155 Batch   38/44   train_loss = 0.926
Epoch 155 Batch   39/44   train_loss = 0.844
Epoch 155 Batch   40/44   train_loss = 0.883
Epoch 155 Batch   41/44   train_loss = 0.915
Epoch 155 Batch   42/44   train_loss = 0.846
Epoch 155 Batch   43/44   train_loss = 0.821
Epoch 156 Batch    0/44   train_loss = 0.866
Epoch 156 Batch    1/44   train_loss = 0.820
Epoch 156 Batch    2/44   train_loss = 0.900
Epoch 156 Batch    3/44   train_loss = 0.904
Epoch 156 Batch    4/44   train_loss = 0.838
Epoch 156 Batch    5/44   train_loss = 0.882
Epoch 156 Batch    6/44   train_loss = 0.900
Epoch 156 Batch    7/44   train_loss = 0.881
Epoch 156 Batch    8/44   train_loss = 0.896
Epoch 156 Batch    9/44   train_loss = 0.914
Epoch 156 Batch   10/44   train_loss = 0.849
Epoch 156 Batch   11/44   train_loss = 0.872
Epoch 156 Batch   12/44   train_loss = 0.917
Epoch 156 Batch   13/44   train_loss = 0.854
Epoch 156 Batch   14/44   train_loss = 0.878
Epoch 156 Batch   15/44   train_loss = 0.908
Epoch 156 Batch   16/44   train_loss = 0.903
Epoch 156 Batch   17/44   train_loss = 0.912
Epoch 156 Batch   18/44   train_loss = 0.920
Epoch 156 Batch   19/44   train_loss = 0.870
Epoch 156 Batch   20/44   train_loss = 0.848
Epoch 156 Batch   21/44   train_loss = 0.771
Epoch 156 Batch   22/44   train_loss = 0.884
Epoch 156 Batch   23/44   train_loss = 0.797
Epoch 156 Batch   24/44   train_loss = 0.799
Epoch 156 Batch   25/44   train_loss = 0.886
Epoch 156 Batch   26/44   train_loss = 0.856
Epoch 156 Batch   27/44   train_loss = 0.898
Epoch 156 Batch   28/44   train_loss = 0.839
Epoch 156 Batch   29/44   train_loss = 0.861
Epoch 156 Batch   30/44   train_loss = 0.818
Epoch 156 Batch   31/44   train_loss = 0.843
Epoch 156 Batch   32/44   train_loss = 0.868
Epoch 156 Batch   33/44   train_loss = 0.905
Epoch 156 Batch   34/44   train_loss = 0.854
Epoch 156 Batch   35/44   train_loss = 0.857
Epoch 156 Batch   36/44   train_loss = 0.971
Epoch 156 Batch   37/44   train_loss = 0.883
Epoch 156 Batch   38/44   train_loss = 0.911
Epoch 156 Batch   39/44   train_loss = 0.823
Epoch 156 Batch   40/44   train_loss = 0.853
Epoch 156 Batch   41/44   train_loss = 0.888
Epoch 156 Batch   42/44   train_loss = 0.821
Epoch 156 Batch   43/44   train_loss = 0.810
Epoch 157 Batch    0/44   train_loss = 0.863
Epoch 157 Batch    1/44   train_loss = 0.824
Epoch 157 Batch    2/44   train_loss = 0.894
Epoch 157 Batch    3/44   train_loss = 0.889
Epoch 157 Batch    4/44   train_loss = 0.828
Epoch 157 Batch    5/44   train_loss = 0.868
Epoch 157 Batch    6/44   train_loss = 0.877
Epoch 157 Batch    7/44   train_loss = 0.860
Epoch 157 Batch    8/44   train_loss = 0.893
Epoch 157 Batch    9/44   train_loss = 0.906
Epoch 157 Batch   10/44   train_loss = 0.845
Epoch 157 Batch   11/44   train_loss = 0.866
Epoch 157 Batch   12/44   train_loss = 0.896
Epoch 157 Batch   13/44   train_loss = 0.834
Epoch 157 Batch   14/44   train_loss = 0.847
Epoch 157 Batch   15/44   train_loss = 0.890
Epoch 157 Batch   16/44   train_loss = 0.905
Epoch 157 Batch   17/44   train_loss = 0.921
Epoch 157 Batch   18/44   train_loss = 0.957
Epoch 157 Batch   19/44   train_loss = 0.901
Epoch 157 Batch   20/44   train_loss = 0.876
Epoch 157 Batch   21/44   train_loss = 0.786
Epoch 157 Batch   22/44   train_loss = 0.880
Epoch 157 Batch   23/44   train_loss = 0.774
Epoch 157 Batch   24/44   train_loss = 0.774
Epoch 157 Batch   25/44   train_loss = 0.860
Epoch 157 Batch   26/44   train_loss = 0.852
Epoch 157 Batch   27/44   train_loss = 0.912
Epoch 157 Batch   28/44   train_loss = 0.876
Epoch 157 Batch   29/44   train_loss = 0.902
Epoch 157 Batch   30/44   train_loss = 0.857
Epoch 157 Batch   31/44   train_loss = 0.871
Epoch 157 Batch   32/44   train_loss = 0.864
Epoch 157 Batch   33/44   train_loss = 0.884
Epoch 157 Batch   34/44   train_loss = 0.827
Epoch 157 Batch   35/44   train_loss = 0.826
Epoch 157 Batch   36/44   train_loss = 0.958
Epoch 157 Batch   37/44   train_loss = 0.895
Epoch 157 Batch   38/44   train_loss = 0.937
Epoch 157 Batch   39/44   train_loss = 0.861
Epoch 157 Batch   40/44   train_loss = 0.876
Epoch 157 Batch   41/44   train_loss = 0.893
Epoch 157 Batch   42/44   train_loss = 0.807
Epoch 157 Batch   43/44   train_loss = 0.801
Epoch 158 Batch    0/44   train_loss = 0.840
Epoch 158 Batch    1/44   train_loss = 0.800
Epoch 158 Batch    2/44   train_loss = 0.860
Epoch 158 Batch    3/44   train_loss = 0.869
Epoch 158 Batch    4/44   train_loss = 0.820
Epoch 158 Batch    5/44   train_loss = 0.862
Epoch 158 Batch    6/44   train_loss = 0.874
Epoch 158 Batch    7/44   train_loss = 0.853
Epoch 158 Batch    8/44   train_loss = 0.894
Epoch 158 Batch    9/44   train_loss = 0.902
Epoch 158 Batch   10/44   train_loss = 0.841
Epoch 158 Batch   11/44   train_loss = 0.868
Epoch 158 Batch   12/44   train_loss = 0.889
Epoch 158 Batch   13/44   train_loss = 0.813
Epoch 158 Batch   14/44   train_loss = 0.826
Epoch 158 Batch   15/44   train_loss = 0.849
Epoch 158 Batch   16/44   train_loss = 0.862
Epoch 158 Batch   17/44   train_loss = 0.890
Epoch 158 Batch   18/44   train_loss = 0.943
Epoch 158 Batch   19/44   train_loss = 0.904
Epoch 158 Batch   20/44   train_loss = 0.912
Epoch 158 Batch   21/44   train_loss = 0.838
Epoch 158 Batch   22/44   train_loss = 0.921
Epoch 158 Batch   23/44   train_loss = 0.792
Epoch 158 Batch   24/44   train_loss = 0.765
Epoch 158 Batch   25/44   train_loss = 0.824
Epoch 158 Batch   26/44   train_loss = 0.796
Epoch 158 Batch   27/44   train_loss = 0.858
Epoch 158 Batch   28/44   train_loss = 0.842
Epoch 158 Batch   29/44   train_loss = 0.889
Epoch 158 Batch   30/44   train_loss = 0.892
Epoch 158 Batch   31/44   train_loss = 0.936
Epoch 158 Batch   32/44   train_loss = 0.938
Epoch 158 Batch   33/44   train_loss = 0.926
Epoch 158 Batch   34/44   train_loss = 0.848
Epoch 158 Batch   35/44   train_loss = 0.821
Epoch 158 Batch   36/44   train_loss = 0.918
Epoch 158 Batch   37/44   train_loss = 0.854
Epoch 158 Batch   38/44   train_loss = 0.900
Epoch 158 Batch   39/44   train_loss = 0.843
Epoch 158 Batch   40/44   train_loss = 0.905
Epoch 158 Batch   41/44   train_loss = 0.947
Epoch 158 Batch   42/44   train_loss = 0.861
Epoch 158 Batch   43/44   train_loss = 0.871
Epoch 159 Batch    0/44   train_loss = 0.882
Epoch 159 Batch    1/44   train_loss = 0.807
Epoch 159 Batch    2/44   train_loss = 0.836
Epoch 159 Batch    3/44   train_loss = 0.830
Epoch 159 Batch    4/44   train_loss = 0.776
Epoch 159 Batch    5/44   train_loss = 0.824
Epoch 159 Batch    6/44   train_loss = 0.857
Epoch 159 Batch    7/44   train_loss = 0.844
Epoch 159 Batch    8/44   train_loss = 0.897
Epoch 159 Batch    9/44   train_loss = 0.921
Epoch 159 Batch   10/44   train_loss = 0.855
Epoch 159 Batch   11/44   train_loss = 0.875
Epoch 159 Batch   12/44   train_loss = 0.887
Epoch 159 Batch   13/44   train_loss = 0.807
Epoch 159 Batch   14/44   train_loss = 0.817
Epoch 159 Batch   15/44   train_loss = 0.819
Epoch 159 Batch   16/44   train_loss = 0.823
Epoch 159 Batch   17/44   train_loss = 0.850
Epoch 159 Batch   18/44   train_loss = 0.897
Epoch 159 Batch   19/44   train_loss = 0.862
Epoch 159 Batch   20/44   train_loss = 0.881
Epoch 159 Batch   21/44   train_loss = 0.829
Epoch 159 Batch   22/44   train_loss = 0.944
Epoch 159 Batch   23/44   train_loss = 0.836
Epoch 159 Batch   24/44   train_loss = 0.810
Epoch 159 Batch   25/44   train_loss = 0.851
Epoch 159 Batch   26/44   train_loss = 0.798
Epoch 159 Batch   27/44   train_loss = 0.823
Epoch 159 Batch   28/44   train_loss = 0.796
Epoch 159 Batch   29/44   train_loss = 0.819
Epoch 159 Batch   30/44   train_loss = 0.828
Epoch 159 Batch   31/44   train_loss = 0.882
Epoch 159 Batch   32/44   train_loss = 0.934
Epoch 159 Batch   33/44   train_loss = 0.954
Epoch 159 Batch   34/44   train_loss = 0.890
Epoch 159 Batch   35/44   train_loss = 0.871
Epoch 159 Batch   36/44   train_loss = 0.941
Epoch 159 Batch   37/44   train_loss = 0.846
Epoch 159 Batch   38/44   train_loss = 0.864
Epoch 159 Batch   39/44   train_loss = 0.795
Epoch 159 Batch   40/44   train_loss = 0.840
Epoch 159 Batch   41/44   train_loss = 0.903
Epoch 159 Batch   42/44   train_loss = 0.856
Epoch 159 Batch   43/44   train_loss = 0.889
Epoch 160 Batch    0/44   train_loss = 0.932
Epoch 160 Batch    1/44   train_loss = 0.859
Epoch 160 Batch    2/44   train_loss = 0.885
Epoch 160 Batch    3/44   train_loss = 0.857
Epoch 160 Batch    4/44   train_loss = 0.768
Epoch 160 Batch    5/44   train_loss = 0.792
Epoch 160 Batch    6/44   train_loss = 0.808
Epoch 160 Batch    7/44   train_loss = 0.790
Epoch 160 Batch    8/44   train_loss = 0.853
Epoch 160 Batch    9/44   train_loss = 0.902
Epoch 160 Batch   10/44   train_loss = 0.859
Epoch 160 Batch   11/44   train_loss = 0.900
Epoch 160 Batch   12/44   train_loss = 0.919
Epoch 160 Batch   13/44   train_loss = 0.830
Epoch 160 Batch   14/44   train_loss = 0.827
Epoch 160 Batch   15/44   train_loss = 0.818
Epoch 160 Batch   16/44   train_loss = 0.794
Epoch 160 Batch   17/44   train_loss = 0.810
Epoch 160 Batch   18/44   train_loss = 0.842
Epoch 160 Batch   19/44   train_loss = 0.804
Epoch 160 Batch   20/44   train_loss = 0.831
Epoch 160 Batch   21/44   train_loss = 0.791
Epoch 160 Batch   22/44   train_loss = 0.932
Epoch 160 Batch   23/44   train_loss = 0.835
Epoch 160 Batch   24/44   train_loss = 0.834
Epoch 160 Batch   25/44   train_loss = 0.872
Epoch 160 Batch   26/44   train_loss = 0.820
Epoch 160 Batch   27/44   train_loss = 0.832
Epoch 160 Batch   28/44   train_loss = 0.783
Epoch 160 Batch   29/44   train_loss = 0.799
Epoch 160 Batch   30/44   train_loss = 0.786
Epoch 160 Batch   31/44   train_loss = 0.829
Epoch 160 Batch   32/44   train_loss = 0.880
Epoch 160 Batch   33/44   train_loss = 0.929
Epoch 160 Batch   34/44   train_loss = 0.875
Epoch 160 Batch   35/44   train_loss = 0.867
Epoch 160 Batch   36/44   train_loss = 0.966
Epoch 160 Batch   37/44   train_loss = 0.855
Epoch 160 Batch   38/44   train_loss = 0.855
Epoch 160 Batch   39/44   train_loss = 0.776
Epoch 160 Batch   40/44   train_loss = 0.801
Epoch 160 Batch   41/44   train_loss = 0.853
Epoch 160 Batch   42/44   train_loss = 0.807
Epoch 160 Batch   43/44   train_loss = 0.845
Epoch 161 Batch    0/44   train_loss = 0.921
Epoch 161 Batch    1/44   train_loss = 0.869
Epoch 161 Batch    2/44   train_loss = 0.920
Epoch 161 Batch    3/44   train_loss = 0.897
Epoch 161 Batch    4/44   train_loss = 0.798
Epoch 161 Batch    5/44   train_loss = 0.805
Epoch 161 Batch    6/44   train_loss = 0.797
Epoch 161 Batch    7/44   train_loss = 0.762
Epoch 161 Batch    8/44   train_loss = 0.802
Epoch 161 Batch    9/44   train_loss = 0.854
Epoch 161 Batch   10/44   train_loss = 0.814
Epoch 161 Batch   11/44   train_loss = 0.873
Epoch 161 Batch   12/44   train_loss = 0.917
Epoch 161 Batch   13/44   train_loss = 0.849
Epoch 161 Batch   14/44   train_loss = 0.853
Epoch 161 Batch   15/44   train_loss = 0.850
Epoch 161 Batch   16/44   train_loss = 0.805
Epoch 161 Batch   17/44   train_loss = 0.799
Epoch 161 Batch   18/44   train_loss = 0.806
Epoch 161 Batch   19/44   train_loss = 0.749
Epoch 161 Batch   20/44   train_loss = 0.767
Epoch 161 Batch   21/44   train_loss = 0.717
Epoch 161 Batch   22/44   train_loss = 0.869
Epoch 161 Batch   23/44   train_loss = 0.794
Epoch 161 Batch   24/44   train_loss = 0.823
Epoch 161 Batch   25/44   train_loss = 0.888
Epoch 161 Batch   26/44   train_loss = 0.833
Epoch 161 Batch   27/44   train_loss = 0.851
Epoch 161 Batch   28/44   train_loss = 0.783
Epoch 161 Batch   29/44   train_loss = 0.778
Epoch 161 Batch   30/44   train_loss = 0.739
Epoch 161 Batch   31/44   train_loss = 0.771
Epoch 161 Batch   32/44   train_loss = 0.806
Epoch 161 Batch   33/44   train_loss = 0.872
Epoch 161 Batch   34/44   train_loss = 0.851
Epoch 161 Batch   35/44   train_loss = 0.865
Epoch 161 Batch   36/44   train_loss = 0.984
Epoch 161 Batch   37/44   train_loss = 0.860
Epoch 161 Batch   38/44   train_loss = 0.857
Epoch 161 Batch   39/44   train_loss = 0.766
Epoch 161 Batch   40/44   train_loss = 0.771
Epoch 161 Batch   41/44   train_loss = 0.802
Epoch 161 Batch   42/44   train_loss = 0.751
Epoch 161 Batch   43/44   train_loss = 0.768
Epoch 162 Batch    0/44   train_loss = 0.850
Epoch 162 Batch    1/44   train_loss = 0.815
Epoch 162 Batch    2/44   train_loss = 0.908
Epoch 162 Batch    3/44   train_loss = 0.914
Epoch 162 Batch    4/44   train_loss = 0.838
Epoch 162 Batch    5/44   train_loss = 0.852
Epoch 162 Batch    6/44   train_loss = 0.830
Epoch 162 Batch    7/44   train_loss = 0.780
Epoch 162 Batch    8/44   train_loss = 0.777
Epoch 162 Batch    9/44   train_loss = 0.792
Epoch 162 Batch   10/44   train_loss = 0.733
Epoch 162 Batch   11/44   train_loss = 0.793
Epoch 162 Batch   12/44   train_loss = 0.842
Epoch 162 Batch   13/44   train_loss = 0.813
Epoch 162 Batch   14/44   train_loss = 0.830
Epoch 162 Batch   15/44   train_loss = 0.874
Epoch 162 Batch   16/44   train_loss = 0.848
Epoch 162 Batch   17/44   train_loss = 0.839
Epoch 162 Batch   18/44   train_loss = 0.837
Epoch 162 Batch   19/44   train_loss = 0.751
Epoch 162 Batch   20/44   train_loss = 0.744
Epoch 162 Batch   21/44   train_loss = 0.673
Epoch 162 Batch   22/44   train_loss = 0.793
Epoch 162 Batch   23/44   train_loss = 0.716
Epoch 162 Batch   24/44   train_loss = 0.747
Epoch 162 Batch   25/44   train_loss = 0.825
Epoch 162 Batch   26/44   train_loss = 0.810
Epoch 162 Batch   27/44   train_loss = 0.846
Epoch 162 Batch   28/44   train_loss = 0.787
Epoch 162 Batch   29/44   train_loss = 0.783
Epoch 162 Batch   30/44   train_loss = 0.740
Epoch 162 Batch   31/44   train_loss = 0.745
Epoch 162 Batch   32/44   train_loss = 0.755
Epoch 162 Batch   33/44   train_loss = 0.808
Epoch 162 Batch   34/44   train_loss = 0.773
Epoch 162 Batch   35/44   train_loss = 0.795
Epoch 162 Batch   36/44   train_loss = 0.918
Epoch 162 Batch   37/44   train_loss = 0.825
Epoch 162 Batch   38/44   train_loss = 0.855
Epoch 162 Batch   39/44   train_loss = 0.785
Epoch 162 Batch   40/44   train_loss = 0.793
Epoch 162 Batch   41/44   train_loss = 0.800
Epoch 162 Batch   42/44   train_loss = 0.739
Epoch 162 Batch   43/44   train_loss = 0.726
Epoch 163 Batch    0/44   train_loss = 0.774
Epoch 163 Batch    1/44   train_loss = 0.742
Epoch 163 Batch    2/44   train_loss = 0.834
Epoch 163 Batch    3/44   train_loss = 0.849
Epoch 163 Batch    4/44   train_loss = 0.805
Epoch 163 Batch    5/44   train_loss = 0.851
Epoch 163 Batch    6/44   train_loss = 0.850
Epoch 163 Batch    7/44   train_loss = 0.814
Epoch 163 Batch    8/44   train_loss = 0.814
Epoch 163 Batch    9/44   train_loss = 0.803
Epoch 163 Batch   10/44   train_loss = 0.717
Epoch 163 Batch   11/44   train_loss = 0.746
Epoch 163 Batch   12/44   train_loss = 0.765
Epoch 163 Batch   13/44   train_loss = 0.730
Epoch 163 Batch   14/44   train_loss = 0.741
Epoch 163 Batch   15/44   train_loss = 0.799
Epoch 163 Batch   16/44   train_loss = 0.801
Epoch 163 Batch   17/44   train_loss = 0.821
Epoch 163 Batch   18/44   train_loss = 0.852
Epoch 163 Batch   19/44   train_loss = 0.775
Epoch 163 Batch   20/44   train_loss = 0.771
Epoch 163 Batch   21/44   train_loss = 0.680
Epoch 163 Batch   22/44   train_loss = 0.772
Epoch 163 Batch   23/44   train_loss = 0.686
Epoch 163 Batch   24/44   train_loss = 0.690
Epoch 163 Batch   25/44   train_loss = 0.757
Epoch 163 Batch   26/44   train_loss = 0.741
Epoch 163 Batch   27/44   train_loss = 0.787
Epoch 163 Batch   28/44   train_loss = 0.744
Epoch 163 Batch   29/44   train_loss = 0.760
Epoch 163 Batch   30/44   train_loss = 0.728
Epoch 163 Batch   31/44   train_loss = 0.732
Epoch 163 Batch   32/44   train_loss = 0.742
Epoch 163 Batch   33/44   train_loss = 0.776
Epoch 163 Batch   34/44   train_loss = 0.727
Epoch 163 Batch   35/44   train_loss = 0.739
Epoch 163 Batch   36/44   train_loss = 0.843
Epoch 163 Batch   37/44   train_loss = 0.767
Epoch 163 Batch   38/44   train_loss = 0.793
Epoch 163 Batch   39/44   train_loss = 0.732
Epoch 163 Batch   40/44   train_loss = 0.753
Epoch 163 Batch   41/44   train_loss = 0.787
Epoch 163 Batch   42/44   train_loss = 0.745
Epoch 163 Batch   43/44   train_loss = 0.722
Epoch 164 Batch    0/44   train_loss = 0.758
Epoch 164 Batch    1/44   train_loss = 0.720
Epoch 164 Batch    2/44   train_loss = 0.791
Epoch 164 Batch    3/44   train_loss = 0.783
Epoch 164 Batch    4/44   train_loss = 0.733
Epoch 164 Batch    5/44   train_loss = 0.777
Epoch 164 Batch    6/44   train_loss = 0.793
Epoch 164 Batch    7/44   train_loss = 0.785
Epoch 164 Batch    8/44   train_loss = 0.813
Epoch 164 Batch    9/44   train_loss = 0.828
Epoch 164 Batch   10/44   train_loss = 0.753
Epoch 164 Batch   11/44   train_loss = 0.768
Epoch 164 Batch   12/44   train_loss = 0.770
Epoch 164 Batch   13/44   train_loss = 0.709
Epoch 164 Batch   14/44   train_loss = 0.704
Epoch 164 Batch   15/44   train_loss = 0.736
Epoch 164 Batch   16/44   train_loss = 0.737
Epoch 164 Batch   17/44   train_loss = 0.753
Epoch 164 Batch   18/44   train_loss = 0.799
Epoch 164 Batch   19/44   train_loss = 0.757
Epoch 164 Batch   20/44   train_loss = 0.769
Epoch 164 Batch   21/44   train_loss = 0.694
Epoch 164 Batch   22/44   train_loss = 0.793
Epoch 164 Batch   23/44   train_loss = 0.704
Epoch 164 Batch   24/44   train_loss = 0.679
Epoch 164 Batch   25/44   train_loss = 0.736
Epoch 164 Batch   26/44   train_loss = 0.703
Epoch 164 Batch   27/44   train_loss = 0.731
Epoch 164 Batch   28/44   train_loss = 0.694
Epoch 164 Batch   29/44   train_loss = 0.715
Epoch 164 Batch   30/44   train_loss = 0.689
Epoch 164 Batch   31/44   train_loss = 0.709
Epoch 164 Batch   32/44   train_loss = 0.724
Epoch 164 Batch   33/44   train_loss = 0.754
Epoch 164 Batch   34/44   train_loss = 0.703
Epoch 164 Batch   35/44   train_loss = 0.708
Epoch 164 Batch   36/44   train_loss = 0.801
Epoch 164 Batch   37/44   train_loss = 0.730
Epoch 164 Batch   38/44   train_loss = 0.744
Epoch 164 Batch   39/44   train_loss = 0.684
Epoch 164 Batch   40/44   train_loss = 0.703
Epoch 164 Batch   41/44   train_loss = 0.738
Epoch 164 Batch   42/44   train_loss = 0.700
Epoch 164 Batch   43/44   train_loss = 0.685
Epoch 165 Batch    0/44   train_loss = 0.731
Epoch 165 Batch    1/44   train_loss = 0.709
Epoch 165 Batch    2/44   train_loss = 0.773
Epoch 165 Batch    3/44   train_loss = 0.762
Epoch 165 Batch    4/44   train_loss = 0.704
Epoch 165 Batch    5/44   train_loss = 0.741
Epoch 165 Batch    6/44   train_loss = 0.747
Epoch 165 Batch    7/44   train_loss = 0.721
Epoch 165 Batch    8/44   train_loss = 0.752
Epoch 165 Batch    9/44   train_loss = 0.774
Epoch 165 Batch   10/44   train_loss = 0.730
Epoch 165 Batch   11/44   train_loss = 0.757
Epoch 165 Batch   12/44   train_loss = 0.774
Epoch 165 Batch   13/44   train_loss = 0.726
Epoch 165 Batch   14/44   train_loss = 0.715
Epoch 165 Batch   15/44   train_loss = 0.729
Epoch 165 Batch   16/44   train_loss = 0.724
Epoch 165 Batch   17/44   train_loss = 0.727
Epoch 165 Batch   18/44   train_loss = 0.762
Epoch 165 Batch   19/44   train_loss = 0.714
Epoch 165 Batch   20/44   train_loss = 0.718
Epoch 165 Batch   21/44   train_loss = 0.666
Epoch 165 Batch   22/44   train_loss = 0.783
Epoch 165 Batch   23/44   train_loss = 0.710
Epoch 165 Batch   24/44   train_loss = 0.685
Epoch 165 Batch   25/44   train_loss = 0.745
Epoch 165 Batch   26/44   train_loss = 0.709
Epoch 165 Batch   27/44   train_loss = 0.725
Epoch 165 Batch   28/44   train_loss = 0.677
Epoch 165 Batch   29/44   train_loss = 0.689
Epoch 165 Batch   30/44   train_loss = 0.658
Epoch 165 Batch   31/44   train_loss = 0.679
Epoch 165 Batch   32/44   train_loss = 0.690
Epoch 165 Batch   33/44   train_loss = 0.725
Epoch 165 Batch   34/44   train_loss = 0.682
Epoch 165 Batch   35/44   train_loss = 0.685
Epoch 165 Batch   36/44   train_loss = 0.781
Epoch 165 Batch   37/44   train_loss = 0.713
Epoch 165 Batch   38/44   train_loss = 0.724
Epoch 165 Batch   39/44   train_loss = 0.664
Epoch 165 Batch   40/44   train_loss = 0.677
Epoch 165 Batch   41/44   train_loss = 0.704
Epoch 165 Batch   42/44   train_loss = 0.670
Epoch 165 Batch   43/44   train_loss = 0.650
Epoch 166 Batch    0/44   train_loss = 0.699
Epoch 166 Batch    1/44   train_loss = 0.675
Epoch 166 Batch    2/44   train_loss = 0.735
Epoch 166 Batch    3/44   train_loss = 0.736
Epoch 166 Batch    4/44   train_loss = 0.677
Epoch 166 Batch    5/44   train_loss = 0.724
Epoch 166 Batch    6/44   train_loss = 0.726
Epoch 166 Batch    7/44   train_loss = 0.700
Epoch 166 Batch    8/44   train_loss = 0.724
Epoch 166 Batch    9/44   train_loss = 0.740
Epoch 166 Batch   10/44   train_loss = 0.695
Epoch 166 Batch   11/44   train_loss = 0.716
Epoch 166 Batch   12/44   train_loss = 0.734
Epoch 166 Batch   13/44   train_loss = 0.697
Epoch 166 Batch   14/44   train_loss = 0.693
Epoch 166 Batch   15/44   train_loss = 0.721
Epoch 166 Batch   16/44   train_loss = 0.729
Epoch 166 Batch   17/44   train_loss = 0.740
Epoch 166 Batch   18/44   train_loss = 0.762
Epoch 166 Batch   19/44   train_loss = 0.703
Epoch 166 Batch   20/44   train_loss = 0.692
Epoch 166 Batch   21/44   train_loss = 0.636
Epoch 166 Batch   22/44   train_loss = 0.743
Epoch 166 Batch   23/44   train_loss = 0.672
Epoch 166 Batch   24/44   train_loss = 0.666
Epoch 166 Batch   25/44   train_loss = 0.741
Epoch 166 Batch   26/44   train_loss = 0.721
Epoch 166 Batch   27/44   train_loss = 0.749
Epoch 166 Batch   28/44   train_loss = 0.698
Epoch 166 Batch   29/44   train_loss = 0.702
Epoch 166 Batch   30/44   train_loss = 0.663
Epoch 166 Batch   31/44   train_loss = 0.673
Epoch 166 Batch   32/44   train_loss = 0.673
Epoch 166 Batch   33/44   train_loss = 0.708
Epoch 166 Batch   34/44   train_loss = 0.667
Epoch 166 Batch   35/44   train_loss = 0.661
Epoch 166 Batch   36/44   train_loss = 0.755
Epoch 166 Batch   37/44   train_loss = 0.692
Epoch 166 Batch   38/44   train_loss = 0.711
Epoch 166 Batch   39/44   train_loss = 0.654
Epoch 166 Batch   40/44   train_loss = 0.669
Epoch 166 Batch   41/44   train_loss = 0.705
Epoch 166 Batch   42/44   train_loss = 0.660
Epoch 166 Batch   43/44   train_loss = 0.638
Epoch 167 Batch    0/44   train_loss = 0.686
Epoch 167 Batch    1/44   train_loss = 0.656
Epoch 167 Batch    2/44   train_loss = 0.714
Epoch 167 Batch    3/44   train_loss = 0.710
Epoch 167 Batch    4/44   train_loss = 0.649
Epoch 167 Batch    5/44   train_loss = 0.698
Epoch 167 Batch    6/44   train_loss = 0.700
Epoch 167 Batch    7/44   train_loss = 0.679
Epoch 167 Batch    8/44   train_loss = 0.707
Epoch 167 Batch    9/44   train_loss = 0.728
Epoch 167 Batch   10/44   train_loss = 0.676
Epoch 167 Batch   11/44   train_loss = 0.698
Epoch 167 Batch   12/44   train_loss = 0.706
Epoch 167 Batch   13/44   train_loss = 0.664
Epoch 167 Batch   14/44   train_loss = 0.649
Epoch 167 Batch   15/44   train_loss = 0.682
Epoch 167 Batch   16/44   train_loss = 0.690
Epoch 167 Batch   17/44   train_loss = 0.711
Epoch 167 Batch   18/44   train_loss = 0.742
Epoch 167 Batch   19/44   train_loss = 0.700
Epoch 167 Batch   20/44   train_loss = 0.695
Epoch 167 Batch   21/44   train_loss = 0.638
Epoch 167 Batch   22/44   train_loss = 0.737
Epoch 167 Batch   23/44   train_loss = 0.648
Epoch 167 Batch   24/44   train_loss = 0.644
Epoch 167 Batch   25/44   train_loss = 0.704
Epoch 167 Batch   26/44   train_loss = 0.687
Epoch 167 Batch   27/44   train_loss = 0.728
Epoch 167 Batch   28/44   train_loss = 0.696
Epoch 167 Batch   29/44   train_loss = 0.717
Epoch 167 Batch   30/44   train_loss = 0.689
Epoch 167 Batch   31/44   train_loss = 0.694
Epoch 167 Batch   32/44   train_loss = 0.695
Epoch 167 Batch   33/44   train_loss = 0.716
Epoch 167 Batch   34/44   train_loss = 0.671
Epoch 167 Batch   35/44   train_loss = 0.653
Epoch 167 Batch   36/44   train_loss = 0.745
Epoch 167 Batch   37/44   train_loss = 0.679
Epoch 167 Batch   38/44   train_loss = 0.700
Epoch 167 Batch   39/44   train_loss = 0.644
Epoch 167 Batch   40/44   train_loss = 0.657
Epoch 167 Batch   41/44   train_loss = 0.697
Epoch 167 Batch   42/44   train_loss = 0.654
Epoch 167 Batch   43/44   train_loss = 0.639
Epoch 168 Batch    0/44   train_loss = 0.689
Epoch 168 Batch    1/44   train_loss = 0.659
Epoch 168 Batch    2/44   train_loss = 0.711
Epoch 168 Batch    3/44   train_loss = 0.714
Epoch 168 Batch    4/44   train_loss = 0.646
Epoch 168 Batch    5/44   train_loss = 0.692
Epoch 168 Batch    6/44   train_loss = 0.691
Epoch 168 Batch    7/44   train_loss = 0.665
Epoch 168 Batch    8/44   train_loss = 0.693
Epoch 168 Batch    9/44   train_loss = 0.713
Epoch 168 Batch   10/44   train_loss = 0.659
Epoch 168 Batch   11/44   train_loss = 0.685
Epoch 168 Batch   12/44   train_loss = 0.697
Epoch 168 Batch   13/44   train_loss = 0.652
Epoch 168 Batch   14/44   train_loss = 0.638
Epoch 168 Batch   15/44   train_loss = 0.666
Epoch 168 Batch   16/44   train_loss = 0.664
Epoch 168 Batch   17/44   train_loss = 0.678
Epoch 168 Batch   18/44   train_loss = 0.705
Epoch 168 Batch   19/44   train_loss = 0.672
Epoch 168 Batch   20/44   train_loss = 0.672
Epoch 168 Batch   21/44   train_loss = 0.622
Epoch 168 Batch   22/44   train_loss = 0.725
Epoch 168 Batch   23/44   train_loss = 0.638
Epoch 168 Batch   24/44   train_loss = 0.633
Epoch 168 Batch   25/44   train_loss = 0.688
Epoch 168 Batch   26/44   train_loss = 0.663
Epoch 168 Batch   27/44   train_loss = 0.694
Epoch 168 Batch   28/44   train_loss = 0.664
Epoch 168 Batch   29/44   train_loss = 0.681
Epoch 168 Batch   30/44   train_loss = 0.665
Epoch 168 Batch   31/44   train_loss = 0.683
Epoch 168 Batch   32/44   train_loss = 0.696
Epoch 168 Batch   33/44   train_loss = 0.729
Epoch 168 Batch   34/44   train_loss = 0.679
Epoch 168 Batch   35/44   train_loss = 0.652
Epoch 168 Batch   36/44   train_loss = 0.738
Epoch 168 Batch   37/44   train_loss = 0.668
Epoch 168 Batch   38/44   train_loss = 0.689
Epoch 168 Batch   39/44   train_loss = 0.636
Epoch 168 Batch   40/44   train_loss = 0.651
Epoch 168 Batch   41/44   train_loss = 0.691
Epoch 168 Batch   42/44   train_loss = 0.645
Epoch 168 Batch   43/44   train_loss = 0.633
Epoch 169 Batch    0/44   train_loss = 0.679
Epoch 169 Batch    1/44   train_loss = 0.650
Epoch 169 Batch    2/44   train_loss = 0.702
Epoch 169 Batch    3/44   train_loss = 0.714
Epoch 169 Batch    4/44   train_loss = 0.648
Epoch 169 Batch    5/44   train_loss = 0.698
Epoch 169 Batch    6/44   train_loss = 0.701
Epoch 169 Batch    7/44   train_loss = 0.672
Epoch 169 Batch    8/44   train_loss = 0.704
Epoch 169 Batch    9/44   train_loss = 0.717
Epoch 169 Batch   10/44   train_loss = 0.653
Epoch 169 Batch   11/44   train_loss = 0.673
Epoch 169 Batch   12/44   train_loss = 0.685
Epoch 169 Batch   13/44   train_loss = 0.642
Epoch 169 Batch   14/44   train_loss = 0.630
Epoch 169 Batch   15/44   train_loss = 0.660
Epoch 169 Batch   16/44   train_loss = 0.659
Epoch 169 Batch   17/44   train_loss = 0.671
Epoch 169 Batch   18/44   train_loss = 0.698
Epoch 169 Batch   19/44   train_loss = 0.659
Epoch 169 Batch   20/44   train_loss = 0.657
Epoch 169 Batch   21/44   train_loss = 0.602
Epoch 169 Batch   22/44   train_loss = 0.701
Epoch 169 Batch   23/44   train_loss = 0.622
Epoch 169 Batch   24/44   train_loss = 0.615
Epoch 169 Batch   25/44   train_loss = 0.672
Epoch 169 Batch   26/44   train_loss = 0.655
Epoch 169 Batch   27/44   train_loss = 0.681
Epoch 169 Batch   28/44   train_loss = 0.648
Epoch 169 Batch   29/44   train_loss = 0.662
Epoch 169 Batch   30/44   train_loss = 0.639
Epoch 169 Batch   31/44   train_loss = 0.654
Epoch 169 Batch   32/44   train_loss = 0.670
Epoch 169 Batch   33/44   train_loss = 0.711
Epoch 169 Batch   34/44   train_loss = 0.666
Epoch 169 Batch   35/44   train_loss = 0.643
Epoch 169 Batch   36/44   train_loss = 0.727
Epoch 169 Batch   37/44   train_loss = 0.655
Epoch 169 Batch   38/44   train_loss = 0.672
Epoch 169 Batch   39/44   train_loss = 0.623
Epoch 169 Batch   40/44   train_loss = 0.633
Epoch 169 Batch   41/44   train_loss = 0.673
Epoch 169 Batch   42/44   train_loss = 0.634
Epoch 169 Batch   43/44   train_loss = 0.628
Epoch 170 Batch    0/44   train_loss = 0.669
Epoch 170 Batch    1/44   train_loss = 0.641
Epoch 170 Batch    2/44   train_loss = 0.686
Epoch 170 Batch    3/44   train_loss = 0.690
Epoch 170 Batch    4/44   train_loss = 0.625
Epoch 170 Batch    5/44   train_loss = 0.673
Epoch 170 Batch    6/44   train_loss = 0.683
Epoch 170 Batch    7/44   train_loss = 0.667
Epoch 170 Batch    8/44   train_loss = 0.715
Epoch 170 Batch    9/44   train_loss = 0.739
Epoch 170 Batch   10/44   train_loss = 0.674
Epoch 170 Batch   11/44   train_loss = 0.688
Epoch 170 Batch   12/44   train_loss = 0.693
Epoch 170 Batch   13/44   train_loss = 0.635
Epoch 170 Batch   14/44   train_loss = 0.618
Epoch 170 Batch   15/44   train_loss = 0.642
Epoch 170 Batch   16/44   train_loss = 0.644
Epoch 170 Batch   17/44   train_loss = 0.664
Epoch 170 Batch   18/44   train_loss = 0.698
Epoch 170 Batch   19/44   train_loss = 0.668
Epoch 170 Batch   20/44   train_loss = 0.668
Epoch 170 Batch   21/44   train_loss = 0.608
Epoch 170 Batch   22/44   train_loss = 0.697
Epoch 170 Batch   23/44   train_loss = 0.619
Epoch 170 Batch   24/44   train_loss = 0.601
Epoch 170 Batch   25/44   train_loss = 0.656
Epoch 170 Batch   26/44   train_loss = 0.644
Epoch 170 Batch   27/44   train_loss = 0.669
Epoch 170 Batch   28/44   train_loss = 0.638
Epoch 170 Batch   29/44   train_loss = 0.656
Epoch 170 Batch   30/44   train_loss = 0.631
Epoch 170 Batch   31/44   train_loss = 0.650
Epoch 170 Batch   32/44   train_loss = 0.660
Epoch 170 Batch   33/44   train_loss = 0.699
Epoch 170 Batch   34/44   train_loss = 0.651
Epoch 170 Batch   35/44   train_loss = 0.625
Epoch 170 Batch   36/44   train_loss = 0.709
Epoch 170 Batch   37/44   train_loss = 0.635
Epoch 170 Batch   38/44   train_loss = 0.652
Epoch 170 Batch   39/44   train_loss = 0.607
Epoch 170 Batch   40/44   train_loss = 0.610
Epoch 170 Batch   41/44   train_loss = 0.651
Epoch 170 Batch   42/44   train_loss = 0.617
Epoch 170 Batch   43/44   train_loss = 0.615
Epoch 171 Batch    0/44   train_loss = 0.655
Epoch 171 Batch    1/44   train_loss = 0.631
Epoch 171 Batch    2/44   train_loss = 0.677
Epoch 171 Batch    3/44   train_loss = 0.673
Epoch 171 Batch    4/44   train_loss = 0.610
Epoch 171 Batch    5/44   train_loss = 0.649
Epoch 171 Batch    6/44   train_loss = 0.654
Epoch 171 Batch    7/44   train_loss = 0.641
Epoch 171 Batch    8/44   train_loss = 0.683
Epoch 171 Batch    9/44   train_loss = 0.722
Epoch 171 Batch   10/44   train_loss = 0.669
Epoch 171 Batch   11/44   train_loss = 0.703
Epoch 171 Batch   12/44   train_loss = 0.720
Epoch 171 Batch   13/44   train_loss = 0.655
Epoch 171 Batch   14/44   train_loss = 0.636
Epoch 171 Batch   15/44   train_loss = 0.638
Epoch 171 Batch   16/44   train_loss = 0.635
Epoch 171 Batch   17/44   train_loss = 0.643
Epoch 171 Batch   18/44   train_loss = 0.668
Epoch 171 Batch   19/44   train_loss = 0.649
Epoch 171 Batch   20/44   train_loss = 0.665
Epoch 171 Batch   21/44   train_loss = 0.623
Epoch 171 Batch   22/44   train_loss = 0.721
Epoch 171 Batch   23/44   train_loss = 0.643
Epoch 171 Batch   24/44   train_loss = 0.611
Epoch 171 Batch   25/44   train_loss = 0.659
Epoch 171 Batch   26/44   train_loss = 0.643
Epoch 171 Batch   27/44   train_loss = 0.661
Epoch 171 Batch   28/44   train_loss = 0.624
Epoch 171 Batch   29/44   train_loss = 0.646
Epoch 171 Batch   30/44   train_loss = 0.632
Epoch 171 Batch   31/44   train_loss = 0.648
Epoch 171 Batch   32/44   train_loss = 0.664
Epoch 171 Batch   33/44   train_loss = 0.705
Epoch 171 Batch   34/44   train_loss = 0.648
Epoch 171 Batch   35/44   train_loss = 0.630
Epoch 171 Batch   36/44   train_loss = 0.710
Epoch 171 Batch   37/44   train_loss = 0.629
Epoch 171 Batch   38/44   train_loss = 0.644
Epoch 171 Batch   39/44   train_loss = 0.594
Epoch 171 Batch   40/44   train_loss = 0.596
Epoch 171 Batch   41/44   train_loss = 0.639
Epoch 171 Batch   42/44   train_loss = 0.606
Epoch 171 Batch   43/44   train_loss = 0.603
Epoch 172 Batch    0/44   train_loss = 0.644
Epoch 172 Batch    1/44   train_loss = 0.620
Epoch 172 Batch    2/44   train_loss = 0.670
Epoch 172 Batch    3/44   train_loss = 0.666
Epoch 172 Batch    4/44   train_loss = 0.607
Epoch 172 Batch    5/44   train_loss = 0.642
Epoch 172 Batch    6/44   train_loss = 0.638
Epoch 172 Batch    7/44   train_loss = 0.622
Epoch 172 Batch    8/44   train_loss = 0.655
Epoch 172 Batch    9/44   train_loss = 0.691
Epoch 172 Batch   10/44   train_loss = 0.635
Epoch 172 Batch   11/44   train_loss = 0.672
Epoch 172 Batch   12/44   train_loss = 0.702
Epoch 172 Batch   13/44   train_loss = 0.657
Epoch 172 Batch   14/44   train_loss = 0.650
Epoch 172 Batch   15/44   train_loss = 0.651
Epoch 172 Batch   16/44   train_loss = 0.650
Epoch 172 Batch   17/44   train_loss = 0.642
Epoch 172 Batch   18/44   train_loss = 0.651
Epoch 172 Batch   19/44   train_loss = 0.622
Epoch 172 Batch   20/44   train_loss = 0.628
Epoch 172 Batch   21/44   train_loss = 0.594
Epoch 172 Batch   22/44   train_loss = 0.708
Epoch 172 Batch   23/44   train_loss = 0.649
Epoch 172 Batch   24/44   train_loss = 0.630
Epoch 172 Batch   25/44   train_loss = 0.684
Epoch 172 Batch   26/44   train_loss = 0.668
Epoch 172 Batch   27/44   train_loss = 0.671
Epoch 172 Batch   28/44   train_loss = 0.622
Epoch 172 Batch   29/44   train_loss = 0.635
Epoch 172 Batch   30/44   train_loss = 0.615
Epoch 172 Batch   31/44   train_loss = 0.644
Epoch 172 Batch   32/44   train_loss = 0.668
Epoch 172 Batch   33/44   train_loss = 0.713
Epoch 172 Batch   34/44   train_loss = 0.658
Epoch 172 Batch   35/44   train_loss = 0.645
Epoch 172 Batch   36/44   train_loss = 0.721
Epoch 172 Batch   37/44   train_loss = 0.638
Epoch 172 Batch   38/44   train_loss = 0.643
Epoch 172 Batch   39/44   train_loss = 0.592
Epoch 172 Batch   40/44   train_loss = 0.595
Epoch 172 Batch   41/44   train_loss = 0.638
Epoch 172 Batch   42/44   train_loss = 0.604
Epoch 172 Batch   43/44   train_loss = 0.600
Epoch 173 Batch    0/44   train_loss = 0.640
Epoch 173 Batch    1/44   train_loss = 0.618
Epoch 173 Batch    2/44   train_loss = 0.665
Epoch 173 Batch    3/44   train_loss = 0.658
Epoch 173 Batch    4/44   train_loss = 0.603
Epoch 173 Batch    5/44   train_loss = 0.640
Epoch 173 Batch    6/44   train_loss = 0.635
Epoch 173 Batch    7/44   train_loss = 0.630
Epoch 173 Batch    8/44   train_loss = 0.650
Epoch 173 Batch    9/44   train_loss = 0.683
Epoch 173 Batch   10/44   train_loss = 0.622
Epoch 173 Batch   11/44   train_loss = 0.650
Epoch 173 Batch   12/44   train_loss = 0.673
Epoch 173 Batch   13/44   train_loss = 0.631
Epoch 173 Batch   14/44   train_loss = 0.631
Epoch 173 Batch   15/44   train_loss = 0.643
Epoch 173 Batch   16/44   train_loss = 0.646
Epoch 173 Batch   17/44   train_loss = 0.650
Epoch 173 Batch   18/44   train_loss = 0.661
Epoch 173 Batch   19/44   train_loss = 0.627
Epoch 173 Batch   20/44   train_loss = 0.623
Epoch 173 Batch   21/44   train_loss = 0.577
Epoch 173 Batch   22/44   train_loss = 0.678
Epoch 173 Batch   23/44   train_loss = 0.619
Epoch 173 Batch   24/44   train_loss = 0.601
Epoch 173 Batch   25/44   train_loss = 0.667
Epoch 173 Batch   26/44   train_loss = 0.664
Epoch 173 Batch   27/44   train_loss = 0.676
Epoch 173 Batch   28/44   train_loss = 0.634
Epoch 173 Batch   29/44   train_loss = 0.647
Epoch 173 Batch   30/44   train_loss = 0.616
Epoch 173 Batch   31/44   train_loss = 0.643
Epoch 173 Batch   32/44   train_loss = 0.649
Epoch 173 Batch   33/44   train_loss = 0.695
Epoch 173 Batch   34/44   train_loss = 0.664
Epoch 173 Batch   35/44   train_loss = 0.654
Epoch 173 Batch   36/44   train_loss = 0.733
Epoch 173 Batch   37/44   train_loss = 0.652
Epoch 173 Batch   38/44   train_loss = 0.660
Epoch 173 Batch   39/44   train_loss = 0.600
Epoch 173 Batch   40/44   train_loss = 0.593
Epoch 173 Batch   41/44   train_loss = 0.630
Epoch 173 Batch   42/44   train_loss = 0.596
Epoch 173 Batch   43/44   train_loss = 0.597
Epoch 174 Batch    0/44   train_loss = 0.642
Epoch 174 Batch    1/44   train_loss = 0.633
Epoch 174 Batch    2/44   train_loss = 0.675
Epoch 174 Batch    3/44   train_loss = 0.669
Epoch 174 Batch    4/44   train_loss = 0.606
Epoch 174 Batch    5/44   train_loss = 0.634
Epoch 174 Batch    6/44   train_loss = 0.630
Epoch 174 Batch    7/44   train_loss = 0.621
Epoch 174 Batch    8/44   train_loss = 0.645
Epoch 174 Batch    9/44   train_loss = 0.683
Epoch 174 Batch   10/44   train_loss = 0.633
Epoch 174 Batch   11/44   train_loss = 0.662
Epoch 174 Batch   12/44   train_loss = 0.679
Epoch 174 Batch   13/44   train_loss = 0.639
Epoch 174 Batch   14/44   train_loss = 0.629
Epoch 174 Batch   15/44   train_loss = 0.632
Epoch 174 Batch   16/44   train_loss = 0.624
Epoch 174 Batch   17/44   train_loss = 0.635
Epoch 174 Batch   18/44   train_loss = 0.652
Epoch 174 Batch   19/44   train_loss = 0.630
Epoch 174 Batch   20/44   train_loss = 0.639
Epoch 174 Batch   21/44   train_loss = 0.595
Epoch 174 Batch   22/44   train_loss = 0.690
Epoch 174 Batch   23/44   train_loss = 0.621
Epoch 174 Batch   24/44   train_loss = 0.589
Epoch 174 Batch   25/44   train_loss = 0.648
Epoch 174 Batch   26/44   train_loss = 0.633
Epoch 174 Batch   27/44   train_loss = 0.641
Epoch 174 Batch   28/44   train_loss = 0.611
Epoch 174 Batch   29/44   train_loss = 0.632
Epoch 174 Batch   30/44   train_loss = 0.610
Epoch 174 Batch   31/44   train_loss = 0.636
Epoch 174 Batch   32/44   train_loss = 0.650
Epoch 174 Batch   33/44   train_loss = 0.701
Epoch 174 Batch   34/44   train_loss = 0.666
Epoch 174 Batch   35/44   train_loss = 0.652
Epoch 174 Batch   36/44   train_loss = 0.726
Epoch 174 Batch   37/44   train_loss = 0.653
Epoch 174 Batch   38/44   train_loss = 0.660
Epoch 174 Batch   39/44   train_loss = 0.604
Epoch 174 Batch   40/44   train_loss = 0.598
Epoch 174 Batch   41/44   train_loss = 0.628
Epoch 174 Batch   42/44   train_loss = 0.590
Epoch 174 Batch   43/44   train_loss = 0.590
Epoch 175 Batch    0/44   train_loss = 0.628
Epoch 175 Batch    1/44   train_loss = 0.615
Epoch 175 Batch    2/44   train_loss = 0.666
Epoch 175 Batch    3/44   train_loss = 0.670
Epoch 175 Batch    4/44   train_loss = 0.618
Epoch 175 Batch    5/44   train_loss = 0.638
Epoch 175 Batch    6/44   train_loss = 0.643
Epoch 175 Batch    7/44   train_loss = 0.623
Epoch 175 Batch    8/44   train_loss = 0.646
Epoch 175 Batch    9/44   train_loss = 0.673
Epoch 175 Batch   10/44   train_loss = 0.624
Epoch 175 Batch   11/44   train_loss = 0.653
Epoch 175 Batch   12/44   train_loss = 0.677
Epoch 175 Batch   13/44   train_loss = 0.653
Epoch 175 Batch   14/44   train_loss = 0.654
Epoch 175 Batch   15/44   train_loss = 0.657
Epoch 175 Batch   16/44   train_loss = 0.639
Epoch 175 Batch   17/44   train_loss = 0.641
Epoch 175 Batch   18/44   train_loss = 0.636
Epoch 175 Batch   19/44   train_loss = 0.607
Epoch 175 Batch   20/44   train_loss = 0.604
Epoch 175 Batch   21/44   train_loss = 0.571
Epoch 175 Batch   22/44   train_loss = 0.682
Epoch 175 Batch   23/44   train_loss = 0.655
Epoch 175 Batch   24/44   train_loss = 0.631
Epoch 175 Batch   25/44   train_loss = 0.701
Epoch 175 Batch   26/44   train_loss = 0.666
Epoch 175 Batch   27/44   train_loss = 0.660
Epoch 175 Batch   28/44   train_loss = 0.612
Epoch 175 Batch   29/44   train_loss = 0.622
Epoch 175 Batch   30/44   train_loss = 0.588
Epoch 175 Batch   31/44   train_loss = 0.612
Epoch 175 Batch   32/44   train_loss = 0.632
Epoch 175 Batch   33/44   train_loss = 0.700
Epoch 175 Batch   34/44   train_loss = 0.675
Epoch 175 Batch   35/44   train_loss = 0.667
Epoch 175 Batch   36/44   train_loss = 0.739
Epoch 175 Batch   37/44   train_loss = 0.658
Epoch 175 Batch   38/44   train_loss = 0.659
Epoch 175 Batch   39/44   train_loss = 0.604
Epoch 175 Batch   40/44   train_loss = 0.600
Epoch 175 Batch   41/44   train_loss = 0.628
Epoch 175 Batch   42/44   train_loss = 0.584
Epoch 175 Batch   43/44   train_loss = 0.588
Epoch 176 Batch    0/44   train_loss = 0.624
Epoch 176 Batch    1/44   train_loss = 0.611
Epoch 176 Batch    2/44   train_loss = 0.657
Epoch 176 Batch    3/44   train_loss = 0.663
Epoch 176 Batch    4/44   train_loss = 0.610
Epoch 176 Batch    5/44   train_loss = 0.633
Epoch 176 Batch    6/44   train_loss = 0.650
Epoch 176 Batch    7/44   train_loss = 0.614
Epoch 176 Batch    8/44   train_loss = 0.641
Epoch 176 Batch    9/44   train_loss = 0.672
Epoch 176 Batch   10/44   train_loss = 0.620
Epoch 176 Batch   11/44   train_loss = 0.642
Epoch 176 Batch   12/44   train_loss = 0.668
Epoch 176 Batch   13/44   train_loss = 0.636
Epoch 176 Batch   14/44   train_loss = 0.638
Epoch 176 Batch   15/44   train_loss = 0.646
Epoch 176 Batch   16/44   train_loss = 0.638
Epoch 176 Batch   17/44   train_loss = 0.651
Epoch 176 Batch   18/44   train_loss = 0.648
Epoch 176 Batch   19/44   train_loss = 0.609
Epoch 176 Batch   20/44   train_loss = 0.597
Epoch 176 Batch   21/44   train_loss = 0.551
Epoch 176 Batch   22/44   train_loss = 0.644
Epoch 176 Batch   23/44   train_loss = 0.611
Epoch 176 Batch   24/44   train_loss = 0.596
Epoch 176 Batch   25/44   train_loss = 0.684
Epoch 176 Batch   26/44   train_loss = 0.677
Epoch 176 Batch   27/44   train_loss = 0.696
Epoch 176 Batch   28/44   train_loss = 0.655
Epoch 176 Batch   29/44   train_loss = 0.655
Epoch 176 Batch   30/44   train_loss = 0.605
Epoch 176 Batch   31/44   train_loss = 0.608
Epoch 176 Batch   32/44   train_loss = 0.600
Epoch 176 Batch   33/44   train_loss = 0.664
Epoch 176 Batch   34/44   train_loss = 0.645
Epoch 176 Batch   35/44   train_loss = 0.670
Epoch 176 Batch   36/44   train_loss = 0.764
Epoch 176 Batch   37/44   train_loss = 0.695
Epoch 176 Batch   38/44   train_loss = 0.705
Epoch 176 Batch   39/44   train_loss = 0.628
Epoch 176 Batch   40/44   train_loss = 0.619
Epoch 176 Batch   41/44   train_loss = 0.638
Epoch 176 Batch   42/44   train_loss = 0.577
Epoch 176 Batch   43/44   train_loss = 0.574
Epoch 177 Batch    0/44   train_loss = 0.619
Epoch 177 Batch    1/44   train_loss = 0.603
Epoch 177 Batch    2/44   train_loss = 0.661
Epoch 177 Batch    3/44   train_loss = 0.676
Epoch 177 Batch    4/44   train_loss = 0.630
Epoch 177 Batch    5/44   train_loss = 0.643
Epoch 177 Batch    6/44   train_loss = 0.658
Epoch 177 Batch    7/44   train_loss = 0.621
Epoch 177 Batch    8/44   train_loss = 0.640
Epoch 177 Batch    9/44   train_loss = 0.662
Epoch 177 Batch   10/44   train_loss = 0.608
Epoch 177 Batch   11/44   train_loss = 0.622
Epoch 177 Batch   12/44   train_loss = 0.656
Epoch 177 Batch   13/44   train_loss = 0.627
Epoch 177 Batch   14/44   train_loss = 0.636
Epoch 177 Batch   15/44   train_loss = 0.649
Epoch 177 Batch   16/44   train_loss = 0.652
Epoch 177 Batch   17/44   train_loss = 0.662
Epoch 177 Batch   18/44   train_loss = 0.648
Epoch 177 Batch   19/44   train_loss = 0.609
Epoch 177 Batch   20/44   train_loss = 0.598
Epoch 177 Batch   21/44   train_loss = 0.539
Epoch 177 Batch   22/44   train_loss = 0.625
Epoch 177 Batch   23/44   train_loss = 0.584
Epoch 177 Batch   24/44   train_loss = 0.566
Epoch 177 Batch   25/44   train_loss = 0.654
Epoch 177 Batch   26/44   train_loss = 0.658
Epoch 177 Batch   27/44   train_loss = 0.674
Epoch 177 Batch   28/44   train_loss = 0.649
Epoch 177 Batch   29/44   train_loss = 0.667
Epoch 177 Batch   30/44   train_loss = 0.625
Epoch 177 Batch   31/44   train_loss = 0.628
Epoch 177 Batch   32/44   train_loss = 0.608
Epoch 177 Batch   33/44   train_loss = 0.645
Epoch 177 Batch   34/44   train_loss = 0.617
Epoch 177 Batch   35/44   train_loss = 0.625
Epoch 177 Batch   36/44   train_loss = 0.716
Epoch 177 Batch   37/44   train_loss = 0.657
Epoch 177 Batch   38/44   train_loss = 0.706
Epoch 177 Batch   39/44   train_loss = 0.663
Epoch 177 Batch   40/44   train_loss = 0.662
Epoch 177 Batch   41/44   train_loss = 0.683
Epoch 177 Batch   42/44   train_loss = 0.620
Epoch 177 Batch   43/44   train_loss = 0.595
Epoch 178 Batch    0/44   train_loss = 0.618
Epoch 178 Batch    1/44   train_loss = 0.582
Epoch 178 Batch    2/44   train_loss = 0.627
Epoch 178 Batch    3/44   train_loss = 0.655
Epoch 178 Batch    4/44   train_loss = 0.610
Epoch 178 Batch    5/44   train_loss = 0.647
Epoch 178 Batch    6/44   train_loss = 0.668
Epoch 178 Batch    7/44   train_loss = 0.649
Epoch 178 Batch    8/44   train_loss = 0.662
Epoch 178 Batch    9/44   train_loss = 0.676
Epoch 178 Batch   10/44   train_loss = 0.616
Epoch 178 Batch   11/44   train_loss = 0.626
Epoch 178 Batch   12/44   train_loss = 0.642
Epoch 178 Batch   13/44   train_loss = 0.601
Epoch 178 Batch   14/44   train_loss = 0.608
Epoch 178 Batch   15/44   train_loss = 0.630
Epoch 178 Batch   16/44   train_loss = 0.643
Epoch 178 Batch   17/44   train_loss = 0.669
Epoch 178 Batch   18/44   train_loss = 0.679
Epoch 178 Batch   19/44   train_loss = 0.647
Epoch 178 Batch   20/44   train_loss = 0.621
Epoch 178 Batch   21/44   train_loss = 0.559
Epoch 178 Batch   22/44   train_loss = 0.618
Epoch 178 Batch   23/44   train_loss = 0.558
Epoch 178 Batch   24/44   train_loss = 0.539
Epoch 178 Batch   25/44   train_loss = 0.627
Epoch 178 Batch   26/44   train_loss = 0.640
Epoch 178 Batch   27/44   train_loss = 0.655
Epoch 178 Batch   28/44   train_loss = 0.643
Epoch 178 Batch   29/44   train_loss = 0.670
Epoch 178 Batch   30/44   train_loss = 0.639
Epoch 178 Batch   31/44   train_loss = 0.642
Epoch 178 Batch   32/44   train_loss = 0.618
Epoch 178 Batch   33/44   train_loss = 0.644
Epoch 178 Batch   34/44   train_loss = 0.604
Epoch 178 Batch   35/44   train_loss = 0.590
Epoch 178 Batch   36/44   train_loss = 0.672
Epoch 178 Batch   37/44   train_loss = 0.619
Epoch 178 Batch   38/44   train_loss = 0.657
Epoch 178 Batch   39/44   train_loss = 0.629
Epoch 178 Batch   40/44   train_loss = 0.649
Epoch 178 Batch   41/44   train_loss = 0.687
Epoch 178 Batch   42/44   train_loss = 0.642
Epoch 178 Batch   43/44   train_loss = 0.621
Epoch 179 Batch    0/44   train_loss = 0.637
Epoch 179 Batch    1/44   train_loss = 0.581
Epoch 179 Batch    2/44   train_loss = 0.619
Epoch 179 Batch    3/44   train_loss = 0.623
Epoch 179 Batch    4/44   train_loss = 0.572
Epoch 179 Batch    5/44   train_loss = 0.608
Epoch 179 Batch    6/44   train_loss = 0.635
Epoch 179 Batch    7/44   train_loss = 0.631
Epoch 179 Batch    8/44   train_loss = 0.654
Epoch 179 Batch    9/44   train_loss = 0.683
Epoch 179 Batch   10/44   train_loss = 0.643
Epoch 179 Batch   11/44   train_loss = 0.640
Epoch 179 Batch   12/44   train_loss = 0.639
Epoch 179 Batch   13/44   train_loss = 0.583
Epoch 179 Batch   14/44   train_loss = 0.584
Epoch 179 Batch   15/44   train_loss = 0.590
Epoch 179 Batch   16/44   train_loss = 0.598
Epoch 179 Batch   17/44   train_loss = 0.627
Epoch 179 Batch   18/44   train_loss = 0.640
Epoch 179 Batch   19/44   train_loss = 0.641
Epoch 179 Batch   20/44   train_loss = 0.630
Epoch 179 Batch   21/44   train_loss = 0.573
Epoch 179 Batch   22/44   train_loss = 0.643
Epoch 179 Batch   23/44   train_loss = 0.573
Epoch 179 Batch   24/44   train_loss = 0.537
Epoch 179 Batch   25/44   train_loss = 0.605
Epoch 179 Batch   26/44   train_loss = 0.596
Epoch 179 Batch   27/44   train_loss = 0.612
Epoch 179 Batch   28/44   train_loss = 0.593
Epoch 179 Batch   29/44   train_loss = 0.637
Epoch 179 Batch   30/44   train_loss = 0.631
Epoch 179 Batch   31/44   train_loss = 0.652
Epoch 179 Batch   32/44   train_loss = 0.652
Epoch 179 Batch   33/44   train_loss = 0.674
Epoch 179 Batch   34/44   train_loss = 0.630
Epoch 179 Batch   35/44   train_loss = 0.585
Epoch 179 Batch   36/44   train_loss = 0.659
Epoch 179 Batch   37/44   train_loss = 0.594
Epoch 179 Batch   38/44   train_loss = 0.608
Epoch 179 Batch   39/44   train_loss = 0.580
Epoch 179 Batch   40/44   train_loss = 0.607
Epoch 179 Batch   41/44   train_loss = 0.658
Epoch 179 Batch   42/44   train_loss = 0.629
Epoch 179 Batch   43/44   train_loss = 0.628
Epoch 180 Batch    0/44   train_loss = 0.663
Epoch 180 Batch    1/44   train_loss = 0.617
Epoch 180 Batch    2/44   train_loss = 0.638
Epoch 180 Batch    3/44   train_loss = 0.623
Epoch 180 Batch    4/44   train_loss = 0.549
Epoch 180 Batch    5/44   train_loss = 0.578
Epoch 180 Batch    6/44   train_loss = 0.585
Epoch 180 Batch    7/44   train_loss = 0.584
Epoch 180 Batch    8/44   train_loss = 0.609
Epoch 180 Batch    9/44   train_loss = 0.658
Epoch 180 Batch   10/44   train_loss = 0.643
Epoch 180 Batch   11/44   train_loss = 0.651
Epoch 180 Batch   12/44   train_loss = 0.660
Epoch 180 Batch   13/44   train_loss = 0.600
Epoch 180 Batch   14/44   train_loss = 0.582
Epoch 180 Batch   15/44   train_loss = 0.576
Epoch 180 Batch   16/44   train_loss = 0.561
Epoch 180 Batch   17/44   train_loss = 0.582
Epoch 180 Batch   18/44   train_loss = 0.588
Epoch 180 Batch   19/44   train_loss = 0.582
Epoch 180 Batch   20/44   train_loss = 0.586
Epoch 180 Batch   21/44   train_loss = 0.551
Epoch 180 Batch   22/44   train_loss = 0.641
Epoch 180 Batch   23/44   train_loss = 0.577
Epoch 180 Batch   24/44   train_loss = 0.549
Epoch 180 Batch   25/44   train_loss = 0.603
Epoch 180 Batch   26/44   train_loss = 0.561
Epoch 180 Batch   27/44   train_loss = 0.577
Epoch 180 Batch   28/44   train_loss = 0.537
Epoch 180 Batch   29/44   train_loss = 0.572
Epoch 180 Batch   30/44   train_loss = 0.557
Epoch 180 Batch   31/44   train_loss = 0.591
Epoch 180 Batch   32/44   train_loss = 0.609
Epoch 180 Batch   33/44   train_loss = 0.671
Epoch 180 Batch   34/44   train_loss = 0.639
Epoch 180 Batch   35/44   train_loss = 0.602
Epoch 180 Batch   36/44   train_loss = 0.661
Epoch 180 Batch   37/44   train_loss = 0.576
Epoch 180 Batch   38/44   train_loss = 0.572
Epoch 180 Batch   39/44   train_loss = 0.532
Epoch 180 Batch   40/44   train_loss = 0.536
Epoch 180 Batch   41/44   train_loss = 0.584
Epoch 180 Batch   42/44   train_loss = 0.565
Epoch 180 Batch   43/44   train_loss = 0.574
Epoch 181 Batch    0/44   train_loss = 0.627
Epoch 181 Batch    1/44   train_loss = 0.613
Epoch 181 Batch    2/44   train_loss = 0.661
Epoch 181 Batch    3/44   train_loss = 0.656
Epoch 181 Batch    4/44   train_loss = 0.566
Epoch 181 Batch    5/44   train_loss = 0.588
Epoch 181 Batch    6/44   train_loss = 0.562
Epoch 181 Batch    7/44   train_loss = 0.553
Epoch 181 Batch    8/44   train_loss = 0.566
Epoch 181 Batch    9/44   train_loss = 0.606
Epoch 181 Batch   10/44   train_loss = 0.586
Epoch 181 Batch   11/44   train_loss = 0.610
Epoch 181 Batch   12/44   train_loss = 0.642
Epoch 181 Batch   13/44   train_loss = 0.607
Epoch 181 Batch   14/44   train_loss = 0.602
Epoch 181 Batch   15/44   train_loss = 0.602
Epoch 181 Batch   16/44   train_loss = 0.578
Epoch 181 Batch   17/44   train_loss = 0.576
Epoch 181 Batch   18/44   train_loss = 0.564
Epoch 181 Batch   19/44   train_loss = 0.539
Epoch 181 Batch   20/44   train_loss = 0.530
Epoch 181 Batch   21/44   train_loss = 0.492
Epoch 181 Batch   22/44   train_loss = 0.588
Epoch 181 Batch   23/44   train_loss = 0.541
Epoch 181 Batch   24/44   train_loss = 0.535
Epoch 181 Batch   25/44   train_loss = 0.601
Epoch 181 Batch   26/44   train_loss = 0.565
Epoch 181 Batch   27/44   train_loss = 0.585
Epoch 181 Batch   28/44   train_loss = 0.536
Epoch 181 Batch   29/44   train_loss = 0.551
Epoch 181 Batch   30/44   train_loss = 0.509
Epoch 181 Batch   31/44   train_loss = 0.534
Epoch 181 Batch   32/44   train_loss = 0.531
Epoch 181 Batch   33/44   train_loss = 0.604
Epoch 181 Batch   34/44   train_loss = 0.579
Epoch 181 Batch   35/44   train_loss = 0.567
Epoch 181 Batch   36/44   train_loss = 0.662
Epoch 181 Batch   37/44   train_loss = 0.584
Epoch 181 Batch   38/44   train_loss = 0.586
Epoch 181 Batch   39/44   train_loss = 0.539
Epoch 181 Batch   40/44   train_loss = 0.515
Epoch 181 Batch   41/44   train_loss = 0.540
Epoch 181 Batch   42/44   train_loss = 0.515
Epoch 181 Batch   43/44   train_loss = 0.508
Epoch 182 Batch    0/44   train_loss = 0.540
Epoch 182 Batch    1/44   train_loss = 0.530
Epoch 182 Batch    2/44   train_loss = 0.589
Epoch 182 Batch    3/44   train_loss = 0.611
Epoch 182 Batch    4/44   train_loss = 0.552
Epoch 182 Batch    5/44   train_loss = 0.602
Epoch 182 Batch    6/44   train_loss = 0.586
Epoch 182 Batch    7/44   train_loss = 0.567
Epoch 182 Batch    8/44   train_loss = 0.569
Epoch 182 Batch    9/44   train_loss = 0.583
Epoch 182 Batch   10/44   train_loss = 0.541
Epoch 182 Batch   11/44   train_loss = 0.551
Epoch 182 Batch   12/44   train_loss = 0.568
Epoch 182 Batch   13/44   train_loss = 0.551
Epoch 182 Batch   14/44   train_loss = 0.555
Epoch 182 Batch   15/44   train_loss = 0.577
Epoch 182 Batch   16/44   train_loss = 0.576
Epoch 182 Batch   17/44   train_loss = 0.593
Epoch 182 Batch   18/44   train_loss = 0.584
Epoch 182 Batch   19/44   train_loss = 0.546
Epoch 182 Batch   20/44   train_loss = 0.525
Epoch 182 Batch   21/44   train_loss = 0.476
Epoch 182 Batch   22/44   train_loss = 0.548
Epoch 182 Batch   23/44   train_loss = 0.504
Epoch 182 Batch   24/44   train_loss = 0.484
Epoch 182 Batch   25/44   train_loss = 0.552
Epoch 182 Batch   26/44   train_loss = 0.533
Epoch 182 Batch   27/44   train_loss = 0.562
Epoch 182 Batch   28/44   train_loss = 0.530
Epoch 182 Batch   29/44   train_loss = 0.547
Epoch 182 Batch   30/44   train_loss = 0.507
Epoch 182 Batch   31/44   train_loss = 0.529
Epoch 182 Batch   32/44   train_loss = 0.511
Epoch 182 Batch   33/44   train_loss = 0.570
Epoch 182 Batch   34/44   train_loss = 0.536
Epoch 182 Batch   35/44   train_loss = 0.517
Epoch 182 Batch   36/44   train_loss = 0.603
Epoch 182 Batch   37/44   train_loss = 0.542
Epoch 182 Batch   38/44   train_loss = 0.557
Epoch 182 Batch   39/44   train_loss = 0.524
Epoch 182 Batch   40/44   train_loss = 0.508
Epoch 182 Batch   41/44   train_loss = 0.535
Epoch 182 Batch   42/44   train_loss = 0.502
Epoch 182 Batch   43/44   train_loss = 0.493
Epoch 183 Batch    0/44   train_loss = 0.511
Epoch 183 Batch    1/44   train_loss = 0.492
Epoch 183 Batch    2/44   train_loss = 0.530
Epoch 183 Batch    3/44   train_loss = 0.549
Epoch 183 Batch    4/44   train_loss = 0.495
Epoch 183 Batch    5/44   train_loss = 0.545
Epoch 183 Batch    6/44   train_loss = 0.544
Epoch 183 Batch    7/44   train_loss = 0.541
Epoch 183 Batch    8/44   train_loss = 0.566
Epoch 183 Batch    9/44   train_loss = 0.591
Epoch 183 Batch   10/44   train_loss = 0.538
Epoch 183 Batch   11/44   train_loss = 0.552
Epoch 183 Batch   12/44   train_loss = 0.551
Epoch 183 Batch   13/44   train_loss = 0.533
Epoch 183 Batch   14/44   train_loss = 0.520
Epoch 183 Batch   15/44   train_loss = 0.534
Epoch 183 Batch   16/44   train_loss = 0.529
Epoch 183 Batch   17/44   train_loss = 0.553
Epoch 183 Batch   18/44   train_loss = 0.555
Epoch 183 Batch   19/44   train_loss = 0.532
Epoch 183 Batch   20/44   train_loss = 0.529
Epoch 183 Batch   21/44   train_loss = 0.485
Epoch 183 Batch   22/44   train_loss = 0.550
Epoch 183 Batch   23/44   train_loss = 0.506
Epoch 183 Batch   24/44   train_loss = 0.478
Epoch 183 Batch   25/44   train_loss = 0.536
Epoch 183 Batch   26/44   train_loss = 0.514
Epoch 183 Batch   27/44   train_loss = 0.532
Epoch 183 Batch   28/44   train_loss = 0.501
Epoch 183 Batch   29/44   train_loss = 0.522
Epoch 183 Batch   30/44   train_loss = 0.490
Epoch 183 Batch   31/44   train_loss = 0.515
Epoch 183 Batch   32/44   train_loss = 0.507
Epoch 183 Batch   33/44   train_loss = 0.561
Epoch 183 Batch   34/44   train_loss = 0.527
Epoch 183 Batch   35/44   train_loss = 0.510
Epoch 183 Batch   36/44   train_loss = 0.584
Epoch 183 Batch   37/44   train_loss = 0.523
Epoch 183 Batch   38/44   train_loss = 0.531
Epoch 183 Batch   39/44   train_loss = 0.498
Epoch 183 Batch   40/44   train_loss = 0.485
Epoch 183 Batch   41/44   train_loss = 0.513
Epoch 183 Batch   42/44   train_loss = 0.488
Epoch 183 Batch   43/44   train_loss = 0.483
Epoch 184 Batch    0/44   train_loss = 0.501
Epoch 184 Batch    1/44   train_loss = 0.486
Epoch 184 Batch    2/44   train_loss = 0.514
Epoch 184 Batch    3/44   train_loss = 0.530
Epoch 184 Batch    4/44   train_loss = 0.474
Epoch 184 Batch    5/44   train_loss = 0.517
Epoch 184 Batch    6/44   train_loss = 0.515
Epoch 184 Batch    7/44   train_loss = 0.501
Epoch 184 Batch    8/44   train_loss = 0.527
Epoch 184 Batch    9/44   train_loss = 0.558
Epoch 184 Batch   10/44   train_loss = 0.519
Epoch 184 Batch   11/44   train_loss = 0.541
Epoch 184 Batch   12/44   train_loss = 0.546
Epoch 184 Batch   13/44   train_loss = 0.527
Epoch 184 Batch   14/44   train_loss = 0.514
Epoch 184 Batch   15/44   train_loss = 0.523
Epoch 184 Batch   16/44   train_loss = 0.514
Epoch 184 Batch   17/44   train_loss = 0.535
Epoch 184 Batch   18/44   train_loss = 0.533
Epoch 184 Batch   19/44   train_loss = 0.512
Epoch 184 Batch   20/44   train_loss = 0.504
Epoch 184 Batch   21/44   train_loss = 0.467
Epoch 184 Batch   22/44   train_loss = 0.535
Epoch 184 Batch   23/44   train_loss = 0.495
Epoch 184 Batch   24/44   train_loss = 0.474
Epoch 184 Batch   25/44   train_loss = 0.536
Epoch 184 Batch   26/44   train_loss = 0.514
Epoch 184 Batch   27/44   train_loss = 0.527
Epoch 184 Batch   28/44   train_loss = 0.496
Epoch 184 Batch   29/44   train_loss = 0.513
Epoch 184 Batch   30/44   train_loss = 0.481
Epoch 184 Batch   31/44   train_loss = 0.501
Epoch 184 Batch   32/44   train_loss = 0.493
Epoch 184 Batch   33/44   train_loss = 0.550
Epoch 184 Batch   34/44   train_loss = 0.520
Epoch 184 Batch   35/44   train_loss = 0.505
Epoch 184 Batch   36/44   train_loss = 0.579
Epoch 184 Batch   37/44   train_loss = 0.518
Epoch 184 Batch   38/44   train_loss = 0.526
Epoch 184 Batch   39/44   train_loss = 0.492
Epoch 184 Batch   40/44   train_loss = 0.478
Epoch 184 Batch   41/44   train_loss = 0.506
Epoch 184 Batch   42/44   train_loss = 0.481
Epoch 184 Batch   43/44   train_loss = 0.475
Epoch 185 Batch    0/44   train_loss = 0.494
Epoch 185 Batch    1/44   train_loss = 0.480
Epoch 185 Batch    2/44   train_loss = 0.507
Epoch 185 Batch    3/44   train_loss = 0.522
Epoch 185 Batch    4/44   train_loss = 0.469
Epoch 185 Batch    5/44   train_loss = 0.506
Epoch 185 Batch    6/44   train_loss = 0.503
Epoch 185 Batch    7/44   train_loss = 0.488
Epoch 185 Batch    8/44   train_loss = 0.513
Epoch 185 Batch    9/44   train_loss = 0.540
Epoch 185 Batch   10/44   train_loss = 0.502
Epoch 185 Batch   11/44   train_loss = 0.522
Epoch 185 Batch   12/44   train_loss = 0.531
Epoch 185 Batch   13/44   train_loss = 0.510
Epoch 185 Batch   14/44   train_loss = 0.506
Epoch 185 Batch   15/44   train_loss = 0.514
Epoch 185 Batch   16/44   train_loss = 0.505
Epoch 185 Batch   17/44   train_loss = 0.528
Epoch 185 Batch   18/44   train_loss = 0.525
Epoch 185 Batch   19/44   train_loss = 0.503
Epoch 185 Batch   20/44   train_loss = 0.490
Epoch 185 Batch   21/44   train_loss = 0.454
Epoch 185 Batch   22/44   train_loss = 0.518
Epoch 185 Batch   23/44   train_loss = 0.477
Epoch 185 Batch   24/44   train_loss = 0.460
Epoch 185 Batch   25/44   train_loss = 0.521
Epoch 185 Batch   26/44   train_loss = 0.506
Epoch 185 Batch   27/44   train_loss = 0.516
Epoch 185 Batch   28/44   train_loss = 0.492
Epoch 185 Batch   29/44   train_loss = 0.512
Epoch 185 Batch   30/44   train_loss = 0.481
Epoch 185 Batch   31/44   train_loss = 0.500
Epoch 185 Batch   32/44   train_loss = 0.488
Epoch 185 Batch   33/44   train_loss = 0.542
Epoch 185 Batch   34/44   train_loss = 0.510
Epoch 185 Batch   35/44   train_loss = 0.491
Epoch 185 Batch   36/44   train_loss = 0.566
Epoch 185 Batch   37/44   train_loss = 0.504
Epoch 185 Batch   38/44   train_loss = 0.515
Epoch 185 Batch   39/44   train_loss = 0.484
Epoch 185 Batch   40/44   train_loss = 0.475
Epoch 185 Batch   41/44   train_loss = 0.507
Epoch 185 Batch   42/44   train_loss = 0.482
Epoch 185 Batch   43/44   train_loss = 0.474
Epoch 186 Batch    0/44   train_loss = 0.491
Epoch 186 Batch    1/44   train_loss = 0.481
Epoch 186 Batch    2/44   train_loss = 0.506
Epoch 186 Batch    3/44   train_loss = 0.516
Epoch 186 Batch    4/44   train_loss = 0.465
Epoch 186 Batch    5/44   train_loss = 0.498
Epoch 186 Batch    6/44   train_loss = 0.497
Epoch 186 Batch    7/44   train_loss = 0.482
Epoch 186 Batch    8/44   train_loss = 0.505
Epoch 186 Batch    9/44   train_loss = 0.529
Epoch 186 Batch   10/44   train_loss = 0.490
Epoch 186 Batch   11/44   train_loss = 0.510
Epoch 186 Batch   12/44   train_loss = 0.519
Epoch 186 Batch   13/44   train_loss = 0.497
Epoch 186 Batch   14/44   train_loss = 0.498
Epoch 186 Batch   15/44   train_loss = 0.505
Epoch 186 Batch   16/44   train_loss = 0.498
Epoch 186 Batch   17/44   train_loss = 0.521
Epoch 186 Batch   18/44   train_loss = 0.519
Epoch 186 Batch   19/44   train_loss = 0.497
Epoch 186 Batch   20/44   train_loss = 0.485
Epoch 186 Batch   21/44   train_loss = 0.449
Epoch 186 Batch   22/44   train_loss = 0.507
Epoch 186 Batch   23/44   train_loss = 0.466
Epoch 186 Batch   24/44   train_loss = 0.449
Epoch 186 Batch   25/44   train_loss = 0.507
Epoch 186 Batch   26/44   train_loss = 0.491
Epoch 186 Batch   27/44   train_loss = 0.500
Epoch 186 Batch   28/44   train_loss = 0.475
Epoch 186 Batch   29/44   train_loss = 0.500
Epoch 186 Batch   30/44   train_loss = 0.472
Epoch 186 Batch   31/44   train_loss = 0.496
Epoch 186 Batch   32/44   train_loss = 0.487
Epoch 186 Batch   33/44   train_loss = 0.541
Epoch 186 Batch   34/44   train_loss = 0.511
Epoch 186 Batch   35/44   train_loss = 0.487
Epoch 186 Batch   36/44   train_loss = 0.559
Epoch 186 Batch   37/44   train_loss = 0.494
Epoch 186 Batch   38/44   train_loss = 0.506
Epoch 186 Batch   39/44   train_loss = 0.473
Epoch 186 Batch   40/44   train_loss = 0.466
Epoch 186 Batch   41/44   train_loss = 0.500
Epoch 186 Batch   42/44   train_loss = 0.477
Epoch 186 Batch   43/44   train_loss = 0.472
Epoch 187 Batch    0/44   train_loss = 0.490
Epoch 187 Batch    1/44   train_loss = 0.482
Epoch 187 Batch    2/44   train_loss = 0.505
Epoch 187 Batch    3/44   train_loss = 0.515
Epoch 187 Batch    4/44   train_loss = 0.461
Epoch 187 Batch    5/44   train_loss = 0.493
Epoch 187 Batch    6/44   train_loss = 0.490
Epoch 187 Batch    7/44   train_loss = 0.478
Epoch 187 Batch    8/44   train_loss = 0.499
Epoch 187 Batch    9/44   train_loss = 0.521
Epoch 187 Batch   10/44   train_loss = 0.485
Epoch 187 Batch   11/44   train_loss = 0.502
Epoch 187 Batch   12/44   train_loss = 0.511
Epoch 187 Batch   13/44   train_loss = 0.489
Epoch 187 Batch   14/44   train_loss = 0.487
Epoch 187 Batch   15/44   train_loss = 0.494
Epoch 187 Batch   16/44   train_loss = 0.487
Epoch 187 Batch   17/44   train_loss = 0.512
Epoch 187 Batch   18/44   train_loss = 0.508
Epoch 187 Batch   19/44   train_loss = 0.489
Epoch 187 Batch   20/44   train_loss = 0.478
Epoch 187 Batch   21/44   train_loss = 0.443
Epoch 187 Batch   22/44   train_loss = 0.501
Epoch 187 Batch   23/44   train_loss = 0.460
Epoch 187 Batch   24/44   train_loss = 0.445
Epoch 187 Batch   25/44   train_loss = 0.501
Epoch 187 Batch   26/44   train_loss = 0.484
Epoch 187 Batch   27/44   train_loss = 0.489
Epoch 187 Batch   28/44   train_loss = 0.462
Epoch 187 Batch   29/44   train_loss = 0.487
Epoch 187 Batch   30/44   train_loss = 0.460
Epoch 187 Batch   31/44   train_loss = 0.485
Epoch 187 Batch   32/44   train_loss = 0.477
Epoch 187 Batch   33/44   train_loss = 0.534
Epoch 187 Batch   34/44   train_loss = 0.507
Epoch 187 Batch   35/44   train_loss = 0.488
Epoch 187 Batch   36/44   train_loss = 0.558
Epoch 187 Batch   37/44   train_loss = 0.492
Epoch 187 Batch   38/44   train_loss = 0.503
Epoch 187 Batch   39/44   train_loss = 0.468
Epoch 187 Batch   40/44   train_loss = 0.459
Epoch 187 Batch   41/44   train_loss = 0.494
Epoch 187 Batch   42/44   train_loss = 0.467
Epoch 187 Batch   43/44   train_loss = 0.464
Epoch 188 Batch    0/44   train_loss = 0.487
Epoch 188 Batch    1/44   train_loss = 0.479
Epoch 188 Batch    2/44   train_loss = 0.504
Epoch 188 Batch    3/44   train_loss = 0.516
Epoch 188 Batch    4/44   train_loss = 0.459
Epoch 188 Batch    5/44   train_loss = 0.491
Epoch 188 Batch    6/44   train_loss = 0.489
Epoch 188 Batch    7/44   train_loss = 0.473
Epoch 188 Batch    8/44   train_loss = 0.495
Epoch 188 Batch    9/44   train_loss = 0.515
Epoch 188 Batch   10/44   train_loss = 0.479
Epoch 188 Batch   11/44   train_loss = 0.497
Epoch 188 Batch   12/44   train_loss = 0.508
Epoch 188 Batch   13/44   train_loss = 0.485
Epoch 188 Batch   14/44   train_loss = 0.481
Epoch 188 Batch   15/44   train_loss = 0.488
Epoch 188 Batch   16/44   train_loss = 0.481
Epoch 188 Batch   17/44   train_loss = 0.503
Epoch 188 Batch   18/44   train_loss = 0.497
Epoch 188 Batch   19/44   train_loss = 0.481
Epoch 188 Batch   20/44   train_loss = 0.469
Epoch 188 Batch   21/44   train_loss = 0.435
Epoch 188 Batch   22/44   train_loss = 0.492
Epoch 188 Batch   23/44   train_loss = 0.455
Epoch 188 Batch   24/44   train_loss = 0.442
Epoch 188 Batch   25/44   train_loss = 0.494
Epoch 188 Batch   26/44   train_loss = 0.479
Epoch 188 Batch   27/44   train_loss = 0.483
Epoch 188 Batch   28/44   train_loss = 0.455
Epoch 188 Batch   29/44   train_loss = 0.475
Epoch 188 Batch   30/44   train_loss = 0.447
Epoch 188 Batch   31/44   train_loss = 0.474
Epoch 188 Batch   32/44   train_loss = 0.464
Epoch 188 Batch   33/44   train_loss = 0.521
Epoch 188 Batch   34/44   train_loss = 0.497
Epoch 188 Batch   35/44   train_loss = 0.480
Epoch 188 Batch   36/44   train_loss = 0.552
Epoch 188 Batch   37/44   train_loss = 0.488
Epoch 188 Batch   38/44   train_loss = 0.500
Epoch 188 Batch   39/44   train_loss = 0.467
Epoch 188 Batch   40/44   train_loss = 0.455
Epoch 188 Batch   41/44   train_loss = 0.489
Epoch 188 Batch   42/44   train_loss = 0.458
Epoch 188 Batch   43/44   train_loss = 0.460
Epoch 189 Batch    0/44   train_loss = 0.480
Epoch 189 Batch    1/44   train_loss = 0.475
Epoch 189 Batch    2/44   train_loss = 0.499
Epoch 189 Batch    3/44   train_loss = 0.514
Epoch 189 Batch    4/44   train_loss = 0.459
Epoch 189 Batch    5/44   train_loss = 0.492
Epoch 189 Batch    6/44   train_loss = 0.487
Epoch 189 Batch    7/44   train_loss = 0.474
Epoch 189 Batch    8/44   train_loss = 0.496
Epoch 189 Batch    9/44   train_loss = 0.511
Epoch 189 Batch   10/44   train_loss = 0.476
Epoch 189 Batch   11/44   train_loss = 0.492
Epoch 189 Batch   12/44   train_loss = 0.501
Epoch 189 Batch   13/44   train_loss = 0.480
Epoch 189 Batch   14/44   train_loss = 0.476
Epoch 189 Batch   15/44   train_loss = 0.486
Epoch 189 Batch   16/44   train_loss = 0.480
Epoch 189 Batch   17/44   train_loss = 0.500
Epoch 189 Batch   18/44   train_loss = 0.493
Epoch 189 Batch   19/44   train_loss = 0.477
Epoch 189 Batch   20/44   train_loss = 0.464
Epoch 189 Batch   21/44   train_loss = 0.426
Epoch 189 Batch   22/44   train_loss = 0.484
Epoch 189 Batch   23/44   train_loss = 0.447
Epoch 189 Batch   24/44   train_loss = 0.436
Epoch 189 Batch   25/44   train_loss = 0.489
Epoch 189 Batch   26/44   train_loss = 0.477
Epoch 189 Batch   27/44   train_loss = 0.480
Epoch 189 Batch   28/44   train_loss = 0.450
Epoch 189 Batch   29/44   train_loss = 0.469
Epoch 189 Batch   30/44   train_loss = 0.439
Epoch 189 Batch   31/44   train_loss = 0.463
Epoch 189 Batch   32/44   train_loss = 0.452
Epoch 189 Batch   33/44   train_loss = 0.506
Epoch 189 Batch   34/44   train_loss = 0.483
Epoch 189 Batch   35/44   train_loss = 0.468
Epoch 189 Batch   36/44   train_loss = 0.541
Epoch 189 Batch   37/44   train_loss = 0.481
Epoch 189 Batch   38/44   train_loss = 0.496
Epoch 189 Batch   39/44   train_loss = 0.464
Epoch 189 Batch   40/44   train_loss = 0.450
Epoch 189 Batch   41/44   train_loss = 0.483
Epoch 189 Batch   42/44   train_loss = 0.452
Epoch 189 Batch   43/44   train_loss = 0.452
Epoch 190 Batch    0/44   train_loss = 0.474
Epoch 190 Batch    1/44   train_loss = 0.470
Epoch 190 Batch    2/44   train_loss = 0.492
Epoch 190 Batch    3/44   train_loss = 0.513
Epoch 190 Batch    4/44   train_loss = 0.455
Epoch 190 Batch    5/44   train_loss = 0.493
Epoch 190 Batch    6/44   train_loss = 0.487
Epoch 190 Batch    7/44   train_loss = 0.475
Epoch 190 Batch    8/44   train_loss = 0.497
Epoch 190 Batch    9/44   train_loss = 0.512
Epoch 190 Batch   10/44   train_loss = 0.477
Epoch 190 Batch   11/44   train_loss = 0.494
Epoch 190 Batch   12/44   train_loss = 0.496
Epoch 190 Batch   13/44   train_loss = 0.478
Epoch 190 Batch   14/44   train_loss = 0.471
Epoch 190 Batch   15/44   train_loss = 0.483
Epoch 190 Batch   16/44   train_loss = 0.478
Epoch 190 Batch   17/44   train_loss = 0.497
Epoch 190 Batch   18/44   train_loss = 0.492
Epoch 190 Batch   19/44   train_loss = 0.478
Epoch 190 Batch   20/44   train_loss = 0.464
Epoch 190 Batch   21/44   train_loss = 0.423
Epoch 190 Batch   22/44   train_loss = 0.483
Epoch 190 Batch   23/44   train_loss = 0.443
Epoch 190 Batch   24/44   train_loss = 0.432
Epoch 190 Batch   25/44   train_loss = 0.484
Epoch 190 Batch   26/44   train_loss = 0.471
Epoch 190 Batch   27/44   train_loss = 0.477
Epoch 190 Batch   28/44   train_loss = 0.447
Epoch 190 Batch   29/44   train_loss = 0.465
Epoch 190 Batch   30/44   train_loss = 0.435
Epoch 190 Batch   31/44   train_loss = 0.457
Epoch 190 Batch   32/44   train_loss = 0.444
Epoch 190 Batch   33/44   train_loss = 0.495
Epoch 190 Batch   34/44   train_loss = 0.471
Epoch 190 Batch   35/44   train_loss = 0.456
Epoch 190 Batch   36/44   train_loss = 0.530
Epoch 190 Batch   37/44   train_loss = 0.470
Epoch 190 Batch   38/44   train_loss = 0.488
Epoch 190 Batch   39/44   train_loss = 0.459
Epoch 190 Batch   40/44   train_loss = 0.444
Epoch 190 Batch   41/44   train_loss = 0.477
Epoch 190 Batch   42/44   train_loss = 0.445
Epoch 190 Batch   43/44   train_loss = 0.444
Epoch 191 Batch    0/44   train_loss = 0.465
Epoch 191 Batch    1/44   train_loss = 0.462
Epoch 191 Batch    2/44   train_loss = 0.479
Epoch 191 Batch    3/44   train_loss = 0.503
Epoch 191 Batch    4/44   train_loss = 0.446
Epoch 191 Batch    5/44   train_loss = 0.486
Epoch 191 Batch    6/44   train_loss = 0.477
Epoch 191 Batch    7/44   train_loss = 0.475
Epoch 191 Batch    8/44   train_loss = 0.497
Epoch 191 Batch    9/44   train_loss = 0.511
Epoch 191 Batch   10/44   train_loss = 0.476
Epoch 191 Batch   11/44   train_loss = 0.494
Epoch 191 Batch   12/44   train_loss = 0.495
Epoch 191 Batch   13/44   train_loss = 0.477
Epoch 191 Batch   14/44   train_loss = 0.469
Epoch 191 Batch   15/44   train_loss = 0.481
Epoch 191 Batch   16/44   train_loss = 0.478
Epoch 191 Batch   17/44   train_loss = 0.494
Epoch 191 Batch   18/44   train_loss = 0.489
Epoch 191 Batch   19/44   train_loss = 0.476
Epoch 191 Batch   20/44   train_loss = 0.463
Epoch 191 Batch   21/44   train_loss = 0.419
Epoch 191 Batch   22/44   train_loss = 0.483
Epoch 191 Batch   23/44   train_loss = 0.443
Epoch 191 Batch   24/44   train_loss = 0.436
Epoch 191 Batch   25/44   train_loss = 0.485
Epoch 191 Batch   26/44   train_loss = 0.471
Epoch 191 Batch   27/44   train_loss = 0.480
Epoch 191 Batch   28/44   train_loss = 0.448
Epoch 191 Batch   29/44   train_loss = 0.465
Epoch 191 Batch   30/44   train_loss = 0.434
Epoch 191 Batch   31/44   train_loss = 0.455
Epoch 191 Batch   32/44   train_loss = 0.440
Epoch 191 Batch   33/44   train_loss = 0.490
Epoch 191 Batch   34/44   train_loss = 0.461
Epoch 191 Batch   35/44   train_loss = 0.446
Epoch 191 Batch   36/44   train_loss = 0.520
Epoch 191 Batch   37/44   train_loss = 0.460
Epoch 191 Batch   38/44   train_loss = 0.475
Epoch 191 Batch   39/44   train_loss = 0.448
Epoch 191 Batch   40/44   train_loss = 0.432
Epoch 191 Batch   41/44   train_loss = 0.466
Epoch 191 Batch   42/44   train_loss = 0.437
Epoch 191 Batch   43/44   train_loss = 0.440
Epoch 192 Batch    0/44   train_loss = 0.457
Epoch 192 Batch    1/44   train_loss = 0.456
Epoch 192 Batch    2/44   train_loss = 0.468
Epoch 192 Batch    3/44   train_loss = 0.492
Epoch 192 Batch    4/44   train_loss = 0.438
Epoch 192 Batch    5/44   train_loss = 0.476
Epoch 192 Batch    6/44   train_loss = 0.467
Epoch 192 Batch    7/44   train_loss = 0.468
Epoch 192 Batch    8/44   train_loss = 0.490
Epoch 192 Batch    9/44   train_loss = 0.507
Epoch 192 Batch   10/44   train_loss = 0.472
Epoch 192 Batch   11/44   train_loss = 0.487
Epoch 192 Batch   12/44   train_loss = 0.487
Epoch 192 Batch   13/44   train_loss = 0.472
Epoch 192 Batch   14/44   train_loss = 0.463
Epoch 192 Batch   15/44   train_loss = 0.479
Epoch 192 Batch   16/44   train_loss = 0.478
Epoch 192 Batch   17/44   train_loss = 0.491
Epoch 192 Batch   18/44   train_loss = 0.492
Epoch 192 Batch   19/44   train_loss = 0.476
Epoch 192 Batch   20/44   train_loss = 0.466
Epoch 192 Batch   21/44   train_loss = 0.421
Epoch 192 Batch   22/44   train_loss = 0.483
Epoch 192 Batch   23/44   train_loss = 0.445
Epoch 192 Batch   24/44   train_loss = 0.433
Epoch 192 Batch   25/44   train_loss = 0.481
Epoch 192 Batch   26/44   train_loss = 0.468
Epoch 192 Batch   27/44   train_loss = 0.481
Epoch 192 Batch   28/44   train_loss = 0.448
Epoch 192 Batch   29/44   train_loss = 0.462
Epoch 192 Batch   30/44   train_loss = 0.433
Epoch 192 Batch   31/44   train_loss = 0.457
Epoch 192 Batch   32/44   train_loss = 0.440
Epoch 192 Batch   33/44   train_loss = 0.489
Epoch 192 Batch   34/44   train_loss = 0.458
Epoch 192 Batch   35/44   train_loss = 0.443
Epoch 192 Batch   36/44   train_loss = 0.514
Epoch 192 Batch   37/44   train_loss = 0.453
Epoch 192 Batch   38/44   train_loss = 0.469
Epoch 192 Batch   39/44   train_loss = 0.442
Epoch 192 Batch   40/44   train_loss = 0.423
Epoch 192 Batch   41/44   train_loss = 0.458
Epoch 192 Batch   42/44   train_loss = 0.429
Epoch 192 Batch   43/44   train_loss = 0.430
Epoch 193 Batch    0/44   train_loss = 0.449
Epoch 193 Batch    1/44   train_loss = 0.449
Epoch 193 Batch    2/44   train_loss = 0.461
Epoch 193 Batch    3/44   train_loss = 0.482
Epoch 193 Batch    4/44   train_loss = 0.428
Epoch 193 Batch    5/44   train_loss = 0.464
Epoch 193 Batch    6/44   train_loss = 0.455
Epoch 193 Batch    7/44   train_loss = 0.457
Epoch 193 Batch    8/44   train_loss = 0.478
Epoch 193 Batch    9/44   train_loss = 0.496
Epoch 193 Batch   10/44   train_loss = 0.468
Epoch 193 Batch   11/44   train_loss = 0.481
Epoch 193 Batch   12/44   train_loss = 0.481
Epoch 193 Batch   13/44   train_loss = 0.464
Epoch 193 Batch   14/44   train_loss = 0.457
Epoch 193 Batch   15/44   train_loss = 0.471
Epoch 193 Batch   16/44   train_loss = 0.469
Epoch 193 Batch   17/44   train_loss = 0.481
Epoch 193 Batch   18/44   train_loss = 0.488
Epoch 193 Batch   19/44   train_loss = 0.468
Epoch 193 Batch   20/44   train_loss = 0.458
Epoch 193 Batch   21/44   train_loss = 0.420
Epoch 193 Batch   22/44   train_loss = 0.486
Epoch 193 Batch   23/44   train_loss = 0.446
Epoch 193 Batch   24/44   train_loss = 0.430
Epoch 193 Batch   25/44   train_loss = 0.480
Epoch 193 Batch   26/44   train_loss = 0.462
Epoch 193 Batch   27/44   train_loss = 0.479
Epoch 193 Batch   28/44   train_loss = 0.440
Epoch 193 Batch   29/44   train_loss = 0.459
Epoch 193 Batch   30/44   train_loss = 0.435
Epoch 193 Batch   31/44   train_loss = 0.462
Epoch 193 Batch   32/44   train_loss = 0.448
Epoch 193 Batch   33/44   train_loss = 0.495
Epoch 193 Batch   34/44   train_loss = 0.464
Epoch 193 Batch   35/44   train_loss = 0.445
Epoch 193 Batch   36/44   train_loss = 0.511
Epoch 193 Batch   37/44   train_loss = 0.451
Epoch 193 Batch   38/44   train_loss = 0.464
Epoch 193 Batch   39/44   train_loss = 0.435
Epoch 193 Batch   40/44   train_loss = 0.416
Epoch 193 Batch   41/44   train_loss = 0.454
Epoch 193 Batch   42/44   train_loss = 0.423
Epoch 193 Batch   43/44   train_loss = 0.427
Epoch 194 Batch    0/44   train_loss = 0.444
Epoch 194 Batch    1/44   train_loss = 0.446
Epoch 194 Batch    2/44   train_loss = 0.458
Epoch 194 Batch    3/44   train_loss = 0.481
Epoch 194 Batch    4/44   train_loss = 0.425
Epoch 194 Batch    5/44   train_loss = 0.453
Epoch 194 Batch    6/44   train_loss = 0.449
Epoch 194 Batch    7/44   train_loss = 0.444
Epoch 194 Batch    8/44   train_loss = 0.465
Epoch 194 Batch    9/44   train_loss = 0.488
Epoch 194 Batch   10/44   train_loss = 0.460
Epoch 194 Batch   11/44   train_loss = 0.472
Epoch 194 Batch   12/44   train_loss = 0.474
Epoch 194 Batch   13/44   train_loss = 0.463
Epoch 194 Batch   14/44   train_loss = 0.460
Epoch 194 Batch   15/44   train_loss = 0.466
Epoch 194 Batch   16/44   train_loss = 0.462
Epoch 194 Batch   17/44   train_loss = 0.469
Epoch 194 Batch   18/44   train_loss = 0.474
Epoch 194 Batch   19/44   train_loss = 0.453
Epoch 194 Batch   20/44   train_loss = 0.445
Epoch 194 Batch   21/44   train_loss = 0.410
Epoch 194 Batch   22/44   train_loss = 0.477
Epoch 194 Batch   23/44   train_loss = 0.440
Epoch 194 Batch   24/44   train_loss = 0.428
Epoch 194 Batch   25/44   train_loss = 0.481
Epoch 194 Batch   26/44   train_loss = 0.462
Epoch 194 Batch   27/44   train_loss = 0.471
Epoch 194 Batch   28/44   train_loss = 0.431
Epoch 194 Batch   29/44   train_loss = 0.451
Epoch 194 Batch   30/44   train_loss = 0.425
Epoch 194 Batch   31/44   train_loss = 0.449
Epoch 194 Batch   32/44   train_loss = 0.443
Epoch 194 Batch   33/44   train_loss = 0.493
Epoch 194 Batch   34/44   train_loss = 0.469
Epoch 194 Batch   35/44   train_loss = 0.456
Epoch 194 Batch   36/44   train_loss = 0.518
Epoch 194 Batch   37/44   train_loss = 0.459
Epoch 194 Batch   38/44   train_loss = 0.467
Epoch 194 Batch   39/44   train_loss = 0.432
Epoch 194 Batch   40/44   train_loss = 0.415
Epoch 194 Batch   41/44   train_loss = 0.445
Epoch 194 Batch   42/44   train_loss = 0.413
Epoch 194 Batch   43/44   train_loss = 0.418
Epoch 195 Batch    0/44   train_loss = 0.437
Epoch 195 Batch    1/44   train_loss = 0.441
Epoch 195 Batch    2/44   train_loss = 0.461
Epoch 195 Batch    3/44   train_loss = 0.478
Epoch 195 Batch    4/44   train_loss = 0.428
Epoch 195 Batch    5/44   train_loss = 0.454
Epoch 195 Batch    6/44   train_loss = 0.452
Epoch 195 Batch    7/44   train_loss = 0.440
Epoch 195 Batch    8/44   train_loss = 0.457
Epoch 195 Batch    9/44   train_loss = 0.473
Epoch 195 Batch   10/44   train_loss = 0.446
Epoch 195 Batch   11/44   train_loss = 0.457
Epoch 195 Batch   12/44   train_loss = 0.458
Epoch 195 Batch   13/44   train_loss = 0.450
Epoch 195 Batch   14/44   train_loss = 0.452
Epoch 195 Batch   15/44   train_loss = 0.461
Epoch 195 Batch   16/44   train_loss = 0.460
Epoch 195 Batch   17/44   train_loss = 0.466
Epoch 195 Batch   18/44   train_loss = 0.474
Epoch 195 Batch   19/44   train_loss = 0.448
Epoch 195 Batch   20/44   train_loss = 0.438
Epoch 195 Batch   21/44   train_loss = 0.402
Epoch 195 Batch   22/44   train_loss = 0.460
Epoch 195 Batch   23/44   train_loss = 0.425
Epoch 195 Batch   24/44   train_loss = 0.416
Epoch 195 Batch   25/44   train_loss = 0.471
Epoch 195 Batch   26/44   train_loss = 0.463
Epoch 195 Batch   27/44   train_loss = 0.474
Epoch 195 Batch   28/44   train_loss = 0.439
Epoch 195 Batch   29/44   train_loss = 0.454
Epoch 195 Batch   30/44   train_loss = 0.422
Epoch 195 Batch   31/44   train_loss = 0.439
Epoch 195 Batch   32/44   train_loss = 0.427
Epoch 195 Batch   33/44   train_loss = 0.480
Epoch 195 Batch   34/44   train_loss = 0.455
Epoch 195 Batch   35/44   train_loss = 0.444
Epoch 195 Batch   36/44   train_loss = 0.515
Epoch 195 Batch   37/44   train_loss = 0.463
Epoch 195 Batch   38/44   train_loss = 0.478
Epoch 195 Batch   39/44   train_loss = 0.441
Epoch 195 Batch   40/44   train_loss = 0.423
Epoch 195 Batch   41/44   train_loss = 0.444
Epoch 195 Batch   42/44   train_loss = 0.407
Epoch 195 Batch   43/44   train_loss = 0.409
Epoch 196 Batch    0/44   train_loss = 0.426
Epoch 196 Batch    1/44   train_loss = 0.427
Epoch 196 Batch    2/44   train_loss = 0.451
Epoch 196 Batch    3/44   train_loss = 0.467
Epoch 196 Batch    4/44   train_loss = 0.426
Epoch 196 Batch    5/44   train_loss = 0.452
Epoch 196 Batch    6/44   train_loss = 0.456
Epoch 196 Batch    7/44   train_loss = 0.446
Epoch 196 Batch    8/44   train_loss = 0.463
Epoch 196 Batch    9/44   train_loss = 0.473
Epoch 196 Batch   10/44   train_loss = 0.442
Epoch 196 Batch   11/44   train_loss = 0.451
Epoch 196 Batch   12/44   train_loss = 0.448
Epoch 196 Batch   13/44   train_loss = 0.441
Epoch 196 Batch   14/44   train_loss = 0.439
Epoch 196 Batch   15/44   train_loss = 0.448
Epoch 196 Batch   16/44   train_loss = 0.446
Epoch 196 Batch   17/44   train_loss = 0.458
Epoch 196 Batch   18/44   train_loss = 0.469
Epoch 196 Batch   19/44   train_loss = 0.447
Epoch 196 Batch   20/44   train_loss = 0.441
Epoch 196 Batch   21/44   train_loss = 0.403
Epoch 196 Batch   22/44   train_loss = 0.454
Epoch 196 Batch   23/44   train_loss = 0.416
Epoch 196 Batch   24/44   train_loss = 0.406
Epoch 196 Batch   25/44   train_loss = 0.454
Epoch 196 Batch   26/44   train_loss = 0.447
Epoch 196 Batch   27/44   train_loss = 0.458
Epoch 196 Batch   28/44   train_loss = 0.430
Epoch 196 Batch   29/44   train_loss = 0.451
Epoch 196 Batch   30/44   train_loss = 0.428
Epoch 196 Batch   31/44   train_loss = 0.447
Epoch 196 Batch   32/44   train_loss = 0.431
Epoch 196 Batch   33/44   train_loss = 0.481
Epoch 196 Batch   34/44   train_loss = 0.448
Epoch 196 Batch   35/44   train_loss = 0.425
Epoch 196 Batch   36/44   train_loss = 0.491
Epoch 196 Batch   37/44   train_loss = 0.444
Epoch 196 Batch   38/44   train_loss = 0.466
Epoch 196 Batch   39/44   train_loss = 0.440
Epoch 196 Batch   40/44   train_loss = 0.439
Epoch 196 Batch   41/44   train_loss = 0.456
Epoch 196 Batch   42/44   train_loss = 0.420
Epoch 196 Batch   43/44   train_loss = 0.416
Epoch 197 Batch    0/44   train_loss = 0.428
Epoch 197 Batch    1/44   train_loss = 0.422
Epoch 197 Batch    2/44   train_loss = 0.437
Epoch 197 Batch    3/44   train_loss = 0.455
Epoch 197 Batch    4/44   train_loss = 0.412
Epoch 197 Batch    5/44   train_loss = 0.435
Epoch 197 Batch    6/44   train_loss = 0.445
Epoch 197 Batch    7/44   train_loss = 0.440
Epoch 197 Batch    8/44   train_loss = 0.460
Epoch 197 Batch    9/44   train_loss = 0.476
Epoch 197 Batch   10/44   train_loss = 0.446
Epoch 197 Batch   11/44   train_loss = 0.458
Epoch 197 Batch   12/44   train_loss = 0.451
Epoch 197 Batch   13/44   train_loss = 0.441
Epoch 197 Batch   14/44   train_loss = 0.435
Epoch 197 Batch   15/44   train_loss = 0.442
Epoch 197 Batch   16/44   train_loss = 0.438
Epoch 197 Batch   17/44   train_loss = 0.447
Epoch 197 Batch   18/44   train_loss = 0.452
Epoch 197 Batch   19/44   train_loss = 0.436
Epoch 197 Batch   20/44   train_loss = 0.433
Epoch 197 Batch   21/44   train_loss = 0.400
Epoch 197 Batch   22/44   train_loss = 0.456
Epoch 197 Batch   23/44   train_loss = 0.418
Epoch 197 Batch   24/44   train_loss = 0.407
Epoch 197 Batch   25/44   train_loss = 0.450
Epoch 197 Batch   26/44   train_loss = 0.441
Epoch 197 Batch   27/44   train_loss = 0.445
Epoch 197 Batch   28/44   train_loss = 0.415
Epoch 197 Batch   29/44   train_loss = 0.438
Epoch 197 Batch   30/44   train_loss = 0.414
Epoch 197 Batch   31/44   train_loss = 0.438
Epoch 197 Batch   32/44   train_loss = 0.426
Epoch 197 Batch   33/44   train_loss = 0.486
Epoch 197 Batch   34/44   train_loss = 0.454
Epoch 197 Batch   35/44   train_loss = 0.425
Epoch 197 Batch   36/44   train_loss = 0.488
Epoch 197 Batch   37/44   train_loss = 0.431
Epoch 197 Batch   38/44   train_loss = 0.446
Epoch 197 Batch   39/44   train_loss = 0.420
Epoch 197 Batch   40/44   train_loss = 0.418
Epoch 197 Batch   41/44   train_loss = 0.445
Epoch 197 Batch   42/44   train_loss = 0.419
Epoch 197 Batch   43/44   train_loss = 0.424
Epoch 198 Batch    0/44   train_loss = 0.435
Epoch 198 Batch    1/44   train_loss = 0.432
Epoch 198 Batch    2/44   train_loss = 0.446
Epoch 198 Batch    3/44   train_loss = 0.454
Epoch 198 Batch    4/44   train_loss = 0.407
Epoch 198 Batch    5/44   train_loss = 0.426
Epoch 198 Batch    6/44   train_loss = 0.427
Epoch 198 Batch    7/44   train_loss = 0.424
Epoch 198 Batch    8/44   train_loss = 0.445
Epoch 198 Batch    9/44   train_loss = 0.464
Epoch 198 Batch   10/44   train_loss = 0.435
Epoch 198 Batch   11/44   train_loss = 0.453
Epoch 198 Batch   12/44   train_loss = 0.448
Epoch 198 Batch   13/44   train_loss = 0.443
Epoch 198 Batch   14/44   train_loss = 0.437
Epoch 198 Batch   15/44   train_loss = 0.443
Epoch 198 Batch   16/44   train_loss = 0.440
Epoch 198 Batch   17/44   train_loss = 0.444
Epoch 198 Batch   18/44   train_loss = 0.442
Epoch 198 Batch   19/44   train_loss = 0.427
Epoch 198 Batch   20/44   train_loss = 0.421
Epoch 198 Batch   21/44   train_loss = 0.387
Epoch 198 Batch   22/44   train_loss = 0.442
Epoch 198 Batch   23/44   train_loss = 0.411
Epoch 198 Batch   24/44   train_loss = 0.404
Epoch 198 Batch   25/44   train_loss = 0.444
Epoch 198 Batch   26/44   train_loss = 0.444
Epoch 198 Batch   27/44   train_loss = 0.444
Epoch 198 Batch   28/44   train_loss = 0.410
Epoch 198 Batch   29/44   train_loss = 0.430
Epoch 198 Batch   30/44   train_loss = 0.406
Epoch 198 Batch   31/44   train_loss = 0.425
Epoch 198 Batch   32/44   train_loss = 0.413
Epoch 198 Batch   33/44   train_loss = 0.472
Epoch 198 Batch   34/44   train_loss = 0.443
Epoch 198 Batch   35/44   train_loss = 0.421
Epoch 198 Batch   36/44   train_loss = 0.486
Epoch 198 Batch   37/44   train_loss = 0.434
Epoch 198 Batch   38/44   train_loss = 0.443
Epoch 198 Batch   39/44   train_loss = 0.419
Epoch 198 Batch   40/44   train_loss = 0.408
Epoch 198 Batch   41/44   train_loss = 0.431
Epoch 198 Batch   42/44   train_loss = 0.406
Epoch 198 Batch   43/44   train_loss = 0.413
Epoch 199 Batch    0/44   train_loss = 0.426
Epoch 199 Batch    1/44   train_loss = 0.430
Epoch 199 Batch    2/44   train_loss = 0.453
Epoch 199 Batch    3/44   train_loss = 0.462
Epoch 199 Batch    4/44   train_loss = 0.413
Epoch 199 Batch    5/44   train_loss = 0.428
Epoch 199 Batch    6/44   train_loss = 0.424
Epoch 199 Batch    7/44   train_loss = 0.416
Epoch 199 Batch    8/44   train_loss = 0.435
Epoch 199 Batch    9/44   train_loss = 0.451
Epoch 199 Batch   10/44   train_loss = 0.417
Epoch 199 Batch   11/44   train_loss = 0.442
Epoch 199 Batch   12/44   train_loss = 0.432
Epoch 199 Batch   13/44   train_loss = 0.436
Epoch 199 Batch   14/44   train_loss = 0.430
Epoch 199 Batch   15/44   train_loss = 0.440
Epoch 199 Batch   16/44   train_loss = 0.440
Epoch 199 Batch   17/44   train_loss = 0.444
Epoch 199 Batch   18/44   train_loss = 0.441
Epoch 199 Batch   19/44   train_loss = 0.426
Epoch 199 Batch   20/44   train_loss = 0.415
Epoch 199 Batch   21/44   train_loss = 0.379
Epoch 199 Batch   22/44   train_loss = 0.434
Epoch 199 Batch   23/44   train_loss = 0.402
Epoch 199 Batch   24/44   train_loss = 0.395
Epoch 199 Batch   25/44   train_loss = 0.435
Epoch 199 Batch   26/44   train_loss = 0.437
Epoch 199 Batch   27/44   train_loss = 0.437
Epoch 199 Batch   28/44   train_loss = 0.405
Epoch 199 Batch   29/44   train_loss = 0.422
Epoch 199 Batch   30/44   train_loss = 0.401
Epoch 199 Batch   31/44   train_loss = 0.418
Epoch 199 Batch   32/44   train_loss = 0.402
Epoch 199 Batch   33/44   train_loss = 0.462
Epoch 199 Batch   34/44   train_loss = 0.433
Epoch 199 Batch   35/44   train_loss = 0.414
Epoch 199 Batch   36/44   train_loss = 0.476
Epoch 199 Batch   37/44   train_loss = 0.426
Epoch 199 Batch   38/44   train_loss = 0.439
Epoch 199 Batch   39/44   train_loss = 0.421
Epoch 199 Batch   40/44   train_loss = 0.407
Epoch 199 Batch   41/44   train_loss = 0.433
Epoch 199 Batch   42/44   train_loss = 0.404
Epoch 199 Batch   43/44   train_loss = 0.406
Epoch 200 Batch    0/44   train_loss = 0.415
Epoch 200 Batch    1/44   train_loss = 0.421
Epoch 200 Batch    2/44   train_loss = 0.442
Epoch 200 Batch    3/44   train_loss = 0.457
Epoch 200 Batch    4/44   train_loss = 0.412
Epoch 200 Batch    5/44   train_loss = 0.429
Epoch 200 Batch    6/44   train_loss = 0.423
Epoch 200 Batch    7/44   train_loss = 0.421
Epoch 200 Batch    8/44   train_loss = 0.437
Epoch 200 Batch    9/44   train_loss = 0.448
Epoch 200 Batch   10/44   train_loss = 0.413
Epoch 200 Batch   11/44   train_loss = 0.433
Epoch 200 Batch   12/44   train_loss = 0.419
Epoch 200 Batch   13/44   train_loss = 0.425
Epoch 200 Batch   14/44   train_loss = 0.414
Epoch 200 Batch   15/44   train_loss = 0.430
Epoch 200 Batch   16/44   train_loss = 0.430
Epoch 200 Batch   17/44   train_loss = 0.439
Epoch 200 Batch   18/44   train_loss = 0.439
Epoch 200 Batch   19/44   train_loss = 0.429
Epoch 200 Batch   20/44   train_loss = 0.415
Epoch 200 Batch   21/44   train_loss = 0.378
Epoch 200 Batch   22/44   train_loss = 0.430
Epoch 200 Batch   23/44   train_loss = 0.397
Epoch 200 Batch   24/44   train_loss = 0.384
Epoch 200 Batch   25/44   train_loss = 0.427
Epoch 200 Batch   26/44   train_loss = 0.426
Epoch 200 Batch   27/44   train_loss = 0.427
Epoch 200 Batch   28/44   train_loss = 0.398
Epoch 200 Batch   29/44   train_loss = 0.414
Epoch 200 Batch   30/44   train_loss = 0.396
Epoch 200 Batch   31/44   train_loss = 0.408
Epoch 200 Batch   32/44   train_loss = 0.390
Epoch 200 Batch   33/44   train_loss = 0.447
Epoch 200 Batch   34/44   train_loss = 0.422
Epoch 200 Batch   35/44   train_loss = 0.401
Epoch 200 Batch   36/44   train_loss = 0.464
Epoch 200 Batch   37/44   train_loss = 0.420
Epoch 200 Batch   38/44   train_loss = 0.434
Epoch 200 Batch   39/44   train_loss = 0.416
Epoch 200 Batch   40/44   train_loss = 0.402
Epoch 200 Batch   41/44   train_loss = 0.428
Epoch 200 Batch   42/44   train_loss = 0.400
Epoch 200 Batch   43/44   train_loss = 0.405
Epoch 201 Batch    0/44   train_loss = 0.412
Epoch 201 Batch    1/44   train_loss = 0.418
Epoch 201 Batch    2/44   train_loss = 0.435
Epoch 201 Batch    3/44   train_loss = 0.448
Epoch 201 Batch    4/44   train_loss = 0.404
Epoch 201 Batch    5/44   train_loss = 0.425
Epoch 201 Batch    6/44   train_loss = 0.421
Epoch 201 Batch    7/44   train_loss = 0.421
Epoch 201 Batch    8/44   train_loss = 0.441
Epoch 201 Batch    9/44   train_loss = 0.449
Epoch 201 Batch   10/44   train_loss = 0.420
Epoch 201 Batch   11/44   train_loss = 0.436
Epoch 201 Batch   12/44   train_loss = 0.417
Epoch 201 Batch   13/44   train_loss = 0.418
Epoch 201 Batch   14/44   train_loss = 0.407
Epoch 201 Batch   15/44   train_loss = 0.420
Epoch 201 Batch   16/44   train_loss = 0.417
Epoch 201 Batch   17/44   train_loss = 0.429
Epoch 201 Batch   18/44   train_loss = 0.433
Epoch 201 Batch   19/44   train_loss = 0.425
Epoch 201 Batch   20/44   train_loss = 0.418
Epoch 201 Batch   21/44   train_loss = 0.383
Epoch 201 Batch   22/44   train_loss = 0.433
Epoch 201 Batch   23/44   train_loss = 0.397
Epoch 201 Batch   24/44   train_loss = 0.381
Epoch 201 Batch   25/44   train_loss = 0.422
Epoch 201 Batch   26/44   train_loss = 0.415
Epoch 201 Batch   27/44   train_loss = 0.419
Epoch 201 Batch   28/44   train_loss = 0.391
Epoch 201 Batch   29/44   train_loss = 0.408
Epoch 201 Batch   30/44   train_loss = 0.392
Epoch 201 Batch   31/44   train_loss = 0.402
Epoch 201 Batch   32/44   train_loss = 0.384
Epoch 201 Batch   33/44   train_loss = 0.440
Epoch 201 Batch   34/44   train_loss = 0.415
Epoch 201 Batch   35/44   train_loss = 0.392
Epoch 201 Batch   36/44   train_loss = 0.449
Epoch 201 Batch   37/44   train_loss = 0.399
Epoch 201 Batch   38/44   train_loss = 0.419
Epoch 201 Batch   39/44   train_loss = 0.407
Epoch 201 Batch   40/44   train_loss = 0.392
Epoch 201 Batch   41/44   train_loss = 0.423
Epoch 201 Batch   42/44   train_loss = 0.397
Epoch 201 Batch   43/44   train_loss = 0.405
Epoch 202 Batch    0/44   train_loss = 0.414
Epoch 202 Batch    1/44   train_loss = 0.414
Epoch 202 Batch    2/44   train_loss = 0.432
Epoch 202 Batch    3/44   train_loss = 0.443
Epoch 202 Batch    4/44   train_loss = 0.396
Epoch 202 Batch    5/44   train_loss = 0.417
Epoch 202 Batch    6/44   train_loss = 0.415
Epoch 202 Batch    7/44   train_loss = 0.417
Epoch 202 Batch    8/44   train_loss = 0.437
Epoch 202 Batch    9/44   train_loss = 0.449
Epoch 202 Batch   10/44   train_loss = 0.423
Epoch 202 Batch   11/44   train_loss = 0.440
Epoch 202 Batch   12/44   train_loss = 0.426
Epoch 202 Batch   13/44   train_loss = 0.421
Epoch 202 Batch   14/44   train_loss = 0.410
Epoch 202 Batch   15/44   train_loss = 0.419
Epoch 202 Batch   16/44   train_loss = 0.408
Epoch 202 Batch   17/44   train_loss = 0.420
Epoch 202 Batch   18/44   train_loss = 0.423
Epoch 202 Batch   19/44   train_loss = 0.413
Epoch 202 Batch   20/44   train_loss = 0.409
Epoch 202 Batch   21/44   train_loss = 0.376
Epoch 202 Batch   22/44   train_loss = 0.436
Epoch 202 Batch   23/44   train_loss = 0.404
Epoch 202 Batch   24/44   train_loss = 0.388
Epoch 202 Batch   25/44   train_loss = 0.426
Epoch 202 Batch   26/44   train_loss = 0.409
Epoch 202 Batch   27/44   train_loss = 0.415
Epoch 202 Batch   28/44   train_loss = 0.382
Epoch 202 Batch   29/44   train_loss = 0.400
Epoch 202 Batch   30/44   train_loss = 0.385
Epoch 202 Batch   31/44   train_loss = 0.395
Epoch 202 Batch   32/44   train_loss = 0.379
Epoch 202 Batch   33/44   train_loss = 0.436
Epoch 202 Batch   34/44   train_loss = 0.413
Epoch 202 Batch   35/44   train_loss = 0.394
Epoch 202 Batch   36/44   train_loss = 0.443
Epoch 202 Batch   37/44   train_loss = 0.391
Epoch 202 Batch   38/44   train_loss = 0.406
Epoch 202 Batch   39/44   train_loss = 0.390
Epoch 202 Batch   40/44   train_loss = 0.374
Epoch 202 Batch   41/44   train_loss = 0.406
Epoch 202 Batch   42/44   train_loss = 0.383
Epoch 202 Batch   43/44   train_loss = 0.400
Epoch 203 Batch    0/44   train_loss = 0.412
Epoch 203 Batch    1/44   train_loss = 0.416
Epoch 203 Batch    2/44   train_loss = 0.438
Epoch 203 Batch    3/44   train_loss = 0.448
Epoch 203 Batch    4/44   train_loss = 0.392
Epoch 203 Batch    5/44   train_loss = 0.413
Epoch 203 Batch    6/44   train_loss = 0.405
Epoch 203 Batch    7/44   train_loss = 0.402
Epoch 203 Batch    8/44   train_loss = 0.420
Epoch 203 Batch    9/44   train_loss = 0.438
Epoch 203 Batch   10/44   train_loss = 0.413
Epoch 203 Batch   11/44   train_loss = 0.437
Epoch 203 Batch   12/44   train_loss = 0.430
Epoch 203 Batch   13/44   train_loss = 0.430
Epoch 203 Batch   14/44   train_loss = 0.418
Epoch 203 Batch   15/44   train_loss = 0.429
Epoch 203 Batch   16/44   train_loss = 0.410
Epoch 203 Batch   17/44   train_loss = 0.421
Epoch 203 Batch   18/44   train_loss = 0.419
Epoch 203 Batch   19/44   train_loss = 0.402
Epoch 203 Batch   20/44   train_loss = 0.395
Epoch 203 Batch   21/44   train_loss = 0.365
Epoch 203 Batch   22/44   train_loss = 0.424
Epoch 203 Batch   23/44   train_loss = 0.401
Epoch 203 Batch   24/44   train_loss = 0.386
Epoch 203 Batch   25/44   train_loss = 0.431
Epoch 203 Batch   26/44   train_loss = 0.418
Epoch 203 Batch   27/44   train_loss = 0.425
Epoch 203 Batch   28/44   train_loss = 0.386
Epoch 203 Batch   29/44   train_loss = 0.401
Epoch 203 Batch   30/44   train_loss = 0.378
Epoch 203 Batch   31/44   train_loss = 0.386
Epoch 203 Batch   32/44   train_loss = 0.365
Epoch 203 Batch   33/44   train_loss = 0.425
Epoch 203 Batch   34/44   train_loss = 0.405
Epoch 203 Batch   35/44   train_loss = 0.392
Epoch 203 Batch   36/44   train_loss = 0.446
Epoch 203 Batch   37/44   train_loss = 0.395
Epoch 203 Batch   38/44   train_loss = 0.407
Epoch 203 Batch   39/44   train_loss = 0.386
Epoch 203 Batch   40/44   train_loss = 0.366
Epoch 203 Batch   41/44   train_loss = 0.390
Epoch 203 Batch   42/44   train_loss = 0.366
Epoch 203 Batch   43/44   train_loss = 0.382
Epoch 204 Batch    0/44   train_loss = 0.395
Epoch 204 Batch    1/44   train_loss = 0.410
Epoch 204 Batch    2/44   train_loss = 0.438
Epoch 204 Batch    3/44   train_loss = 0.457
Epoch 204 Batch    4/44   train_loss = 0.402
Epoch 204 Batch    5/44   train_loss = 0.424
Epoch 204 Batch    6/44   train_loss = 0.409
Epoch 204 Batch    7/44   train_loss = 0.400
Epoch 204 Batch    8/44   train_loss = 0.411
Epoch 204 Batch    9/44   train_loss = 0.426
Epoch 204 Batch   10/44   train_loss = 0.395
Epoch 204 Batch   11/44   train_loss = 0.419
Epoch 204 Batch   12/44   train_loss = 0.408
Epoch 204 Batch   13/44   train_loss = 0.420
Epoch 204 Batch   14/44   train_loss = 0.411
Epoch 204 Batch   15/44   train_loss = 0.437
Epoch 204 Batch   16/44   train_loss = 0.423
Epoch 204 Batch   17/44   train_loss = 0.435
Epoch 204 Batch   18/44   train_loss = 0.430
Epoch 204 Batch   19/44   train_loss = 0.408
Epoch 204 Batch   20/44   train_loss = 0.394
Epoch 204 Batch   21/44   train_loss = 0.360
Epoch 204 Batch   22/44   train_loss = 0.411
Epoch 204 Batch   23/44   train_loss = 0.388
Epoch 204 Batch   24/44   train_loss = 0.376
Epoch 204 Batch   25/44   train_loss = 0.426
Epoch 204 Batch   26/44   train_loss = 0.412
Epoch 204 Batch   27/44   train_loss = 0.425
Epoch 204 Batch   28/44   train_loss = 0.395
Epoch 204 Batch   29/44   train_loss = 0.409
Epoch 204 Batch   30/44   train_loss = 0.390
Epoch 204 Batch   31/44   train_loss = 0.394
Epoch 204 Batch   32/44   train_loss = 0.368
Epoch 204 Batch   33/44   train_loss = 0.419
Epoch 204 Batch   34/44   train_loss = 0.396
Epoch 204 Batch   35/44   train_loss = 0.382
Epoch 204 Batch   36/44   train_loss = 0.436
Epoch 204 Batch   37/44   train_loss = 0.390
Epoch 204 Batch   38/44   train_loss = 0.404
Epoch 204 Batch   39/44   train_loss = 0.382
Epoch 204 Batch   40/44   train_loss = 0.370
Epoch 204 Batch   41/44   train_loss = 0.386
Epoch 204 Batch   42/44   train_loss = 0.359
Epoch 204 Batch   43/44   train_loss = 0.368
Epoch 205 Batch    0/44   train_loss = 0.379
Epoch 205 Batch    1/44   train_loss = 0.389
Epoch 205 Batch    2/44   train_loss = 0.414
Epoch 205 Batch    3/44   train_loss = 0.442
Epoch 205 Batch    4/44   train_loss = 0.399
Epoch 205 Batch    5/44   train_loss = 0.427
Epoch 205 Batch    6/44   train_loss = 0.419
Epoch 205 Batch    7/44   train_loss = 0.411
Epoch 205 Batch    8/44   train_loss = 0.421
Epoch 205 Batch    9/44   train_loss = 0.426
Epoch 205 Batch   10/44   train_loss = 0.389
Epoch 205 Batch   11/44   train_loss = 0.410
Epoch 205 Batch   12/44   train_loss = 0.389
Epoch 205 Batch   13/44   train_loss = 0.402
Epoch 205 Batch   14/44   train_loss = 0.395
Epoch 205 Batch   15/44   train_loss = 0.421
Epoch 205 Batch   16/44   train_loss = 0.413
Epoch 205 Batch   17/44   train_loss = 0.433
Epoch 205 Batch   18/44   train_loss = 0.434
Epoch 205 Batch   19/44   train_loss = 0.420
Epoch 205 Batch   20/44   train_loss = 0.402
Epoch 205 Batch   21/44   train_loss = 0.367
Epoch 205 Batch   22/44   train_loss = 0.414
Epoch 205 Batch   23/44   train_loss = 0.387
Epoch 205 Batch   24/44   train_loss = 0.372
Epoch 205 Batch   25/44   train_loss = 0.417
Epoch 205 Batch   26/44   train_loss = 0.404
Epoch 205 Batch   27/44   train_loss = 0.416
Epoch 205 Batch   28/44   train_loss = 0.390
Epoch 205 Batch   29/44   train_loss = 0.405
Epoch 205 Batch   30/44   train_loss = 0.393
Epoch 205 Batch   31/44   train_loss = 0.400
Epoch 205 Batch   32/44   train_loss = 0.379
Epoch 205 Batch   33/44   train_loss = 0.426
Epoch 205 Batch   34/44   train_loss = 0.397
Epoch 205 Batch   35/44   train_loss = 0.377
Epoch 205 Batch   36/44   train_loss = 0.428
Epoch 205 Batch   37/44   train_loss = 0.382
Epoch 205 Batch   38/44   train_loss = 0.396
Epoch 205 Batch   39/44   train_loss = 0.376
Epoch 205 Batch   40/44   train_loss = 0.363
Epoch 205 Batch   41/44   train_loss = 0.383
Epoch 205 Batch   42/44   train_loss = 0.357
Epoch 205 Batch   43/44   train_loss = 0.367
Epoch 206 Batch    0/44   train_loss = 0.375
Epoch 206 Batch    1/44   train_loss = 0.379
Epoch 206 Batch    2/44   train_loss = 0.402
Epoch 206 Batch    3/44   train_loss = 0.424
Epoch 206 Batch    4/44   train_loss = 0.382
Epoch 206 Batch    5/44   train_loss = 0.409
Epoch 206 Batch    6/44   train_loss = 0.405
Epoch 206 Batch    7/44   train_loss = 0.412
Epoch 206 Batch    8/44   train_loss = 0.427
Epoch 206 Batch    9/44   train_loss = 0.436
Epoch 206 Batch   10/44   train_loss = 0.399
Epoch 206 Batch   11/44   train_loss = 0.417
Epoch 206 Batch   12/44   train_loss = 0.390
Epoch 206 Batch   13/44   train_loss = 0.394
Epoch 206 Batch   14/44   train_loss = 0.381
Epoch 206 Batch   15/44   train_loss = 0.400
Epoch 206 Batch   16/44   train_loss = 0.391
Epoch 206 Batch   17/44   train_loss = 0.411
Epoch 206 Batch   18/44   train_loss = 0.416
Epoch 206 Batch   19/44   train_loss = 0.417
Epoch 206 Batch   20/44   train_loss = 0.408
Epoch 206 Batch   21/44   train_loss = 0.374
Epoch 206 Batch   22/44   train_loss = 0.426
Epoch 206 Batch   23/44   train_loss = 0.393
Epoch 206 Batch   24/44   train_loss = 0.375
Epoch 206 Batch   25/44   train_loss = 0.419
Epoch 206 Batch   26/44   train_loss = 0.402
Epoch 206 Batch   27/44   train_loss = 0.408
Epoch 206 Batch   28/44   train_loss = 0.381
Epoch 206 Batch   29/44   train_loss = 0.399
Epoch 206 Batch   30/44   train_loss = 0.387
Epoch 206 Batch   31/44   train_loss = 0.394
Epoch 206 Batch   32/44   train_loss = 0.379
Epoch 206 Batch   33/44   train_loss = 0.433
Epoch 206 Batch   34/44   train_loss = 0.407
Epoch 206 Batch   35/44   train_loss = 0.386
Epoch 206 Batch   36/44   train_loss = 0.440
Epoch 206 Batch   37/44   train_loss = 0.385
Epoch 206 Batch   38/44   train_loss = 0.393
Epoch 206 Batch   39/44   train_loss = 0.374
Epoch 206 Batch   40/44   train_loss = 0.359
Epoch 206 Batch   41/44   train_loss = 0.378
Epoch 206 Batch   42/44   train_loss = 0.356
Epoch 206 Batch   43/44   train_loss = 0.365
Epoch 207 Batch    0/44   train_loss = 0.373
Epoch 207 Batch    1/44   train_loss = 0.377
Epoch 207 Batch    2/44   train_loss = 0.398
Epoch 207 Batch    3/44   train_loss = 0.415
Epoch 207 Batch    4/44   train_loss = 0.371
Epoch 207 Batch    5/44   train_loss = 0.391
Epoch 207 Batch    6/44   train_loss = 0.392
Epoch 207 Batch    7/44   train_loss = 0.400
Epoch 207 Batch    8/44   train_loss = 0.416
Epoch 207 Batch    9/44   train_loss = 0.433
Epoch 207 Batch   10/44   train_loss = 0.399
Epoch 207 Batch   11/44   train_loss = 0.420
Epoch 207 Batch   12/44   train_loss = 0.396
Epoch 207 Batch   13/44   train_loss = 0.395
Epoch 207 Batch   14/44   train_loss = 0.379
Epoch 207 Batch   15/44   train_loss = 0.392
Epoch 207 Batch   16/44   train_loss = 0.377
Epoch 207 Batch   17/44   train_loss = 0.394
Epoch 207 Batch   18/44   train_loss = 0.394
Epoch 207 Batch   19/44   train_loss = 0.395
Epoch 207 Batch   20/44   train_loss = 0.388
Epoch 207 Batch   21/44   train_loss = 0.365
Epoch 207 Batch   22/44   train_loss = 0.421
Epoch 207 Batch   23/44   train_loss = 0.395
Epoch 207 Batch   24/44   train_loss = 0.379
Epoch 207 Batch   25/44   train_loss = 0.423
Epoch 207 Batch   26/44   train_loss = 0.410
Epoch 207 Batch   27/44   train_loss = 0.409
Epoch 207 Batch   28/44   train_loss = 0.375
Epoch 207 Batch   29/44   train_loss = 0.392
Epoch 207 Batch   30/44   train_loss = 0.379
Epoch 207 Batch   31/44   train_loss = 0.387
Epoch 207 Batch   32/44   train_loss = 0.371
Epoch 207 Batch   33/44   train_loss = 0.426
Epoch 207 Batch   34/44   train_loss = 0.401
Epoch 207 Batch   35/44   train_loss = 0.383
Epoch 207 Batch   36/44   train_loss = 0.447
Epoch 207 Batch   37/44   train_loss = 0.393
Epoch 207 Batch   38/44   train_loss = 0.404
Epoch 207 Batch   39/44   train_loss = 0.388
Epoch 207 Batch   40/44   train_loss = 0.368
Epoch 207 Batch   41/44   train_loss = 0.386
Epoch 207 Batch   42/44   train_loss = 0.360
Epoch 207 Batch   43/44   train_loss = 0.364
Epoch 208 Batch    0/44   train_loss = 0.373
Epoch 208 Batch    1/44   train_loss = 0.375
Epoch 208 Batch    2/44   train_loss = 0.398
Epoch 208 Batch    3/44   train_loss = 0.413
Epoch 208 Batch    4/44   train_loss = 0.370
Epoch 208 Batch    5/44   train_loss = 0.393
Epoch 208 Batch    6/44   train_loss = 0.394
Epoch 208 Batch    7/44   train_loss = 0.398
Epoch 208 Batch    8/44   train_loss = 0.414
Epoch 208 Batch    9/44   train_loss = 0.426
Epoch 208 Batch   10/44   train_loss = 0.390
Epoch 208 Batch   11/44   train_loss = 0.412
Epoch 208 Batch   12/44   train_loss = 0.396
Epoch 208 Batch   13/44   train_loss = 0.397
Epoch 208 Batch   14/44   train_loss = 0.381
Epoch 208 Batch   15/44   train_loss = 0.394
Epoch 208 Batch   16/44   train_loss = 0.375
Epoch 208 Batch   17/44   train_loss = 0.389
Epoch 208 Batch   18/44   train_loss = 0.384
Epoch 208 Batch   19/44   train_loss = 0.382
Epoch 208 Batch   20/44   train_loss = 0.373
Epoch 208 Batch   21/44   train_loss = 0.346
Epoch 208 Batch   22/44   train_loss = 0.403
Epoch 208 Batch   23/44   train_loss = 0.381
Epoch 208 Batch   24/44   train_loss = 0.369
Epoch 208 Batch   25/44   train_loss = 0.416
Epoch 208 Batch   26/44   train_loss = 0.408
Epoch 208 Batch   27/44   train_loss = 0.405
Epoch 208 Batch   28/44   train_loss = 0.375
Epoch 208 Batch   29/44   train_loss = 0.390
Epoch 208 Batch   30/44   train_loss = 0.371
Epoch 208 Batch   31/44   train_loss = 0.378
Epoch 208 Batch   32/44   train_loss = 0.363
Epoch 208 Batch   33/44   train_loss = 0.413
Epoch 208 Batch   34/44   train_loss = 0.389
Epoch 208 Batch   35/44   train_loss = 0.370
Epoch 208 Batch   36/44   train_loss = 0.433
Epoch 208 Batch   37/44   train_loss = 0.382
Epoch 208 Batch   38/44   train_loss = 0.404
Epoch 208 Batch   39/44   train_loss = 0.384
Epoch 208 Batch   40/44   train_loss = 0.378
Epoch 208 Batch   41/44   train_loss = 0.398
Epoch 208 Batch   42/44   train_loss = 0.370
Epoch 208 Batch   43/44   train_loss = 0.376
Epoch 209 Batch    0/44   train_loss = 0.380
Epoch 209 Batch    1/44   train_loss = 0.377
Epoch 209 Batch    2/44   train_loss = 0.397
Epoch 209 Batch    3/44   train_loss = 0.407
Epoch 209 Batch    4/44   train_loss = 0.367
Epoch 209 Batch    5/44   train_loss = 0.388
Epoch 209 Batch    6/44   train_loss = 0.391
Epoch 209 Batch    7/44   train_loss = 0.401
Epoch 209 Batch    8/44   train_loss = 0.419
Epoch 209 Batch    9/44   train_loss = 0.432
Epoch 209 Batch   10/44   train_loss = 0.397
Epoch 209 Batch   11/44   train_loss = 0.420
Epoch 209 Batch   12/44   train_loss = 0.404
Epoch 209 Batch   13/44   train_loss = 0.400
Epoch 209 Batch   14/44   train_loss = 0.384
Epoch 209 Batch   15/44   train_loss = 0.395
Epoch 209 Batch   16/44   train_loss = 0.377
Epoch 209 Batch   17/44   train_loss = 0.395
Epoch 209 Batch   18/44   train_loss = 0.387
Epoch 209 Batch   19/44   train_loss = 0.384
Epoch 209 Batch   20/44   train_loss = 0.371
Epoch 209 Batch   21/44   train_loss = 0.342
Epoch 209 Batch   22/44   train_loss = 0.395
Epoch 209 Batch   23/44   train_loss = 0.373
Epoch 209 Batch   24/44   train_loss = 0.356
Epoch 209 Batch   25/44   train_loss = 0.399
Epoch 209 Batch   26/44   train_loss = 0.396
Epoch 209 Batch   27/44   train_loss = 0.396
Epoch 209 Batch   28/44   train_loss = 0.370
Epoch 209 Batch   29/44   train_loss = 0.386
Epoch 209 Batch   30/44   train_loss = 0.371
Epoch 209 Batch   31/44   train_loss = 0.379
Epoch 209 Batch   32/44   train_loss = 0.359
Epoch 209 Batch   33/44   train_loss = 0.408
Epoch 209 Batch   34/44   train_loss = 0.381
Epoch 209 Batch   35/44   train_loss = 0.361
Epoch 209 Batch   36/44   train_loss = 0.417
Epoch 209 Batch   37/44   train_loss = 0.370
Epoch 209 Batch   38/44   train_loss = 0.386
Epoch 209 Batch   39/44   train_loss = 0.366
Epoch 209 Batch   40/44   train_loss = 0.359
Epoch 209 Batch   41/44   train_loss = 0.387
Epoch 209 Batch   42/44   train_loss = 0.364
Epoch 209 Batch   43/44   train_loss = 0.378
Epoch 210 Batch    0/44   train_loss = 0.387
Epoch 210 Batch    1/44   train_loss = 0.385
Epoch 210 Batch    2/44   train_loss = 0.403
Epoch 210 Batch    3/44   train_loss = 0.409
Epoch 210 Batch    4/44   train_loss = 0.366
Epoch 210 Batch    5/44   train_loss = 0.384
Epoch 210 Batch    6/44   train_loss = 0.381
Epoch 210 Batch    7/44   train_loss = 0.386
Epoch 210 Batch    8/44   train_loss = 0.403
Epoch 210 Batch    9/44   train_loss = 0.424
Epoch 210 Batch   10/44   train_loss = 0.396
Epoch 210 Batch   11/44   train_loss = 0.433
Epoch 210 Batch   12/44   train_loss = 0.421
Epoch 210 Batch   13/44   train_loss = 0.413
Epoch 210 Batch   14/44   train_loss = 0.400
Epoch 210 Batch   15/44   train_loss = 0.405
Epoch 210 Batch   16/44   train_loss = 0.380
Epoch 210 Batch   17/44   train_loss = 0.395
Epoch 210 Batch   18/44   train_loss = 0.388
Epoch 210 Batch   19/44   train_loss = 0.386
Epoch 210 Batch   20/44   train_loss = 0.374
Epoch 210 Batch   21/44   train_loss = 0.347
Epoch 210 Batch   22/44   train_loss = 0.402
Epoch 210 Batch   23/44   train_loss = 0.382
Epoch 210 Batch   24/44   train_loss = 0.357
Epoch 210 Batch   25/44   train_loss = 0.400
Epoch 210 Batch   26/44   train_loss = 0.391
Epoch 210 Batch   27/44   train_loss = 0.387
Epoch 210 Batch   28/44   train_loss = 0.359
Epoch 210 Batch   29/44   train_loss = 0.378
Epoch 210 Batch   30/44   train_loss = 0.366
Epoch 210 Batch   31/44   train_loss = 0.377
Epoch 210 Batch   32/44   train_loss = 0.358
Epoch 210 Batch   33/44   train_loss = 0.409
Epoch 210 Batch   34/44   train_loss = 0.382
Epoch 210 Batch   35/44   train_loss = 0.361
Epoch 210 Batch   36/44   train_loss = 0.413
Epoch 210 Batch   37/44   train_loss = 0.362
Epoch 210 Batch   38/44   train_loss = 0.378
Epoch 210 Batch   39/44   train_loss = 0.355
Epoch 210 Batch   40/44   train_loss = 0.348
Epoch 210 Batch   41/44   train_loss = 0.373
Epoch 210 Batch   42/44   train_loss = 0.353
Epoch 210 Batch   43/44   train_loss = 0.363
Epoch 211 Batch    0/44   train_loss = 0.375
Epoch 211 Batch    1/44   train_loss = 0.380
Epoch 211 Batch    2/44   train_loss = 0.401
Epoch 211 Batch    3/44   train_loss = 0.414
Epoch 211 Batch    4/44   train_loss = 0.368
Epoch 211 Batch    5/44   train_loss = 0.384
Epoch 211 Batch    6/44   train_loss = 0.378
Epoch 211 Batch    7/44   train_loss = 0.384
Epoch 211 Batch    8/44   train_loss = 0.393
Epoch 211 Batch    9/44   train_loss = 0.416
Epoch 211 Batch   10/44   train_loss = 0.384
Epoch 211 Batch   11/44   train_loss = 0.418
Epoch 211 Batch   12/44   train_loss = 0.405
Epoch 211 Batch   13/44   train_loss = 0.408
Epoch 211 Batch   14/44   train_loss = 0.405
Epoch 211 Batch   15/44   train_loss = 0.418
Epoch 211 Batch   16/44   train_loss = 0.395
Epoch 211 Batch   17/44   train_loss = 0.413
Epoch 211 Batch   18/44   train_loss = 0.396
Epoch 211 Batch   19/44   train_loss = 0.388
Epoch 211 Batch   20/44   train_loss = 0.374
Epoch 211 Batch   21/44   train_loss = 0.345
Epoch 211 Batch   22/44   train_loss = 0.399
Epoch 211 Batch   23/44   train_loss = 0.383
Epoch 211 Batch   24/44   train_loss = 0.361
Epoch 211 Batch   25/44   train_loss = 0.409
Epoch 211 Batch   26/44   train_loss = 0.403
Epoch 211 Batch   27/44   train_loss = 0.400
Epoch 211 Batch   28/44   train_loss = 0.365
Epoch 211 Batch   29/44   train_loss = 0.378
Epoch 211 Batch   30/44   train_loss = 0.363
Epoch 211 Batch   31/44   train_loss = 0.371
Epoch 211 Batch   32/44   train_loss = 0.356
Epoch 211 Batch   33/44   train_loss = 0.407
Epoch 211 Batch   34/44   train_loss = 0.382
Epoch 211 Batch   35/44   train_loss = 0.364
Epoch 211 Batch   36/44   train_loss = 0.417
Epoch 211 Batch   37/44   train_loss = 0.364
Epoch 211 Batch   38/44   train_loss = 0.378
Epoch 211 Batch   39/44   train_loss = 0.352
Epoch 211 Batch   40/44   train_loss = 0.341
Epoch 211 Batch   41/44   train_loss = 0.363
Epoch 211 Batch   42/44   train_loss = 0.340
Epoch 211 Batch   43/44   train_loss = 0.354
Epoch 212 Batch    0/44   train_loss = 0.365
Epoch 212 Batch    1/44   train_loss = 0.372
Epoch 212 Batch    2/44   train_loss = 0.395
Epoch 212 Batch    3/44   train_loss = 0.412
Epoch 212 Batch    4/44   train_loss = 0.365
Epoch 212 Batch    5/44   train_loss = 0.379
Epoch 212 Batch    6/44   train_loss = 0.372
Epoch 212 Batch    7/44   train_loss = 0.377
Epoch 212 Batch    8/44   train_loss = 0.385
Epoch 212 Batch    9/44   train_loss = 0.408
Epoch 212 Batch   10/44   train_loss = 0.377
Epoch 212 Batch   11/44   train_loss = 0.412
Epoch 212 Batch   12/44   train_loss = 0.396
Epoch 212 Batch   13/44   train_loss = 0.400
Epoch 212 Batch   14/44   train_loss = 0.396
Epoch 212 Batch   15/44   train_loss = 0.409
Epoch 212 Batch   16/44   train_loss = 0.392
Epoch 212 Batch   17/44   train_loss = 0.414
Epoch 212 Batch   18/44   train_loss = 0.400
Epoch 212 Batch   19/44   train_loss = 0.390
Epoch 212 Batch   20/44   train_loss = 0.379
Epoch 212 Batch   21/44   train_loss = 0.347
Epoch 212 Batch   22/44   train_loss = 0.397
Epoch 212 Batch   23/44   train_loss = 0.381
Epoch 212 Batch   24/44   train_loss = 0.361
Epoch 212 Batch   25/44   train_loss = 0.410
Epoch 212 Batch   26/44   train_loss = 0.404
Epoch 212 Batch   27/44   train_loss = 0.409
Epoch 212 Batch   28/44   train_loss = 0.372
Epoch 212 Batch   29/44   train_loss = 0.383
Epoch 212 Batch   30/44   train_loss = 0.372
Epoch 212 Batch   31/44   train_loss = 0.377
Epoch 212 Batch   32/44   train_loss = 0.359
Epoch 212 Batch   33/44   train_loss = 0.409
Epoch 212 Batch   34/44   train_loss = 0.382
Epoch 212 Batch   35/44   train_loss = 0.365
Epoch 212 Batch   36/44   train_loss = 0.423
Epoch 212 Batch   37/44   train_loss = 0.369
Epoch 212 Batch   38/44   train_loss = 0.386
Epoch 212 Batch   39/44   train_loss = 0.359
Epoch 212 Batch   40/44   train_loss = 0.349
Epoch 212 Batch   41/44   train_loss = 0.369
Epoch 212 Batch   42/44   train_loss = 0.342
Epoch 212 Batch   43/44   train_loss = 0.351
Epoch 213 Batch    0/44   train_loss = 0.360
Epoch 213 Batch    1/44   train_loss = 0.362
Epoch 213 Batch    2/44   train_loss = 0.388
Epoch 213 Batch    3/44   train_loss = 0.406
Epoch 213 Batch    4/44   train_loss = 0.359
Epoch 213 Batch    5/44   train_loss = 0.378
Epoch 213 Batch    6/44   train_loss = 0.370
Epoch 213 Batch    7/44   train_loss = 0.372
Epoch 213 Batch    8/44   train_loss = 0.380
Epoch 213 Batch    9/44   train_loss = 0.402
Epoch 213 Batch   10/44   train_loss = 0.368
Epoch 213 Batch   11/44   train_loss = 0.406
Epoch 213 Batch   12/44   train_loss = 0.388
Epoch 213 Batch   13/44   train_loss = 0.394
Epoch 213 Batch   14/44   train_loss = 0.391
Epoch 213 Batch   15/44   train_loss = 0.403
Epoch 213 Batch   16/44   train_loss = 0.388
Epoch 213 Batch   17/44   train_loss = 0.408
Epoch 213 Batch   18/44   train_loss = 0.393
Epoch 213 Batch   19/44   train_loss = 0.384
Epoch 213 Batch   20/44   train_loss = 0.375
Epoch 213 Batch   21/44   train_loss = 0.341
Epoch 213 Batch   22/44   train_loss = 0.393
Epoch 213 Batch   23/44   train_loss = 0.378
Epoch 213 Batch   24/44   train_loss = 0.362
Epoch 213 Batch   25/44   train_loss = 0.413
Epoch 213 Batch   26/44   train_loss = 0.408
Epoch 213 Batch   27/44   train_loss = 0.414
Epoch 213 Batch   28/44   train_loss = 0.375
Epoch 213 Batch   29/44   train_loss = 0.385
Epoch 213 Batch   30/44   train_loss = 0.376
Epoch 213 Batch   31/44   train_loss = 0.377
Epoch 213 Batch   32/44   train_loss = 0.358
Epoch 213 Batch   33/44   train_loss = 0.409
Epoch 213 Batch   34/44   train_loss = 0.383
Epoch 213 Batch   35/44   train_loss = 0.367
Epoch 213 Batch   36/44   train_loss = 0.427
Epoch 213 Batch   37/44   train_loss = 0.375
Epoch 213 Batch   38/44   train_loss = 0.392
Epoch 213 Batch   39/44   train_loss = 0.367
Epoch 213 Batch   40/44   train_loss = 0.351
Epoch 213 Batch   41/44   train_loss = 0.374
Epoch 213 Batch   42/44   train_loss = 0.349
Epoch 213 Batch   43/44   train_loss = 0.356
Epoch 214 Batch    0/44   train_loss = 0.367
Epoch 214 Batch    1/44   train_loss = 0.366
Epoch 214 Batch    2/44   train_loss = 0.394
Epoch 214 Batch    3/44   train_loss = 0.411
Epoch 214 Batch    4/44   train_loss = 0.359
Epoch 214 Batch    5/44   train_loss = 0.375
Epoch 214 Batch    6/44   train_loss = 0.365
Epoch 214 Batch    7/44   train_loss = 0.368
Epoch 214 Batch    8/44   train_loss = 0.378
Epoch 214 Batch    9/44   train_loss = 0.399
Epoch 214 Batch   10/44   train_loss = 0.364
Epoch 214 Batch   11/44   train_loss = 0.402
Epoch 214 Batch   12/44   train_loss = 0.383
Epoch 214 Batch   13/44   train_loss = 0.389
Epoch 214 Batch   14/44   train_loss = 0.381
Epoch 214 Batch   15/44   train_loss = 0.398
Epoch 214 Batch   16/44   train_loss = 0.385
Epoch 214 Batch   17/44   train_loss = 0.405
Epoch 214 Batch   18/44   train_loss = 0.391
Epoch 214 Batch   19/44   train_loss = 0.383
Epoch 214 Batch   20/44   train_loss = 0.373
Epoch 214 Batch   21/44   train_loss = 0.334
Epoch 214 Batch   22/44   train_loss = 0.378
Epoch 214 Batch   23/44   train_loss = 0.361
Epoch 214 Batch   24/44   train_loss = 0.348
Epoch 214 Batch   25/44   train_loss = 0.400
Epoch 214 Batch   26/44   train_loss = 0.398
Epoch 214 Batch   27/44   train_loss = 0.415
Epoch 214 Batch   28/44   train_loss = 0.387
Epoch 214 Batch   29/44   train_loss = 0.396
Epoch 214 Batch   30/44   train_loss = 0.385
Epoch 214 Batch   31/44   train_loss = 0.382
Epoch 214 Batch   32/44   train_loss = 0.357
Epoch 214 Batch   33/44   train_loss = 0.402
Epoch 214 Batch   34/44   train_loss = 0.377
Epoch 214 Batch   35/44   train_loss = 0.360
Epoch 214 Batch   36/44   train_loss = 0.428
Epoch 214 Batch   37/44   train_loss = 0.379
Epoch 214 Batch   38/44   train_loss = 0.397
Epoch 214 Batch   39/44   train_loss = 0.379
Epoch 214 Batch   40/44   train_loss = 0.357
Epoch 214 Batch   41/44   train_loss = 0.380
Epoch 214 Batch   42/44   train_loss = 0.351
Epoch 214 Batch   43/44   train_loss = 0.357
Epoch 215 Batch    0/44   train_loss = 0.366
Epoch 215 Batch    1/44   train_loss = 0.370
Epoch 215 Batch    2/44   train_loss = 0.398
Epoch 215 Batch    3/44   train_loss = 0.418
Epoch 215 Batch    4/44   train_loss = 0.366
Epoch 215 Batch    5/44   train_loss = 0.384
Epoch 215 Batch    6/44   train_loss = 0.373
Epoch 215 Batch    7/44   train_loss = 0.371
Epoch 215 Batch    8/44   train_loss = 0.379
Epoch 215 Batch    9/44   train_loss = 0.397
Epoch 215 Batch   10/44   train_loss = 0.359
Epoch 215 Batch   11/44   train_loss = 0.396
Epoch 215 Batch   12/44   train_loss = 0.377
Epoch 215 Batch   13/44   train_loss = 0.387
Epoch 215 Batch   14/44   train_loss = 0.379
Epoch 215 Batch   15/44   train_loss = 0.399
Epoch 215 Batch   16/44   train_loss = 0.386
Epoch 215 Batch   17/44   train_loss = 0.404
Epoch 215 Batch   18/44   train_loss = 0.388
Epoch 215 Batch   19/44   train_loss = 0.380
Epoch 215 Batch   20/44   train_loss = 0.373
Epoch 215 Batch   21/44   train_loss = 0.332
Epoch 215 Batch   22/44   train_loss = 0.376
Epoch 215 Batch   23/44   train_loss = 0.355
Epoch 215 Batch   24/44   train_loss = 0.338
Epoch 215 Batch   25/44   train_loss = 0.389
Epoch 215 Batch   26/44   train_loss = 0.382
Epoch 215 Batch   27/44   train_loss = 0.399
Epoch 215 Batch   28/44   train_loss = 0.374
Epoch 215 Batch   29/44   train_loss = 0.391
Epoch 215 Batch   30/44   train_loss = 0.391
Epoch 215 Batch   31/44   train_loss = 0.391
Epoch 215 Batch   32/44   train_loss = 0.369
Epoch 215 Batch   33/44   train_loss = 0.410
Epoch 215 Batch   34/44   train_loss = 0.377
Epoch 215 Batch   35/44   train_loss = 0.350
Epoch 215 Batch   36/44   train_loss = 0.408
Epoch 215 Batch   37/44   train_loss = 0.368
Epoch 215 Batch   38/44   train_loss = 0.388
Epoch 215 Batch   39/44   train_loss = 0.379
Epoch 215 Batch   40/44   train_loss = 0.366
Epoch 215 Batch   41/44   train_loss = 0.398
Epoch 215 Batch   42/44   train_loss = 0.361
Epoch 215 Batch   43/44   train_loss = 0.367
Epoch 216 Batch    0/44   train_loss = 0.366
Epoch 216 Batch    1/44   train_loss = 0.368
Epoch 216 Batch    2/44   train_loss = 0.389
Epoch 216 Batch    3/44   train_loss = 0.413
Epoch 216 Batch    4/44   train_loss = 0.367
Epoch 216 Batch    5/44   train_loss = 0.395
Epoch 216 Batch    6/44   train_loss = 0.394
Epoch 216 Batch    7/44   train_loss = 0.390
Epoch 216 Batch    8/44   train_loss = 0.391
Epoch 216 Batch    9/44   train_loss = 0.404
Epoch 216 Batch   10/44   train_loss = 0.362
Epoch 216 Batch   11/44   train_loss = 0.391
Epoch 216 Batch   12/44   train_loss = 0.368
Epoch 216 Batch   13/44   train_loss = 0.382
Epoch 216 Batch   14/44   train_loss = 0.373
Epoch 216 Batch   15/44   train_loss = 0.394
Epoch 216 Batch   16/44   train_loss = 0.389
Epoch 216 Batch   17/44   train_loss = 0.413
Epoch 216 Batch   18/44   train_loss = 0.400
Epoch 216 Batch   19/44   train_loss = 0.392
Epoch 216 Batch   20/44   train_loss = 0.377
Epoch 216 Batch   21/44   train_loss = 0.332
Epoch 216 Batch   22/44   train_loss = 0.380
Epoch 216 Batch   23/44   train_loss = 0.354
Epoch 216 Batch   24/44   train_loss = 0.331
Epoch 216 Batch   25/44   train_loss = 0.383
Epoch 216 Batch   26/44   train_loss = 0.378
Epoch 216 Batch   27/44   train_loss = 0.391
Epoch 216 Batch   28/44   train_loss = 0.365
Epoch 216 Batch   29/44   train_loss = 0.382
Epoch 216 Batch   30/44   train_loss = 0.380
Epoch 216 Batch   31/44   train_loss = 0.387
Epoch 216 Batch   32/44   train_loss = 0.376
Epoch 216 Batch   33/44   train_loss = 0.410
Epoch 216 Batch   34/44   train_loss = 0.384
Epoch 216 Batch   35/44   train_loss = 0.353
Epoch 216 Batch   36/44   train_loss = 0.405
Epoch 216 Batch   37/44   train_loss = 0.357
Epoch 216 Batch   38/44   train_loss = 0.372
Epoch 216 Batch   39/44   train_loss = 0.362
Epoch 216 Batch   40/44   train_loss = 0.347
Epoch 216 Batch   41/44   train_loss = 0.386
Epoch 216 Batch   42/44   train_loss = 0.358
Epoch 216 Batch   43/44   train_loss = 0.383
Epoch 217 Batch    0/44   train_loss = 0.379
Epoch 217 Batch    1/44   train_loss = 0.390
Epoch 217 Batch    2/44   train_loss = 0.392
Epoch 217 Batch    3/44   train_loss = 0.414
Epoch 217 Batch    4/44   train_loss = 0.357
Epoch 217 Batch    5/44   train_loss = 0.380
Epoch 217 Batch    6/44   train_loss = 0.384
Epoch 217 Batch    7/44   train_loss = 0.391
Epoch 217 Batch    8/44   train_loss = 0.414
Epoch 217 Batch    9/44   train_loss = 0.433
Epoch 217 Batch   10/44   train_loss = 0.389
Epoch 217 Batch   11/44   train_loss = 0.401
Epoch 217 Batch   12/44   train_loss = 0.370
Epoch 217 Batch   13/44   train_loss = 0.378
Epoch 217 Batch   14/44   train_loss = 0.360
Epoch 217 Batch   15/44   train_loss = 0.383
Epoch 217 Batch   16/44   train_loss = 0.374
Epoch 217 Batch   17/44   train_loss = 0.408
Epoch 217 Batch   18/44   train_loss = 0.408
Epoch 217 Batch   19/44   train_loss = 0.415
Epoch 217 Batch   20/44   train_loss = 0.397
Epoch 217 Batch   21/44   train_loss = 0.347
Epoch 217 Batch   22/44   train_loss = 0.394
Epoch 217 Batch   23/44   train_loss = 0.361
Epoch 217 Batch   24/44   train_loss = 0.332
Epoch 217 Batch   25/44   train_loss = 0.382
Epoch 217 Batch   26/44   train_loss = 0.376
Epoch 217 Batch   27/44   train_loss = 0.388
Epoch 217 Batch   28/44   train_loss = 0.359
Epoch 217 Batch   29/44   train_loss = 0.376
Epoch 217 Batch   30/44   train_loss = 0.381
Epoch 217 Batch   31/44   train_loss = 0.386
Epoch 217 Batch   32/44   train_loss = 0.376
Epoch 217 Batch   33/44   train_loss = 0.411
Epoch 217 Batch   34/44   train_loss = 0.386
Epoch 217 Batch   35/44   train_loss = 0.357
Epoch 217 Batch   36/44   train_loss = 0.405
Epoch 217 Batch   37/44   train_loss = 0.355
Epoch 217 Batch   38/44   train_loss = 0.370
Epoch 217 Batch   39/44   train_loss = 0.357
Epoch 217 Batch   40/44   train_loss = 0.338
Epoch 217 Batch   41/44   train_loss = 0.372
Epoch 217 Batch   42/44   train_loss = 0.348
Epoch 217 Batch   43/44   train_loss = 0.370
Epoch 218 Batch    0/44   train_loss = 0.368
Epoch 218 Batch    1/44   train_loss = 0.387
Epoch 218 Batch    2/44   train_loss = 0.396
Epoch 218 Batch    3/44   train_loss = 0.422
Epoch 218 Batch    4/44   train_loss = 0.364
Epoch 218 Batch    5/44   train_loss = 0.380
Epoch 218 Batch    6/44   train_loss = 0.375
Epoch 218 Batch    7/44   train_loss = 0.374
Epoch 218 Batch    8/44   train_loss = 0.391
Epoch 218 Batch    9/44   train_loss = 0.420
Epoch 218 Batch   10/44   train_loss = 0.392
Epoch 218 Batch   11/44   train_loss = 0.418
Epoch 218 Batch   12/44   train_loss = 0.393
Epoch 218 Batch   13/44   train_loss = 0.398
Epoch 218 Batch   14/44   train_loss = 0.375
Epoch 218 Batch   15/44   train_loss = 0.388
Epoch 218 Batch   16/44   train_loss = 0.360
Epoch 218 Batch   17/44   train_loss = 0.383
Epoch 218 Batch   18/44   train_loss = 0.377
Epoch 218 Batch   19/44   train_loss = 0.390
Epoch 218 Batch   20/44   train_loss = 0.399
Epoch 218 Batch   21/44   train_loss = 0.374
Epoch 218 Batch   22/44   train_loss = 0.438
Epoch 218 Batch   23/44   train_loss = 0.397
Epoch 218 Batch   24/44   train_loss = 0.363
Epoch 218 Batch   25/44   train_loss = 0.399
Epoch 218 Batch   26/44   train_loss = 0.378
Epoch 218 Batch   27/44   train_loss = 0.382
Epoch 218 Batch   28/44   train_loss = 0.351
Epoch 218 Batch   29/44   train_loss = 0.374
Epoch 218 Batch   30/44   train_loss = 0.379
Epoch 218 Batch   31/44   train_loss = 0.396
Epoch 218 Batch   32/44   train_loss = 0.395
Epoch 218 Batch   33/44   train_loss = 0.426
Epoch 218 Batch   34/44   train_loss = 0.400
Epoch 218 Batch   35/44   train_loss = 0.370
Epoch 218 Batch   36/44   train_loss = 0.409
Epoch 218 Batch   37/44   train_loss = 0.359
Epoch 218 Batch   38/44   train_loss = 0.369
Epoch 218 Batch   39/44   train_loss = 0.352
Epoch 218 Batch   40/44   train_loss = 0.336
Epoch 218 Batch   41/44   train_loss = 0.369
Epoch 218 Batch   42/44   train_loss = 0.342
Epoch 218 Batch   43/44   train_loss = 0.360
Epoch 219 Batch    0/44   train_loss = 0.362
Epoch 219 Batch    1/44   train_loss = 0.378
Epoch 219 Batch    2/44   train_loss = 0.392
Epoch 219 Batch    3/44   train_loss = 0.420
Epoch 219 Batch    4/44   train_loss = 0.366
Epoch 219 Batch    5/44   train_loss = 0.381
Epoch 219 Batch    6/44   train_loss = 0.372
Epoch 219 Batch    7/44   train_loss = 0.372
Epoch 219 Batch    8/44   train_loss = 0.382
Epoch 219 Batch    9/44   train_loss = 0.409
Epoch 219 Batch   10/44   train_loss = 0.377
Epoch 219 Batch   11/44   train_loss = 0.405
Epoch 219 Batch   12/44   train_loss = 0.388
Epoch 219 Batch   13/44   train_loss = 0.401
Epoch 219 Batch   14/44   train_loss = 0.379
Epoch 219 Batch   15/44   train_loss = 0.405
Epoch 219 Batch   16/44   train_loss = 0.370
Epoch 219 Batch   17/44   train_loss = 0.395
Epoch 219 Batch   18/44   train_loss = 0.380
Epoch 219 Batch   19/44   train_loss = 0.371
Epoch 219 Batch   20/44   train_loss = 0.375
Epoch 219 Batch   21/44   train_loss = 0.341
Epoch 219 Batch   22/44   train_loss = 0.407
Epoch 219 Batch   23/44   train_loss = 0.391
Epoch 219 Batch   24/44   train_loss = 0.383
Epoch 219 Batch   25/44   train_loss = 0.440
Epoch 219 Batch   26/44   train_loss = 0.408
Epoch 219 Batch   27/44   train_loss = 0.414
Epoch 219 Batch   28/44   train_loss = 0.367
Epoch 219 Batch   29/44   train_loss = 0.370
Epoch 219 Batch   30/44   train_loss = 0.355
Epoch 219 Batch   31/44   train_loss = 0.370
Epoch 219 Batch   32/44   train_loss = 0.365
Epoch 219 Batch   33/44   train_loss = 0.431
Epoch 219 Batch   34/44   train_loss = 0.430
Epoch 219 Batch   35/44   train_loss = 0.419
Epoch 219 Batch   36/44   train_loss = 0.463
Epoch 219 Batch   37/44   train_loss = 0.396
Epoch 219 Batch   38/44   train_loss = 0.386
Epoch 219 Batch   39/44   train_loss = 0.359
Epoch 219 Batch   40/44   train_loss = 0.337
Epoch 219 Batch   41/44   train_loss = 0.366
Epoch 219 Batch   42/44   train_loss = 0.342
Epoch 219 Batch   43/44   train_loss = 0.369
Epoch 220 Batch    0/44   train_loss = 0.376
Epoch 220 Batch    1/44   train_loss = 0.392
Epoch 220 Batch    2/44   train_loss = 0.408
Epoch 220 Batch    3/44   train_loss = 0.438
Epoch 220 Batch    4/44   train_loss = 0.374
Epoch 220 Batch    5/44   train_loss = 0.381
Epoch 220 Batch    6/44   train_loss = 0.372
Epoch 220 Batch    7/44   train_loss = 0.375
Epoch 220 Batch    8/44   train_loss = 0.385
Epoch 220 Batch    9/44   train_loss = 0.415
Epoch 220 Batch   10/44   train_loss = 0.376
Epoch 220 Batch   11/44   train_loss = 0.407
Epoch 220 Batch   12/44   train_loss = 0.387
Epoch 220 Batch   13/44   train_loss = 0.392
Epoch 220 Batch   14/44   train_loss = 0.376
Epoch 220 Batch   15/44   train_loss = 0.399
Epoch 220 Batch   16/44   train_loss = 0.369
Epoch 220 Batch   17/44   train_loss = 0.393
Epoch 220 Batch   18/44   train_loss = 0.380
Epoch 220 Batch   19/44   train_loss = 0.369
Epoch 220 Batch   20/44   train_loss = 0.369
Epoch 220 Batch   21/44   train_loss = 0.333
Epoch 220 Batch   22/44   train_loss = 0.390
Epoch 220 Batch   23/44   train_loss = 0.372
Epoch 220 Batch   24/44   train_loss = 0.357
Epoch 220 Batch   25/44   train_loss = 0.416
Epoch 220 Batch   26/44   train_loss = 0.402
Epoch 220 Batch   27/44   train_loss = 0.417
Epoch 220 Batch   28/44   train_loss = 0.379
Epoch 220 Batch   29/44   train_loss = 0.387
Epoch 220 Batch   30/44   train_loss = 0.367
Epoch 220 Batch   31/44   train_loss = 0.377
Epoch 220 Batch   32/44   train_loss = 0.361
Epoch 220 Batch   33/44   train_loss = 0.406
Epoch 220 Batch   34/44   train_loss = 0.389
Epoch 220 Batch   35/44   train_loss = 0.376
Epoch 220 Batch   36/44   train_loss = 0.445
Epoch 220 Batch   37/44   train_loss = 0.417
Epoch 220 Batch   38/44   train_loss = 0.434
Epoch 220 Batch   39/44   train_loss = 0.404
Epoch 220 Batch   40/44   train_loss = 0.364
Epoch 220 Batch   41/44   train_loss = 0.368
Epoch 220 Batch   42/44   train_loss = 0.341
Epoch 220 Batch   43/44   train_loss = 0.348
Epoch 221 Batch    0/44   train_loss = 0.354
Epoch 221 Batch    1/44   train_loss = 0.373
Epoch 221 Batch    2/44   train_loss = 0.406
Epoch 221 Batch    3/44   train_loss = 0.466
Epoch 221 Batch    4/44   train_loss = 0.419
Epoch 221 Batch    5/44   train_loss = 0.430
Epoch 221 Batch    6/44   train_loss = 0.396
Epoch 221 Batch    7/44   train_loss = 0.395
Epoch 221 Batch    8/44   train_loss = 0.395
Epoch 221 Batch    9/44   train_loss = 0.404
Epoch 221 Batch   10/44   train_loss = 0.372
Epoch 221 Batch   11/44   train_loss = 0.402
Epoch 221 Batch   12/44   train_loss = 0.391
Epoch 221 Batch   13/44   train_loss = 0.396
Epoch 221 Batch   14/44   train_loss = 0.391
Epoch 221 Batch   15/44   train_loss = 0.421
Epoch 221 Batch   16/44   train_loss = 0.380
Epoch 221 Batch   17/44   train_loss = 0.403
Epoch 221 Batch   18/44   train_loss = 0.380
Epoch 221 Batch   19/44   train_loss = 0.373
Epoch 221 Batch   20/44   train_loss = 0.364
Epoch 221 Batch   21/44   train_loss = 0.325
Epoch 221 Batch   22/44   train_loss = 0.378
Epoch 221 Batch   23/44   train_loss = 0.362
Epoch 221 Batch   24/44   train_loss = 0.354
Epoch 221 Batch   25/44   train_loss = 0.406
Epoch 221 Batch   26/44   train_loss = 0.399
Epoch 221 Batch   27/44   train_loss = 0.409
Epoch 221 Batch   28/44   train_loss = 0.373
Epoch 221 Batch   29/44   train_loss = 0.381
Epoch 221 Batch   30/44   train_loss = 0.361
Epoch 221 Batch   31/44   train_loss = 0.367
Epoch 221 Batch   32/44   train_loss = 0.344
Epoch 221 Batch   33/44   train_loss = 0.397
Epoch 221 Batch   34/44   train_loss = 0.377
Epoch 221 Batch   35/44   train_loss = 0.365
Epoch 221 Batch   36/44   train_loss = 0.417
Epoch 221 Batch   37/44   train_loss = 0.381
Epoch 221 Batch   38/44   train_loss = 0.403
Epoch 221 Batch   39/44   train_loss = 0.375
Epoch 221 Batch   40/44   train_loss = 0.374
Epoch 221 Batch   41/44   train_loss = 0.391
Epoch 221 Batch   42/44   train_loss = 0.366
Epoch 221 Batch   43/44   train_loss = 0.372
Epoch 222 Batch    0/44   train_loss = 0.361
Epoch 222 Batch    1/44   train_loss = 0.357
Epoch 222 Batch    2/44   train_loss = 0.374
Epoch 222 Batch    3/44   train_loss = 0.404
Epoch 222 Batch    4/44   train_loss = 0.374
Epoch 222 Batch    5/44   train_loss = 0.397
Epoch 222 Batch    6/44   train_loss = 0.418
Epoch 222 Batch    7/44   train_loss = 0.440
Epoch 222 Batch    8/44   train_loss = 0.446
Epoch 222 Batch    9/44   train_loss = 0.429
Epoch 222 Batch   10/44   train_loss = 0.383
Epoch 222 Batch   11/44   train_loss = 0.402
Epoch 222 Batch   12/44   train_loss = 0.373
Epoch 222 Batch   13/44   train_loss = 0.380
Epoch 222 Batch   14/44   train_loss = 0.370
Epoch 222 Batch   15/44   train_loss = 0.406
Epoch 222 Batch   16/44   train_loss = 0.393
Epoch 222 Batch   17/44   train_loss = 0.409
Epoch 222 Batch   18/44   train_loss = 0.412
Epoch 222 Batch   19/44   train_loss = 0.422
Epoch 222 Batch   20/44   train_loss = 0.392
Epoch 222 Batch   21/44   train_loss = 0.336
Epoch 222 Batch   22/44   train_loss = 0.374
Epoch 222 Batch   23/44   train_loss = 0.361
Epoch 222 Batch   24/44   train_loss = 0.339
Epoch 222 Batch   25/44   train_loss = 0.392
Epoch 222 Batch   26/44   train_loss = 0.386
Epoch 222 Batch   27/44   train_loss = 0.404
Epoch 222 Batch   28/44   train_loss = 0.377
Epoch 222 Batch   29/44   train_loss = 0.392
Epoch 222 Batch   30/44   train_loss = 0.375
Epoch 222 Batch   31/44   train_loss = 0.375
Epoch 222 Batch   32/44   train_loss = 0.353
Epoch 222 Batch   33/44   train_loss = 0.400
Epoch 222 Batch   34/44   train_loss = 0.371
Epoch 222 Batch   35/44   train_loss = 0.347
Epoch 222 Batch   36/44   train_loss = 0.399
Epoch 222 Batch   37/44   train_loss = 0.360
Epoch 222 Batch   38/44   train_loss = 0.378
Epoch 222 Batch   39/44   train_loss = 0.365
Epoch 222 Batch   40/44   train_loss = 0.354
Epoch 222 Batch   41/44   train_loss = 0.376
Epoch 222 Batch   42/44   train_loss = 0.363
Epoch 222 Batch   43/44   train_loss = 0.377
Epoch 223 Batch    0/44   train_loss = 0.368
Epoch 223 Batch    1/44   train_loss = 0.366
Epoch 223 Batch    2/44   train_loss = 0.377
Epoch 223 Batch    3/44   train_loss = 0.392
Epoch 223 Batch    4/44   train_loss = 0.352
Epoch 223 Batch    5/44   train_loss = 0.362
Epoch 223 Batch    6/44   train_loss = 0.371
Epoch 223 Batch    7/44   train_loss = 0.382
Epoch 223 Batch    8/44   train_loss = 0.409
Epoch 223 Batch    9/44   train_loss = 0.434
Epoch 223 Batch   10/44   train_loss = 0.414
Epoch 223 Batch   11/44   train_loss = 0.448
Epoch 223 Batch   12/44   train_loss = 0.411
Epoch 223 Batch   13/44   train_loss = 0.396
Epoch 223 Batch   14/44   train_loss = 0.371
Epoch 223 Batch   15/44   train_loss = 0.389
Epoch 223 Batch   16/44   train_loss = 0.360
Epoch 223 Batch   17/44   train_loss = 0.376
Epoch 223 Batch   18/44   train_loss = 0.379
Epoch 223 Batch   19/44   train_loss = 0.399
Epoch 223 Batch   20/44   train_loss = 0.401
Epoch 223 Batch   21/44   train_loss = 0.374
Epoch 223 Batch   22/44   train_loss = 0.404
Epoch 223 Batch   23/44   train_loss = 0.384
Epoch 223 Batch   24/44   train_loss = 0.347
Epoch 223 Batch   25/44   train_loss = 0.387
Epoch 223 Batch   26/44   train_loss = 0.375
Epoch 223 Batch   27/44   train_loss = 0.380
Epoch 223 Batch   28/44   train_loss = 0.356
Epoch 223 Batch   29/44   train_loss = 0.376
Epoch 223 Batch   30/44   train_loss = 0.371
Epoch 223 Batch   31/44   train_loss = 0.382
Epoch 223 Batch   32/44   train_loss = 0.365
Epoch 223 Batch   33/44   train_loss = 0.412
Epoch 223 Batch   34/44   train_loss = 0.379
Epoch 223 Batch   35/44   train_loss = 0.356
Epoch 223 Batch   36/44   train_loss = 0.402
Epoch 223 Batch   37/44   train_loss = 0.351
Epoch 223 Batch   38/44   train_loss = 0.364
Epoch 223 Batch   39/44   train_loss = 0.344
Epoch 223 Batch   40/44   train_loss = 0.333
Epoch 223 Batch   41/44   train_loss = 0.357
Epoch 223 Batch   42/44   train_loss = 0.348
Epoch 223 Batch   43/44   train_loss = 0.360
Epoch 224 Batch    0/44   train_loss = 0.367
Epoch 224 Batch    1/44   train_loss = 0.379
Epoch 224 Batch    2/44   train_loss = 0.388
Epoch 224 Batch    3/44   train_loss = 0.404
Epoch 224 Batch    4/44   train_loss = 0.353
Epoch 224 Batch    5/44   train_loss = 0.362
Epoch 224 Batch    6/44   train_loss = 0.353
Epoch 224 Batch    7/44   train_loss = 0.358
Epoch 224 Batch    8/44   train_loss = 0.370
Epoch 224 Batch    9/44   train_loss = 0.394
Epoch 224 Batch   10/44   train_loss = 0.371
Epoch 224 Batch   11/44   train_loss = 0.416
Epoch 224 Batch   12/44   train_loss = 0.397
Epoch 224 Batch   13/44   train_loss = 0.406
Epoch 224 Batch   14/44   train_loss = 0.387
Epoch 224 Batch   15/44   train_loss = 0.406
Epoch 224 Batch   16/44   train_loss = 0.375
Epoch 224 Batch   17/44   train_loss = 0.382
Epoch 224 Batch   18/44   train_loss = 0.370
Epoch 224 Batch   19/44   train_loss = 0.363
Epoch 224 Batch   20/44   train_loss = 0.355
Epoch 224 Batch   21/44   train_loss = 0.329
Epoch 224 Batch   22/44   train_loss = 0.379
Epoch 224 Batch   23/44   train_loss = 0.372
Epoch 224 Batch   24/44   train_loss = 0.360
Epoch 224 Batch   25/44   train_loss = 0.409
Epoch 224 Batch   26/44   train_loss = 0.396
Epoch 224 Batch   27/44   train_loss = 0.394
Epoch 224 Batch   28/44   train_loss = 0.354
Epoch 224 Batch   29/44   train_loss = 0.358
Epoch 224 Batch   30/44   train_loss = 0.353
Epoch 224 Batch   31/44   train_loss = 0.363
Epoch 224 Batch   32/44   train_loss = 0.343
Epoch 224 Batch   33/44   train_loss = 0.394
Epoch 224 Batch   34/44   train_loss = 0.371
Epoch 224 Batch   35/44   train_loss = 0.356
Epoch 224 Batch   36/44   train_loss = 0.410
Epoch 224 Batch   37/44   train_loss = 0.357
Epoch 224 Batch   38/44   train_loss = 0.369
Epoch 224 Batch   39/44   train_loss = 0.342
Epoch 224 Batch   40/44   train_loss = 0.328
Epoch 224 Batch   41/44   train_loss = 0.345
Epoch 224 Batch   42/44   train_loss = 0.328
Epoch 224 Batch   43/44   train_loss = 0.336
Epoch 225 Batch    0/44   train_loss = 0.344
Epoch 225 Batch    1/44   train_loss = 0.357
Epoch 225 Batch    2/44   train_loss = 0.375
Epoch 225 Batch    3/44   train_loss = 0.401
Epoch 225 Batch    4/44   train_loss = 0.361
Epoch 225 Batch    5/44   train_loss = 0.373
Epoch 225 Batch    6/44   train_loss = 0.361
Epoch 225 Batch    7/44   train_loss = 0.361
Epoch 225 Batch    8/44   train_loss = 0.364
Epoch 225 Batch    9/44   train_loss = 0.386
Epoch 225 Batch   10/44   train_loss = 0.355
Epoch 225 Batch   11/44   train_loss = 0.380
Epoch 225 Batch   12/44   train_loss = 0.363
Epoch 225 Batch   13/44   train_loss = 0.381
Epoch 225 Batch   14/44   train_loss = 0.374
Epoch 225 Batch   15/44   train_loss = 0.391
Epoch 225 Batch   16/44   train_loss = 0.380
Epoch 225 Batch   17/44   train_loss = 0.394
Epoch 225 Batch   18/44   train_loss = 0.384
Epoch 225 Batch   19/44   train_loss = 0.370
Epoch 225 Batch   20/44   train_loss = 0.358
Epoch 225 Batch   21/44   train_loss = 0.323
Epoch 225 Batch   22/44   train_loss = 0.365
Epoch 225 Batch   23/44   train_loss = 0.348
Epoch 225 Batch   24/44   train_loss = 0.333
Epoch 225 Batch   25/44   train_loss = 0.384
Epoch 225 Batch   26/44   train_loss = 0.379
Epoch 225 Batch   27/44   train_loss = 0.390
Epoch 225 Batch   28/44   train_loss = 0.361
Epoch 225 Batch   29/44   train_loss = 0.367
Epoch 225 Batch   30/44   train_loss = 0.363
Epoch 225 Batch   31/44   train_loss = 0.368
Epoch 225 Batch   32/44   train_loss = 0.338
Epoch 225 Batch   33/44   train_loss = 0.380
Epoch 225 Batch   34/44   train_loss = 0.357
Epoch 225 Batch   35/44   train_loss = 0.336
Epoch 225 Batch   36/44   train_loss = 0.395
Epoch 225 Batch   37/44   train_loss = 0.347
Epoch 225 Batch   38/44   train_loss = 0.369
Epoch 225 Batch   39/44   train_loss = 0.339
Epoch 225 Batch   40/44   train_loss = 0.327
Epoch 225 Batch   41/44   train_loss = 0.346
Epoch 225 Batch   42/44   train_loss = 0.325
Epoch 225 Batch   43/44   train_loss = 0.330
Epoch 226 Batch    0/44   train_loss = 0.330
Epoch 226 Batch    1/44   train_loss = 0.337
Epoch 226 Batch    2/44   train_loss = 0.352
Epoch 226 Batch    3/44   train_loss = 0.382
Epoch 226 Batch    4/44   train_loss = 0.340
Epoch 226 Batch    5/44   train_loss = 0.358
Epoch 226 Batch    6/44   train_loss = 0.357
Epoch 226 Batch    7/44   train_loss = 0.363
Epoch 226 Batch    8/44   train_loss = 0.378
Epoch 226 Batch    9/44   train_loss = 0.396
Epoch 226 Batch   10/44   train_loss = 0.357
Epoch 226 Batch   11/44   train_loss = 0.378
Epoch 226 Batch   12/44   train_loss = 0.356
Epoch 226 Batch   13/44   train_loss = 0.366
Epoch 226 Batch   14/44   train_loss = 0.353
Epoch 226 Batch   15/44   train_loss = 0.375
Epoch 226 Batch   16/44   train_loss = 0.356
Epoch 226 Batch   17/44   train_loss = 0.377
Epoch 226 Batch   18/44   train_loss = 0.367
Epoch 226 Batch   19/44   train_loss = 0.370
Epoch 226 Batch   20/44   train_loss = 0.357
Epoch 226 Batch   21/44   train_loss = 0.323
Epoch 226 Batch   22/44   train_loss = 0.367
Epoch 226 Batch   23/44   train_loss = 0.349
Epoch 226 Batch   24/44   train_loss = 0.325
Epoch 226 Batch   25/44   train_loss = 0.377
Epoch 226 Batch   26/44   train_loss = 0.365
Epoch 226 Batch   27/44   train_loss = 0.375
Epoch 226 Batch   28/44   train_loss = 0.351
Epoch 226 Batch   29/44   train_loss = 0.362
Epoch 226 Batch   30/44   train_loss = 0.359
Epoch 226 Batch   31/44   train_loss = 0.361
Epoch 226 Batch   32/44   train_loss = 0.343
Epoch 226 Batch   33/44   train_loss = 0.382
Epoch 226 Batch   34/44   train_loss = 0.359
Epoch 226 Batch   35/44   train_loss = 0.334
Epoch 226 Batch   36/44   train_loss = 0.387
Epoch 226 Batch   37/44   train_loss = 0.341
Epoch 226 Batch   38/44   train_loss = 0.358
Epoch 226 Batch   39/44   train_loss = 0.331
Epoch 226 Batch   40/44   train_loss = 0.321
Epoch 226 Batch   41/44   train_loss = 0.346
Epoch 226 Batch   42/44   train_loss = 0.326
Epoch 226 Batch   43/44   train_loss = 0.332
Epoch 227 Batch    0/44   train_loss = 0.332
Epoch 227 Batch    1/44   train_loss = 0.338
Epoch 227 Batch    2/44   train_loss = 0.347
Epoch 227 Batch    3/44   train_loss = 0.373
Epoch 227 Batch    4/44   train_loss = 0.329
Epoch 227 Batch    5/44   train_loss = 0.345
Epoch 227 Batch    6/44   train_loss = 0.347
Epoch 227 Batch    7/44   train_loss = 0.349
Epoch 227 Batch    8/44   train_loss = 0.362
Epoch 227 Batch    9/44   train_loss = 0.385
Epoch 227 Batch   10/44   train_loss = 0.355
Epoch 227 Batch   11/44   train_loss = 0.380
Epoch 227 Batch   12/44   train_loss = 0.359
Epoch 227 Batch   13/44   train_loss = 0.368
Epoch 227 Batch   14/44   train_loss = 0.356
Epoch 227 Batch   15/44   train_loss = 0.371
Epoch 227 Batch   16/44   train_loss = 0.351
Epoch 227 Batch   17/44   train_loss = 0.365
Epoch 227 Batch   18/44   train_loss = 0.356
Epoch 227 Batch   19/44   train_loss = 0.356
Epoch 227 Batch   20/44   train_loss = 0.348
Epoch 227 Batch   21/44   train_loss = 0.319
Epoch 227 Batch   22/44   train_loss = 0.361
Epoch 227 Batch   23/44   train_loss = 0.345
Epoch 227 Batch   24/44   train_loss = 0.329
Epoch 227 Batch   25/44   train_loss = 0.378
Epoch 227 Batch   26/44   train_loss = 0.366
Epoch 227 Batch   27/44   train_loss = 0.373
Epoch 227 Batch   28/44   train_loss = 0.343
Epoch 227 Batch   29/44   train_loss = 0.351
Epoch 227 Batch   30/44   train_loss = 0.352
Epoch 227 Batch   31/44   train_loss = 0.358
Epoch 227 Batch   32/44   train_loss = 0.346
Epoch 227 Batch   33/44   train_loss = 0.384
Epoch 227 Batch   34/44   train_loss = 0.360
Epoch 227 Batch   35/44   train_loss = 0.332
Epoch 227 Batch   36/44   train_loss = 0.387
Epoch 227 Batch   37/44   train_loss = 0.337
Epoch 227 Batch   38/44   train_loss = 0.355
Epoch 227 Batch   39/44   train_loss = 0.331
Epoch 227 Batch   40/44   train_loss = 0.320
Epoch 227 Batch   41/44   train_loss = 0.342
Epoch 227 Batch   42/44   train_loss = 0.323
Epoch 227 Batch   43/44   train_loss = 0.330
Epoch 228 Batch    0/44   train_loss = 0.334
Epoch 228 Batch    1/44   train_loss = 0.340
Epoch 228 Batch    2/44   train_loss = 0.349
Epoch 228 Batch    3/44   train_loss = 0.374
Epoch 228 Batch    4/44   train_loss = 0.327
Epoch 228 Batch    5/44   train_loss = 0.344
Epoch 228 Batch    6/44   train_loss = 0.345
Epoch 228 Batch    7/44   train_loss = 0.345
Epoch 228 Batch    8/44   train_loss = 0.359
Epoch 228 Batch    9/44   train_loss = 0.379
Epoch 228 Batch   10/44   train_loss = 0.352
Epoch 228 Batch   11/44   train_loss = 0.379
Epoch 228 Batch   12/44   train_loss = 0.355
Epoch 228 Batch   13/44   train_loss = 0.366
Epoch 228 Batch   14/44   train_loss = 0.355
Epoch 228 Batch   15/44   train_loss = 0.370
Epoch 228 Batch   16/44   train_loss = 0.349
Epoch 228 Batch   17/44   train_loss = 0.366
Epoch 228 Batch   18/44   train_loss = 0.355
Epoch 228 Batch   19/44   train_loss = 0.353
Epoch 228 Batch   20/44   train_loss = 0.342
Epoch 228 Batch   21/44   train_loss = 0.310
Epoch 228 Batch   22/44   train_loss = 0.357
Epoch 228 Batch   23/44   train_loss = 0.338
Epoch 228 Batch   24/44   train_loss = 0.326
Epoch 228 Batch   25/44   train_loss = 0.370
Epoch 228 Batch   26/44   train_loss = 0.364
Epoch 228 Batch   27/44   train_loss = 0.371
Epoch 228 Batch   28/44   train_loss = 0.342
Epoch 228 Batch   29/44   train_loss = 0.352
Epoch 228 Batch   30/44   train_loss = 0.346
Epoch 228 Batch   31/44   train_loss = 0.355
Epoch 228 Batch   32/44   train_loss = 0.339
Epoch 228 Batch   33/44   train_loss = 0.383
Epoch 228 Batch   34/44   train_loss = 0.361
Epoch 228 Batch   35/44   train_loss = 0.331
Epoch 228 Batch   36/44   train_loss = 0.385
Epoch 228 Batch   37/44   train_loss = 0.333
Epoch 228 Batch   38/44   train_loss = 0.351
Epoch 228 Batch   39/44   train_loss = 0.329
Epoch 228 Batch   40/44   train_loss = 0.318
Epoch 228 Batch   41/44   train_loss = 0.341
Epoch 228 Batch   42/44   train_loss = 0.323
Epoch 228 Batch   43/44   train_loss = 0.333
Epoch 229 Batch    0/44   train_loss = 0.338
Epoch 229 Batch    1/44   train_loss = 0.346
Epoch 229 Batch    2/44   train_loss = 0.353
Epoch 229 Batch    3/44   train_loss = 0.377
Epoch 229 Batch    4/44   train_loss = 0.328
Epoch 229 Batch    5/44   train_loss = 0.344
Epoch 229 Batch    6/44   train_loss = 0.341
Epoch 229 Batch    7/44   train_loss = 0.340
Epoch 229 Batch    8/44   train_loss = 0.353
Epoch 229 Batch    9/44   train_loss = 0.378
Epoch 229 Batch   10/44   train_loss = 0.352
Epoch 229 Batch   11/44   train_loss = 0.378
Epoch 229 Batch   12/44   train_loss = 0.360
Epoch 229 Batch   13/44   train_loss = 0.366
Epoch 229 Batch   14/44   train_loss = 0.355
Epoch 229 Batch   15/44   train_loss = 0.367
Epoch 229 Batch   16/44   train_loss = 0.347
Epoch 229 Batch   17/44   train_loss = 0.362
Epoch 229 Batch   18/44   train_loss = 0.354
Epoch 229 Batch   19/44   train_loss = 0.349
Epoch 229 Batch   20/44   train_loss = 0.342
Epoch 229 Batch   21/44   train_loss = 0.311
Epoch 229 Batch   22/44   train_loss = 0.365
Epoch 229 Batch   23/44   train_loss = 0.338
Epoch 229 Batch   24/44   train_loss = 0.322
Epoch 229 Batch   25/44   train_loss = 0.367
Epoch 229 Batch   26/44   train_loss = 0.359
Epoch 229 Batch   27/44   train_loss = 0.366
Epoch 229 Batch   28/44   train_loss = 0.335
Epoch 229 Batch   29/44   train_loss = 0.349
Epoch 229 Batch   30/44   train_loss = 0.343
Epoch 229 Batch   31/44   train_loss = 0.354
Epoch 229 Batch   32/44   train_loss = 0.341
Epoch 229 Batch   33/44   train_loss = 0.386
Epoch 229 Batch   34/44   train_loss = 0.364
Epoch 229 Batch   35/44   train_loss = 0.334
Epoch 229 Batch   36/44   train_loss = 0.386
Epoch 229 Batch   37/44   train_loss = 0.332
Epoch 229 Batch   38/44   train_loss = 0.350
Epoch 229 Batch   39/44   train_loss = 0.328
Epoch 229 Batch   40/44   train_loss = 0.313
Epoch 229 Batch   41/44   train_loss = 0.335
Epoch 229 Batch   42/44   train_loss = 0.315
Epoch 229 Batch   43/44   train_loss = 0.326
Epoch 230 Batch    0/44   train_loss = 0.333
Epoch 230 Batch    1/44   train_loss = 0.345
Epoch 230 Batch    2/44   train_loss = 0.356
Epoch 230 Batch    3/44   train_loss = 0.386
Epoch 230 Batch    4/44   train_loss = 0.338
Epoch 230 Batch    5/44   train_loss = 0.351
Epoch 230 Batch    6/44   train_loss = 0.343
Epoch 230 Batch    7/44   train_loss = 0.340
Epoch 230 Batch    8/44   train_loss = 0.347
Epoch 230 Batch    9/44   train_loss = 0.372
Epoch 230 Batch   10/44   train_loss = 0.344
Epoch 230 Batch   11/44   train_loss = 0.369
Epoch 230 Batch   12/44   train_loss = 0.352
Epoch 230 Batch   13/44   train_loss = 0.366
Epoch 230 Batch   14/44   train_loss = 0.358
Epoch 230 Batch   15/44   train_loss = 0.375
Epoch 230 Batch   16/44   train_loss = 0.356
Epoch 230 Batch   17/44   train_loss = 0.367
Epoch 230 Batch   18/44   train_loss = 0.355
Epoch 230 Batch   19/44   train_loss = 0.348
Epoch 230 Batch   20/44   train_loss = 0.337
Epoch 230 Batch   21/44   train_loss = 0.308
Epoch 230 Batch   22/44   train_loss = 0.353
Epoch 230 Batch   23/44   train_loss = 0.334
Epoch 230 Batch   24/44   train_loss = 0.318
Epoch 230 Batch   25/44   train_loss = 0.367
Epoch 230 Batch   26/44   train_loss = 0.361
Epoch 230 Batch   27/44   train_loss = 0.371
Epoch 230 Batch   28/44   train_loss = 0.339
Epoch 230 Batch   29/44   train_loss = 0.349
Epoch 230 Batch   30/44   train_loss = 0.338
Epoch 230 Batch   31/44   train_loss = 0.349
Epoch 230 Batch   32/44   train_loss = 0.334
Epoch 230 Batch   33/44   train_loss = 0.382
Epoch 230 Batch   34/44   train_loss = 0.363
Epoch 230 Batch   35/44   train_loss = 0.336
Epoch 230 Batch   36/44   train_loss = 0.394
Epoch 230 Batch   37/44   train_loss = 0.339
Epoch 230 Batch   38/44   train_loss = 0.352
Epoch 230 Batch   39/44   train_loss = 0.331
Epoch 230 Batch   40/44   train_loss = 0.314
Epoch 230 Batch   41/44   train_loss = 0.331
Epoch 230 Batch   42/44   train_loss = 0.308
Epoch 230 Batch   43/44   train_loss = 0.320
Epoch 231 Batch    0/44   train_loss = 0.327
Epoch 231 Batch    1/44   train_loss = 0.337
Epoch 231 Batch    2/44   train_loss = 0.350
Epoch 231 Batch    3/44   train_loss = 0.387
Epoch 231 Batch    4/44   train_loss = 0.343
Epoch 231 Batch    5/44   train_loss = 0.360
Epoch 231 Batch    6/44   train_loss = 0.355
Epoch 231 Batch    7/44   train_loss = 0.347
Epoch 231 Batch    8/44   train_loss = 0.351
Epoch 231 Batch    9/44   train_loss = 0.371
Epoch 231 Batch   10/44   train_loss = 0.343
Epoch 231 Batch   11/44   train_loss = 0.364
Epoch 231 Batch   12/44   train_loss = 0.343
Epoch 231 Batch   13/44   train_loss = 0.360
Epoch 231 Batch   14/44   train_loss = 0.351
Epoch 231 Batch   15/44   train_loss = 0.372
Epoch 231 Batch   16/44   train_loss = 0.357
Epoch 231 Batch   17/44   train_loss = 0.372
Epoch 231 Batch   18/44   train_loss = 0.363
Epoch 231 Batch   19/44   train_loss = 0.355
Epoch 231 Batch   20/44   train_loss = 0.342
Epoch 231 Batch   21/44   train_loss = 0.311
Epoch 231 Batch   22/44   train_loss = 0.349
Epoch 231 Batch   23/44   train_loss = 0.329
Epoch 231 Batch   24/44   train_loss = 0.314
Epoch 231 Batch   25/44   train_loss = 0.362
Epoch 231 Batch   26/44   train_loss = 0.355
Epoch 231 Batch   27/44   train_loss = 0.368
Epoch 231 Batch   28/44   train_loss = 0.338
Epoch 231 Batch   29/44   train_loss = 0.353
Epoch 231 Batch   30/44   train_loss = 0.341
Epoch 231 Batch   31/44   train_loss = 0.351
Epoch 231 Batch   32/44   train_loss = 0.335
Epoch 231 Batch   33/44   train_loss = 0.380
Epoch 231 Batch   34/44   train_loss = 0.361
Epoch 231 Batch   35/44   train_loss = 0.334
Epoch 231 Batch   36/44   train_loss = 0.393
Epoch 231 Batch   37/44   train_loss = 0.339
Epoch 231 Batch   38/44   train_loss = 0.354
Epoch 231 Batch   39/44   train_loss = 0.334
Epoch 231 Batch   40/44   train_loss = 0.316
Epoch 231 Batch   41/44   train_loss = 0.331
Epoch 231 Batch   42/44   train_loss = 0.309
Epoch 231 Batch   43/44   train_loss = 0.321
Epoch 232 Batch    0/44   train_loss = 0.322
Epoch 232 Batch    1/44   train_loss = 0.328
Epoch 232 Batch    2/44   train_loss = 0.341
Epoch 232 Batch    3/44   train_loss = 0.377
Epoch 232 Batch    4/44   train_loss = 0.337
Epoch 232 Batch    5/44   train_loss = 0.358
Epoch 232 Batch    6/44   train_loss = 0.360
Epoch 232 Batch    7/44   train_loss = 0.361
Epoch 232 Batch    8/44   train_loss = 0.364
Epoch 232 Batch    9/44   train_loss = 0.380
Epoch 232 Batch   10/44   train_loss = 0.348
Epoch 232 Batch   11/44   train_loss = 0.366
Epoch 232 Batch   12/44   train_loss = 0.339
Epoch 232 Batch   13/44   train_loss = 0.353
Epoch 232 Batch   14/44   train_loss = 0.343
Epoch 232 Batch   15/44   train_loss = 0.364
Epoch 232 Batch   16/44   train_loss = 0.348
Epoch 232 Batch   17/44   train_loss = 0.365
Epoch 232 Batch   18/44   train_loss = 0.360
Epoch 232 Batch   19/44   train_loss = 0.356
Epoch 232 Batch   20/44   train_loss = 0.351
Epoch 232 Batch   21/44   train_loss = 0.317
Epoch 232 Batch   22/44   train_loss = 0.356
Epoch 232 Batch   23/44   train_loss = 0.332
Epoch 232 Batch   24/44   train_loss = 0.317
Epoch 232 Batch   25/44   train_loss = 0.359
Epoch 232 Batch   26/44   train_loss = 0.352
Epoch 232 Batch   27/44   train_loss = 0.361
Epoch 232 Batch   28/44   train_loss = 0.335
Epoch 232 Batch   29/44   train_loss = 0.347
Epoch 232 Batch   30/44   train_loss = 0.342
Epoch 232 Batch   31/44   train_loss = 0.349
Epoch 232 Batch   32/44   train_loss = 0.336
Epoch 232 Batch   33/44   train_loss = 0.377
Epoch 232 Batch   34/44   train_loss = 0.363
Epoch 232 Batch   35/44   train_loss = 0.333
Epoch 232 Batch   36/44   train_loss = 0.391
Epoch 232 Batch   37/44   train_loss = 0.339
Epoch 232 Batch   38/44   train_loss = 0.353
Epoch 232 Batch   39/44   train_loss = 0.335
Epoch 232 Batch   40/44   train_loss = 0.318
Epoch 232 Batch   41/44   train_loss = 0.333
Epoch 232 Batch   42/44   train_loss = 0.312
Epoch 232 Batch   43/44   train_loss = 0.321
Epoch 233 Batch    0/44   train_loss = 0.325
Epoch 233 Batch    1/44   train_loss = 0.327
Epoch 233 Batch    2/44   train_loss = 0.337
Epoch 233 Batch    3/44   train_loss = 0.369
Epoch 233 Batch    4/44   train_loss = 0.328
Epoch 233 Batch    5/44   train_loss = 0.346
Epoch 233 Batch    6/44   train_loss = 0.351
Epoch 233 Batch    7/44   train_loss = 0.360
Epoch 233 Batch    8/44   train_loss = 0.368
Epoch 233 Batch    9/44   train_loss = 0.393
Epoch 233 Batch   10/44   train_loss = 0.356
Epoch 233 Batch   11/44   train_loss = 0.379
Epoch 233 Batch   12/44   train_loss = 0.347
Epoch 233 Batch   13/44   train_loss = 0.353
Epoch 233 Batch   14/44   train_loss = 0.341
Epoch 233 Batch   15/44   train_loss = 0.361
Epoch 233 Batch   16/44   train_loss = 0.338
Epoch 233 Batch   17/44   train_loss = 0.356
Epoch 233 Batch   18/44   train_loss = 0.352
Epoch 233 Batch   19/44   train_loss = 0.353
Epoch 233 Batch   20/44   train_loss = 0.349
Epoch 233 Batch   21/44   train_loss = 0.322
Epoch 233 Batch   22/44   train_loss = 0.368
Epoch 233 Batch   23/44   train_loss = 0.340
Epoch 233 Batch   24/44   train_loss = 0.322
Epoch 233 Batch   25/44   train_loss = 0.364
Epoch 233 Batch   26/44   train_loss = 0.351
Epoch 233 Batch   27/44   train_loss = 0.355
Epoch 233 Batch   28/44   train_loss = 0.333
Epoch 233 Batch   29/44   train_loss = 0.343
Epoch 233 Batch   30/44   train_loss = 0.339
Epoch 233 Batch   31/44   train_loss = 0.346
Epoch 233 Batch   32/44   train_loss = 0.333
Epoch 233 Batch   33/44   train_loss = 0.375
Epoch 233 Batch   34/44   train_loss = 0.363
Epoch 233 Batch   35/44   train_loss = 0.337
Epoch 233 Batch   36/44   train_loss = 0.389
Epoch 233 Batch   37/44   train_loss = 0.337
Epoch 233 Batch   38/44   train_loss = 0.352
Epoch 233 Batch   39/44   train_loss = 0.334
Epoch 233 Batch   40/44   train_loss = 0.321
Epoch 233 Batch   41/44   train_loss = 0.336
Epoch 233 Batch   42/44   train_loss = 0.316
Epoch 233 Batch   43/44   train_loss = 0.326
Epoch 234 Batch    0/44   train_loss = 0.332
Epoch 234 Batch    1/44   train_loss = 0.331
Epoch 234 Batch    2/44   train_loss = 0.337
Epoch 234 Batch    3/44   train_loss = 0.367
Epoch 234 Batch    4/44   train_loss = 0.324
Epoch 234 Batch    5/44   train_loss = 0.335
Epoch 234 Batch    6/44   train_loss = 0.341
Epoch 234 Batch    7/44   train_loss = 0.347
Epoch 234 Batch    8/44   train_loss = 0.358
Epoch 234 Batch    9/44   train_loss = 0.386
Epoch 234 Batch   10/44   train_loss = 0.357
Epoch 234 Batch   11/44   train_loss = 0.394
Epoch 234 Batch   12/44   train_loss = 0.367
Epoch 234 Batch   13/44   train_loss = 0.371
Epoch 234 Batch   14/44   train_loss = 0.356
Epoch 234 Batch   15/44   train_loss = 0.370
Epoch 234 Batch   16/44   train_loss = 0.339
Epoch 234 Batch   17/44   train_loss = 0.352
Epoch 234 Batch   18/44   train_loss = 0.342
Epoch 234 Batch   19/44   train_loss = 0.342
Epoch 234 Batch   20/44   train_loss = 0.339
Epoch 234 Batch   21/44   train_loss = 0.315
Epoch 234 Batch   22/44   train_loss = 0.362
Epoch 234 Batch   23/44   train_loss = 0.345
Epoch 234 Batch   24/44   train_loss = 0.334
Epoch 234 Batch   25/44   train_loss = 0.378
Epoch 234 Batch   26/44   train_loss = 0.358
Epoch 234 Batch   27/44   train_loss = 0.362
Epoch 234 Batch   28/44   train_loss = 0.340
Epoch 234 Batch   29/44   train_loss = 0.341
Epoch 234 Batch   30/44   train_loss = 0.334
Epoch 234 Batch   31/44   train_loss = 0.339
Epoch 234 Batch   32/44   train_loss = 0.326
Epoch 234 Batch   33/44   train_loss = 0.375
Epoch 234 Batch   34/44   train_loss = 0.366
Epoch 234 Batch   35/44   train_loss = 0.343
Epoch 234 Batch   36/44   train_loss = 0.394
Epoch 234 Batch   37/44   train_loss = 0.336
Epoch 234 Batch   38/44   train_loss = 0.353
Epoch 234 Batch   39/44   train_loss = 0.329
Epoch 234 Batch   40/44   train_loss = 0.311
Epoch 234 Batch   41/44   train_loss = 0.328
Epoch 234 Batch   42/44   train_loss = 0.311
Epoch 234 Batch   43/44   train_loss = 0.323
Epoch 235 Batch    0/44   train_loss = 0.340
Epoch 235 Batch    1/44   train_loss = 0.342
Epoch 235 Batch    2/44   train_loss = 0.342
Epoch 235 Batch    3/44   train_loss = 0.374
Epoch 235 Batch    4/44   train_loss = 0.329
Epoch 235 Batch    5/44   train_loss = 0.333
Epoch 235 Batch    6/44   train_loss = 0.337
Epoch 235 Batch    7/44   train_loss = 0.337
Epoch 235 Batch    8/44   train_loss = 0.345
Epoch 235 Batch    9/44   train_loss = 0.373
Epoch 235 Batch   10/44   train_loss = 0.346
Epoch 235 Batch   11/44   train_loss = 0.384
Epoch 235 Batch   12/44   train_loss = 0.367
Epoch 235 Batch   13/44   train_loss = 0.378
Epoch 235 Batch   14/44   train_loss = 0.372
Epoch 235 Batch   15/44   train_loss = 0.388
Epoch 235 Batch   16/44   train_loss = 0.358
Epoch 235 Batch   17/44   train_loss = 0.359
Epoch 235 Batch   18/44   train_loss = 0.348
Epoch 235 Batch   19/44   train_loss = 0.341
Epoch 235 Batch   20/44   train_loss = 0.334
Epoch 235 Batch   21/44   train_loss = 0.305
Epoch 235 Batch   22/44   train_loss = 0.352
Epoch 235 Batch   23/44   train_loss = 0.337
Epoch 235 Batch   24/44   train_loss = 0.328
Epoch 235 Batch   25/44   train_loss = 0.382
Epoch 235 Batch   26/44   train_loss = 0.373
Epoch 235 Batch   27/44   train_loss = 0.379
Epoch 235 Batch   28/44   train_loss = 0.348
Epoch 235 Batch   29/44   train_loss = 0.347
Epoch 235 Batch   30/44   train_loss = 0.336
Epoch 235 Batch   31/44   train_loss = 0.335
Epoch 235 Batch   32/44   train_loss = 0.320
Epoch 235 Batch   33/44   train_loss = 0.366
Epoch 235 Batch   34/44   train_loss = 0.356
Epoch 235 Batch   35/44   train_loss = 0.337
Epoch 235 Batch   36/44   train_loss = 0.395
Epoch 235 Batch   37/44   train_loss = 0.347
Epoch 235 Batch   38/44   train_loss = 0.367
Epoch 235 Batch   39/44   train_loss = 0.339
Epoch 235 Batch   40/44   train_loss = 0.317
Epoch 235 Batch   41/44   train_loss = 0.329
Epoch 235 Batch   42/44   train_loss = 0.305
Epoch 235 Batch   43/44   train_loss = 0.314
Epoch 236 Batch    0/44   train_loss = 0.323
Epoch 236 Batch    1/44   train_loss = 0.328
Epoch 236 Batch    2/44   train_loss = 0.337
Epoch 236 Batch    3/44   train_loss = 0.376
Epoch 236 Batch    4/44   train_loss = 0.336
Epoch 236 Batch    5/44   train_loss = 0.347
Epoch 236 Batch    6/44   train_loss = 0.352
Epoch 236 Batch    7/44   train_loss = 0.343
Epoch 236 Batch    8/44   train_loss = 0.344
Epoch 236 Batch    9/44   train_loss = 0.365
Epoch 236 Batch   10/44   train_loss = 0.336
Epoch 236 Batch   11/44   train_loss = 0.363
Epoch 236 Batch   12/44   train_loss = 0.348
Epoch 236 Batch   13/44   train_loss = 0.363
Epoch 236 Batch   14/44   train_loss = 0.365
Epoch 236 Batch   15/44   train_loss = 0.390
Epoch 236 Batch   16/44   train_loss = 0.373
Epoch 236 Batch   17/44   train_loss = 0.374
Epoch 236 Batch   18/44   train_loss = 0.361
Epoch 236 Batch   19/44   train_loss = 0.354
Epoch 236 Batch   20/44   train_loss = 0.337
Epoch 236 Batch   21/44   train_loss = 0.302
Epoch 236 Batch   22/44   train_loss = 0.345
Epoch 236 Batch   23/44   train_loss = 0.327
Epoch 236 Batch   24/44   train_loss = 0.312
Epoch 236 Batch   25/44   train_loss = 0.362
Epoch 236 Batch   26/44   train_loss = 0.363
Epoch 236 Batch   27/44   train_loss = 0.381
Epoch 236 Batch   28/44   train_loss = 0.360
Epoch 236 Batch   29/44   train_loss = 0.365
Epoch 236 Batch   30/44   train_loss = 0.356
Epoch 236 Batch   31/44   train_loss = 0.346
Epoch 236 Batch   32/44   train_loss = 0.326
Epoch 236 Batch   33/44   train_loss = 0.361
Epoch 236 Batch   34/44   train_loss = 0.344
Epoch 236 Batch   35/44   train_loss = 0.324
Epoch 236 Batch   36/44   train_loss = 0.382
Epoch 236 Batch   37/44   train_loss = 0.335
Epoch 236 Batch   38/44   train_loss = 0.359
Epoch 236 Batch   39/44   train_loss = 0.343
Epoch 236 Batch   40/44   train_loss = 0.335
Epoch 236 Batch   41/44   train_loss = 0.348
Epoch 236 Batch   42/44   train_loss = 0.318
Epoch 236 Batch   43/44   train_loss = 0.324
Epoch 237 Batch    0/44   train_loss = 0.324
Epoch 237 Batch    1/44   train_loss = 0.323
Epoch 237 Batch    2/44   train_loss = 0.328
Epoch 237 Batch    3/44   train_loss = 0.360
Epoch 237 Batch    4/44   train_loss = 0.326
Epoch 237 Batch    5/44   train_loss = 0.343
Epoch 237 Batch    6/44   train_loss = 0.356
Epoch 237 Batch    7/44   train_loss = 0.354
Epoch 237 Batch    8/44   train_loss = 0.358
Epoch 237 Batch    9/44   train_loss = 0.384
Epoch 237 Batch   10/44   train_loss = 0.348
Epoch 237 Batch   11/44   train_loss = 0.362
Epoch 237 Batch   12/44   train_loss = 0.341
Epoch 237 Batch   13/44   train_loss = 0.346
Epoch 237 Batch   14/44   train_loss = 0.345
Epoch 237 Batch   15/44   train_loss = 0.365
Epoch 237 Batch   16/44   train_loss = 0.354
Epoch 237 Batch   17/44   train_loss = 0.370
Epoch 237 Batch   18/44   train_loss = 0.371
Epoch 237 Batch   19/44   train_loss = 0.367
Epoch 237 Batch   20/44   train_loss = 0.359
Epoch 237 Batch   21/44   train_loss = 0.318
Epoch 237 Batch   22/44   train_loss = 0.359
Epoch 237 Batch   23/44   train_loss = 0.329
Epoch 237 Batch   24/44   train_loss = 0.304
Epoch 237 Batch   25/44   train_loss = 0.346
Epoch 237 Batch   26/44   train_loss = 0.346
Epoch 237 Batch   27/44   train_loss = 0.361
Epoch 237 Batch   28/44   train_loss = 0.337
Epoch 237 Batch   29/44   train_loss = 0.361
Epoch 237 Batch   30/44   train_loss = 0.373
Epoch 237 Batch   31/44   train_loss = 0.372
Epoch 237 Batch   32/44   train_loss = 0.357
Epoch 237 Batch   33/44   train_loss = 0.382
Epoch 237 Batch   34/44   train_loss = 0.350
Epoch 237 Batch   35/44   train_loss = 0.321
Epoch 237 Batch   36/44   train_loss = 0.370
Epoch 237 Batch   37/44   train_loss = 0.321
Epoch 237 Batch   38/44   train_loss = 0.345
Epoch 237 Batch   39/44   train_loss = 0.328
Epoch 237 Batch   40/44   train_loss = 0.321
Epoch 237 Batch   41/44   train_loss = 0.353
Epoch 237 Batch   42/44   train_loss = 0.332
Epoch 237 Batch   43/44   train_loss = 0.342
Epoch 238 Batch    0/44   train_loss = 0.336
Epoch 238 Batch    1/44   train_loss = 0.335
Epoch 238 Batch    2/44   train_loss = 0.334
Epoch 238 Batch    3/44   train_loss = 0.357
Epoch 238 Batch    4/44   train_loss = 0.314
Epoch 238 Batch    5/44   train_loss = 0.329
Epoch 238 Batch    6/44   train_loss = 0.338
Epoch 238 Batch    7/44   train_loss = 0.338
Epoch 238 Batch    8/44   train_loss = 0.355
Epoch 238 Batch    9/44   train_loss = 0.380
Epoch 238 Batch   10/44   train_loss = 0.358
Epoch 238 Batch   11/44   train_loss = 0.383
Epoch 238 Batch   12/44   train_loss = 0.361
Epoch 238 Batch   13/44   train_loss = 0.348
Epoch 238 Batch   14/44   train_loss = 0.340
Epoch 238 Batch   15/44   train_loss = 0.355
Epoch 238 Batch   16/44   train_loss = 0.335
Epoch 238 Batch   17/44   train_loss = 0.346
Epoch 238 Batch   18/44   train_loss = 0.346
Epoch 238 Batch   19/44   train_loss = 0.350
Epoch 238 Batch   20/44   train_loss = 0.350
Epoch 238 Batch   21/44   train_loss = 0.321
Epoch 238 Batch   22/44   train_loss = 0.372
Epoch 238 Batch   23/44   train_loss = 0.348
Epoch 238 Batch   24/44   train_loss = 0.319
Epoch 238 Batch   25/44   train_loss = 0.360
Epoch 238 Batch   26/44   train_loss = 0.350
Epoch 238 Batch   27/44   train_loss = 0.346
Epoch 238 Batch   28/44   train_loss = 0.316
Epoch 238 Batch   29/44   train_loss = 0.329
Epoch 238 Batch   30/44   train_loss = 0.333
Epoch 238 Batch   31/44   train_loss = 0.347
Epoch 238 Batch   32/44   train_loss = 0.345
Epoch 238 Batch   33/44   train_loss = 0.407
Epoch 238 Batch   34/44   train_loss = 0.389
Epoch 238 Batch   35/44   train_loss = 0.349
Epoch 238 Batch   36/44   train_loss = 0.392
Epoch 238 Batch   37/44   train_loss = 0.328
Epoch 238 Batch   38/44   train_loss = 0.338
Epoch 238 Batch   39/44   train_loss = 0.314
Epoch 238 Batch   40/44   train_loss = 0.304
Epoch 238 Batch   41/44   train_loss = 0.328
Epoch 238 Batch   42/44   train_loss = 0.315
Epoch 238 Batch   43/44   train_loss = 0.336
Epoch 239 Batch    0/44   train_loss = 0.351
Epoch 239 Batch    1/44   train_loss = 0.356
Epoch 239 Batch    2/44   train_loss = 0.355
Epoch 239 Batch    3/44   train_loss = 0.374
Epoch 239 Batch    4/44   train_loss = 0.320
Epoch 239 Batch    5/44   train_loss = 0.335
Epoch 239 Batch    6/44   train_loss = 0.329
Epoch 239 Batch    7/44   train_loss = 0.325
Epoch 239 Batch    8/44   train_loss = 0.339
Epoch 239 Batch    9/44   train_loss = 0.369
Epoch 239 Batch   10/44   train_loss = 0.346
Epoch 239 Batch   11/44   train_loss = 0.379
Epoch 239 Batch   12/44   train_loss = 0.366
Epoch 239 Batch   13/44   train_loss = 0.359
Epoch 239 Batch   14/44   train_loss = 0.351
Epoch 239 Batch   15/44   train_loss = 0.366
Epoch 239 Batch   16/44   train_loss = 0.339
Epoch 239 Batch   17/44   train_loss = 0.347
Epoch 239 Batch   18/44   train_loss = 0.339
Epoch 239 Batch   19/44   train_loss = 0.336
Epoch 239 Batch   20/44   train_loss = 0.328
Epoch 239 Batch   21/44   train_loss = 0.301
Epoch 239 Batch   22/44   train_loss = 0.353
Epoch 239 Batch   23/44   train_loss = 0.334
Epoch 239 Batch   24/44   train_loss = 0.322
Epoch 239 Batch   25/44   train_loss = 0.371
Epoch 239 Batch   26/44   train_loss = 0.363
Epoch 239 Batch   27/44   train_loss = 0.365
Epoch 239 Batch   28/44   train_loss = 0.326
Epoch 239 Batch   29/44   train_loss = 0.332
Epoch 239 Batch   30/44   train_loss = 0.328
Epoch 239 Batch   31/44   train_loss = 0.331
Epoch 239 Batch   32/44   train_loss = 0.311
Epoch 239 Batch   33/44   train_loss = 0.363
Epoch 239 Batch   34/44   train_loss = 0.357
Epoch 239 Batch   35/44   train_loss = 0.336
Epoch 239 Batch   36/44   train_loss = 0.408
Epoch 239 Batch   37/44   train_loss = 0.360
Epoch 239 Batch   38/44   train_loss = 0.360
Epoch 239 Batch   39/44   train_loss = 0.333
Epoch 239 Batch   40/44   train_loss = 0.308
Epoch 239 Batch   41/44   train_loss = 0.319
Epoch 239 Batch   42/44   train_loss = 0.297
Epoch 239 Batch   43/44   train_loss = 0.310
Epoch 240 Batch    0/44   train_loss = 0.322
Epoch 240 Batch    1/44   train_loss = 0.339
Epoch 240 Batch    2/44   train_loss = 0.356
Epoch 240 Batch    3/44   train_loss = 0.400
Epoch 240 Batch    4/44   train_loss = 0.348
Epoch 240 Batch    5/44   train_loss = 0.363
Epoch 240 Batch    6/44   train_loss = 0.341
Epoch 240 Batch    7/44   train_loss = 0.332
Epoch 240 Batch    8/44   train_loss = 0.332
Epoch 240 Batch    9/44   train_loss = 0.357
Epoch 240 Batch   10/44   train_loss = 0.325
Epoch 240 Batch   11/44   train_loss = 0.362
Epoch 240 Batch   12/44   train_loss = 0.348
Epoch 240 Batch   13/44   train_loss = 0.349
Epoch 240 Batch   14/44   train_loss = 0.353
Epoch 240 Batch   15/44   train_loss = 0.375
Epoch 240 Batch   16/44   train_loss = 0.367
Epoch 240 Batch   17/44   train_loss = 0.365
Epoch 240 Batch   18/44   train_loss = 0.351
Epoch 240 Batch   19/44   train_loss = 0.336
Epoch 240 Batch   20/44   train_loss = 0.321
Epoch 240 Batch   21/44   train_loss = 0.291
Epoch 240 Batch   22/44   train_loss = 0.339
Epoch 240 Batch   23/44   train_loss = 0.316
Epoch 240 Batch   24/44   train_loss = 0.306
Epoch 240 Batch   25/44   train_loss = 0.353
Epoch 240 Batch   26/44   train_loss = 0.351
Epoch 240 Batch   27/44   train_loss = 0.361
Epoch 240 Batch   28/44   train_loss = 0.333
Epoch 240 Batch   29/44   train_loss = 0.342
Epoch 240 Batch   30/44   train_loss = 0.335
Epoch 240 Batch   31/44   train_loss = 0.336
Epoch 240 Batch   32/44   train_loss = 0.310
Epoch 240 Batch   33/44   train_loss = 0.354
Epoch 240 Batch   34/44   train_loss = 0.341
Epoch 240 Batch   35/44   train_loss = 0.315
Epoch 240 Batch   36/44   train_loss = 0.373
Epoch 240 Batch   37/44   train_loss = 0.336
Epoch 240 Batch   38/44   train_loss = 0.351
Epoch 240 Batch   39/44   train_loss = 0.340
Epoch 240 Batch   40/44   train_loss = 0.322
Epoch 240 Batch   41/44   train_loss = 0.337
Epoch 240 Batch   42/44   train_loss = 0.311
Epoch 240 Batch   43/44   train_loss = 0.311
Epoch 241 Batch    0/44   train_loss = 0.316
Epoch 241 Batch    1/44   train_loss = 0.320
Epoch 241 Batch    2/44   train_loss = 0.332
Epoch 241 Batch    3/44   train_loss = 0.355
Epoch 241 Batch    4/44   train_loss = 0.323
Epoch 241 Batch    5/44   train_loss = 0.347
Epoch 241 Batch    6/44   train_loss = 0.355
Epoch 241 Batch    7/44   train_loss = 0.363
Epoch 241 Batch    8/44   train_loss = 0.372
Epoch 241 Batch    9/44   train_loss = 0.372
Epoch 241 Batch   10/44   train_loss = 0.338
Epoch 241 Batch   11/44   train_loss = 0.353
Epoch 241 Batch   12/44   train_loss = 0.331
Epoch 241 Batch   13/44   train_loss = 0.333
Epoch 241 Batch   14/44   train_loss = 0.330
Epoch 241 Batch   15/44   train_loss = 0.354
Epoch 241 Batch   16/44   train_loss = 0.345
Epoch 241 Batch   17/44   train_loss = 0.364
Epoch 241 Batch   18/44   train_loss = 0.363
Epoch 241 Batch   19/44   train_loss = 0.362
Epoch 241 Batch   20/44   train_loss = 0.349
Epoch 241 Batch   21/44   train_loss = 0.308
Epoch 241 Batch   22/44   train_loss = 0.349
Epoch 241 Batch   23/44   train_loss = 0.315
Epoch 241 Batch   24/44   train_loss = 0.300
Epoch 241 Batch   25/44   train_loss = 0.341
Epoch 241 Batch   26/44   train_loss = 0.337
Epoch 241 Batch   27/44   train_loss = 0.345
Epoch 241 Batch   28/44   train_loss = 0.319
Epoch 241 Batch   29/44   train_loss = 0.332
Epoch 241 Batch   30/44   train_loss = 0.337
Epoch 241 Batch   31/44   train_loss = 0.340
Epoch 241 Batch   32/44   train_loss = 0.319
Epoch 241 Batch   33/44   train_loss = 0.361
Epoch 241 Batch   34/44   train_loss = 0.344
Epoch 241 Batch   35/44   train_loss = 0.317
Epoch 241 Batch   36/44   train_loss = 0.367
Epoch 241 Batch   37/44   train_loss = 0.318
Epoch 241 Batch   38/44   train_loss = 0.333
Epoch 241 Batch   39/44   train_loss = 0.319
Epoch 241 Batch   40/44   train_loss = 0.305
Epoch 241 Batch   41/44   train_loss = 0.328
Epoch 241 Batch   42/44   train_loss = 0.308
Epoch 241 Batch   43/44   train_loss = 0.315
Epoch 242 Batch    0/44   train_loss = 0.320
Epoch 242 Batch    1/44   train_loss = 0.321
Epoch 242 Batch    2/44   train_loss = 0.326
Epoch 242 Batch    3/44   train_loss = 0.350
Epoch 242 Batch    4/44   train_loss = 0.309
Epoch 242 Batch    5/44   train_loss = 0.327
Epoch 242 Batch    6/44   train_loss = 0.326
Epoch 242 Batch    7/44   train_loss = 0.329
Epoch 242 Batch    8/44   train_loss = 0.347
Epoch 242 Batch    9/44   train_loss = 0.368
Epoch 242 Batch   10/44   train_loss = 0.344
Epoch 242 Batch   11/44   train_loss = 0.368
Epoch 242 Batch   12/44   train_loss = 0.351
Epoch 242 Batch   13/44   train_loss = 0.348
Epoch 242 Batch   14/44   train_loss = 0.332
Epoch 242 Batch   15/44   train_loss = 0.353
Epoch 242 Batch   16/44   train_loss = 0.328
Epoch 242 Batch   17/44   train_loss = 0.339
Epoch 242 Batch   18/44   train_loss = 0.329
Epoch 242 Batch   19/44   train_loss = 0.335
Epoch 242 Batch   20/44   train_loss = 0.335
Epoch 242 Batch   21/44   train_loss = 0.308
Epoch 242 Batch   22/44   train_loss = 0.355
Epoch 242 Batch   23/44   train_loss = 0.342
Epoch 242 Batch   24/44   train_loss = 0.329
Epoch 242 Batch   25/44   train_loss = 0.356
Epoch 242 Batch   26/44   train_loss = 0.343
Epoch 242 Batch   27/44   train_loss = 0.343
Epoch 242 Batch   28/44   train_loss = 0.313
Epoch 242 Batch   29/44   train_loss = 0.320
Epoch 242 Batch   30/44   train_loss = 0.320
Epoch 242 Batch   31/44   train_loss = 0.327
Epoch 242 Batch   32/44   train_loss = 0.308
Epoch 242 Batch   33/44   train_loss = 0.355
Epoch 242 Batch   34/44   train_loss = 0.346
Epoch 242 Batch   35/44   train_loss = 0.323
Epoch 242 Batch   36/44   train_loss = 0.380
Epoch 242 Batch   37/44   train_loss = 0.325
Epoch 242 Batch   38/44   train_loss = 0.341
Epoch 242 Batch   39/44   train_loss = 0.318
Epoch 242 Batch   40/44   train_loss = 0.298
Epoch 242 Batch   41/44   train_loss = 0.317
Epoch 242 Batch   42/44   train_loss = 0.296
Epoch 242 Batch   43/44   train_loss = 0.304
Epoch 243 Batch    0/44   train_loss = 0.310
Epoch 243 Batch    1/44   train_loss = 0.313
Epoch 243 Batch    2/44   train_loss = 0.327
Epoch 243 Batch    3/44   train_loss = 0.354
Epoch 243 Batch    4/44   train_loss = 0.316
Epoch 243 Batch    5/44   train_loss = 0.329
Epoch 243 Batch    6/44   train_loss = 0.325
Epoch 243 Batch    7/44   train_loss = 0.325
Epoch 243 Batch    8/44   train_loss = 0.335
Epoch 243 Batch    9/44   train_loss = 0.356
Epoch 243 Batch   10/44   train_loss = 0.327
Epoch 243 Batch   11/44   train_loss = 0.354
Epoch 243 Batch   12/44   train_loss = 0.338
Epoch 243 Batch   13/44   train_loss = 0.340
Epoch 243 Batch   14/44   train_loss = 0.333
Epoch 243 Batch   15/44   train_loss = 0.358
Epoch 243 Batch   16/44   train_loss = 0.333
Epoch 243 Batch   17/44   train_loss = 0.346
Epoch 243 Batch   18/44   train_loss = 0.334
Epoch 243 Batch   19/44   train_loss = 0.334
Epoch 243 Batch   20/44   train_loss = 0.324
Epoch 243 Batch   21/44   train_loss = 0.293
Epoch 243 Batch   22/44   train_loss = 0.338
Epoch 243 Batch   23/44   train_loss = 0.322
Epoch 243 Batch   24/44   train_loss = 0.307
Epoch 243 Batch   25/44   train_loss = 0.348
Epoch 243 Batch   26/44   train_loss = 0.348
Epoch 243 Batch   27/44   train_loss = 0.354
Epoch 243 Batch   28/44   train_loss = 0.327
Epoch 243 Batch   29/44   train_loss = 0.332
Epoch 243 Batch   30/44   train_loss = 0.327
Epoch 243 Batch   31/44   train_loss = 0.328
Epoch 243 Batch   32/44   train_loss = 0.303
Epoch 243 Batch   33/44   train_loss = 0.346
Epoch 243 Batch   34/44   train_loss = 0.331
Epoch 243 Batch   35/44   train_loss = 0.307
Epoch 243 Batch   36/44   train_loss = 0.361
Epoch 243 Batch   37/44   train_loss = 0.315
Epoch 243 Batch   38/44   train_loss = 0.338
Epoch 243 Batch   39/44   train_loss = 0.321
Epoch 243 Batch   40/44   train_loss = 0.304
Epoch 243 Batch   41/44   train_loss = 0.325
Epoch 243 Batch   42/44   train_loss = 0.301
Epoch 243 Batch   43/44   train_loss = 0.308
Epoch 244 Batch    0/44   train_loss = 0.311
Epoch 244 Batch    1/44   train_loss = 0.314
Epoch 244 Batch    2/44   train_loss = 0.328
Epoch 244 Batch    3/44   train_loss = 0.349
Epoch 244 Batch    4/44   train_loss = 0.308
Epoch 244 Batch    5/44   train_loss = 0.325
Epoch 244 Batch    6/44   train_loss = 0.324
Epoch 244 Batch    7/44   train_loss = 0.325
Epoch 244 Batch    8/44   train_loss = 0.333
Epoch 244 Batch    9/44   train_loss = 0.358
Epoch 244 Batch   10/44   train_loss = 0.326
Epoch 244 Batch   11/44   train_loss = 0.353
Epoch 244 Batch   12/44   train_loss = 0.332
Epoch 244 Batch   13/44   train_loss = 0.335
Epoch 244 Batch   14/44   train_loss = 0.323
Epoch 244 Batch   15/44   train_loss = 0.351
Epoch 244 Batch   16/44   train_loss = 0.323
Epoch 244 Batch   17/44   train_loss = 0.341
Epoch 244 Batch   18/44   train_loss = 0.329
Epoch 244 Batch   19/44   train_loss = 0.331
Epoch 244 Batch   20/44   train_loss = 0.322
Epoch 244 Batch   21/44   train_loss = 0.293
Epoch 244 Batch   22/44   train_loss = 0.339
Epoch 244 Batch   23/44   train_loss = 0.321
Epoch 244 Batch   24/44   train_loss = 0.302
Epoch 244 Batch   25/44   train_loss = 0.339
Epoch 244 Batch   26/44   train_loss = 0.339
Epoch 244 Batch   27/44   train_loss = 0.338
Epoch 244 Batch   28/44   train_loss = 0.312
Epoch 244 Batch   29/44   train_loss = 0.322
Epoch 244 Batch   30/44   train_loss = 0.325
Epoch 244 Batch   31/44   train_loss = 0.332
Epoch 244 Batch   32/44   train_loss = 0.312
Epoch 244 Batch   33/44   train_loss = 0.356
Epoch 244 Batch   34/44   train_loss = 0.338
Epoch 244 Batch   35/44   train_loss = 0.308
Epoch 244 Batch   36/44   train_loss = 0.360
Epoch 244 Batch   37/44   train_loss = 0.312
Epoch 244 Batch   38/44   train_loss = 0.330
Epoch 244 Batch   39/44   train_loss = 0.310
Epoch 244 Batch   40/44   train_loss = 0.292
Epoch 244 Batch   41/44   train_loss = 0.316
Epoch 244 Batch   42/44   train_loss = 0.297
Epoch 244 Batch   43/44   train_loss = 0.304
Epoch 245 Batch    0/44   train_loss = 0.313
Epoch 245 Batch    1/44   train_loss = 0.318
Epoch 245 Batch    2/44   train_loss = 0.333
Epoch 245 Batch    3/44   train_loss = 0.355
Epoch 245 Batch    4/44   train_loss = 0.312
Epoch 245 Batch    5/44   train_loss = 0.326
Epoch 245 Batch    6/44   train_loss = 0.325
Epoch 245 Batch    7/44   train_loss = 0.324
Epoch 245 Batch    8/44   train_loss = 0.329
Epoch 245 Batch    9/44   train_loss = 0.352
Epoch 245 Batch   10/44   train_loss = 0.322
Epoch 245 Batch   11/44   train_loss = 0.349
Epoch 245 Batch   12/44   train_loss = 0.332
Epoch 245 Batch   13/44   train_loss = 0.335
Epoch 245 Batch   14/44   train_loss = 0.323
Epoch 245 Batch   15/44   train_loss = 0.350
Epoch 245 Batch   16/44   train_loss = 0.321
Epoch 245 Batch   17/44   train_loss = 0.342
Epoch 245 Batch   18/44   train_loss = 0.326
Epoch 245 Batch   19/44   train_loss = 0.329
Epoch 245 Batch   20/44   train_loss = 0.319
Epoch 245 Batch   21/44   train_loss = 0.292
Epoch 245 Batch   22/44   train_loss = 0.334
Epoch 245 Batch   23/44   train_loss = 0.317
Epoch 245 Batch   24/44   train_loss = 0.299
Epoch 245 Batch   25/44   train_loss = 0.335
Epoch 245 Batch   26/44   train_loss = 0.335
Epoch 245 Batch   27/44   train_loss = 0.335
Epoch 245 Batch   28/44   train_loss = 0.309
Epoch 245 Batch   29/44   train_loss = 0.317
Epoch 245 Batch   30/44   train_loss = 0.320
Epoch 245 Batch   31/44   train_loss = 0.325
Epoch 245 Batch   32/44   train_loss = 0.302
Epoch 245 Batch   33/44   train_loss = 0.348
Epoch 245 Batch   34/44   train_loss = 0.334
Epoch 245 Batch   35/44   train_loss = 0.306
Epoch 245 Batch   36/44   train_loss = 0.358
Epoch 245 Batch   37/44   train_loss = 0.313
Epoch 245 Batch   38/44   train_loss = 0.331
Epoch 245 Batch   39/44   train_loss = 0.314
Epoch 245 Batch   40/44   train_loss = 0.292
Epoch 245 Batch   41/44   train_loss = 0.314
Epoch 245 Batch   42/44   train_loss = 0.292
Epoch 245 Batch   43/44   train_loss = 0.298
Epoch 246 Batch    0/44   train_loss = 0.306
Epoch 246 Batch    1/44   train_loss = 0.311
Epoch 246 Batch    2/44   train_loss = 0.325
Epoch 246 Batch    3/44   train_loss = 0.348
Epoch 246 Batch    4/44   train_loss = 0.309
Epoch 246 Batch    5/44   train_loss = 0.325
Epoch 246 Batch    6/44   train_loss = 0.327
Epoch 246 Batch    7/44   train_loss = 0.325
Epoch 246 Batch    8/44   train_loss = 0.335
Epoch 246 Batch    9/44   train_loss = 0.355
Epoch 246 Batch   10/44   train_loss = 0.323
Epoch 246 Batch   11/44   train_loss = 0.350
Epoch 246 Batch   12/44   train_loss = 0.326
Epoch 246 Batch   13/44   train_loss = 0.330
Epoch 246 Batch   14/44   train_loss = 0.319
Epoch 246 Batch   15/44   train_loss = 0.347
Epoch 246 Batch   16/44   train_loss = 0.319
Epoch 246 Batch   17/44   train_loss = 0.343
Epoch 246 Batch   18/44   train_loss = 0.326
Epoch 246 Batch   19/44   train_loss = 0.331
Epoch 246 Batch   20/44   train_loss = 0.322
Epoch 246 Batch   21/44   train_loss = 0.293
Epoch 246 Batch   22/44   train_loss = 0.335
Epoch 246 Batch   23/44   train_loss = 0.318
Epoch 246 Batch   24/44   train_loss = 0.297
Epoch 246 Batch   25/44   train_loss = 0.334
Epoch 246 Batch   26/44   train_loss = 0.333
Epoch 246 Batch   27/44   train_loss = 0.334
Epoch 246 Batch   28/44   train_loss = 0.309
Epoch 246 Batch   29/44   train_loss = 0.318
Epoch 246 Batch   30/44   train_loss = 0.321
Epoch 246 Batch   31/44   train_loss = 0.324
Epoch 246 Batch   32/44   train_loss = 0.301
Epoch 246 Batch   33/44   train_loss = 0.345
Epoch 246 Batch   34/44   train_loss = 0.332
Epoch 246 Batch   35/44   train_loss = 0.302
Epoch 246 Batch   36/44   train_loss = 0.352
Epoch 246 Batch   37/44   train_loss = 0.309
Epoch 246 Batch   38/44   train_loss = 0.326
Epoch 246 Batch   39/44   train_loss = 0.310
Epoch 246 Batch   40/44   train_loss = 0.291
Epoch 246 Batch   41/44   train_loss = 0.312
Epoch 246 Batch   42/44   train_loss = 0.291
Epoch 246 Batch   43/44   train_loss = 0.299
Epoch 247 Batch    0/44   train_loss = 0.305
Epoch 247 Batch    1/44   train_loss = 0.308
Epoch 247 Batch    2/44   train_loss = 0.322
Epoch 247 Batch    3/44   train_loss = 0.344
Epoch 247 Batch    4/44   train_loss = 0.304
Epoch 247 Batch    5/44   train_loss = 0.318
Epoch 247 Batch    6/44   train_loss = 0.319
Epoch 247 Batch    7/44   train_loss = 0.321
Epoch 247 Batch    8/44   train_loss = 0.329
Epoch 247 Batch    9/44   train_loss = 0.353
Epoch 247 Batch   10/44   train_loss = 0.323
Epoch 247 Batch   11/44   train_loss = 0.354
Epoch 247 Batch   12/44   train_loss = 0.330
Epoch 247 Batch   13/44   train_loss = 0.334
Epoch 247 Batch   14/44   train_loss = 0.321
Epoch 247 Batch   15/44   train_loss = 0.348
Epoch 247 Batch   16/44   train_loss = 0.316
Epoch 247 Batch   17/44   train_loss = 0.337
Epoch 247 Batch   18/44   train_loss = 0.320
Epoch 247 Batch   19/44   train_loss = 0.323
Epoch 247 Batch   20/44   train_loss = 0.317
Epoch 247 Batch   21/44   train_loss = 0.290
Epoch 247 Batch   22/44   train_loss = 0.331
Epoch 247 Batch   23/44   train_loss = 0.317
Epoch 247 Batch   24/44   train_loss = 0.297
Epoch 247 Batch   25/44   train_loss = 0.336
Epoch 247 Batch   26/44   train_loss = 0.334
Epoch 247 Batch   27/44   train_loss = 0.336
Epoch 247 Batch   28/44   train_loss = 0.309
Epoch 247 Batch   29/44   train_loss = 0.316
Epoch 247 Batch   30/44   train_loss = 0.320
Epoch 247 Batch   31/44   train_loss = 0.324
Epoch 247 Batch   32/44   train_loss = 0.299
Epoch 247 Batch   33/44   train_loss = 0.345
Epoch 247 Batch   34/44   train_loss = 0.330
Epoch 247 Batch   35/44   train_loss = 0.303
Epoch 247 Batch   36/44   train_loss = 0.351
Epoch 247 Batch   37/44   train_loss = 0.309
Epoch 247 Batch   38/44   train_loss = 0.322
Epoch 247 Batch   39/44   train_loss = 0.307
Epoch 247 Batch   40/44   train_loss = 0.288
Epoch 247 Batch   41/44   train_loss = 0.311
Epoch 247 Batch   42/44   train_loss = 0.289
Epoch 247 Batch   43/44   train_loss = 0.298
Epoch 248 Batch    0/44   train_loss = 0.305
Epoch 248 Batch    1/44   train_loss = 0.308
Epoch 248 Batch    2/44   train_loss = 0.321
Epoch 248 Batch    3/44   train_loss = 0.344
Epoch 248 Batch    4/44   train_loss = 0.303
Epoch 248 Batch    5/44   train_loss = 0.316
Epoch 248 Batch    6/44   train_loss = 0.316
Epoch 248 Batch    7/44   train_loss = 0.317
Epoch 248 Batch    8/44   train_loss = 0.322
Epoch 248 Batch    9/44   train_loss = 0.346
Epoch 248 Batch   10/44   train_loss = 0.315
Epoch 248 Batch   11/44   train_loss = 0.346
Epoch 248 Batch   12/44   train_loss = 0.323
Epoch 248 Batch   13/44   train_loss = 0.331
Epoch 248 Batch   14/44   train_loss = 0.322
Epoch 248 Batch   15/44   train_loss = 0.351
Epoch 248 Batch   16/44   train_loss = 0.321
Epoch 248 Batch   17/44   train_loss = 0.341
Epoch 248 Batch   18/44   train_loss = 0.323
Epoch 248 Batch   19/44   train_loss = 0.324
Epoch 248 Batch   20/44   train_loss = 0.312
Epoch 248 Batch   21/44   train_loss = 0.287
Epoch 248 Batch   22/44   train_loss = 0.326
Epoch 248 Batch   23/44   train_loss = 0.311
Epoch 248 Batch   24/44   train_loss = 0.292
Epoch 248 Batch   25/44   train_loss = 0.331
Epoch 248 Batch   26/44   train_loss = 0.333
Epoch 248 Batch   27/44   train_loss = 0.335
Epoch 248 Batch   28/44   train_loss = 0.307
Epoch 248 Batch   29/44   train_loss = 0.316
Epoch 248 Batch   30/44   train_loss = 0.319
Epoch 248 Batch   31/44   train_loss = 0.323
Epoch 248 Batch   32/44   train_loss = 0.299
Epoch 248 Batch   33/44   train_loss = 0.347
Epoch 248 Batch   34/44   train_loss = 0.330
Epoch 248 Batch   35/44   train_loss = 0.302
Epoch 248 Batch   36/44   train_loss = 0.349
Epoch 248 Batch   37/44   train_loss = 0.309
Epoch 248 Batch   38/44   train_loss = 0.321
Epoch 248 Batch   39/44   train_loss = 0.306
Epoch 248 Batch   40/44   train_loss = 0.285
Epoch 248 Batch   41/44   train_loss = 0.309
Epoch 248 Batch   42/44   train_loss = 0.287
Epoch 248 Batch   43/44   train_loss = 0.297
Epoch 249 Batch    0/44   train_loss = 0.304
Epoch 249 Batch    1/44   train_loss = 0.308
Epoch 249 Batch    2/44   train_loss = 0.320
Epoch 249 Batch    3/44   train_loss = 0.346
Epoch 249 Batch    4/44   train_loss = 0.304
Epoch 249 Batch    5/44   train_loss = 0.317
Epoch 249 Batch    6/44   train_loss = 0.316
Epoch 249 Batch    7/44   train_loss = 0.316
Epoch 249 Batch    8/44   train_loss = 0.322
Epoch 249 Batch    9/44   train_loss = 0.345
Epoch 249 Batch   10/44   train_loss = 0.311
Epoch 249 Batch   11/44   train_loss = 0.341
Epoch 249 Batch   12/44   train_loss = 0.315
Epoch 249 Batch   13/44   train_loss = 0.326
Epoch 249 Batch   14/44   train_loss = 0.316
Epoch 249 Batch   15/44   train_loss = 0.344
Epoch 249 Batch   16/44   train_loss = 0.317
Epoch 249 Batch   17/44   train_loss = 0.338
Epoch 249 Batch   18/44   train_loss = 0.324
Epoch 249 Batch   19/44   train_loss = 0.327
Epoch 249 Batch   20/44   train_loss = 0.315
Epoch 249 Batch   21/44   train_loss = 0.290
Epoch 249 Batch   22/44   train_loss = 0.326
Epoch 249 Batch   23/44   train_loss = 0.310
Epoch 249 Batch   24/44   train_loss = 0.290
Epoch 249 Batch   25/44   train_loss = 0.329
Epoch 249 Batch   26/44   train_loss = 0.328
Epoch 249 Batch   27/44   train_loss = 0.329
Epoch 249 Batch   28/44   train_loss = 0.301
Epoch 249 Batch   29/44   train_loss = 0.310
Epoch 249 Batch   30/44   train_loss = 0.315
Epoch 249 Batch   31/44   train_loss = 0.321
Epoch 249 Batch   32/44   train_loss = 0.298
Epoch 249 Batch   33/44   train_loss = 0.349
Epoch 249 Batch   34/44   train_loss = 0.332
Epoch 249 Batch   35/44   train_loss = 0.305
Epoch 249 Batch   36/44   train_loss = 0.351
Epoch 249 Batch   37/44   train_loss = 0.309
Epoch 249 Batch   38/44   train_loss = 0.320
Epoch 249 Batch   39/44   train_loss = 0.305
Epoch 249 Batch   40/44   train_loss = 0.284
Epoch 249 Batch   41/44   train_loss = 0.306
Epoch 249 Batch   42/44   train_loss = 0.284
Epoch 249 Batch   43/44   train_loss = 0.294
Epoch 250 Batch    0/44   train_loss = 0.301
Epoch 250 Batch    1/44   train_loss = 0.303
Epoch 250 Batch    2/44   train_loss = 0.318
Epoch 250 Batch    3/44   train_loss = 0.344
Epoch 250 Batch    4/44   train_loss = 0.304
Epoch 250 Batch    5/44   train_loss = 0.317
Epoch 250 Batch    6/44   train_loss = 0.317
Epoch 250 Batch    7/44   train_loss = 0.317
Epoch 250 Batch    8/44   train_loss = 0.324
Epoch 250 Batch    9/44   train_loss = 0.347
Epoch 250 Batch   10/44   train_loss = 0.311
Epoch 250 Batch   11/44   train_loss = 0.340
Epoch 250 Batch   12/44   train_loss = 0.313
Epoch 250 Batch   13/44   train_loss = 0.324
Epoch 250 Batch   14/44   train_loss = 0.312
Epoch 250 Batch   15/44   train_loss = 0.339
Epoch 250 Batch   16/44   train_loss = 0.313
Epoch 250 Batch   17/44   train_loss = 0.333
Epoch 250 Batch   18/44   train_loss = 0.322
Epoch 250 Batch   19/44   train_loss = 0.324
Epoch 250 Batch   20/44   train_loss = 0.314
Epoch 250 Batch   21/44   train_loss = 0.290
Epoch 250 Batch   22/44   train_loss = 0.327
Epoch 250 Batch   23/44   train_loss = 0.311
Epoch 250 Batch   24/44   train_loss = 0.290
Epoch 250 Batch   25/44   train_loss = 0.328
Epoch 250 Batch   26/44   train_loss = 0.327
Epoch 250 Batch   27/44   train_loss = 0.328
Epoch 250 Batch   28/44   train_loss = 0.298
Epoch 250 Batch   29/44   train_loss = 0.307
Epoch 250 Batch   30/44   train_loss = 0.311
Epoch 250 Batch   31/44   train_loss = 0.315
Epoch 250 Batch   32/44   train_loss = 0.293
Epoch 250 Batch   33/44   train_loss = 0.345
Epoch 250 Batch   34/44   train_loss = 0.329
Epoch 250 Batch   35/44   train_loss = 0.305
Epoch 250 Batch   36/44   train_loss = 0.354
Epoch 250 Batch   37/44   train_loss = 0.313
Epoch 250 Batch   38/44   train_loss = 0.323
Epoch 250 Batch   39/44   train_loss = 0.308
Epoch 250 Batch   40/44   train_loss = 0.286
Epoch 250 Batch   41/44   train_loss = 0.305
Epoch 250 Batch   42/44   train_loss = 0.283
Epoch 250 Batch   43/44   train_loss = 0.293
Epoch 251 Batch    0/44   train_loss = 0.298
Epoch 251 Batch    1/44   train_loss = 0.299
Epoch 251 Batch    2/44   train_loss = 0.315
Epoch 251 Batch    3/44   train_loss = 0.340
Epoch 251 Batch    4/44   train_loss = 0.301
Epoch 251 Batch    5/44   train_loss = 0.316
Epoch 251 Batch    6/44   train_loss = 0.314
Epoch 251 Batch    7/44   train_loss = 0.317
Epoch 251 Batch    8/44   train_loss = 0.325
Epoch 251 Batch    9/44   train_loss = 0.349
Epoch 251 Batch   10/44   train_loss = 0.312
Epoch 251 Batch   11/44   train_loss = 0.340
Epoch 251 Batch   12/44   train_loss = 0.313
Epoch 251 Batch   13/44   train_loss = 0.324
Epoch 251 Batch   14/44   train_loss = 0.310
Epoch 251 Batch   15/44   train_loss = 0.335
Epoch 251 Batch   16/44   train_loss = 0.309
Epoch 251 Batch   17/44   train_loss = 0.328
Epoch 251 Batch   18/44   train_loss = 0.316
Epoch 251 Batch   19/44   train_loss = 0.318
Epoch 251 Batch   20/44   train_loss = 0.310
Epoch 251 Batch   21/44   train_loss = 0.288
Epoch 251 Batch   22/44   train_loss = 0.327
Epoch 251 Batch   23/44   train_loss = 0.312
Epoch 251 Batch   24/44   train_loss = 0.292
Epoch 251 Batch   25/44   train_loss = 0.333
Epoch 251 Batch   26/44   train_loss = 0.329
Epoch 251 Batch   27/44   train_loss = 0.327
Epoch 251 Batch   28/44   train_loss = 0.298
Epoch 251 Batch   29/44   train_loss = 0.306
Epoch 251 Batch   30/44   train_loss = 0.307
Epoch 251 Batch   31/44   train_loss = 0.311
Epoch 251 Batch   32/44   train_loss = 0.289
Epoch 251 Batch   33/44   train_loss = 0.340
Epoch 251 Batch   34/44   train_loss = 0.325
Epoch 251 Batch   35/44   train_loss = 0.303
Epoch 251 Batch   36/44   train_loss = 0.353
Epoch 251 Batch   37/44   train_loss = 0.311
Epoch 251 Batch   38/44   train_loss = 0.325
Epoch 251 Batch   39/44   train_loss = 0.310
Epoch 251 Batch   40/44   train_loss = 0.289
Epoch 251 Batch   41/44   train_loss = 0.306
Epoch 251 Batch   42/44   train_loss = 0.284
Epoch 251 Batch   43/44   train_loss = 0.295
Epoch 252 Batch    0/44   train_loss = 0.298
Epoch 252 Batch    1/44   train_loss = 0.298
Epoch 252 Batch    2/44   train_loss = 0.313
Epoch 252 Batch    3/44   train_loss = 0.338
Epoch 252 Batch    4/44   train_loss = 0.299
Epoch 252 Batch    5/44   train_loss = 0.314
Epoch 252 Batch    6/44   train_loss = 0.312
Epoch 252 Batch    7/44   train_loss = 0.317
Epoch 252 Batch    8/44   train_loss = 0.323
Epoch 252 Batch    9/44   train_loss = 0.348
Epoch 252 Batch   10/44   train_loss = 0.314
Epoch 252 Batch   11/44   train_loss = 0.340
Epoch 252 Batch   12/44   train_loss = 0.316
Epoch 252 Batch   13/44   train_loss = 0.325
Epoch 252 Batch   14/44   train_loss = 0.310
Epoch 252 Batch   15/44   train_loss = 0.335
Epoch 252 Batch   16/44   train_loss = 0.308
Epoch 252 Batch   17/44   train_loss = 0.325
Epoch 252 Batch   18/44   train_loss = 0.311
Epoch 252 Batch   19/44   train_loss = 0.315
Epoch 252 Batch   20/44   train_loss = 0.305
Epoch 252 Batch   21/44   train_loss = 0.282
Epoch 252 Batch   22/44   train_loss = 0.323
Epoch 252 Batch   23/44   train_loss = 0.309
Epoch 252 Batch   24/44   train_loss = 0.293
Epoch 252 Batch   25/44   train_loss = 0.335
Epoch 252 Batch   26/44   train_loss = 0.330
Epoch 252 Batch   27/44   train_loss = 0.329
Epoch 252 Batch   28/44   train_loss = 0.299
Epoch 252 Batch   29/44   train_loss = 0.307
Epoch 252 Batch   30/44   train_loss = 0.307
Epoch 252 Batch   31/44   train_loss = 0.311
Epoch 252 Batch   32/44   train_loss = 0.286
Epoch 252 Batch   33/44   train_loss = 0.337
Epoch 252 Batch   34/44   train_loss = 0.320
Epoch 252 Batch   35/44   train_loss = 0.298
Epoch 252 Batch   36/44   train_loss = 0.348
Epoch 252 Batch   37/44   train_loss = 0.310
Epoch 252 Batch   38/44   train_loss = 0.324
Epoch 252 Batch   39/44   train_loss = 0.313
Epoch 252 Batch   40/44   train_loss = 0.291
Epoch 252 Batch   41/44   train_loss = 0.310
Epoch 252 Batch   42/44   train_loss = 0.288
Epoch 252 Batch   43/44   train_loss = 0.296
Epoch 253 Batch    0/44   train_loss = 0.301
Epoch 253 Batch    1/44   train_loss = 0.298
Epoch 253 Batch    2/44   train_loss = 0.313
Epoch 253 Batch    3/44   train_loss = 0.335
Epoch 253 Batch    4/44   train_loss = 0.297
Epoch 253 Batch    5/44   train_loss = 0.313
Epoch 253 Batch    6/44   train_loss = 0.310
Epoch 253 Batch    7/44   train_loss = 0.316
Epoch 253 Batch    8/44   train_loss = 0.322
Epoch 253 Batch    9/44   train_loss = 0.347
Epoch 253 Batch   10/44   train_loss = 0.312
Epoch 253 Batch   11/44   train_loss = 0.339
Epoch 253 Batch   12/44   train_loss = 0.317
Epoch 253 Batch   13/44   train_loss = 0.325
Epoch 253 Batch   14/44   train_loss = 0.312
Epoch 253 Batch   15/44   train_loss = 0.335
Epoch 253 Batch   16/44   train_loss = 0.309
Epoch 253 Batch   17/44   train_loss = 0.327
Epoch 253 Batch   18/44   train_loss = 0.311
Epoch 253 Batch   19/44   train_loss = 0.313
Epoch 253 Batch   20/44   train_loss = 0.302
Epoch 253 Batch   21/44   train_loss = 0.278
Epoch 253 Batch   22/44   train_loss = 0.319
Epoch 253 Batch   23/44   train_loss = 0.302
Epoch 253 Batch   24/44   train_loss = 0.287
Epoch 253 Batch   25/44   train_loss = 0.331
Epoch 253 Batch   26/44   train_loss = 0.326
Epoch 253 Batch   27/44   train_loss = 0.327
Epoch 253 Batch   28/44   train_loss = 0.299
Epoch 253 Batch   29/44   train_loss = 0.309
Epoch 253 Batch   30/44   train_loss = 0.309
Epoch 253 Batch   31/44   train_loss = 0.312
Epoch 253 Batch   32/44   train_loss = 0.285
Epoch 253 Batch   33/44   train_loss = 0.336
Epoch 253 Batch   34/44   train_loss = 0.317
Epoch 253 Batch   35/44   train_loss = 0.292
Epoch 253 Batch   36/44   train_loss = 0.343
Epoch 253 Batch   37/44   train_loss = 0.303
Epoch 253 Batch   38/44   train_loss = 0.319
Epoch 253 Batch   39/44   train_loss = 0.307
Epoch 253 Batch   40/44   train_loss = 0.288
Epoch 253 Batch   41/44   train_loss = 0.310
Epoch 253 Batch   42/44   train_loss = 0.292
Epoch 253 Batch   43/44   train_loss = 0.300
Epoch 254 Batch    0/44   train_loss = 0.306
Epoch 254 Batch    1/44   train_loss = 0.304
Epoch 254 Batch    2/44   train_loss = 0.315
Epoch 254 Batch    3/44   train_loss = 0.334
Epoch 254 Batch    4/44   train_loss = 0.297
Epoch 254 Batch    5/44   train_loss = 0.312
Epoch 254 Batch    6/44   train_loss = 0.308
Epoch 254 Batch    7/44   train_loss = 0.315
Epoch 254 Batch    8/44   train_loss = 0.320
Epoch 254 Batch    9/44   train_loss = 0.347
Epoch 254 Batch   10/44   train_loss = 0.314
Epoch 254 Batch   11/44   train_loss = 0.340
Epoch 254 Batch   12/44   train_loss = 0.320
Epoch 254 Batch   13/44   train_loss = 0.327
Epoch 254 Batch   14/44   train_loss = 0.315
Epoch 254 Batch   15/44   train_loss = 0.336
Epoch 254 Batch   16/44   train_loss = 0.310
Epoch 254 Batch   17/44   train_loss = 0.327
Epoch 254 Batch   18/44   train_loss = 0.312
Epoch 254 Batch   19/44   train_loss = 0.313
Epoch 254 Batch   20/44   train_loss = 0.300
Epoch 254 Batch   21/44   train_loss = 0.276
Epoch 254 Batch   22/44   train_loss = 0.318
Epoch 254 Batch   23/44   train_loss = 0.301
Epoch 254 Batch   24/44   train_loss = 0.285
Epoch 254 Batch   25/44   train_loss = 0.328
Epoch 254 Batch   26/44   train_loss = 0.324
Epoch 254 Batch   27/44   train_loss = 0.324
Epoch 254 Batch   28/44   train_loss = 0.294
Epoch 254 Batch   29/44   train_loss = 0.307
Epoch 254 Batch   30/44   train_loss = 0.309
Epoch 254 Batch   31/44   train_loss = 0.312
Epoch 254 Batch   32/44   train_loss = 0.286
Epoch 254 Batch   33/44   train_loss = 0.336
Epoch 254 Batch   34/44   train_loss = 0.318
Epoch 254 Batch   35/44   train_loss = 0.292
Epoch 254 Batch   36/44   train_loss = 0.341
Epoch 254 Batch   37/44   train_loss = 0.306
Epoch 254 Batch   38/44   train_loss = 0.315
Epoch 254 Batch   39/44   train_loss = 0.300
Epoch 254 Batch   40/44   train_loss = 0.281
Epoch 254 Batch   41/44   train_loss = 0.302
Epoch 254 Batch   42/44   train_loss = 0.286
Epoch 254 Batch   43/44   train_loss = 0.295
Epoch 255 Batch    0/44   train_loss = 0.305
Epoch 255 Batch    1/44   train_loss = 0.307
Epoch 255 Batch    2/44   train_loss = 0.321
Epoch 255 Batch    3/44   train_loss = 0.339
Epoch 255 Batch    4/44   train_loss = 0.300
Epoch 255 Batch    5/44   train_loss = 0.314
Epoch 255 Batch    6/44   train_loss = 0.309
Epoch 255 Batch    7/44   train_loss = 0.314
Epoch 255 Batch    8/44   train_loss = 0.316
Epoch 255 Batch    9/44   train_loss = 0.340
Epoch 255 Batch   10/44   train_loss = 0.308
Epoch 255 Batch   11/44   train_loss = 0.334
Epoch 255 Batch   12/44   train_loss = 0.320
Epoch 255 Batch   13/44   train_loss = 0.330
Epoch 255 Batch   14/44   train_loss = 0.323
Epoch 255 Batch   15/44   train_loss = 0.345
Epoch 255 Batch   16/44   train_loss = 0.318
Epoch 255 Batch   17/44   train_loss = 0.332
Epoch 255 Batch   18/44   train_loss = 0.316
Epoch 255 Batch   19/44   train_loss = 0.314
Epoch 255 Batch   20/44   train_loss = 0.300
Epoch 255 Batch   21/44   train_loss = 0.276
Epoch 255 Batch   22/44   train_loss = 0.317
Epoch 255 Batch   23/44   train_loss = 0.300
Epoch 255 Batch   24/44   train_loss = 0.284
Epoch 255 Batch   25/44   train_loss = 0.327
Epoch 255 Batch   26/44   train_loss = 0.323
Epoch 255 Batch   27/44   train_loss = 0.324
Epoch 255 Batch   28/44   train_loss = 0.292
Epoch 255 Batch   29/44   train_loss = 0.304
Epoch 255 Batch   30/44   train_loss = 0.307
Epoch 255 Batch   31/44   train_loss = 0.309
Epoch 255 Batch   32/44   train_loss = 0.285
Epoch 255 Batch   33/44   train_loss = 0.334
Epoch 255 Batch   34/44   train_loss = 0.318
Epoch 255 Batch   35/44   train_loss = 0.292
Epoch 255 Batch   36/44   train_loss = 0.341
Epoch 255 Batch   37/44   train_loss = 0.299
Epoch 255 Batch   38/44   train_loss = 0.313
Epoch 255 Batch   39/44   train_loss = 0.295
Epoch 255 Batch   40/44   train_loss = 0.277
Epoch 255 Batch   41/44   train_loss = 0.297
Epoch 255 Batch   42/44   train_loss = 0.281
Epoch 255 Batch   43/44   train_loss = 0.290
Epoch 256 Batch    0/44   train_loss = 0.299
Epoch 256 Batch    1/44   train_loss = 0.302
Epoch 256 Batch    2/44   train_loss = 0.319
Epoch 256 Batch    3/44   train_loss = 0.340
Epoch 256 Batch    4/44   train_loss = 0.300
Epoch 256 Batch    5/44   train_loss = 0.316
Epoch 256 Batch    6/44   train_loss = 0.311
Epoch 256 Batch    7/44   train_loss = 0.313
Epoch 256 Batch    8/44   train_loss = 0.317
Epoch 256 Batch    9/44   train_loss = 0.338
Epoch 256 Batch   10/44   train_loss = 0.303
Epoch 256 Batch   11/44   train_loss = 0.328
Epoch 256 Batch   12/44   train_loss = 0.310
Epoch 256 Batch   13/44   train_loss = 0.320
Epoch 256 Batch   14/44   train_loss = 0.316
Epoch 256 Batch   15/44   train_loss = 0.343
Epoch 256 Batch   16/44   train_loss = 0.328
Epoch 256 Batch   17/44   train_loss = 0.347
Epoch 256 Batch   18/44   train_loss = 0.332
Epoch 256 Batch   19/44   train_loss = 0.325
Epoch 256 Batch   20/44   train_loss = 0.309
Epoch 256 Batch   21/44   train_loss = 0.280
Epoch 256 Batch   22/44   train_loss = 0.318
Epoch 256 Batch   23/44   train_loss = 0.299
Epoch 256 Batch   24/44   train_loss = 0.281
Epoch 256 Batch   25/44   train_loss = 0.325
Epoch 256 Batch   26/44   train_loss = 0.324
Epoch 256 Batch   27/44   train_loss = 0.326
Epoch 256 Batch   28/44   train_loss = 0.292
Epoch 256 Batch   29/44   train_loss = 0.308
Epoch 256 Batch   30/44   train_loss = 0.310
Epoch 256 Batch   31/44   train_loss = 0.310
Epoch 256 Batch   32/44   train_loss = 0.286
Epoch 256 Batch   33/44   train_loss = 0.334
Epoch 256 Batch   34/44   train_loss = 0.318
Epoch 256 Batch   35/44   train_loss = 0.290
Epoch 256 Batch   36/44   train_loss = 0.338
Epoch 256 Batch   37/44   train_loss = 0.296
Epoch 256 Batch   38/44   train_loss = 0.311
Epoch 256 Batch   39/44   train_loss = 0.295
Epoch 256 Batch   40/44   train_loss = 0.276
Epoch 256 Batch   41/44   train_loss = 0.296
Epoch 256 Batch   42/44   train_loss = 0.277
Epoch 256 Batch   43/44   train_loss = 0.286
Epoch 257 Batch    0/44   train_loss = 0.293
Epoch 257 Batch    1/44   train_loss = 0.296
Epoch 257 Batch    2/44   train_loss = 0.315
Epoch 257 Batch    3/44   train_loss = 0.336
Epoch 257 Batch    4/44   train_loss = 0.297
Epoch 257 Batch    5/44   train_loss = 0.314
Epoch 257 Batch    6/44   train_loss = 0.310
Epoch 257 Batch    7/44   train_loss = 0.314
Epoch 257 Batch    8/44   train_loss = 0.317
Epoch 257 Batch    9/44   train_loss = 0.337
Epoch 257 Batch   10/44   train_loss = 0.303
Epoch 257 Batch   11/44   train_loss = 0.327
Epoch 257 Batch   12/44   train_loss = 0.306
Epoch 257 Batch   13/44   train_loss = 0.313
Epoch 257 Batch   14/44   train_loss = 0.307
Epoch 257 Batch   15/44   train_loss = 0.330
Epoch 257 Batch   16/44   train_loss = 0.312
Epoch 257 Batch   17/44   train_loss = 0.335
Epoch 257 Batch   18/44   train_loss = 0.333
Epoch 257 Batch   19/44   train_loss = 0.343
Epoch 257 Batch   20/44   train_loss = 0.334
Epoch 257 Batch   21/44   train_loss = 0.301
Epoch 257 Batch   22/44   train_loss = 0.333
Epoch 257 Batch   23/44   train_loss = 0.305
Epoch 257 Batch   24/44   train_loss = 0.280
Epoch 257 Batch   25/44   train_loss = 0.324
Epoch 257 Batch   26/44   train_loss = 0.322
Epoch 257 Batch   27/44   train_loss = 0.327
Epoch 257 Batch   28/44   train_loss = 0.295
Epoch 257 Batch   29/44   train_loss = 0.311
Epoch 257 Batch   30/44   train_loss = 0.318
Epoch 257 Batch   31/44   train_loss = 0.318
Epoch 257 Batch   32/44   train_loss = 0.298
Epoch 257 Batch   33/44   train_loss = 0.338
Epoch 257 Batch   34/44   train_loss = 0.320
Epoch 257 Batch   35/44   train_loss = 0.289
Epoch 257 Batch   36/44   train_loss = 0.337
Epoch 257 Batch   37/44   train_loss = 0.293
Epoch 257 Batch   38/44   train_loss = 0.310
Epoch 257 Batch   39/44   train_loss = 0.294
Epoch 257 Batch   40/44   train_loss = 0.277
Epoch 257 Batch   41/44   train_loss = 0.298
Epoch 257 Batch   42/44   train_loss = 0.279
Epoch 257 Batch   43/44   train_loss = 0.286
Epoch 258 Batch    0/44   train_loss = 0.291
Epoch 258 Batch    1/44   train_loss = 0.293
Epoch 258 Batch    2/44   train_loss = 0.310
Epoch 258 Batch    3/44   train_loss = 0.332
Epoch 258 Batch    4/44   train_loss = 0.294
Epoch 258 Batch    5/44   train_loss = 0.310
Epoch 258 Batch    6/44   train_loss = 0.307
Epoch 258 Batch    7/44   train_loss = 0.311
Epoch 258 Batch    8/44   train_loss = 0.316
Epoch 258 Batch    9/44   train_loss = 0.337
Epoch 258 Batch   10/44   train_loss = 0.303
Epoch 258 Batch   11/44   train_loss = 0.329
Epoch 258 Batch   12/44   train_loss = 0.306
Epoch 258 Batch   13/44   train_loss = 0.312
Epoch 258 Batch   14/44   train_loss = 0.303
Epoch 258 Batch   15/44   train_loss = 0.324
Epoch 258 Batch   16/44   train_loss = 0.302
Epoch 258 Batch   17/44   train_loss = 0.323
Epoch 258 Batch   18/44   train_loss = 0.317
Epoch 258 Batch   19/44   train_loss = 0.326
Epoch 258 Batch   20/44   train_loss = 0.323
Epoch 258 Batch   21/44   train_loss = 0.309
Epoch 258 Batch   22/44   train_loss = 0.356
Epoch 258 Batch   23/44   train_loss = 0.328
Epoch 258 Batch   24/44   train_loss = 0.295
Epoch 258 Batch   25/44   train_loss = 0.332
Epoch 258 Batch   26/44   train_loss = 0.322
Epoch 258 Batch   27/44   train_loss = 0.321
Epoch 258 Batch   28/44   train_loss = 0.287
Epoch 258 Batch   29/44   train_loss = 0.301
Epoch 258 Batch   30/44   train_loss = 0.307
Epoch 258 Batch   31/44   train_loss = 0.315
Epoch 258 Batch   32/44   train_loss = 0.307
Epoch 258 Batch   33/44   train_loss = 0.360
Epoch 258 Batch   34/44   train_loss = 0.346
Epoch 258 Batch   35/44   train_loss = 0.304
Epoch 258 Batch   36/44   train_loss = 0.342
Epoch 258 Batch   37/44   train_loss = 0.294
Epoch 258 Batch   38/44   train_loss = 0.309
Epoch 258 Batch   39/44   train_loss = 0.293
Epoch 258 Batch   40/44   train_loss = 0.277
Epoch 258 Batch   41/44   train_loss = 0.300
Epoch 258 Batch   42/44   train_loss = 0.284
Epoch 258 Batch   43/44   train_loss = 0.291
Epoch 259 Batch    0/44   train_loss = 0.295
Epoch 259 Batch    1/44   train_loss = 0.296
Epoch 259 Batch    2/44   train_loss = 0.312
Epoch 259 Batch    3/44   train_loss = 0.333
Epoch 259 Batch    4/44   train_loss = 0.293
Epoch 259 Batch    5/44   train_loss = 0.309
Epoch 259 Batch    6/44   train_loss = 0.304
Epoch 259 Batch    7/44   train_loss = 0.310
Epoch 259 Batch    8/44   train_loss = 0.313
Epoch 259 Batch    9/44   train_loss = 0.336
Epoch 259 Batch   10/44   train_loss = 0.306
Epoch 259 Batch   11/44   train_loss = 0.331
Epoch 259 Batch   12/44   train_loss = 0.307
Epoch 259 Batch   13/44   train_loss = 0.313
Epoch 259 Batch   14/44   train_loss = 0.302
Epoch 259 Batch   15/44   train_loss = 0.324
Epoch 259 Batch   16/44   train_loss = 0.300
Epoch 259 Batch   17/44   train_loss = 0.318
Epoch 259 Batch   18/44   train_loss = 0.308
Epoch 259 Batch   19/44   train_loss = 0.335
Epoch 259 Batch   20/44   train_loss = 0.310
Epoch 259 Batch   21/44   train_loss = 0.290
Epoch 259 Batch   22/44   train_loss = 0.339
Epoch 259 Batch   23/44   train_loss = 0.325
Epoch 259 Batch   24/44   train_loss = 0.310
Epoch 259 Batch   25/44   train_loss = 0.352
Epoch 259 Batch   26/44   train_loss = 0.335
Epoch 259 Batch   27/44   train_loss = 0.331
Epoch 259 Batch   28/44   train_loss = 0.293
Epoch 259 Batch   29/44   train_loss = 0.297
Epoch 259 Batch   30/44   train_loss = 0.297
Epoch 259 Batch   31/44   train_loss = 0.301
Epoch 259 Batch   32/44   train_loss = 0.283
Epoch 259 Batch   33/44   train_loss = 0.341
Epoch 259 Batch   34/44   train_loss = 0.338
Epoch 259 Batch   35/44   train_loss = 0.333
Epoch 259 Batch   36/44   train_loss = 0.403
Epoch 259 Batch   37/44   train_loss = 0.325
Epoch 259 Batch   38/44   train_loss = 0.318
Epoch 259 Batch   39/44   train_loss = 0.295
Epoch 259 Batch   40/44   train_loss = 0.272
Epoch 259 Batch   41/44   train_loss = 0.295
Epoch 259 Batch   42/44   train_loss = 0.282
Epoch 259 Batch   43/44   train_loss = 0.293
Epoch 260 Batch    0/44   train_loss = 0.300
Epoch 260 Batch    1/44   train_loss = 0.303
Epoch 260 Batch    2/44   train_loss = 0.321
Epoch 260 Batch    3/44   train_loss = 0.344
Epoch 260 Batch    4/44   train_loss = 0.300
Epoch 260 Batch    5/44   train_loss = 0.313
Epoch 260 Batch    6/44   train_loss = 0.306
Epoch 260 Batch    7/44   train_loss = 0.311
Epoch 260 Batch    8/44   train_loss = 0.311
Epoch 260 Batch    9/44   train_loss = 0.337
Epoch 260 Batch   10/44   train_loss = 0.303
Epoch 260 Batch   11/44   train_loss = 0.332
Epoch 260 Batch   12/44   train_loss = 0.307
Epoch 260 Batch   13/44   train_loss = 0.316
Epoch 260 Batch   14/44   train_loss = 0.307
Epoch 260 Batch   15/44   train_loss = 0.327
Epoch 260 Batch   16/44   train_loss = 0.302
Epoch 260 Batch   17/44   train_loss = 0.320
Epoch 260 Batch   18/44   train_loss = 0.305
Epoch 260 Batch   19/44   train_loss = 0.317
Epoch 260 Batch   20/44   train_loss = 0.301
Epoch 260 Batch   21/44   train_loss = 0.278
Epoch 260 Batch   22/44   train_loss = 0.325
Epoch 260 Batch   23/44   train_loss = 0.310
Epoch 260 Batch   24/44   train_loss = 0.294
Epoch 260 Batch   25/44   train_loss = 0.346
Epoch 260 Batch   26/44   train_loss = 0.342
Epoch 260 Batch   27/44   train_loss = 0.348
Epoch 260 Batch   28/44   train_loss = 0.312
Epoch 260 Batch   29/44   train_loss = 0.311
Epoch 260 Batch   30/44   train_loss = 0.305
Epoch 260 Batch   31/44   train_loss = 0.304
Epoch 260 Batch   32/44   train_loss = 0.276
Epoch 260 Batch   33/44   train_loss = 0.325
Epoch 260 Batch   34/44   train_loss = 0.312
Epoch 260 Batch   35/44   train_loss = 0.291
Epoch 260 Batch   36/44   train_loss = 0.357
Epoch 260 Batch   37/44   train_loss = 0.347
Epoch 260 Batch   38/44   train_loss = 0.391
Epoch 260 Batch   39/44   train_loss = 0.358
Epoch 260 Batch   40/44   train_loss = 0.300
Epoch 260 Batch   41/44   train_loss = 0.301
Epoch 260 Batch   42/44   train_loss = 0.278
Epoch 260 Batch   43/44   train_loss = 0.285
Epoch 261 Batch    0/44   train_loss = 0.290
Epoch 261 Batch    1/44   train_loss = 0.295
Epoch 261 Batch    2/44   train_loss = 0.314
Epoch 261 Batch    3/44   train_loss = 0.352
Epoch 261 Batch    4/44   train_loss = 0.317
Epoch 261 Batch    5/44   train_loss = 0.334
Epoch 261 Batch    6/44   train_loss = 0.326
Epoch 261 Batch    7/44   train_loss = 0.323
Epoch 261 Batch    8/44   train_loss = 0.316
Epoch 261 Batch    9/44   train_loss = 0.338
Epoch 261 Batch   10/44   train_loss = 0.300
Epoch 261 Batch   11/44   train_loss = 0.331
Epoch 261 Batch   12/44   train_loss = 0.306
Epoch 261 Batch   13/44   train_loss = 0.316
Epoch 261 Batch   14/44   train_loss = 0.312
Epoch 261 Batch   15/44   train_loss = 0.331
Epoch 261 Batch   16/44   train_loss = 0.309
Epoch 261 Batch   17/44   train_loss = 0.324
Epoch 261 Batch   18/44   train_loss = 0.307
Epoch 261 Batch   19/44   train_loss = 0.316
Epoch 261 Batch   20/44   train_loss = 0.299
Epoch 261 Batch   21/44   train_loss = 0.275
Epoch 261 Batch   22/44   train_loss = 0.317
Epoch 261 Batch   23/44   train_loss = 0.299
Epoch 261 Batch   24/44   train_loss = 0.282
Epoch 261 Batch   25/44   train_loss = 0.329
Epoch 261 Batch   26/44   train_loss = 0.327
Epoch 261 Batch   27/44   train_loss = 0.337
Epoch 261 Batch   28/44   train_loss = 0.308
Epoch 261 Batch   29/44   train_loss = 0.319
Epoch 261 Batch   30/44   train_loss = 0.317
Epoch 261 Batch   31/44   train_loss = 0.320
Epoch 261 Batch   32/44   train_loss = 0.289
Epoch 261 Batch   33/44   train_loss = 0.329
Epoch 261 Batch   34/44   train_loss = 0.309
Epoch 261 Batch   35/44   train_loss = 0.279
Epoch 261 Batch   36/44   train_loss = 0.329
Epoch 261 Batch   37/44   train_loss = 0.294
Epoch 261 Batch   38/44   train_loss = 0.325
Epoch 261 Batch   39/44   train_loss = 0.329
Epoch 261 Batch   40/44   train_loss = 0.340
Epoch 261 Batch   41/44   train_loss = 0.369
Epoch 261 Batch   42/44   train_loss = 0.330
Epoch 261 Batch   43/44   train_loss = 0.312
Epoch 262 Batch    0/44   train_loss = 0.299
Epoch 262 Batch    1/44   train_loss = 0.293
Epoch 262 Batch    2/44   train_loss = 0.307
Epoch 262 Batch    3/44   train_loss = 0.330
Epoch 262 Batch    4/44   train_loss = 0.295
Epoch 262 Batch    5/44   train_loss = 0.325
Epoch 262 Batch    6/44   train_loss = 0.332
Epoch 262 Batch    7/44   train_loss = 0.341
Epoch 262 Batch    8/44   train_loss = 0.361
Epoch 262 Batch    9/44   train_loss = 0.369
Epoch 262 Batch   10/44   train_loss = 0.313
Epoch 262 Batch   11/44   train_loss = 0.337
Epoch 262 Batch   12/44   train_loss = 0.308
Epoch 262 Batch   13/44   train_loss = 0.315
Epoch 262 Batch   14/44   train_loss = 0.311
Epoch 262 Batch   15/44   train_loss = 0.332
Epoch 262 Batch   16/44   train_loss = 0.309
Epoch 262 Batch   17/44   train_loss = 0.330
Epoch 262 Batch   18/44   train_loss = 0.316
Epoch 262 Batch   19/44   train_loss = 0.326
Epoch 262 Batch   20/44   train_loss = 0.305
Epoch 262 Batch   21/44   train_loss = 0.278
Epoch 262 Batch   22/44   train_loss = 0.316
Epoch 262 Batch   23/44   train_loss = 0.298
Epoch 262 Batch   24/44   train_loss = 0.278
Epoch 262 Batch   25/44   train_loss = 0.324
Epoch 262 Batch   26/44   train_loss = 0.319
Epoch 262 Batch   27/44   train_loss = 0.325
Epoch 262 Batch   28/44   train_loss = 0.298
Epoch 262 Batch   29/44   train_loss = 0.308
Epoch 262 Batch   30/44   train_loss = 0.312
Epoch 262 Batch   31/44   train_loss = 0.320
Epoch 262 Batch   32/44   train_loss = 0.296
Epoch 262 Batch   33/44   train_loss = 0.335
Epoch 262 Batch   34/44   train_loss = 0.314
Epoch 262 Batch   35/44   train_loss = 0.286
Epoch 262 Batch   36/44   train_loss = 0.332
Epoch 262 Batch   37/44   train_loss = 0.288
Epoch 262 Batch   38/44   train_loss = 0.309
Epoch 262 Batch   39/44   train_loss = 0.296
Epoch 262 Batch   40/44   train_loss = 0.288
Epoch 262 Batch   41/44   train_loss = 0.312
Epoch 262 Batch   42/44   train_loss = 0.311
Epoch 262 Batch   43/44   train_loss = 0.338
Epoch 263 Batch    0/44   train_loss = 0.358
Epoch 263 Batch    1/44   train_loss = 0.335
Epoch 263 Batch    2/44   train_loss = 0.337
Epoch 263 Batch    3/44   train_loss = 0.342
Epoch 263 Batch    4/44   train_loss = 0.298
Epoch 263 Batch    5/44   train_loss = 0.313
Epoch 263 Batch    6/44   train_loss = 0.309
Epoch 263 Batch    7/44   train_loss = 0.310
Epoch 263 Batch    8/44   train_loss = 0.323
Epoch 263 Batch    9/44   train_loss = 0.363
Epoch 263 Batch   10/44   train_loss = 0.345
Epoch 263 Batch   11/44   train_loss = 0.375
Epoch 263 Batch   12/44   train_loss = 0.354
Epoch 263 Batch   13/44   train_loss = 0.331
Epoch 263 Batch   14/44   train_loss = 0.316
Epoch 263 Batch   15/44   train_loss = 0.329
Epoch 263 Batch   16/44   train_loss = 0.305
Epoch 263 Batch   17/44   train_loss = 0.324
Epoch 263 Batch   18/44   train_loss = 0.314
Epoch 263 Batch   19/44   train_loss = 0.327
Epoch 263 Batch   20/44   train_loss = 0.320
Epoch 263 Batch   21/44   train_loss = 0.291
Epoch 263 Batch   22/44   train_loss = 0.331
Epoch 263 Batch   23/44   train_loss = 0.306
Epoch 263 Batch   24/44   train_loss = 0.282
Epoch 263 Batch   25/44   train_loss = 0.319
Epoch 263 Batch   26/44   train_loss = 0.317
Epoch 263 Batch   27/44   train_loss = 0.319
Epoch 263 Batch   28/44   train_loss = 0.292
Epoch 263 Batch   29/44   train_loss = 0.302
Epoch 263 Batch   30/44   train_loss = 0.307
Epoch 263 Batch   31/44   train_loss = 0.319
Epoch 263 Batch   32/44   train_loss = 0.292
Epoch 263 Batch   33/44   train_loss = 0.335
Epoch 263 Batch   34/44   train_loss = 0.316
Epoch 263 Batch   35/44   train_loss = 0.289
Epoch 263 Batch   36/44   train_loss = 0.334
Epoch 263 Batch   37/44   train_loss = 0.288
Epoch 263 Batch   38/44   train_loss = 0.309
Epoch 263 Batch   39/44   train_loss = 0.291
Epoch 263 Batch   40/44   train_loss = 0.274
Epoch 263 Batch   41/44   train_loss = 0.296
Epoch 263 Batch   42/44   train_loss = 0.282
Epoch 263 Batch   43/44   train_loss = 0.298
Epoch 264 Batch    0/44   train_loss = 0.316
Epoch 264 Batch    1/44   train_loss = 0.322
Epoch 264 Batch    2/44   train_loss = 0.351
Epoch 264 Batch    3/44   train_loss = 0.364
Epoch 264 Batch    4/44   train_loss = 0.321
Epoch 264 Batch    5/44   train_loss = 0.326
Epoch 264 Batch    6/44   train_loss = 0.317
Epoch 264 Batch    7/44   train_loss = 0.311
Epoch 264 Batch    8/44   train_loss = 0.308
Epoch 264 Batch    9/44   train_loss = 0.332
Epoch 264 Batch   10/44   train_loss = 0.299
Epoch 264 Batch   11/44   train_loss = 0.333
Epoch 264 Batch   12/44   train_loss = 0.320
Epoch 264 Batch   13/44   train_loss = 0.331
Epoch 264 Batch   14/44   train_loss = 0.346
Epoch 264 Batch   15/44   train_loss = 0.371
Epoch 264 Batch   16/44   train_loss = 0.338
Epoch 264 Batch   17/44   train_loss = 0.339
Epoch 264 Batch   18/44   train_loss = 0.321
Epoch 264 Batch   19/44   train_loss = 0.319
Epoch 264 Batch   20/44   train_loss = 0.305
Epoch 264 Batch   21/44   train_loss = 0.282
Epoch 264 Batch   22/44   train_loss = 0.326
Epoch 264 Batch   23/44   train_loss = 0.313
Epoch 264 Batch   24/44   train_loss = 0.293
Epoch 264 Batch   25/44   train_loss = 0.333
Epoch 264 Batch   26/44   train_loss = 0.329
Epoch 264 Batch   27/44   train_loss = 0.323
Epoch 264 Batch   28/44   train_loss = 0.288
Epoch 264 Batch   29/44   train_loss = 0.300
Epoch 264 Batch   30/44   train_loss = 0.300
Epoch 264 Batch   31/44   train_loss = 0.306
Epoch 264 Batch   32/44   train_loss = 0.284
Epoch 264 Batch   33/44   train_loss = 0.329
Epoch 264 Batch   34/44   train_loss = 0.315
Epoch 264 Batch   35/44   train_loss = 0.289
Epoch 264 Batch   36/44   train_loss = 0.335
Epoch 264 Batch   37/44   train_loss = 0.294
Epoch 264 Batch   38/44   train_loss = 0.307
Epoch 264 Batch   39/44   train_loss = 0.291
Epoch 264 Batch   40/44   train_loss = 0.275
Epoch 264 Batch   41/44   train_loss = 0.293
Epoch 264 Batch   42/44   train_loss = 0.274
Epoch 264 Batch   43/44   train_loss = 0.287
Epoch 265 Batch    0/44   train_loss = 0.296
Epoch 265 Batch    1/44   train_loss = 0.301
Epoch 265 Batch    2/44   train_loss = 0.327
Epoch 265 Batch    3/44   train_loss = 0.347
Epoch 265 Batch    4/44   train_loss = 0.310
Epoch 265 Batch    5/44   train_loss = 0.328
Epoch 265 Batch    6/44   train_loss = 0.321
Epoch 265 Batch    7/44   train_loss = 0.317
Epoch 265 Batch    8/44   train_loss = 0.314
Epoch 265 Batch    9/44   train_loss = 0.334
Epoch 265 Batch   10/44   train_loss = 0.297
Epoch 265 Batch   11/44   train_loss = 0.324
Epoch 265 Batch   12/44   train_loss = 0.296
Epoch 265 Batch   13/44   train_loss = 0.303
Epoch 265 Batch   14/44   train_loss = 0.302
Epoch 265 Batch   15/44   train_loss = 0.328
Epoch 265 Batch   16/44   train_loss = 0.312
Epoch 265 Batch   17/44   train_loss = 0.347
Epoch 265 Batch   18/44   train_loss = 0.348
Epoch 265 Batch   19/44   train_loss = 0.350
Epoch 265 Batch   20/44   train_loss = 0.326
Epoch 265 Batch   21/44   train_loss = 0.296
Epoch 265 Batch   22/44   train_loss = 0.329
Epoch 265 Batch   23/44   train_loss = 0.306
Epoch 265 Batch   24/44   train_loss = 0.282
Epoch 265 Batch   25/44   train_loss = 0.327
Epoch 265 Batch   26/44   train_loss = 0.325
Epoch 265 Batch   27/44   train_loss = 0.330
Epoch 265 Batch   28/44   train_loss = 0.298
Epoch 265 Batch   29/44   train_loss = 0.307
Epoch 265 Batch   30/44   train_loss = 0.309
Epoch 265 Batch   31/44   train_loss = 0.307
Epoch 265 Batch   32/44   train_loss = 0.282
Epoch 265 Batch   33/44   train_loss = 0.331
Epoch 265 Batch   34/44   train_loss = 0.319
Epoch 265 Batch   35/44   train_loss = 0.293
Epoch 265 Batch   36/44   train_loss = 0.337
Epoch 265 Batch   37/44   train_loss = 0.297
Epoch 265 Batch   38/44   train_loss = 0.312
Epoch 265 Batch   39/44   train_loss = 0.296
Epoch 265 Batch   40/44   train_loss = 0.277
Epoch 265 Batch   41/44   train_loss = 0.296
Epoch 265 Batch   42/44   train_loss = 0.276
Epoch 265 Batch   43/44   train_loss = 0.287
Epoch 266 Batch    0/44   train_loss = 0.290
Epoch 266 Batch    1/44   train_loss = 0.292
Epoch 266 Batch    2/44   train_loss = 0.310
Epoch 266 Batch    3/44   train_loss = 0.333
Epoch 266 Batch    4/44   train_loss = 0.297
Epoch 266 Batch    5/44   train_loss = 0.315
Epoch 266 Batch    6/44   train_loss = 0.311
Epoch 266 Batch    7/44   train_loss = 0.311
Epoch 266 Batch    8/44   train_loss = 0.313
Epoch 266 Batch    9/44   train_loss = 0.338
Epoch 266 Batch   10/44   train_loss = 0.303
Epoch 266 Batch   11/44   train_loss = 0.324
Epoch 266 Batch   12/44   train_loss = 0.294
Epoch 266 Batch   13/44   train_loss = 0.301
Epoch 266 Batch   14/44   train_loss = 0.294
Epoch 266 Batch   15/44   train_loss = 0.320
Epoch 266 Batch   16/44   train_loss = 0.294
Epoch 266 Batch   17/44   train_loss = 0.314
Epoch 266 Batch   18/44   train_loss = 0.311
Epoch 266 Batch   19/44   train_loss = 0.321
Epoch 266 Batch   20/44   train_loss = 0.326
Epoch 266 Batch   21/44   train_loss = 0.307
Epoch 266 Batch   22/44   train_loss = 0.354
Epoch 266 Batch   23/44   train_loss = 0.318
Epoch 266 Batch   24/44   train_loss = 0.288
Epoch 266 Batch   25/44   train_loss = 0.327
Epoch 266 Batch   26/44   train_loss = 0.321
Epoch 266 Batch   27/44   train_loss = 0.323
Epoch 266 Batch   28/44   train_loss = 0.293
Epoch 266 Batch   29/44   train_loss = 0.299
Epoch 266 Batch   30/44   train_loss = 0.301
Epoch 266 Batch   31/44   train_loss = 0.304
Epoch 266 Batch   32/44   train_loss = 0.285
Epoch 266 Batch   33/44   train_loss = 0.333
Epoch 266 Batch   34/44   train_loss = 0.323
Epoch 266 Batch   35/44   train_loss = 0.295
Epoch 266 Batch   36/44   train_loss = 0.340
Epoch 266 Batch   37/44   train_loss = 0.297
Epoch 266 Batch   38/44   train_loss = 0.313
Epoch 266 Batch   39/44   train_loss = 0.303
Epoch 266 Batch   40/44   train_loss = 0.283
Epoch 266 Batch   41/44   train_loss = 0.301
Epoch 266 Batch   42/44   train_loss = 0.280
Epoch 266 Batch   43/44   train_loss = 0.287
Epoch 267 Batch    0/44   train_loss = 0.293
Epoch 267 Batch    1/44   train_loss = 0.293
Epoch 267 Batch    2/44   train_loss = 0.306
Epoch 267 Batch    3/44   train_loss = 0.328
Epoch 267 Batch    4/44   train_loss = 0.293
Epoch 267 Batch    5/44   train_loss = 0.307
Epoch 267 Batch    6/44   train_loss = 0.306
Epoch 267 Batch    7/44   train_loss = 0.306
Epoch 267 Batch    8/44   train_loss = 0.310
Epoch 267 Batch    9/44   train_loss = 0.337
Epoch 267 Batch   10/44   train_loss = 0.304
Epoch 267 Batch   11/44   train_loss = 0.326
Epoch 267 Batch   12/44   train_loss = 0.296
Epoch 267 Batch   13/44   train_loss = 0.302
Epoch 267 Batch   14/44   train_loss = 0.297
Epoch 267 Batch   15/44   train_loss = 0.321
Epoch 267 Batch   16/44   train_loss = 0.293
Epoch 267 Batch   17/44   train_loss = 0.310
Epoch 267 Batch   18/44   train_loss = 0.303
Epoch 267 Batch   19/44   train_loss = 0.309
Epoch 267 Batch   20/44   train_loss = 0.304
Epoch 267 Batch   21/44   train_loss = 0.286
Epoch 267 Batch   22/44   train_loss = 0.335
Epoch 267 Batch   23/44   train_loss = 0.315
Epoch 267 Batch   24/44   train_loss = 0.296
Epoch 267 Batch   25/44   train_loss = 0.345
Epoch 267 Batch   26/44   train_loss = 0.335
Epoch 267 Batch   27/44   train_loss = 0.330
Epoch 267 Batch   28/44   train_loss = 0.294
Epoch 267 Batch   29/44   train_loss = 0.299
Epoch 267 Batch   30/44   train_loss = 0.298
Epoch 267 Batch   31/44   train_loss = 0.299
Epoch 267 Batch   32/44   train_loss = 0.275
Epoch 267 Batch   33/44   train_loss = 0.324
Epoch 267 Batch   34/44   train_loss = 0.312
Epoch 267 Batch   35/44   train_loss = 0.285
Epoch 267 Batch   36/44   train_loss = 0.337
Epoch 267 Batch   37/44   train_loss = 0.300
Epoch 267 Batch   38/44   train_loss = 0.317
Epoch 267 Batch   39/44   train_loss = 0.302
Epoch 267 Batch   40/44   train_loss = 0.290
Epoch 267 Batch   41/44   train_loss = 0.304
Epoch 267 Batch   42/44   train_loss = 0.283
Epoch 267 Batch   43/44   train_loss = 0.292
Epoch 268 Batch    0/44   train_loss = 0.295
Epoch 268 Batch    1/44   train_loss = 0.296
Epoch 268 Batch    2/44   train_loss = 0.310
Epoch 268 Batch    3/44   train_loss = 0.331
Epoch 268 Batch    4/44   train_loss = 0.292
Epoch 268 Batch    5/44   train_loss = 0.308
Epoch 268 Batch    6/44   train_loss = 0.304
Epoch 268 Batch    7/44   train_loss = 0.301
Epoch 268 Batch    8/44   train_loss = 0.307
Epoch 268 Batch    9/44   train_loss = 0.333
Epoch 268 Batch   10/44   train_loss = 0.298
Epoch 268 Batch   11/44   train_loss = 0.325
Epoch 268 Batch   12/44   train_loss = 0.296
Epoch 268 Batch   13/44   train_loss = 0.305
Epoch 268 Batch   14/44   train_loss = 0.301
Epoch 268 Batch   15/44   train_loss = 0.324
Epoch 268 Batch   16/44   train_loss = 0.296
Epoch 268 Batch   17/44   train_loss = 0.314
Epoch 268 Batch   18/44   train_loss = 0.304
Epoch 268 Batch   19/44   train_loss = 0.308
Epoch 268 Batch   20/44   train_loss = 0.300
Epoch 268 Batch   21/44   train_loss = 0.277
Epoch 268 Batch   22/44   train_loss = 0.323
Epoch 268 Batch   23/44   train_loss = 0.302
Epoch 268 Batch   24/44   train_loss = 0.282
Epoch 268 Batch   25/44   train_loss = 0.330
Epoch 268 Batch   26/44   train_loss = 0.329
Epoch 268 Batch   27/44   train_loss = 0.335
Epoch 268 Batch   28/44   train_loss = 0.303
Epoch 268 Batch   29/44   train_loss = 0.307
Epoch 268 Batch   30/44   train_loss = 0.304
Epoch 268 Batch   31/44   train_loss = 0.305
Epoch 268 Batch   32/44   train_loss = 0.276
Epoch 268 Batch   33/44   train_loss = 0.322
Epoch 268 Batch   34/44   train_loss = 0.307
Epoch 268 Batch   35/44   train_loss = 0.278
Epoch 268 Batch   36/44   train_loss = 0.326
Epoch 268 Batch   37/44   train_loss = 0.284
Epoch 268 Batch   38/44   train_loss = 0.307
Epoch 268 Batch   39/44   train_loss = 0.296
Epoch 268 Batch   40/44   train_loss = 0.289
Epoch 268 Batch   41/44   train_loss = 0.309
Epoch 268 Batch   42/44   train_loss = 0.297
Epoch 268 Batch   43/44   train_loss = 0.299
Epoch 269 Batch    0/44   train_loss = 0.302
Epoch 269 Batch    1/44   train_loss = 0.300
Epoch 269 Batch    2/44   train_loss = 0.314
Epoch 269 Batch    3/44   train_loss = 0.332
Epoch 269 Batch    4/44   train_loss = 0.295
Epoch 269 Batch    5/44   train_loss = 0.310
Epoch 269 Batch    6/44   train_loss = 0.305
Epoch 269 Batch    7/44   train_loss = 0.304
Epoch 269 Batch    8/44   train_loss = 0.307
Epoch 269 Batch    9/44   train_loss = 0.334
Epoch 269 Batch   10/44   train_loss = 0.296
Epoch 269 Batch   11/44   train_loss = 0.325
Epoch 269 Batch   12/44   train_loss = 0.295
Epoch 269 Batch   13/44   train_loss = 0.304
Epoch 269 Batch   14/44   train_loss = 0.299
Epoch 269 Batch   15/44   train_loss = 0.324
Epoch 269 Batch   16/44   train_loss = 0.297
Epoch 269 Batch   17/44   train_loss = 0.317
Epoch 269 Batch   18/44   train_loss = 0.307
Epoch 269 Batch   19/44   train_loss = 0.311
Epoch 269 Batch   20/44   train_loss = 0.302
Epoch 269 Batch   21/44   train_loss = 0.278
Epoch 269 Batch   22/44   train_loss = 0.319
Epoch 269 Batch   23/44   train_loss = 0.299
Epoch 269 Batch   24/44   train_loss = 0.276
Epoch 269 Batch   25/44   train_loss = 0.322
Epoch 269 Batch   26/44   train_loss = 0.320
Epoch 269 Batch   27/44   train_loss = 0.325
Epoch 269 Batch   28/44   train_loss = 0.296
Epoch 269 Batch   29/44   train_loss = 0.305
Epoch 269 Batch   30/44   train_loss = 0.307
Epoch 269 Batch   31/44   train_loss = 0.309
Epoch 269 Batch   32/44   train_loss = 0.281
Epoch 269 Batch   33/44   train_loss = 0.327
Epoch 269 Batch   34/44   train_loss = 0.312
Epoch 269 Batch   35/44   train_loss = 0.279
Epoch 269 Batch   36/44   train_loss = 0.324
Epoch 269 Batch   37/44   train_loss = 0.280
Epoch 269 Batch   38/44   train_loss = 0.302
Epoch 269 Batch   39/44   train_loss = 0.286
Epoch 269 Batch   40/44   train_loss = 0.274
Epoch 269 Batch   41/44   train_loss = 0.295
Epoch 269 Batch   42/44   train_loss = 0.283
Epoch 269 Batch   43/44   train_loss = 0.301
Epoch 270 Batch    0/44   train_loss = 0.309
Epoch 270 Batch    1/44   train_loss = 0.316
Epoch 270 Batch    2/44   train_loss = 0.330
Epoch 270 Batch    3/44   train_loss = 0.342
Epoch 270 Batch    4/44   train_loss = 0.303
Epoch 270 Batch    5/44   train_loss = 0.314
Epoch 270 Batch    6/44   train_loss = 0.307
Epoch 270 Batch    7/44   train_loss = 0.303
Epoch 270 Batch    8/44   train_loss = 0.307
Epoch 270 Batch    9/44   train_loss = 0.334
Epoch 270 Batch   10/44   train_loss = 0.297
Epoch 270 Batch   11/44   train_loss = 0.327
Epoch 270 Batch   12/44   train_loss = 0.295
Epoch 270 Batch   13/44   train_loss = 0.304
Epoch 270 Batch   14/44   train_loss = 0.302
Epoch 270 Batch   15/44   train_loss = 0.326
Epoch 270 Batch   16/44   train_loss = 0.299
Epoch 270 Batch   17/44   train_loss = 0.317
Epoch 270 Batch   18/44   train_loss = 0.308
Epoch 270 Batch   19/44   train_loss = 0.310
Epoch 270 Batch   20/44   train_loss = 0.303
Epoch 270 Batch   21/44   train_loss = 0.279
Epoch 270 Batch   22/44   train_loss = 0.317
Epoch 270 Batch   23/44   train_loss = 0.298
Epoch 270 Batch   24/44   train_loss = 0.276
Epoch 270 Batch   25/44   train_loss = 0.320
Epoch 270 Batch   26/44   train_loss = 0.316
Epoch 270 Batch   27/44   train_loss = 0.320
Epoch 270 Batch   28/44   train_loss = 0.290
Epoch 270 Batch   29/44   train_loss = 0.298
Epoch 270 Batch   30/44   train_loss = 0.301
Epoch 270 Batch   31/44   train_loss = 0.307
Epoch 270 Batch   32/44   train_loss = 0.280
Epoch 270 Batch   33/44   train_loss = 0.326
Epoch 270 Batch   34/44   train_loss = 0.315
Epoch 270 Batch   35/44   train_loss = 0.281
Epoch 270 Batch   36/44   train_loss = 0.325
Epoch 270 Batch   37/44   train_loss = 0.281
Epoch 270 Batch   38/44   train_loss = 0.303
Epoch 270 Batch   39/44   train_loss = 0.284
Epoch 270 Batch   40/44   train_loss = 0.271
Epoch 270 Batch   41/44   train_loss = 0.288
Epoch 270 Batch   42/44   train_loss = 0.272
Epoch 270 Batch   43/44   train_loss = 0.287
Epoch 271 Batch    0/44   train_loss = 0.295
Epoch 271 Batch    1/44   train_loss = 0.305
Epoch 271 Batch    2/44   train_loss = 0.329
Epoch 271 Batch    3/44   train_loss = 0.351
Epoch 271 Batch    4/44   train_loss = 0.316
Epoch 271 Batch    5/44   train_loss = 0.327
Epoch 271 Batch    6/44   train_loss = 0.317
Epoch 271 Batch    7/44   train_loss = 0.313
Epoch 271 Batch    8/44   train_loss = 0.312
Epoch 271 Batch    9/44   train_loss = 0.337
Epoch 271 Batch   10/44   train_loss = 0.298
Epoch 271 Batch   11/44   train_loss = 0.326
Epoch 271 Batch   12/44   train_loss = 0.295
Epoch 271 Batch   13/44   train_loss = 0.303
Epoch 271 Batch   14/44   train_loss = 0.300
Epoch 271 Batch   15/44   train_loss = 0.326
Epoch 271 Batch   16/44   train_loss = 0.302
Epoch 271 Batch   17/44   train_loss = 0.320
Epoch 271 Batch   18/44   train_loss = 0.312
Epoch 271 Batch   19/44   train_loss = 0.313
Epoch 271 Batch   20/44   train_loss = 0.307
Epoch 271 Batch   21/44   train_loss = 0.283
Epoch 271 Batch   22/44   train_loss = 0.319
Epoch 271 Batch   23/44   train_loss = 0.300
Epoch 271 Batch   24/44   train_loss = 0.279
Epoch 271 Batch   25/44   train_loss = 0.322
Epoch 271 Batch   26/44   train_loss = 0.316
Epoch 271 Batch   27/44   train_loss = 0.320
Epoch 271 Batch   28/44   train_loss = 0.289
Epoch 271 Batch   29/44   train_loss = 0.295
Epoch 271 Batch   30/44   train_loss = 0.298
Epoch 271 Batch   31/44   train_loss = 0.300
Epoch 271 Batch   32/44   train_loss = 0.277
Epoch 271 Batch   33/44   train_loss = 0.325
Epoch 271 Batch   34/44   train_loss = 0.314
Epoch 271 Batch   35/44   train_loss = 0.281
Epoch 271 Batch   36/44   train_loss = 0.327
Epoch 271 Batch   37/44   train_loss = 0.280
Epoch 271 Batch   38/44   train_loss = 0.303
Epoch 271 Batch   39/44   train_loss = 0.284
Epoch 271 Batch   40/44   train_loss = 0.270
Epoch 271 Batch   41/44   train_loss = 0.286
Epoch 271 Batch   42/44   train_loss = 0.268
Epoch 271 Batch   43/44   train_loss = 0.283
Epoch 272 Batch    0/44   train_loss = 0.287
Epoch 272 Batch    1/44   train_loss = 0.295
Epoch 272 Batch    2/44   train_loss = 0.316
Epoch 272 Batch    3/44   train_loss = 0.341
Epoch 272 Batch    4/44   train_loss = 0.306
Epoch 272 Batch    5/44   train_loss = 0.324
Epoch 272 Batch    6/44   train_loss = 0.325
Epoch 272 Batch    7/44   train_loss = 0.319
Epoch 272 Batch    8/44   train_loss = 0.322
Epoch 272 Batch    9/44   train_loss = 0.344
Epoch 272 Batch   10/44   train_loss = 0.306
Epoch 272 Batch   11/44   train_loss = 0.330
Epoch 272 Batch   12/44   train_loss = 0.296
Epoch 272 Batch   13/44   train_loss = 0.304
Epoch 272 Batch   14/44   train_loss = 0.297
Epoch 272 Batch   15/44   train_loss = 0.319
Epoch 272 Batch   16/44   train_loss = 0.296
Epoch 272 Batch   17/44   train_loss = 0.314
Epoch 272 Batch   18/44   train_loss = 0.309
Epoch 272 Batch   19/44   train_loss = 0.314
Epoch 272 Batch   20/44   train_loss = 0.314
Epoch 272 Batch   21/44   train_loss = 0.292
Epoch 272 Batch   22/44   train_loss = 0.327
Epoch 272 Batch   23/44   train_loss = 0.309
Epoch 272 Batch   24/44   train_loss = 0.287
Epoch 272 Batch   25/44   train_loss = 0.328
Epoch 272 Batch   26/44   train_loss = 0.320
Epoch 272 Batch   27/44   train_loss = 0.326
Epoch 272 Batch   28/44   train_loss = 0.293
Epoch 272 Batch   29/44   train_loss = 0.297
Epoch 272 Batch   30/44   train_loss = 0.299
Epoch 272 Batch   31/44   train_loss = 0.300
Epoch 272 Batch   32/44   train_loss = 0.275
Epoch 272 Batch   33/44   train_loss = 0.325
Epoch 272 Batch   34/44   train_loss = 0.314
Epoch 272 Batch   35/44   train_loss = 0.283
Epoch 272 Batch   36/44   train_loss = 0.330
Epoch 272 Batch   37/44   train_loss = 0.282
Epoch 272 Batch   38/44   train_loss = 0.306
Epoch 272 Batch   39/44   train_loss = 0.287
Epoch 272 Batch   40/44   train_loss = 0.271
Epoch 272 Batch   41/44   train_loss = 0.287
Epoch 272 Batch   42/44   train_loss = 0.269
Epoch 272 Batch   43/44   train_loss = 0.281
Epoch 273 Batch    0/44   train_loss = 0.283
Epoch 273 Batch    1/44   train_loss = 0.287
Epoch 273 Batch    2/44   train_loss = 0.306
Epoch 273 Batch    3/44   train_loss = 0.331
Epoch 273 Batch    4/44   train_loss = 0.298
Epoch 273 Batch    5/44   train_loss = 0.316
Epoch 273 Batch    6/44   train_loss = 0.316
Epoch 273 Batch    7/44   train_loss = 0.315
Epoch 273 Batch    8/44   train_loss = 0.319
Epoch 273 Batch    9/44   train_loss = 0.344
Epoch 273 Batch   10/44   train_loss = 0.311
Epoch 273 Batch   11/44   train_loss = 0.332
Epoch 273 Batch   12/44   train_loss = 0.300
Epoch 273 Batch   13/44   train_loss = 0.306
Epoch 273 Batch   14/44   train_loss = 0.298
Epoch 273 Batch   15/44   train_loss = 0.319
Epoch 273 Batch   16/44   train_loss = 0.291
Epoch 273 Batch   17/44   train_loss = 0.309
Epoch 273 Batch   18/44   train_loss = 0.301
Epoch 273 Batch   19/44   train_loss = 0.303
Epoch 273 Batch   20/44   train_loss = 0.304
Epoch 273 Batch   21/44   train_loss = 0.284
Epoch 273 Batch   22/44   train_loss = 0.334
Epoch 273 Batch   23/44   train_loss = 0.314
Epoch 273 Batch   24/44   train_loss = 0.301
Epoch 273 Batch   25/44   train_loss = 0.347
Epoch 273 Batch   26/44   train_loss = 0.337
Epoch 273 Batch   27/44   train_loss = 0.338
Epoch 273 Batch   28/44   train_loss = 0.302
Epoch 273 Batch   29/44   train_loss = 0.304
Epoch 273 Batch   30/44   train_loss = 0.302
Epoch 273 Batch   31/44   train_loss = 0.304
Epoch 273 Batch   32/44   train_loss = 0.281
Epoch 273 Batch   33/44   train_loss = 0.330
Epoch 273 Batch   34/44   train_loss = 0.317
Epoch 273 Batch   35/44   train_loss = 0.290
Epoch 273 Batch   36/44   train_loss = 0.340
Epoch 273 Batch   37/44   train_loss = 0.287
Epoch 273 Batch   38/44   train_loss = 0.309
Epoch 273 Batch   39/44   train_loss = 0.290
Epoch 273 Batch   40/44   train_loss = 0.275
Epoch 273 Batch   41/44   train_loss = 0.292
Epoch 273 Batch   42/44   train_loss = 0.273
Epoch 273 Batch   43/44   train_loss = 0.282
Epoch 274 Batch    0/44   train_loss = 0.284
Epoch 274 Batch    1/44   train_loss = 0.287
Epoch 274 Batch    2/44   train_loss = 0.303
Epoch 274 Batch    3/44   train_loss = 0.326
Epoch 274 Batch    4/44   train_loss = 0.292
Epoch 274 Batch    5/44   train_loss = 0.307
Epoch 274 Batch    6/44   train_loss = 0.308
Epoch 274 Batch    7/44   train_loss = 0.308
Epoch 274 Batch    8/44   train_loss = 0.314
Epoch 274 Batch    9/44   train_loss = 0.338
Epoch 274 Batch   10/44   train_loss = 0.308
Epoch 274 Batch   11/44   train_loss = 0.329
Epoch 274 Batch   12/44   train_loss = 0.299
Epoch 274 Batch   13/44   train_loss = 0.306
Epoch 274 Batch   14/44   train_loss = 0.300
Epoch 274 Batch   15/44   train_loss = 0.320
Epoch 274 Batch   16/44   train_loss = 0.292
Epoch 274 Batch   17/44   train_loss = 0.309
Epoch 274 Batch   18/44   train_loss = 0.297
Epoch 274 Batch   19/44   train_loss = 0.300
Epoch 274 Batch   20/44   train_loss = 0.295
Epoch 274 Batch   21/44   train_loss = 0.272
Epoch 274 Batch   22/44   train_loss = 0.325
Epoch 274 Batch   23/44   train_loss = 0.299
Epoch 274 Batch   24/44   train_loss = 0.289
Epoch 274 Batch   25/44   train_loss = 0.343
Epoch 274 Batch   26/44   train_loss = 0.343
Epoch 274 Batch   27/44   train_loss = 0.358
Epoch 274 Batch   28/44   train_loss = 0.330
Epoch 274 Batch   29/44   train_loss = 0.325
Epoch 274 Batch   30/44   train_loss = 0.314
Epoch 274 Batch   31/44   train_loss = 0.316
Epoch 274 Batch   32/44   train_loss = 0.284
Epoch 274 Batch   33/44   train_loss = 0.332
Epoch 274 Batch   34/44   train_loss = 0.318
Epoch 274 Batch   35/44   train_loss = 0.291
Epoch 274 Batch   36/44   train_loss = 0.341
Epoch 274 Batch   37/44   train_loss = 0.298
Epoch 274 Batch   38/44   train_loss = 0.318
Epoch 274 Batch   39/44   train_loss = 0.304
Epoch 274 Batch   40/44   train_loss = 0.286
Epoch 274 Batch   41/44   train_loss = 0.305
Epoch 274 Batch   42/44   train_loss = 0.281
Epoch 274 Batch   43/44   train_loss = 0.287
Epoch 275 Batch    0/44   train_loss = 0.287
Epoch 275 Batch    1/44   train_loss = 0.289
Epoch 275 Batch    2/44   train_loss = 0.302
Epoch 275 Batch    3/44   train_loss = 0.325
Epoch 275 Batch    4/44   train_loss = 0.291
Epoch 275 Batch    5/44   train_loss = 0.306
Epoch 275 Batch    6/44   train_loss = 0.310
Epoch 275 Batch    7/44   train_loss = 0.308
Epoch 275 Batch    8/44   train_loss = 0.311
Epoch 275 Batch    9/44   train_loss = 0.336
Epoch 275 Batch   10/44   train_loss = 0.305
Epoch 275 Batch   11/44   train_loss = 0.327
Epoch 275 Batch   12/44   train_loss = 0.300
Epoch 275 Batch   13/44   train_loss = 0.305
Epoch 275 Batch   14/44   train_loss = 0.299
Epoch 275 Batch   15/44   train_loss = 0.320
Epoch 275 Batch   16/44   train_loss = 0.293
Epoch 275 Batch   17/44   train_loss = 0.311
Epoch 275 Batch   18/44   train_loss = 0.298
Epoch 275 Batch   19/44   train_loss = 0.301
Epoch 275 Batch   20/44   train_loss = 0.294
Epoch 275 Batch   21/44   train_loss = 0.271
Epoch 275 Batch   22/44   train_loss = 0.313
Epoch 275 Batch   23/44   train_loss = 0.293
Epoch 275 Batch   24/44   train_loss = 0.276
Epoch 275 Batch   25/44   train_loss = 0.325
Epoch 275 Batch   26/44   train_loss = 0.323
Epoch 275 Batch   27/44   train_loss = 0.333
Epoch 275 Batch   28/44   train_loss = 0.313
Epoch 275 Batch   29/44   train_loss = 0.329
Epoch 275 Batch   30/44   train_loss = 0.331
Epoch 275 Batch   31/44   train_loss = 0.338
Epoch 275 Batch   32/44   train_loss = 0.306
Epoch 275 Batch   33/44   train_loss = 0.348
Epoch 275 Batch   34/44   train_loss = 0.325
Epoch 275 Batch   35/44   train_loss = 0.288
Epoch 275 Batch   36/44   train_loss = 0.333
Epoch 275 Batch   37/44   train_loss = 0.286
Epoch 275 Batch   38/44   train_loss = 0.307
Epoch 275 Batch   39/44   train_loss = 0.294
Epoch 275 Batch   40/44   train_loss = 0.283
Epoch 275 Batch   41/44   train_loss = 0.317
Epoch 275 Batch   42/44   train_loss = 0.308
Epoch 275 Batch   43/44   train_loss = 0.311
Epoch 276 Batch    0/44   train_loss = 0.309
Epoch 276 Batch    1/44   train_loss = 0.312
Epoch 276 Batch    2/44   train_loss = 0.310
Epoch 276 Batch    3/44   train_loss = 0.332
Epoch 276 Batch    4/44   train_loss = 0.291
Epoch 276 Batch    5/44   train_loss = 0.307
Epoch 276 Batch    6/44   train_loss = 0.305
Epoch 276 Batch    7/44   train_loss = 0.315
Epoch 276 Batch    8/44   train_loss = 0.313
Epoch 276 Batch    9/44   train_loss = 0.338
Epoch 276 Batch   10/44   train_loss = 0.307
Epoch 276 Batch   11/44   train_loss = 0.328
Epoch 276 Batch   12/44   train_loss = 0.304
Epoch 276 Batch   13/44   train_loss = 0.307
Epoch 276 Batch   14/44   train_loss = 0.302
Epoch 276 Batch   15/44   train_loss = 0.319
Epoch 276 Batch   16/44   train_loss = 0.294
Epoch 276 Batch   17/44   train_loss = 0.313
Epoch 276 Batch   18/44   train_loss = 0.300
Epoch 276 Batch   19/44   train_loss = 0.302
Epoch 276 Batch   20/44   train_loss = 0.295
Epoch 276 Batch   21/44   train_loss = 0.272
Epoch 276 Batch   22/44   train_loss = 0.314
Epoch 276 Batch   23/44   train_loss = 0.293
Epoch 276 Batch   24/44   train_loss = 0.273
Epoch 276 Batch   25/44   train_loss = 0.320
Epoch 276 Batch   26/44   train_loss = 0.317
Epoch 276 Batch   27/44   train_loss = 0.321
Epoch 276 Batch   28/44   train_loss = 0.299
Epoch 276 Batch   29/44   train_loss = 0.305
Epoch 276 Batch   30/44   train_loss = 0.313
Epoch 276 Batch   31/44   train_loss = 0.322
Epoch 276 Batch   32/44   train_loss = 0.299
Epoch 276 Batch   33/44   train_loss = 0.351
Epoch 276 Batch   34/44   train_loss = 0.333
Epoch 276 Batch   35/44   train_loss = 0.299
Epoch 276 Batch   36/44   train_loss = 0.345
Epoch 276 Batch   37/44   train_loss = 0.290
Epoch 276 Batch   38/44   train_loss = 0.306
Epoch 276 Batch   39/44   train_loss = 0.286
Epoch 276 Batch   40/44   train_loss = 0.267
Epoch 276 Batch   41/44   train_loss = 0.290
Epoch 276 Batch   42/44   train_loss = 0.274
Epoch 276 Batch   43/44   train_loss = 0.292
Epoch 277 Batch    0/44   train_loss = 0.311
Epoch 277 Batch    1/44   train_loss = 0.328
Epoch 277 Batch    2/44   train_loss = 0.347
Epoch 277 Batch    3/44   train_loss = 0.354
Epoch 277 Batch    4/44   train_loss = 0.319
Epoch 277 Batch    5/44   train_loss = 0.322
Epoch 277 Batch    6/44   train_loss = 0.316
Epoch 277 Batch    7/44   train_loss = 0.315
Epoch 277 Batch    8/44   train_loss = 0.317
Epoch 277 Batch    9/44   train_loss = 0.340
Epoch 277 Batch   10/44   train_loss = 0.309
Epoch 277 Batch   11/44   train_loss = 0.331
Epoch 277 Batch   12/44   train_loss = 0.305
Epoch 277 Batch   13/44   train_loss = 0.315
Epoch 277 Batch   14/44   train_loss = 0.310
Epoch 277 Batch   15/44   train_loss = 0.324
Epoch 277 Batch   16/44   train_loss = 0.301
Epoch 277 Batch   17/44   train_loss = 0.316
Epoch 277 Batch   18/44   train_loss = 0.306
Epoch 277 Batch   19/44   train_loss = 0.306
Epoch 277 Batch   20/44   train_loss = 0.298
Epoch 277 Batch   21/44   train_loss = 0.276
Epoch 277 Batch   22/44   train_loss = 0.313
Epoch 277 Batch   23/44   train_loss = 0.293
Epoch 277 Batch   24/44   train_loss = 0.273
Epoch 277 Batch   25/44   train_loss = 0.320
Epoch 277 Batch   26/44   train_loss = 0.314
Epoch 277 Batch   27/44   train_loss = 0.316
Epoch 277 Batch   28/44   train_loss = 0.290
Epoch 277 Batch   29/44   train_loss = 0.296
Epoch 277 Batch   30/44   train_loss = 0.304
Epoch 277 Batch   31/44   train_loss = 0.310
Epoch 277 Batch   32/44   train_loss = 0.285
Epoch 277 Batch   33/44   train_loss = 0.337
Epoch 277 Batch   34/44   train_loss = 0.324
Epoch 277 Batch   35/44   train_loss = 0.297
Epoch 277 Batch   36/44   train_loss = 0.343
Epoch 277 Batch   37/44   train_loss = 0.292
Epoch 277 Batch   38/44   train_loss = 0.311
Epoch 277 Batch   39/44   train_loss = 0.287
Epoch 277 Batch   40/44   train_loss = 0.267
Epoch 277 Batch   41/44   train_loss = 0.287
Epoch 277 Batch   42/44   train_loss = 0.269
Epoch 277 Batch   43/44   train_loss = 0.281
Epoch 278 Batch    0/44   train_loss = 0.282
Epoch 278 Batch    1/44   train_loss = 0.291
Epoch 278 Batch    2/44   train_loss = 0.318
Epoch 278 Batch    3/44   train_loss = 0.346
Epoch 278 Batch    4/44   train_loss = 0.329
Epoch 278 Batch    5/44   train_loss = 0.345
Epoch 278 Batch    6/44   train_loss = 0.342
Epoch 278 Batch    7/44   train_loss = 0.329
Epoch 278 Batch    8/44   train_loss = 0.329
Epoch 278 Batch    9/44   train_loss = 0.345
Epoch 278 Batch   10/44   train_loss = 0.310
Epoch 278 Batch   11/44   train_loss = 0.332
Epoch 278 Batch   12/44   train_loss = 0.303
Epoch 278 Batch   13/44   train_loss = 0.317
Epoch 278 Batch   14/44   train_loss = 0.314
Epoch 278 Batch   15/44   train_loss = 0.329
Epoch 278 Batch   16/44   train_loss = 0.313
Epoch 278 Batch   17/44   train_loss = 0.322
Epoch 278 Batch   18/44   train_loss = 0.316
Epoch 278 Batch   19/44   train_loss = 0.313
Epoch 278 Batch   20/44   train_loss = 0.305
Epoch 278 Batch   21/44   train_loss = 0.282
Epoch 278 Batch   22/44   train_loss = 0.320
Epoch 278 Batch   23/44   train_loss = 0.302
Epoch 278 Batch   24/44   train_loss = 0.281
Epoch 278 Batch   25/44   train_loss = 0.325
Epoch 278 Batch   26/44   train_loss = 0.320
Epoch 278 Batch   27/44   train_loss = 0.320
Epoch 278 Batch   28/44   train_loss = 0.292
Epoch 278 Batch   29/44   train_loss = 0.295
Epoch 278 Batch   30/44   train_loss = 0.299
Epoch 278 Batch   31/44   train_loss = 0.307
Epoch 278 Batch   32/44   train_loss = 0.279
Epoch 278 Batch   33/44   train_loss = 0.329
Epoch 278 Batch   34/44   train_loss = 0.316
Epoch 278 Batch   35/44   train_loss = 0.286
Epoch 278 Batch   36/44   train_loss = 0.336
Epoch 278 Batch   37/44   train_loss = 0.288
Epoch 278 Batch   38/44   train_loss = 0.307
Epoch 278 Batch   39/44   train_loss = 0.287
Epoch 278 Batch   40/44   train_loss = 0.270
Epoch 278 Batch   41/44   train_loss = 0.289
Epoch 278 Batch   42/44   train_loss = 0.270
Epoch 278 Batch   43/44   train_loss = 0.281
Epoch 279 Batch    0/44   train_loss = 0.280
Epoch 279 Batch    1/44   train_loss = 0.282
Epoch 279 Batch    2/44   train_loss = 0.305
Epoch 279 Batch    3/44   train_loss = 0.326
Epoch 279 Batch    4/44   train_loss = 0.298
Epoch 279 Batch    5/44   train_loss = 0.316
Epoch 279 Batch    6/44   train_loss = 0.324
Epoch 279 Batch    7/44   train_loss = 0.333
Epoch 279 Batch    8/44   train_loss = 0.341
Epoch 279 Batch    9/44   train_loss = 0.362
Epoch 279 Batch   10/44   train_loss = 0.325
Epoch 279 Batch   11/44   train_loss = 0.345
Epoch 279 Batch   12/44   train_loss = 0.309
Epoch 279 Batch   13/44   train_loss = 0.314
Epoch 279 Batch   14/44   train_loss = 0.305
Epoch 279 Batch   15/44   train_loss = 0.321
Epoch 279 Batch   16/44   train_loss = 0.303
Epoch 279 Batch   17/44   train_loss = 0.318
Epoch 279 Batch   18/44   train_loss = 0.319
Epoch 279 Batch   19/44   train_loss = 0.319
Epoch 279 Batch   20/44   train_loss = 0.316
Epoch 279 Batch   21/44   train_loss = 0.284
Epoch 279 Batch   22/44   train_loss = 0.322
Epoch 279 Batch   23/44   train_loss = 0.304
Epoch 279 Batch   24/44   train_loss = 0.285
Epoch 279 Batch   25/44   train_loss = 0.330
Epoch 279 Batch   26/44   train_loss = 0.330
Epoch 279 Batch   27/44   train_loss = 0.331
Epoch 279 Batch   28/44   train_loss = 0.304
Epoch 279 Batch   29/44   train_loss = 0.305
Epoch 279 Batch   30/44   train_loss = 0.304
Epoch 279 Batch   31/44   train_loss = 0.308
Epoch 279 Batch   32/44   train_loss = 0.280
Epoch 279 Batch   33/44   train_loss = 0.331
Epoch 279 Batch   34/44   train_loss = 0.314
Epoch 279 Batch   35/44   train_loss = 0.283
Epoch 279 Batch   36/44   train_loss = 0.333
Epoch 279 Batch   37/44   train_loss = 0.286
Epoch 279 Batch   38/44   train_loss = 0.307
Epoch 279 Batch   39/44   train_loss = 0.290
Epoch 279 Batch   40/44   train_loss = 0.273
Epoch 279 Batch   41/44   train_loss = 0.290
Epoch 279 Batch   42/44   train_loss = 0.272
Epoch 279 Batch   43/44   train_loss = 0.281
Epoch 280 Batch    0/44   train_loss = 0.279
Epoch 280 Batch    1/44   train_loss = 0.284
Epoch 280 Batch    2/44   train_loss = 0.304
Epoch 280 Batch    3/44   train_loss = 0.323
Epoch 280 Batch    4/44   train_loss = 0.291
Epoch 280 Batch    5/44   train_loss = 0.307
Epoch 280 Batch    6/44   train_loss = 0.311
Epoch 280 Batch    7/44   train_loss = 0.314
Epoch 280 Batch    8/44   train_loss = 0.322
Epoch 280 Batch    9/44   train_loss = 0.352
Epoch 280 Batch   10/44   train_loss = 0.321
Epoch 280 Batch   11/44   train_loss = 0.345
Epoch 280 Batch   12/44   train_loss = 0.317
Epoch 280 Batch   13/44   train_loss = 0.320
Epoch 280 Batch   14/44   train_loss = 0.311
Epoch 280 Batch   15/44   train_loss = 0.330
Epoch 280 Batch   16/44   train_loss = 0.297
Epoch 280 Batch   17/44   train_loss = 0.319
Epoch 280 Batch   18/44   train_loss = 0.301
Epoch 280 Batch   19/44   train_loss = 0.304
Epoch 280 Batch   20/44   train_loss = 0.297
Epoch 280 Batch   21/44   train_loss = 0.276
Epoch 280 Batch   22/44   train_loss = 0.322
Epoch 280 Batch   23/44   train_loss = 0.309
Epoch 280 Batch   24/44   train_loss = 0.296
Epoch 280 Batch   25/44   train_loss = 0.344
Epoch 280 Batch   26/44   train_loss = 0.340
Epoch 280 Batch   27/44   train_loss = 0.331
Epoch 280 Batch   28/44   train_loss = 0.303
Epoch 280 Batch   29/44   train_loss = 0.308
Epoch 280 Batch   30/44   train_loss = 0.310
Epoch 280 Batch   31/44   train_loss = 0.317
Epoch 280 Batch   32/44   train_loss = 0.295
Epoch 280 Batch   33/44   train_loss = 0.341
Epoch 280 Batch   34/44   train_loss = 0.319
Epoch 280 Batch   35/44   train_loss = 0.288
Epoch 280 Batch   36/44   train_loss = 0.339
Epoch 280 Batch   37/44   train_loss = 0.287
Epoch 280 Batch   38/44   train_loss = 0.303
Epoch 280 Batch   39/44   train_loss = 0.287
Epoch 280 Batch   40/44   train_loss = 0.272
Epoch 280 Batch   41/44   train_loss = 0.293
Epoch 280 Batch   42/44   train_loss = 0.279
Epoch 280 Batch   43/44   train_loss = 0.287
Epoch 281 Batch    0/44   train_loss = 0.287
Epoch 281 Batch    1/44   train_loss = 0.291
Epoch 281 Batch    2/44   train_loss = 0.306
Epoch 281 Batch    3/44   train_loss = 0.323
Epoch 281 Batch    4/44   train_loss = 0.290
Epoch 281 Batch    5/44   train_loss = 0.308
Epoch 281 Batch    6/44   train_loss = 0.309
Epoch 281 Batch    7/44   train_loss = 0.311
Epoch 281 Batch    8/44   train_loss = 0.315
Epoch 281 Batch    9/44   train_loss = 0.339
Epoch 281 Batch   10/44   train_loss = 0.313
Epoch 281 Batch   11/44   train_loss = 0.336
Epoch 281 Batch   12/44   train_loss = 0.309
Epoch 281 Batch   13/44   train_loss = 0.316
Epoch 281 Batch   14/44   train_loss = 0.310
Epoch 281 Batch   15/44   train_loss = 0.327
Epoch 281 Batch   16/44   train_loss = 0.298
Epoch 281 Batch   17/44   train_loss = 0.317
Epoch 281 Batch   18/44   train_loss = 0.301
Epoch 281 Batch   19/44   train_loss = 0.301
Epoch 281 Batch   20/44   train_loss = 0.296
Epoch 281 Batch   21/44   train_loss = 0.266
Epoch 281 Batch   22/44   train_loss = 0.309
Epoch 281 Batch   23/44   train_loss = 0.291
Epoch 281 Batch   24/44   train_loss = 0.284
Epoch 281 Batch   25/44   train_loss = 0.331
Epoch 281 Batch   26/44   train_loss = 0.332
Epoch 281 Batch   27/44   train_loss = 0.337
Epoch 281 Batch   28/44   train_loss = 0.313
Epoch 281 Batch   29/44   train_loss = 0.316
Epoch 281 Batch   30/44   train_loss = 0.315
Epoch 281 Batch   31/44   train_loss = 0.323
Epoch 281 Batch   32/44   train_loss = 0.304
Epoch 281 Batch   33/44   train_loss = 0.347
Epoch 281 Batch   34/44   train_loss = 0.325
Epoch 281 Batch   35/44   train_loss = 0.294
Epoch 281 Batch   36/44   train_loss = 0.342
Epoch 281 Batch   37/44   train_loss = 0.291
Epoch 281 Batch   38/44   train_loss = 0.307
Epoch 281 Batch   39/44   train_loss = 0.290
Epoch 281 Batch   40/44   train_loss = 0.272
Epoch 281 Batch   41/44   train_loss = 0.292
Epoch 281 Batch   42/44   train_loss = 0.277
Epoch 281 Batch   43/44   train_loss = 0.286
Epoch 282 Batch    0/44   train_loss = 0.291
Epoch 282 Batch    1/44   train_loss = 0.297
Epoch 282 Batch    2/44   train_loss = 0.309
Epoch 282 Batch    3/44   train_loss = 0.332
Epoch 282 Batch    4/44   train_loss = 0.295
Epoch 282 Batch    5/44   train_loss = 0.311
Epoch 282 Batch    6/44   train_loss = 0.307
Epoch 282 Batch    7/44   train_loss = 0.310
Epoch 282 Batch    8/44   train_loss = 0.313
Epoch 282 Batch    9/44   train_loss = 0.339
Epoch 282 Batch   10/44   train_loss = 0.306
Epoch 282 Batch   11/44   train_loss = 0.330
Epoch 282 Batch   12/44   train_loss = 0.305
Epoch 282 Batch   13/44   train_loss = 0.313
Epoch 282 Batch   14/44   train_loss = 0.311
Epoch 282 Batch   15/44   train_loss = 0.325
Epoch 282 Batch   16/44   train_loss = 0.298
Epoch 282 Batch   17/44   train_loss = 0.315
Epoch 282 Batch   18/44   train_loss = 0.300
Epoch 282 Batch   19/44   train_loss = 0.299
Epoch 282 Batch   20/44   train_loss = 0.295
Epoch 282 Batch   21/44   train_loss = 0.267
Epoch 282 Batch   22/44   train_loss = 0.307
Epoch 282 Batch   23/44   train_loss = 0.291
Epoch 282 Batch   24/44   train_loss = 0.276
Epoch 282 Batch   25/44   train_loss = 0.323
Epoch 282 Batch   26/44   train_loss = 0.317
Epoch 282 Batch   27/44   train_loss = 0.320
Epoch 282 Batch   28/44   train_loss = 0.304
Epoch 282 Batch   29/44   train_loss = 0.310
Epoch 282 Batch   30/44   train_loss = 0.312
Epoch 282 Batch   31/44   train_loss = 0.319
Epoch 282 Batch   32/44   train_loss = 0.304
Epoch 282 Batch   33/44   train_loss = 0.353
Epoch 282 Batch   34/44   train_loss = 0.333
Epoch 282 Batch   35/44   train_loss = 0.298
Epoch 282 Batch   36/44   train_loss = 0.352
Epoch 282 Batch   37/44   train_loss = 0.298
Epoch 282 Batch   38/44   train_loss = 0.310
Epoch 282 Batch   39/44   train_loss = 0.291
Epoch 282 Batch   40/44   train_loss = 0.277
Epoch 282 Batch   41/44   train_loss = 0.290
Epoch 282 Batch   42/44   train_loss = 0.275
Epoch 282 Batch   43/44   train_loss = 0.285
Epoch 283 Batch    0/44   train_loss = 0.289
Epoch 283 Batch    1/44   train_loss = 0.295
Epoch 283 Batch    2/44   train_loss = 0.309
Epoch 283 Batch    3/44   train_loss = 0.336
Epoch 283 Batch    4/44   train_loss = 0.304
Epoch 283 Batch    5/44   train_loss = 0.321
Epoch 283 Batch    6/44   train_loss = 0.317
Epoch 283 Batch    7/44   train_loss = 0.321
Epoch 283 Batch    8/44   train_loss = 0.321
Epoch 283 Batch    9/44   train_loss = 0.339
Epoch 283 Batch   10/44   train_loss = 0.307
Epoch 283 Batch   11/44   train_loss = 0.329
Epoch 283 Batch   12/44   train_loss = 0.302
Epoch 283 Batch   13/44   train_loss = 0.314
Epoch 283 Batch   14/44   train_loss = 0.310
Epoch 283 Batch   15/44   train_loss = 0.321
Epoch 283 Batch   16/44   train_loss = 0.298
Epoch 283 Batch   17/44   train_loss = 0.315
Epoch 283 Batch   18/44   train_loss = 0.302
Epoch 283 Batch   19/44   train_loss = 0.301
Epoch 283 Batch   20/44   train_loss = 0.296
Epoch 283 Batch   21/44   train_loss = 0.267
Epoch 283 Batch   22/44   train_loss = 0.307
Epoch 283 Batch   23/44   train_loss = 0.289
Epoch 283 Batch   24/44   train_loss = 0.273
Epoch 283 Batch   25/44   train_loss = 0.321
Epoch 283 Batch   26/44   train_loss = 0.314
Epoch 283 Batch   27/44   train_loss = 0.317
Epoch 283 Batch   28/44   train_loss = 0.292
Epoch 283 Batch   29/44   train_loss = 0.300
Epoch 283 Batch   30/44   train_loss = 0.307
Epoch 283 Batch   31/44   train_loss = 0.313
Epoch 283 Batch   32/44   train_loss = 0.290
Epoch 283 Batch   33/44   train_loss = 0.348
Epoch 283 Batch   34/44   train_loss = 0.328
Epoch 283 Batch   35/44   train_loss = 0.299
Epoch 283 Batch   36/44   train_loss = 0.355
Epoch 283 Batch   37/44   train_loss = 0.299
Epoch 283 Batch   38/44   train_loss = 0.313
Epoch 283 Batch   39/44   train_loss = 0.291
Epoch 283 Batch   40/44   train_loss = 0.276
Epoch 283 Batch   41/44   train_loss = 0.289
Epoch 283 Batch   42/44   train_loss = 0.274
Epoch 283 Batch   43/44   train_loss = 0.278
Epoch 284 Batch    0/44   train_loss = 0.283
Epoch 284 Batch    1/44   train_loss = 0.290
Epoch 284 Batch    2/44   train_loss = 0.307
Epoch 284 Batch    3/44   train_loss = 0.329
Epoch 284 Batch    4/44   train_loss = 0.299
Epoch 284 Batch    5/44   train_loss = 0.318
Epoch 284 Batch    6/44   train_loss = 0.321
Epoch 284 Batch    7/44   train_loss = 0.328
Epoch 284 Batch    8/44   train_loss = 0.325
Epoch 284 Batch    9/44   train_loss = 0.347
Epoch 284 Batch   10/44   train_loss = 0.316
Epoch 284 Batch   11/44   train_loss = 0.341
Epoch 284 Batch   12/44   train_loss = 0.309
Epoch 284 Batch   13/44   train_loss = 0.317
Epoch 284 Batch   14/44   train_loss = 0.308
Epoch 284 Batch   15/44   train_loss = 0.321
Epoch 284 Batch   16/44   train_loss = 0.299
Epoch 284 Batch   17/44   train_loss = 0.318
Epoch 284 Batch   18/44   train_loss = 0.302
Epoch 284 Batch   19/44   train_loss = 0.304
Epoch 284 Batch   20/44   train_loss = 0.297
Epoch 284 Batch   21/44   train_loss = 0.272
Epoch 284 Batch   22/44   train_loss = 0.308
Epoch 284 Batch   23/44   train_loss = 0.293
Epoch 284 Batch   24/44   train_loss = 0.274
Epoch 284 Batch   25/44   train_loss = 0.320
Epoch 284 Batch   26/44   train_loss = 0.314
Epoch 284 Batch   27/44   train_loss = 0.315
Epoch 284 Batch   28/44   train_loss = 0.290
Epoch 284 Batch   29/44   train_loss = 0.297
Epoch 284 Batch   30/44   train_loss = 0.300
Epoch 284 Batch   31/44   train_loss = 0.309
Epoch 284 Batch   32/44   train_loss = 0.286
Epoch 284 Batch   33/44   train_loss = 0.342
Epoch 284 Batch   34/44   train_loss = 0.323
Epoch 284 Batch   35/44   train_loss = 0.292
Epoch 284 Batch   36/44   train_loss = 0.347
Epoch 284 Batch   37/44   train_loss = 0.299
Epoch 284 Batch   38/44   train_loss = 0.309
Epoch 284 Batch   39/44   train_loss = 0.289
Epoch 284 Batch   40/44   train_loss = 0.276
Epoch 284 Batch   41/44   train_loss = 0.293
Epoch 284 Batch   42/44   train_loss = 0.273
Epoch 284 Batch   43/44   train_loss = 0.279
Epoch 285 Batch    0/44   train_loss = 0.281
Epoch 285 Batch    1/44   train_loss = 0.284
Epoch 285 Batch    2/44   train_loss = 0.302
Epoch 285 Batch    3/44   train_loss = 0.321
Epoch 285 Batch    4/44   train_loss = 0.294
Epoch 285 Batch    5/44   train_loss = 0.306
Epoch 285 Batch    6/44   train_loss = 0.309
Epoch 285 Batch    7/44   train_loss = 0.314
Epoch 285 Batch    8/44   train_loss = 0.324
Epoch 285 Batch    9/44   train_loss = 0.348
Epoch 285 Batch   10/44   train_loss = 0.321
Epoch 285 Batch   11/44   train_loss = 0.354
Epoch 285 Batch   12/44   train_loss = 0.320
Epoch 285 Batch   13/44   train_loss = 0.324
Epoch 285 Batch   14/44   train_loss = 0.316
Epoch 285 Batch   15/44   train_loss = 0.330
Epoch 285 Batch   16/44   train_loss = 0.300
Epoch 285 Batch   17/44   train_loss = 0.319
Epoch 285 Batch   18/44   train_loss = 0.303
Epoch 285 Batch   19/44   train_loss = 0.310
Epoch 285 Batch   20/44   train_loss = 0.299
Epoch 285 Batch   21/44   train_loss = 0.274
Epoch 285 Batch   22/44   train_loss = 0.315
Epoch 285 Batch   23/44   train_loss = 0.295
Epoch 285 Batch   24/44   train_loss = 0.278
Epoch 285 Batch   25/44   train_loss = 0.319
Epoch 285 Batch   26/44   train_loss = 0.317
Epoch 285 Batch   27/44   train_loss = 0.319
Epoch 285 Batch   28/44   train_loss = 0.291
Epoch 285 Batch   29/44   train_loss = 0.300
Epoch 285 Batch   30/44   train_loss = 0.300
Epoch 285 Batch   31/44   train_loss = 0.310
Epoch 285 Batch   32/44   train_loss = 0.285
Epoch 285 Batch   33/44   train_loss = 0.336
Epoch 285 Batch   34/44   train_loss = 0.321
Epoch 285 Batch   35/44   train_loss = 0.289
Epoch 285 Batch   36/44   train_loss = 0.345
Epoch 285 Batch   37/44   train_loss = 0.295
Epoch 285 Batch   38/44   train_loss = 0.307
Epoch 285 Batch   39/44   train_loss = 0.290
Epoch 285 Batch   40/44   train_loss = 0.276
Epoch 285 Batch   41/44   train_loss = 0.292
Epoch 285 Batch   42/44   train_loss = 0.276
Epoch 285 Batch   43/44   train_loss = 0.278
Epoch 286 Batch    0/44   train_loss = 0.283
Epoch 286 Batch    1/44   train_loss = 0.289
Epoch 286 Batch    2/44   train_loss = 0.303
Epoch 286 Batch    3/44   train_loss = 0.322
Epoch 286 Batch    4/44   train_loss = 0.293
Epoch 286 Batch    5/44   train_loss = 0.304
Epoch 286 Batch    6/44   train_loss = 0.303
Epoch 286 Batch    7/44   train_loss = 0.308
Epoch 286 Batch    8/44   train_loss = 0.314
Epoch 286 Batch    9/44   train_loss = 0.337
Epoch 286 Batch   10/44   train_loss = 0.308
Epoch 286 Batch   11/44   train_loss = 0.341
Epoch 286 Batch   12/44   train_loss = 0.315
Epoch 286 Batch   13/44   train_loss = 0.324
Epoch 286 Batch   14/44   train_loss = 0.320
Epoch 286 Batch   15/44   train_loss = 0.342
Epoch 286 Batch   16/44   train_loss = 0.311
Epoch 286 Batch   17/44   train_loss = 0.329
Epoch 286 Batch   18/44   train_loss = 0.308
Epoch 286 Batch   19/44   train_loss = 0.310
Epoch 286 Batch   20/44   train_loss = 0.298
Epoch 286 Batch   21/44   train_loss = 0.269
Epoch 286 Batch   22/44   train_loss = 0.311
Epoch 286 Batch   23/44   train_loss = 0.292
Epoch 286 Batch   24/44   train_loss = 0.278
Epoch 286 Batch   25/44   train_loss = 0.321
Epoch 286 Batch   26/44   train_loss = 0.320
Epoch 286 Batch   27/44   train_loss = 0.325
Epoch 286 Batch   28/44   train_loss = 0.302
Epoch 286 Batch   29/44   train_loss = 0.305
Epoch 286 Batch   30/44   train_loss = 0.304
Epoch 286 Batch   31/44   train_loss = 0.312
Epoch 286 Batch   32/44   train_loss = 0.284
Epoch 286 Batch   33/44   train_loss = 0.335
Epoch 286 Batch   34/44   train_loss = 0.322
Epoch 286 Batch   35/44   train_loss = 0.291
Epoch 286 Batch   36/44   train_loss = 0.348
Epoch 286 Batch   37/44   train_loss = 0.298
Epoch 286 Batch   38/44   train_loss = 0.307
Epoch 286 Batch   39/44   train_loss = 0.293
Epoch 286 Batch   40/44   train_loss = 0.274
Epoch 286 Batch   41/44   train_loss = 0.290
Epoch 286 Batch   42/44   train_loss = 0.272
Epoch 286 Batch   43/44   train_loss = 0.280
Epoch 287 Batch    0/44   train_loss = 0.285
Epoch 287 Batch    1/44   train_loss = 0.289
Epoch 287 Batch    2/44   train_loss = 0.302
Epoch 287 Batch    3/44   train_loss = 0.322
Epoch 287 Batch    4/44   train_loss = 0.294
Epoch 287 Batch    5/44   train_loss = 0.303
Epoch 287 Batch    6/44   train_loss = 0.304
Epoch 287 Batch    7/44   train_loss = 0.311
Epoch 287 Batch    8/44   train_loss = 0.313
Epoch 287 Batch    9/44   train_loss = 0.332
Epoch 287 Batch   10/44   train_loss = 0.302
Epoch 287 Batch   11/44   train_loss = 0.332
Epoch 287 Batch   12/44   train_loss = 0.302
Epoch 287 Batch   13/44   train_loss = 0.314
Epoch 287 Batch   14/44   train_loss = 0.312
Epoch 287 Batch   15/44   train_loss = 0.337
Epoch 287 Batch   16/44   train_loss = 0.310
Epoch 287 Batch   17/44   train_loss = 0.333
Epoch 287 Batch   18/44   train_loss = 0.314
Epoch 287 Batch   19/44   train_loss = 0.315
Epoch 287 Batch   20/44   train_loss = 0.302
Epoch 287 Batch   21/44   train_loss = 0.274
Epoch 287 Batch   22/44   train_loss = 0.310
Epoch 287 Batch   23/44   train_loss = 0.293
Epoch 287 Batch   24/44   train_loss = 0.275
Epoch 287 Batch   25/44   train_loss = 0.315
Epoch 287 Batch   26/44   train_loss = 0.312
Epoch 287 Batch   27/44   train_loss = 0.318
Epoch 287 Batch   28/44   train_loss = 0.298
Epoch 287 Batch   29/44   train_loss = 0.301
Epoch 287 Batch   30/44   train_loss = 0.305
Epoch 287 Batch   31/44   train_loss = 0.316
Epoch 287 Batch   32/44   train_loss = 0.291
Epoch 287 Batch   33/44   train_loss = 0.338
Epoch 287 Batch   34/44   train_loss = 0.322
Epoch 287 Batch   35/44   train_loss = 0.291
Epoch 287 Batch   36/44   train_loss = 0.344
Epoch 287 Batch   37/44   train_loss = 0.299
Epoch 287 Batch   38/44   train_loss = 0.313
Epoch 287 Batch   39/44   train_loss = 0.298
Epoch 287 Batch   40/44   train_loss = 0.279
Epoch 287 Batch   41/44   train_loss = 0.296
Epoch 287 Batch   42/44   train_loss = 0.277
Epoch 287 Batch   43/44   train_loss = 0.281
Epoch 288 Batch    0/44   train_loss = 0.289
Epoch 288 Batch    1/44   train_loss = 0.288
Epoch 288 Batch    2/44   train_loss = 0.301
Epoch 288 Batch    3/44   train_loss = 0.321
Epoch 288 Batch    4/44   train_loss = 0.291
Epoch 288 Batch    5/44   train_loss = 0.301
Epoch 288 Batch    6/44   train_loss = 0.302
Epoch 288 Batch    7/44   train_loss = 0.312
Epoch 288 Batch    8/44   train_loss = 0.315
Epoch 288 Batch    9/44   train_loss = 0.332
Epoch 288 Batch   10/44   train_loss = 0.305
Epoch 288 Batch   11/44   train_loss = 0.331
Epoch 288 Batch   12/44   train_loss = 0.301
Epoch 288 Batch   13/44   train_loss = 0.314
Epoch 288 Batch   14/44   train_loss = 0.305
Epoch 288 Batch   15/44   train_loss = 0.331
Epoch 288 Batch   16/44   train_loss = 0.304
Epoch 288 Batch   17/44   train_loss = 0.324
Epoch 288 Batch   18/44   train_loss = 0.309
Epoch 288 Batch   19/44   train_loss = 0.315
Epoch 288 Batch   20/44   train_loss = 0.306
Epoch 288 Batch   21/44   train_loss = 0.279
Epoch 288 Batch   22/44   train_loss = 0.315
Epoch 288 Batch   23/44   train_loss = 0.295
Epoch 288 Batch   24/44   train_loss = 0.278
Epoch 288 Batch   25/44   train_loss = 0.316
Epoch 288 Batch   26/44   train_loss = 0.314
Epoch 288 Batch   27/44   train_loss = 0.314
Epoch 288 Batch   28/44   train_loss = 0.292
Epoch 288 Batch   29/44   train_loss = 0.294
Epoch 288 Batch   30/44   train_loss = 0.298
Epoch 288 Batch   31/44   train_loss = 0.305
Epoch 288 Batch   32/44   train_loss = 0.288
Epoch 288 Batch   33/44   train_loss = 0.338
Epoch 288 Batch   34/44   train_loss = 0.325
Epoch 288 Batch   35/44   train_loss = 0.301
Epoch 288 Batch   36/44   train_loss = 0.355
Epoch 288 Batch   37/44   train_loss = 0.308
Epoch 288 Batch   38/44   train_loss = 0.314
Epoch 288 Batch   39/44   train_loss = 0.297
Epoch 288 Batch   40/44   train_loss = 0.278
Epoch 288 Batch   41/44   train_loss = 0.293
Epoch 288 Batch   42/44   train_loss = 0.278
Epoch 288 Batch   43/44   train_loss = 0.286
Epoch 289 Batch    0/44   train_loss = 0.298
Epoch 289 Batch    1/44   train_loss = 0.294
Epoch 289 Batch    2/44   train_loss = 0.311
Epoch 289 Batch    3/44   train_loss = 0.330
Epoch 289 Batch    4/44   train_loss = 0.296
Epoch 289 Batch    5/44   train_loss = 0.303
Epoch 289 Batch    6/44   train_loss = 0.302
Epoch 289 Batch    7/44   train_loss = 0.312
Epoch 289 Batch    8/44   train_loss = 0.311
Epoch 289 Batch    9/44   train_loss = 0.332
Epoch 289 Batch   10/44   train_loss = 0.300
Epoch 289 Batch   11/44   train_loss = 0.333
Epoch 289 Batch   12/44   train_loss = 0.303
Epoch 289 Batch   13/44   train_loss = 0.316
Epoch 289 Batch   14/44   train_loss = 0.307
Epoch 289 Batch   15/44   train_loss = 0.330
Epoch 289 Batch   16/44   train_loss = 0.303
Epoch 289 Batch   17/44   train_loss = 0.323
Epoch 289 Batch   18/44   train_loss = 0.306
Epoch 289 Batch   19/44   train_loss = 0.308
Epoch 289 Batch   20/44   train_loss = 0.300
Epoch 289 Batch   21/44   train_loss = 0.276
Epoch 289 Batch   22/44   train_loss = 0.314
Epoch 289 Batch   23/44   train_loss = 0.299
Epoch 289 Batch   24/44   train_loss = 0.280
Epoch 289 Batch   25/44   train_loss = 0.321
Epoch 289 Batch   26/44   train_loss = 0.317
Epoch 289 Batch   27/44   train_loss = 0.316
Epoch 289 Batch   28/44   train_loss = 0.291
Epoch 289 Batch   29/44   train_loss = 0.295
Epoch 289 Batch   30/44   train_loss = 0.297
Epoch 289 Batch   31/44   train_loss = 0.303
Epoch 289 Batch   32/44   train_loss = 0.277
Epoch 289 Batch   33/44   train_loss = 0.327
Epoch 289 Batch   34/44   train_loss = 0.317
Epoch 289 Batch   35/44   train_loss = 0.293
Epoch 289 Batch   36/44   train_loss = 0.348
Epoch 289 Batch   37/44   train_loss = 0.310
Epoch 289 Batch   38/44   train_loss = 0.327
Epoch 289 Batch   39/44   train_loss = 0.304
Epoch 289 Batch   40/44   train_loss = 0.288
Epoch 289 Batch   41/44   train_loss = 0.299
Epoch 289 Batch   42/44   train_loss = 0.278
Epoch 289 Batch   43/44   train_loss = 0.284
Epoch 290 Batch    0/44   train_loss = 0.288
Epoch 290 Batch    1/44   train_loss = 0.289
Epoch 290 Batch    2/44   train_loss = 0.314
Epoch 290 Batch    3/44   train_loss = 0.329
Epoch 290 Batch    4/44   train_loss = 0.299
Epoch 290 Batch    5/44   train_loss = 0.308
Epoch 290 Batch    6/44   train_loss = 0.306
Epoch 290 Batch    7/44   train_loss = 0.319
Epoch 290 Batch    8/44   train_loss = 0.317
Epoch 290 Batch    9/44   train_loss = 0.338
Epoch 290 Batch   10/44   train_loss = 0.301
Epoch 290 Batch   11/44   train_loss = 0.335
Epoch 290 Batch   12/44   train_loss = 0.304
Epoch 290 Batch   13/44   train_loss = 0.313
Epoch 290 Batch   14/44   train_loss = 0.305
Epoch 290 Batch   15/44   train_loss = 0.330
Epoch 290 Batch   16/44   train_loss = 0.305
Epoch 290 Batch   17/44   train_loss = 0.323
Epoch 290 Batch   18/44   train_loss = 0.310
Epoch 290 Batch   19/44   train_loss = 0.312
Epoch 290 Batch   20/44   train_loss = 0.302
Epoch 290 Batch   21/44   train_loss = 0.278
Epoch 290 Batch   22/44   train_loss = 0.317
Epoch 290 Batch   23/44   train_loss = 0.297
Epoch 290 Batch   24/44   train_loss = 0.281
Epoch 290 Batch   25/44   train_loss = 0.322
Epoch 290 Batch   26/44   train_loss = 0.316
Epoch 290 Batch   27/44   train_loss = 0.316
Epoch 290 Batch   28/44   train_loss = 0.291
Epoch 290 Batch   29/44   train_loss = 0.299
Epoch 290 Batch   30/44   train_loss = 0.301
Epoch 290 Batch   31/44   train_loss = 0.303
Epoch 290 Batch   32/44   train_loss = 0.275
Epoch 290 Batch   33/44   train_loss = 0.323
Epoch 290 Batch   34/44   train_loss = 0.312
Epoch 290 Batch   35/44   train_loss = 0.285
Epoch 290 Batch   36/44   train_loss = 0.339
Epoch 290 Batch   37/44   train_loss = 0.297
Epoch 290 Batch   38/44   train_loss = 0.317
Epoch 290 Batch   39/44   train_loss = 0.299
Epoch 290 Batch   40/44   train_loss = 0.287
Epoch 290 Batch   41/44   train_loss = 0.306
Epoch 290 Batch   42/44   train_loss = 0.285
Epoch 290 Batch   43/44   train_loss = 0.291
Epoch 291 Batch    0/44   train_loss = 0.299
Epoch 291 Batch    1/44   train_loss = 0.291
Epoch 291 Batch    2/44   train_loss = 0.314
Epoch 291 Batch    3/44   train_loss = 0.325
Epoch 291 Batch    4/44   train_loss = 0.293
Epoch 291 Batch    5/44   train_loss = 0.303
Epoch 291 Batch    6/44   train_loss = 0.298
Epoch 291 Batch    7/44   train_loss = 0.312
Epoch 291 Batch    8/44   train_loss = 0.317
Epoch 291 Batch    9/44   train_loss = 0.338
Epoch 291 Batch   10/44   train_loss = 0.303
Epoch 291 Batch   11/44   train_loss = 0.339
Epoch 291 Batch   12/44   train_loss = 0.312
Epoch 291 Batch   13/44   train_loss = 0.319
Epoch 291 Batch   14/44   train_loss = 0.307
Epoch 291 Batch   15/44   train_loss = 0.335
Epoch 291 Batch   16/44   train_loss = 0.305
Epoch 291 Batch   17/44   train_loss = 0.322
Epoch 291 Batch   18/44   train_loss = 0.310
Epoch 291 Batch   19/44   train_loss = 0.312
Epoch 291 Batch   20/44   train_loss = 0.301
Epoch 291 Batch   21/44   train_loss = 0.275
Epoch 291 Batch   22/44   train_loss = 0.318
Epoch 291 Batch   23/44   train_loss = 0.300
Epoch 291 Batch   24/44   train_loss = 0.283
Epoch 291 Batch   25/44   train_loss = 0.324
Epoch 291 Batch   26/44   train_loss = 0.318
Epoch 291 Batch   27/44   train_loss = 0.322
Epoch 291 Batch   28/44   train_loss = 0.296
Epoch 291 Batch   29/44   train_loss = 0.299
Epoch 291 Batch   30/44   train_loss = 0.301
Epoch 291 Batch   31/44   train_loss = 0.305
Epoch 291 Batch   32/44   train_loss = 0.275
Epoch 291 Batch   33/44   train_loss = 0.324
Epoch 291 Batch   34/44   train_loss = 0.313
Epoch 291 Batch   35/44   train_loss = 0.281
Epoch 291 Batch   36/44   train_loss = 0.335
Epoch 291 Batch   37/44   train_loss = 0.288
Epoch 291 Batch   38/44   train_loss = 0.308
Epoch 291 Batch   39/44   train_loss = 0.289
Epoch 291 Batch   40/44   train_loss = 0.275
Epoch 291 Batch   41/44   train_loss = 0.299
Epoch 291 Batch   42/44   train_loss = 0.279
Epoch 291 Batch   43/44   train_loss = 0.291
Epoch 292 Batch    0/44   train_loss = 0.303
Epoch 292 Batch    1/44   train_loss = 0.300
Epoch 292 Batch    2/44   train_loss = 0.320
Epoch 292 Batch    3/44   train_loss = 0.327
Epoch 292 Batch    4/44   train_loss = 0.292
Epoch 292 Batch    5/44   train_loss = 0.301
Epoch 292 Batch    6/44   train_loss = 0.295
Epoch 292 Batch    7/44   train_loss = 0.308
Epoch 292 Batch    8/44   train_loss = 0.308
Epoch 292 Batch    9/44   train_loss = 0.332
Epoch 292 Batch   10/44   train_loss = 0.298
Epoch 292 Batch   11/44   train_loss = 0.329
Epoch 292 Batch   12/44   train_loss = 0.304
Epoch 292 Batch   13/44   train_loss = 0.315
Epoch 292 Batch   14/44   train_loss = 0.309
Epoch 292 Batch   15/44   train_loss = 0.333
Epoch 292 Batch   16/44   train_loss = 0.306
Epoch 292 Batch   17/44   train_loss = 0.328
Epoch 292 Batch   18/44   train_loss = 0.315
Epoch 292 Batch   19/44   train_loss = 0.316
Epoch 292 Batch   20/44   train_loss = 0.304
Epoch 292 Batch   21/44   train_loss = 0.274
Epoch 292 Batch   22/44   train_loss = 0.320
Epoch 292 Batch   23/44   train_loss = 0.297
Epoch 292 Batch   24/44   train_loss = 0.277
Epoch 292 Batch   25/44   train_loss = 0.321
Epoch 292 Batch   26/44   train_loss = 0.317
Epoch 292 Batch   27/44   train_loss = 0.322
Epoch 292 Batch   28/44   train_loss = 0.299
Epoch 292 Batch   29/44   train_loss = 0.306
Epoch 292 Batch   30/44   train_loss = 0.308
Epoch 292 Batch   31/44   train_loss = 0.312
Epoch 292 Batch   32/44   train_loss = 0.282
Epoch 292 Batch   33/44   train_loss = 0.328
Epoch 292 Batch   34/44   train_loss = 0.316
Epoch 292 Batch   35/44   train_loss = 0.284
Epoch 292 Batch   36/44   train_loss = 0.334
Epoch 292 Batch   37/44   train_loss = 0.287
Epoch 292 Batch   38/44   train_loss = 0.308
Epoch 292 Batch   39/44   train_loss = 0.287
Epoch 292 Batch   40/44   train_loss = 0.271
Epoch 292 Batch   41/44   train_loss = 0.296
Epoch 292 Batch   42/44   train_loss = 0.275
Epoch 292 Batch   43/44   train_loss = 0.286
Epoch 293 Batch    0/44   train_loss = 0.296
Epoch 293 Batch    1/44   train_loss = 0.299
Epoch 293 Batch    2/44   train_loss = 0.318
Epoch 293 Batch    3/44   train_loss = 0.330
Epoch 293 Batch    4/44   train_loss = 0.294
Epoch 293 Batch    5/44   train_loss = 0.305
Epoch 293 Batch    6/44   train_loss = 0.298
Epoch 293 Batch    7/44   train_loss = 0.309
Epoch 293 Batch    8/44   train_loss = 0.308
Epoch 293 Batch    9/44   train_loss = 0.334
Epoch 293 Batch   10/44   train_loss = 0.296
Epoch 293 Batch   11/44   train_loss = 0.329
Epoch 293 Batch   12/44   train_loss = 0.300
Epoch 293 Batch   13/44   train_loss = 0.307
Epoch 293 Batch   14/44   train_loss = 0.302
Epoch 293 Batch   15/44   train_loss = 0.327
Epoch 293 Batch   16/44   train_loss = 0.299
Epoch 293 Batch   17/44   train_loss = 0.323
Epoch 293 Batch   18/44   train_loss = 0.312
Epoch 293 Batch   19/44   train_loss = 0.315
Epoch 293 Batch   20/44   train_loss = 0.302
Epoch 293 Batch   21/44   train_loss = 0.274
Epoch 293 Batch   22/44   train_loss = 0.324
Epoch 293 Batch   23/44   train_loss = 0.302
Epoch 293 Batch   24/44   train_loss = 0.278
Epoch 293 Batch   25/44   train_loss = 0.321
Epoch 293 Batch   26/44   train_loss = 0.317
Epoch 293 Batch   27/44   train_loss = 0.316
Epoch 293 Batch   28/44   train_loss = 0.295
Epoch 293 Batch   29/44   train_loss = 0.300
Epoch 293 Batch   30/44   train_loss = 0.302
Epoch 293 Batch   31/44   train_loss = 0.309
Epoch 293 Batch   32/44   train_loss = 0.283
Epoch 293 Batch   33/44   train_loss = 0.335
Epoch 293 Batch   34/44   train_loss = 0.324
Epoch 293 Batch   35/44   train_loss = 0.298
Epoch 293 Batch   36/44   train_loss = 0.348
Epoch 293 Batch   37/44   train_loss = 0.292
Epoch 293 Batch   38/44   train_loss = 0.312
Epoch 293 Batch   39/44   train_loss = 0.290
Epoch 293 Batch   40/44   train_loss = 0.269
Epoch 293 Batch   41/44   train_loss = 0.291
Epoch 293 Batch   42/44   train_loss = 0.274
Epoch 293 Batch   43/44   train_loss = 0.289
Epoch 294 Batch    0/44   train_loss = 0.296
Epoch 294 Batch    1/44   train_loss = 0.299
Epoch 294 Batch    2/44   train_loss = 0.322
Epoch 294 Batch    3/44   train_loss = 0.333
Epoch 294 Batch    4/44   train_loss = 0.297
Epoch 294 Batch    5/44   train_loss = 0.309
Epoch 294 Batch    6/44   train_loss = 0.299
Epoch 294 Batch    7/44   train_loss = 0.312
Epoch 294 Batch    8/44   train_loss = 0.312
Epoch 294 Batch    9/44   train_loss = 0.339
Epoch 294 Batch   10/44   train_loss = 0.302
Epoch 294 Batch   11/44   train_loss = 0.328
Epoch 294 Batch   12/44   train_loss = 0.302
Epoch 294 Batch   13/44   train_loss = 0.307
Epoch 294 Batch   14/44   train_loss = 0.299
Epoch 294 Batch   15/44   train_loss = 0.327
Epoch 294 Batch   16/44   train_loss = 0.298
Epoch 294 Batch   17/44   train_loss = 0.318
Epoch 294 Batch   18/44   train_loss = 0.307
Epoch 294 Batch   19/44   train_loss = 0.307
Epoch 294 Batch   20/44   train_loss = 0.297
Epoch 294 Batch   21/44   train_loss = 0.273
Epoch 294 Batch   22/44   train_loss = 0.320
Epoch 294 Batch   23/44   train_loss = 0.303
Epoch 294 Batch   24/44   train_loss = 0.279
Epoch 294 Batch   25/44   train_loss = 0.322
Epoch 294 Batch   26/44   train_loss = 0.317
Epoch 294 Batch   27/44   train_loss = 0.317
Epoch 294 Batch   28/44   train_loss = 0.293
Epoch 294 Batch   29/44   train_loss = 0.299
Epoch 294 Batch   30/44   train_loss = 0.298
Epoch 294 Batch   31/44   train_loss = 0.304
Epoch 294 Batch   32/44   train_loss = 0.280
Epoch 294 Batch   33/44   train_loss = 0.328
Epoch 294 Batch   34/44   train_loss = 0.320
Epoch 294 Batch   35/44   train_loss = 0.290
Epoch 294 Batch   36/44   train_loss = 0.341
Epoch 294 Batch   37/44   train_loss = 0.293
Epoch 294 Batch   38/44   train_loss = 0.314
Epoch 294 Batch   39/44   train_loss = 0.297
Epoch 294 Batch   40/44   train_loss = 0.279
Epoch 294 Batch   41/44   train_loss = 0.294
Epoch 294 Batch   42/44   train_loss = 0.270
Epoch 294 Batch   43/44   train_loss = 0.285
Epoch 295 Batch    0/44   train_loss = 0.289
Epoch 295 Batch    1/44   train_loss = 0.289
Epoch 295 Batch    2/44   train_loss = 0.317
Epoch 295 Batch    3/44   train_loss = 0.333
Epoch 295 Batch    4/44   train_loss = 0.306
Epoch 295 Batch    5/44   train_loss = 0.326
Epoch 295 Batch    6/44   train_loss = 0.313
Epoch 295 Batch    7/44   train_loss = 0.318
Epoch 295 Batch    8/44   train_loss = 0.313
Epoch 295 Batch    9/44   train_loss = 0.342
Epoch 295 Batch   10/44   train_loss = 0.303
Epoch 295 Batch   11/44   train_loss = 0.328
Epoch 295 Batch   12/44   train_loss = 0.305
Epoch 295 Batch   13/44   train_loss = 0.310
Epoch 295 Batch   14/44   train_loss = 0.303
Epoch 295 Batch   15/44   train_loss = 0.330
Epoch 295 Batch   16/44   train_loss = 0.303
Epoch 295 Batch   17/44   train_loss = 0.322
Epoch 295 Batch   18/44   train_loss = 0.310
Epoch 295 Batch   19/44   train_loss = 0.312
Epoch 295 Batch   20/44   train_loss = 0.298
Epoch 295 Batch   21/44   train_loss = 0.271
Epoch 295 Batch   22/44   train_loss = 0.317
Epoch 295 Batch   23/44   train_loss = 0.297
Epoch 295 Batch   24/44   train_loss = 0.278
Epoch 295 Batch   25/44   train_loss = 0.320
Epoch 295 Batch   26/44   train_loss = 0.315
Epoch 295 Batch   27/44   train_loss = 0.316
Epoch 295 Batch   28/44   train_loss = 0.293
Epoch 295 Batch   29/44   train_loss = 0.297
Epoch 295 Batch   30/44   train_loss = 0.299
Epoch 295 Batch   31/44   train_loss = 0.304
Epoch 295 Batch   32/44   train_loss = 0.280
Epoch 295 Batch   33/44   train_loss = 0.325
Epoch 295 Batch   34/44   train_loss = 0.314
Epoch 295 Batch   35/44   train_loss = 0.285
Epoch 295 Batch   36/44   train_loss = 0.337
Epoch 295 Batch   37/44   train_loss = 0.285
Epoch 295 Batch   38/44   train_loss = 0.311
Epoch 295 Batch   39/44   train_loss = 0.294
Epoch 295 Batch   40/44   train_loss = 0.275
Epoch 295 Batch   41/44   train_loss = 0.291
Epoch 295 Batch   42/44   train_loss = 0.270
Epoch 295 Batch   43/44   train_loss = 0.287
Epoch 296 Batch    0/44   train_loss = 0.292
Epoch 296 Batch    1/44   train_loss = 0.289
Epoch 296 Batch    2/44   train_loss = 0.311
Epoch 296 Batch    3/44   train_loss = 0.325
Epoch 296 Batch    4/44   train_loss = 0.297
Epoch 296 Batch    5/44   train_loss = 0.310
Epoch 296 Batch    6/44   train_loss = 0.304
Epoch 296 Batch    7/44   train_loss = 0.320
Epoch 296 Batch    8/44   train_loss = 0.320
Epoch 296 Batch    9/44   train_loss = 0.351
Epoch 296 Batch   10/44   train_loss = 0.308
Epoch 296 Batch   11/44   train_loss = 0.334
Epoch 296 Batch   12/44   train_loss = 0.312
Epoch 296 Batch   13/44   train_loss = 0.314
Epoch 296 Batch   14/44   train_loss = 0.299
Epoch 296 Batch   15/44   train_loss = 0.325
Epoch 296 Batch   16/44   train_loss = 0.296
Epoch 296 Batch   17/44   train_loss = 0.319
Epoch 296 Batch   18/44   train_loss = 0.305
Epoch 296 Batch   19/44   train_loss = 0.319
Epoch 296 Batch   20/44   train_loss = 0.303
Epoch 296 Batch   21/44   train_loss = 0.280
Epoch 296 Batch   22/44   train_loss = 0.327
Epoch 296 Batch   23/44   train_loss = 0.310
Epoch 296 Batch   24/44   train_loss = 0.277
Epoch 296 Batch   25/44   train_loss = 0.319
Epoch 296 Batch   26/44   train_loss = 0.313
Epoch 296 Batch   27/44   train_loss = 0.316
Epoch 296 Batch   28/44   train_loss = 0.291
Epoch 296 Batch   29/44   train_loss = 0.299
Epoch 296 Batch   30/44   train_loss = 0.301
Epoch 296 Batch   31/44   train_loss = 0.307
Epoch 296 Batch   32/44   train_loss = 0.284
Epoch 296 Batch   33/44   train_loss = 0.324
Epoch 296 Batch   34/44   train_loss = 0.315
Epoch 296 Batch   35/44   train_loss = 0.281
Epoch 296 Batch   36/44   train_loss = 0.333
Epoch 296 Batch   37/44   train_loss = 0.282
Epoch 296 Batch   38/44   train_loss = 0.307
Epoch 296 Batch   39/44   train_loss = 0.291
Epoch 296 Batch   40/44   train_loss = 0.271
Epoch 296 Batch   41/44   train_loss = 0.288
Epoch 296 Batch   42/44   train_loss = 0.267
Epoch 296 Batch   43/44   train_loss = 0.287
Epoch 297 Batch    0/44   train_loss = 0.289
Epoch 297 Batch    1/44   train_loss = 0.290
Epoch 297 Batch    2/44   train_loss = 0.308
Epoch 297 Batch    3/44   train_loss = 0.319
Epoch 297 Batch    4/44   train_loss = 0.290
Epoch 297 Batch    5/44   train_loss = 0.304
Epoch 297 Batch    6/44   train_loss = 0.296
Epoch 297 Batch    7/44   train_loss = 0.305
Epoch 297 Batch    8/44   train_loss = 0.307
Epoch 297 Batch    9/44   train_loss = 0.340
Epoch 297 Batch   10/44   train_loss = 0.305
Epoch 297 Batch   11/44   train_loss = 0.336
Epoch 297 Batch   12/44   train_loss = 0.319
Epoch 297 Batch   13/44   train_loss = 0.318
Epoch 297 Batch   14/44   train_loss = 0.307
Epoch 297 Batch   15/44   train_loss = 0.331
Epoch 297 Batch   16/44   train_loss = 0.296
Epoch 297 Batch   17/44   train_loss = 0.317
Epoch 297 Batch   18/44   train_loss = 0.301
Epoch 297 Batch   19/44   train_loss = 0.308
Epoch 297 Batch   20/44   train_loss = 0.296
Epoch 297 Batch   21/44   train_loss = 0.272
Epoch 297 Batch   22/44   train_loss = 0.323
Epoch 297 Batch   23/44   train_loss = 0.307
Epoch 297 Batch   24/44   train_loss = 0.285
Epoch 297 Batch   25/44   train_loss = 0.336
Epoch 297 Batch   26/44   train_loss = 0.323
Epoch 297 Batch   27/44   train_loss = 0.324
Epoch 297 Batch   28/44   train_loss = 0.293
Epoch 297 Batch   29/44   train_loss = 0.298
Epoch 297 Batch   30/44   train_loss = 0.300
Epoch 297 Batch   31/44   train_loss = 0.302
Epoch 297 Batch   32/44   train_loss = 0.281
Epoch 297 Batch   33/44   train_loss = 0.325
Epoch 297 Batch   34/44   train_loss = 0.314
Epoch 297 Batch   35/44   train_loss = 0.285
Epoch 297 Batch   36/44   train_loss = 0.337
Epoch 297 Batch   37/44   train_loss = 0.287
Epoch 297 Batch   38/44   train_loss = 0.303
Epoch 297 Batch   39/44   train_loss = 0.290
Epoch 297 Batch   40/44   train_loss = 0.269
Epoch 297 Batch   41/44   train_loss = 0.286
Epoch 297 Batch   42/44   train_loss = 0.267
Epoch 297 Batch   43/44   train_loss = 0.282
Epoch 298 Batch    0/44   train_loss = 0.286
Epoch 298 Batch    1/44   train_loss = 0.287
Epoch 298 Batch    2/44   train_loss = 0.310
Epoch 298 Batch    3/44   train_loss = 0.319
Epoch 298 Batch    4/44   train_loss = 0.288
Epoch 298 Batch    5/44   train_loss = 0.303
Epoch 298 Batch    6/44   train_loss = 0.296
Epoch 298 Batch    7/44   train_loss = 0.301
Epoch 298 Batch    8/44   train_loss = 0.304
Epoch 298 Batch    9/44   train_loss = 0.335
Epoch 298 Batch   10/44   train_loss = 0.299
Epoch 298 Batch   11/44   train_loss = 0.324
Epoch 298 Batch   12/44   train_loss = 0.307
Epoch 298 Batch   13/44   train_loss = 0.311
Epoch 298 Batch   14/44   train_loss = 0.305
Epoch 298 Batch   15/44   train_loss = 0.326
Epoch 298 Batch   16/44   train_loss = 0.299
Epoch 298 Batch   17/44   train_loss = 0.323
Epoch 298 Batch   18/44   train_loss = 0.305
Epoch 298 Batch   19/44   train_loss = 0.311
Epoch 298 Batch   20/44   train_loss = 0.293
Epoch 298 Batch   21/44   train_loss = 0.267
Epoch 298 Batch   22/44   train_loss = 0.308
Epoch 298 Batch   23/44   train_loss = 0.296
Epoch 298 Batch   24/44   train_loss = 0.269
Epoch 298 Batch   25/44   train_loss = 0.319
Epoch 298 Batch   26/44   train_loss = 0.327
Epoch 298 Batch   27/44   train_loss = 0.329
Epoch 298 Batch   28/44   train_loss = 0.301
Epoch 298 Batch   29/44   train_loss = 0.309
Epoch 298 Batch   30/44   train_loss = 0.313
Epoch 298 Batch   31/44   train_loss = 0.310
Epoch 298 Batch   32/44   train_loss = 0.285
Epoch 298 Batch   33/44   train_loss = 0.330
Epoch 298 Batch   34/44   train_loss = 0.310
Epoch 298 Batch   35/44   train_loss = 0.279
Epoch 298 Batch   36/44   train_loss = 0.330
Epoch 298 Batch   37/44   train_loss = 0.285
Epoch 298 Batch   38/44   train_loss = 0.305
Epoch 298 Batch   39/44   train_loss = 0.292
Epoch 298 Batch   40/44   train_loss = 0.275
Epoch 298 Batch   41/44   train_loss = 0.293
Epoch 298 Batch   42/44   train_loss = 0.270
Epoch 298 Batch   43/44   train_loss = 0.280
Epoch 299 Batch    0/44   train_loss = 0.283
Epoch 299 Batch    1/44   train_loss = 0.284
Epoch 299 Batch    2/44   train_loss = 0.299
Epoch 299 Batch    3/44   train_loss = 0.319
Epoch 299 Batch    4/44   train_loss = 0.286
Epoch 299 Batch    5/44   train_loss = 0.301
Epoch 299 Batch    6/44   train_loss = 0.298
Epoch 299 Batch    7/44   train_loss = 0.301
Epoch 299 Batch    8/44   train_loss = 0.303
Epoch 299 Batch    9/44   train_loss = 0.333
Epoch 299 Batch   10/44   train_loss = 0.296
Epoch 299 Batch   11/44   train_loss = 0.324
Epoch 299 Batch   12/44   train_loss = 0.302
Epoch 299 Batch   13/44   train_loss = 0.303
Epoch 299 Batch   14/44   train_loss = 0.299
Epoch 299 Batch   15/44   train_loss = 0.322
Epoch 299 Batch   16/44   train_loss = 0.293
Epoch 299 Batch   17/44   train_loss = 0.316
Epoch 299 Batch   18/44   train_loss = 0.303
Epoch 299 Batch   19/44   train_loss = 0.307
Epoch 299 Batch   20/44   train_loss = 0.294
Epoch 299 Batch   21/44   train_loss = 0.266
Epoch 299 Batch   22/44   train_loss = 0.308
Epoch 299 Batch   23/44   train_loss = 0.294
Epoch 299 Batch   24/44   train_loss = 0.265
Epoch 299 Batch   25/44   train_loss = 0.311
Epoch 299 Batch   26/44   train_loss = 0.316
Epoch 299 Batch   27/44   train_loss = 0.316
Epoch 299 Batch   28/44   train_loss = 0.289
Epoch 299 Batch   29/44   train_loss = 0.297
Epoch 299 Batch   30/44   train_loss = 0.304
Epoch 299 Batch   31/44   train_loss = 0.309
Epoch 299 Batch   32/44   train_loss = 0.296
Epoch 299 Batch   33/44   train_loss = 0.339
Epoch 299 Batch   34/44   train_loss = 0.318
Epoch 299 Batch   35/44   train_loss = 0.288
Epoch 299 Batch   36/44   train_loss = 0.331
Epoch 299 Batch   37/44   train_loss = 0.283
Epoch 299 Batch   38/44   train_loss = 0.301
Epoch 299 Batch   39/44   train_loss = 0.289
Epoch 299 Batch   40/44   train_loss = 0.266
Epoch 299 Batch   41/44   train_loss = 0.287
Epoch 299 Batch   42/44   train_loss = 0.270
Epoch 299 Batch   43/44   train_loss = 0.286
Model Trained and Saved
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="&#20648;&#23384;&#21442;&#25968;">&#20648;&#23384;&#21442;&#25968;<a class="anchor-link" href="#&#20648;&#23384;&#21442;&#25968;">&#182;</a></h2><p>储存 <code>seq_length</code> 和 <code>save_dir</code> 来生成新的电视剧剧本。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[26]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="c1"># Save parameters for checkpoint</span>
<span class="n">helper</span><span class="o">.</span><span class="n">save_params</span><span class="p">((</span><span class="n">seq_length</span><span class="p">,</span> <span class="n">save_dir</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="&#26816;&#26597;&#28857;">&#26816;&#26597;&#28857;<a class="anchor-link" href="#&#26816;&#26597;&#28857;">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[27]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="kn">as</span> <span class="nn">tests</span>

<span class="n">_</span><span class="p">,</span> <span class="n">vocab_to_int</span><span class="p">,</span> <span class="n">int_to_vocab</span><span class="p">,</span> <span class="n">token_dict</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
<span class="n">seq_length</span><span class="p">,</span> <span class="n">load_dir</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_params</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="&#23454;&#29616;&#29983;&#25104;&#20989;&#25968;">&#23454;&#29616;&#29983;&#25104;&#20989;&#25968;<a class="anchor-link" href="#&#23454;&#29616;&#29983;&#25104;&#20989;&#25968;">&#182;</a></h2><h3 id="&#33719;&#21462;-Tensors">&#33719;&#21462; Tensors<a class="anchor-link" href="#&#33719;&#21462;-Tensors">&#182;</a></h3><p>使用 <a href="https://www.tensorflow.org/api_docs/python/tf/Graph#get_tensor_by_name"><code>get_tensor_by_name()</code></a>函数从 <code>loaded_graph</code> 中获取 tensor。  使用下面的名称获取 tensor：</p>
<ul>
<li>"input:0"</li>
<li>"initial_state:0"</li>
<li>"final_state:0"</li>
<li>"probs:0"</li>
</ul>
<p>返回下列元组中的 tensor <code>(InputTensor, InitialStateTensor, FinalStateTensor, ProbsTensor)</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[28]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">def</span> <span class="nf">get_tensors</span><span class="p">(</span><span class="n">loaded_graph</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get input, initial state, final state, and probabilities tensor from &lt;loaded_graph&gt;</span>
<span class="sd">    :param loaded_graph: TensorFlow graph loaded from file</span>
<span class="sd">    :return: Tuple (InputTensor, InitialStateTensor, FinalStateTensor, ProbsTensor)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">input_tensor</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;input:0&#39;</span><span class="p">)</span>
    <span class="n">initialstate_tensor</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;initial_state:0&#39;</span><span class="p">)</span>
    <span class="n">finalstate_tensor</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;final_state:0&#39;</span><span class="p">)</span>
    <span class="n">probs_tensor</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;probs:0&#39;</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">input_tensor</span><span class="p">,</span> <span class="n">initialstate_tensor</span><span class="p">,</span> <span class="n">finalstate_tensor</span><span class="p">,</span> <span class="n">probs_tensor</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_get_tensors</span><span class="p">(</span><span class="n">get_tensors</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="&#36873;&#25321;&#35789;&#27719;">&#36873;&#25321;&#35789;&#27719;<a class="anchor-link" href="#&#36873;&#25321;&#35789;&#27719;">&#182;</a></h3><p>实现 <code>pick_word()</code> 函数来使用 <code>probabilities</code> 选择下一个词汇。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[29]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">def</span> <span class="nf">pick_word</span><span class="p">(</span><span class="n">probabilities</span><span class="p">,</span> <span class="n">int_to_vocab</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Pick the next word in the generated text</span>
<span class="sd">    :param probabilities: Probabilites of the next word</span>
<span class="sd">    :param int_to_vocab: Dictionary of word ids as the keys and words as the values</span>
<span class="sd">    :return: String of the predicted word</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: Implement Function</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">probabilities</span><span class="p">)</span>
    <span class="n">p</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">p</span><span class="p">)[:</span><span class="o">-</span><span class="mi">5</span><span class="p">]]</span><span class="o">=</span><span class="mi">0</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">p</span><span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
    <span class="n">string</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">int_to_vocab</span><span class="o">.</span><span class="n">values</span><span class="p">(),</span><span class="mi">1</span><span class="p">,</span><span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    
    <span class="k">return</span> <span class="n">string</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_pick_word</span><span class="p">(</span><span class="n">pick_word</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="&#29983;&#25104;&#30005;&#35270;&#21095;&#21095;&#26412;">&#29983;&#25104;&#30005;&#35270;&#21095;&#21095;&#26412;<a class="anchor-link" href="#&#29983;&#25104;&#30005;&#35270;&#21095;&#21095;&#26412;">&#182;</a></h2><p>这将为你生成一个电视剧剧本。通过设置 <code>gen_length</code> 来调整你想生成的剧本长度。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[30]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">gen_length</span> <span class="o">=</span> <span class="mi">200</span>
<span class="c1"># homer_simpson, moe_szyslak, or Barney_Gumble</span>
<span class="n">prime_word</span> <span class="o">=</span> <span class="s1">&#39;moe_szyslak&#39;</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">loaded_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">loaded_graph</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="c1"># Load saved model</span>
    <span class="n">loader</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">import_meta_graph</span><span class="p">(</span><span class="n">load_dir</span> <span class="o">+</span> <span class="s1">&#39;.meta&#39;</span><span class="p">)</span>
    <span class="n">loader</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">load_dir</span><span class="p">)</span>

    <span class="c1"># Get Tensors from loaded model</span>
    <span class="n">input_text</span><span class="p">,</span> <span class="n">initial_state</span><span class="p">,</span> <span class="n">final_state</span><span class="p">,</span> <span class="n">probs</span> <span class="o">=</span> <span class="n">get_tensors</span><span class="p">(</span><span class="n">loaded_graph</span><span class="p">)</span>

    <span class="c1"># Sentences generation setup</span>
    <span class="n">gen_sentences</span> <span class="o">=</span> <span class="p">[</span><span class="n">prime_word</span> <span class="o">+</span> <span class="s1">&#39;:&#39;</span><span class="p">]</span>
    <span class="n">prev_state</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">initial_state</span><span class="p">,</span> <span class="p">{</span><span class="n">input_text</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">]])})</span>

    <span class="c1"># Generate sentences</span>
    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">gen_length</span><span class="p">):</span>
        <span class="c1"># Dynamic Input</span>
        <span class="n">dyn_input</span> <span class="o">=</span> <span class="p">[[</span><span class="n">vocab_to_int</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">gen_sentences</span><span class="p">[</span><span class="o">-</span><span class="n">seq_length</span><span class="p">:]]]</span>
        <span class="n">dyn_seq_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dyn_input</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="c1"># Get Prediction</span>
        <span class="n">probabilities</span><span class="p">,</span> <span class="n">prev_state</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
            <span class="p">[</span><span class="n">probs</span><span class="p">,</span> <span class="n">final_state</span><span class="p">],</span>
            <span class="p">{</span><span class="n">input_text</span><span class="p">:</span> <span class="n">dyn_input</span><span class="p">,</span> <span class="n">initial_state</span><span class="p">:</span> <span class="n">prev_state</span><span class="p">})</span>
        
        <span class="n">pred_word</span> <span class="o">=</span> <span class="n">pick_word</span><span class="p">(</span><span class="n">probabilities</span><span class="p">[</span><span class="n">dyn_seq_length</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">int_to_vocab</span><span class="p">)</span>

        <span class="n">gen_sentences</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred_word</span><span class="p">)</span>
    
    <span class="c1"># Remove tokens</span>
    <span class="n">tv_script</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">gen_sentences</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">token_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">ending</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span> <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39;(&#39;</span><span class="p">,</span> <span class="s1">&#39;&quot;&#39;</span><span class="p">]</span> <span class="k">else</span> <span class="s1">&#39;&#39;</span>
        <span class="n">tv_script</span> <span class="o">=</span> <span class="n">tv_script</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39; &#39;</span> <span class="o">+</span> <span class="n">token</span><span class="o">.</span><span class="n">lower</span><span class="p">(),</span> <span class="n">key</span><span class="p">)</span>
    <span class="n">tv_script</span> <span class="o">=</span> <span class="n">tv_script</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1"> &#39;</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">tv_script</span> <span class="o">=</span> <span class="n">tv_script</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;( &#39;</span><span class="p">,</span> <span class="s1">&#39;(&#39;</span><span class="p">)</span>
        
    <span class="k">print</span><span class="p">(</span><span class="n">tv_script</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>moe_szyslak: oh.
moe_szyslak: what&#39;s the matter, homer? the depressin&#39; hands of ireland!
moe_szyslak:(into phone) listen to this tape!
moe_szyslak:(big knowing) hey, homer.
homer_simpson: moe, see you get a free time? uh, moe.
moe_szyslak:(sigh) yeah, but a lot laugh is... that i got so good in the wrong...
lisa_simpson:(singing) oh, that&#39;s a terrible job, but your favorite ones / get me!
duffman:(laughs) hey, that&#39;s a little hand.
moe_szyslak:(laughs) you dropped that.
moe_szyslak:(singing, then) i was&#34; hot moe is with a thing.&#34;
lenny_leonard: hey, moe, you really smell her like a good day.
homer_simpson: uh, sure, you didn&#39;t even get this way to kill.
moe_szyslak: hey, hey, no. i&#39;m gonna help you, and it&#39;s just us to...
moe_szyslak:(defensive) no, wait... counting
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="&#36825;&#20010;&#30005;&#35270;&#21095;&#21095;&#26412;&#26159;&#26080;&#24847;&#20041;&#30340;">&#36825;&#20010;&#30005;&#35270;&#21095;&#21095;&#26412;&#26159;&#26080;&#24847;&#20041;&#30340;<a class="anchor-link" href="#&#36825;&#20010;&#30005;&#35270;&#21095;&#21095;&#26412;&#26159;&#26080;&#24847;&#20041;&#30340;">&#182;</a></h1><p>如果这个电视剧剧本毫无意义，那也没有关系。我们的训练文本不到一兆字节。为了获得更好的结果，你需要使用更小的词汇范围或是更多数据。幸运的是，我们的确拥有更多数据！在本项目开始之初我们也曾提过，这是<a href="https://www.kaggle.com/wcukierski/the-simpsons-by-the-data">另一个数据集</a>的子集。我们并没有让你基于所有数据进行训练，因为这将耗费大量时间。然而，你可以随意使用这些数据训练你的神经网络。当然，是在完成本项目之后。</p>
<h1 id="&#25552;&#20132;&#39033;&#30446;">&#25552;&#20132;&#39033;&#30446;<a class="anchor-link" href="#&#25552;&#20132;&#39033;&#30446;">&#182;</a></h1><p>在提交项目时，请确保你在保存 notebook 前运行了所有的单元格代码。请将 notebook 文件保存为 "dlnd_tv_script_generation.ipynb"，并将它作为 HTML 文件保存在 "File" -&gt; "Download as" 中。请将 "helper.py" 和 "problem_unittests.py" 文件一并提交。</p>

</div>
</div>
</div>
    </div>
  </div>
</body>

 


</html>
